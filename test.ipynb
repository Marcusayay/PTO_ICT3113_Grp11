{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43764203",
   "metadata": {},
   "source": [
    "### Hello Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Install the marker library\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# # 2. Import necessary components\n",
    "# from marker.converters.pdf import PdfConverter\n",
    "# from marker.models import create_model_dict\n",
    "# from marker.output import text_from_rendered\n",
    "# from pathlib import Path\n",
    "\n",
    "# # 3. Define the path to your uploaded PDF\n",
    "# pdf_path = Path(\"/content/2Q25_CFO_presentation.pdf\")\n",
    "\n",
    "# # 4. (NEW) Automatically create the folder structure based on the PDF name\n",
    "# # This creates a main folder like \"/content/2Q25_CFO_presentation/\"\n",
    "# main_output_folder = Path(pdf_path.stem)\n",
    "# # This creates a subfolder like \"/content/2Q25_CFO_presentation/images/\"\n",
    "# image_subfolder = main_output_folder / \"images\"\n",
    "\n",
    "# main_output_folder.mkdir(exist_ok=True)\n",
    "# image_subfolder.mkdir(exist_ok=True)\n",
    "\n",
    "# # 5. Set up and run the converter\n",
    "# try:\n",
    "#     converter = PdfConverter(\n",
    "#         artifact_dict=create_model_dict(),\n",
    "#     )\n",
    "\n",
    "#     print(\"Converting PDF... (This may take a moment)\")\n",
    "#     rendered = converter(str(pdf_path)) # Convert path object to string for the converter\n",
    "#     text, _, images = text_from_rendered(rendered)\n",
    "\n",
    "#     # 6. (UPDATED) Save the markdown file inside the main folder\n",
    "#     output_md_path = main_output_folder / \"output.md\"\n",
    "#     with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(rendered.markdown)\n",
    "#     print(f\"\\nMarkdown content saved to '{output_md_path}'\")\n",
    "\n",
    "#     # 7. (UPDATED) Save images into the new subfolder\n",
    "#     print(f\"Found {len(images)} images. Saving them into '{image_subfolder}'...\")\n",
    "#     for img_filename, img_object in images.items():\n",
    "#         # Prepend the subfolder path to the filename\n",
    "#         save_path = image_subfolder / img_filename\n",
    "#         img_object.save(save_path, format=\"PNG\")\n",
    "#     print(\"✅ All images have been saved successfully!\")\n",
    "\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"❌ ERROR: The file was not found at '{pdf_path}'.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7981676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 03:26:24,430 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting '2Q25_CFO_presentation.pdf'... (This may take a moment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Layout: 100%|██████████| 29/29 [02:31<00:00,  5.23s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:01<00:00,  7.66it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n",
      "Recognizing Text: 100%|██████████| 4/4 [00:19<00:00,  4.87s/it]\n",
      "Recognizing tables: 100%|██████████| 4/4 [00:13<00:00,  3.42s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "Recognizing Text: 100%|██████████| 60/60 [00:24<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ JSON metadata saved to '2Q25_CFO_presentation/output.json'\n",
      "Found 38 images. Saving them into '2Q25_CFO_presentation/images'...\n",
      "✅ All images have been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import json\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "from pathlib import Path\n",
    "\n",
    "# 3. Define the path to your uploaded PDF\n",
    "# Make sure to upload your PDF file to the environment if you are using a cloud notebook.\n",
    "# For example, in Google Colab, upload it to the \"/content/\" directory.\n",
    "pdf_path = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation.pdf\")\n",
    "\n",
    "# Check if the PDF file exists before proceeding\n",
    "if not pdf_path.exists():\n",
    "    print(f\"❌ ERROR: The file was not found at '{pdf_path}'.\")\n",
    "    print(\"Please make sure you have uploaded the PDF file to the correct path.\")\n",
    "else:\n",
    "    # 4. Automatically create the folder structure based on the PDF name\n",
    "    # This creates a main folder like \"/content/2Q25_CFO_presentation/\"\n",
    "    main_output_folder = Path(pdf_path.stem)\n",
    "    # This creates a subfolder like \"/content/2Q25_CFO_presentation/images/\"\n",
    "    image_subfolder = main_output_folder / \"images\"\n",
    "\n",
    "    main_output_folder.mkdir(exist_ok=True)\n",
    "    image_subfolder.mkdir(exist_ok=True)\n",
    "\n",
    "    # 5. Set up and run the converter\n",
    "    try:\n",
    "        converter = PdfConverter(\n",
    "            artifact_dict=create_model_dict(),\n",
    "        )\n",
    "\n",
    "        print(f\"Converting '{pdf_path.name}'... (This may take a moment)\")\n",
    "        rendered = converter(str(pdf_path)) # Convert path object to string for the converter\n",
    "\n",
    "        # The second return value from text_from_rendered is the structured metadata\n",
    "        text, doc_metadata, images = text_from_rendered(rendered)\n",
    "\n",
    "        # 6. (UPDATED) Save the metadata as a JSON file inside the main folder\n",
    "        output_json_path = main_output_folder / \"output.json\"\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            # Use indent=4 for a human-readable, pretty-printed JSON file\n",
    "            json.dump(doc_metadata, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"\\n✅ JSON metadata saved to '{output_json_path}'\")\n",
    "\n",
    "        # 7. (UPDATED) Save images into the new subfolder\n",
    "        if images:\n",
    "            print(f\"Found {len(images)} images. Saving them into '{image_subfolder}'...\")\n",
    "            for img_filename, img_object in images.items():\n",
    "                # Prepend the subfolder path to the filename\n",
    "                save_path = image_subfolder / img_filename\n",
    "                img_object.save(save_path, format=\"PNG\")\n",
    "            print(\"✅ All images have been saved successfully!\")\n",
    "        else:\n",
    "            print(\"No images found in the document.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f453010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for JSON output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:12:41,595 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 30/30 [02:32<00:00,  5.07s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 19.81it/s]\n",
      "Detecting bboxes: 100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n",
      "Recognizing Text: 100%|██████████| 12/12 [00:58<00:00,  4.87s/it]\n",
      "Recognizing tables: 100%|██████████| 2/2 [00:09<00:00,  4.82s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Recognizing Text: 100%|██████████| 44/44 [00:17<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON metadata saved to '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/output.json'\n",
      "\n",
      "Processing for Markdown and Image output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:16:48,867 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 30/30 [02:28<00:00,  4.95s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 10.82it/s]\n",
      "Detecting bboxes: 100%|██████████| 2/2 [00:01<00:00,  1.49it/s]\n",
      "Recognizing Text: 100%|██████████| 12/12 [00:59<00:00,  4.95s/it]\n",
      "Recognizing tables: 100%|██████████| 2/2 [00:09<00:00,  4.89s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "Recognizing Text: 100%|██████████| 44/44 [00:17<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown content saved to '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/output.md'\n",
      "\n",
      "Found 44 images. Saving them into '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/images'...\n",
      "✅ All images have been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import json\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "from pathlib import Path\n",
    "from PIL.Image import Image as PILImage # Import the Image class to identify it\n",
    "\n",
    "# 3. Define the path to your uploaded PDF\n",
    "pdf_path = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation.pdf\")\n",
    "\n",
    "# Check if the PDF file exists before proceeding\n",
    "if not pdf_path.exists():\n",
    "    print(f\"❌ ERROR: The file was not found at '{pdf_path}'.\")\n",
    "    print(\"Please make sure you have uploaded the PDF file to the correct path.\")\n",
    "else:\n",
    "    # 4. Set up output folders\n",
    "    main_output_folder = pdf_path.parent / pdf_path.stem\n",
    "    image_subfolder = main_output_folder / \"images\"\n",
    "    main_output_folder.mkdir(exist_ok=True)\n",
    "    image_subfolder.mkdir(exist_ok=True)\n",
    "\n",
    "    def custom_serializer(obj):\n",
    "        \"\"\"Custom JSON serializer to handle non-serializable objects like PIL Images.\"\"\"\n",
    "        if isinstance(obj, PILImage):\n",
    "            # Replace the unserializable Image object with a descriptive string placeholder\n",
    "            return f\"[Image object: format={getattr(obj, 'format', 'N/A')}, size={getattr(obj, 'size', 'N/A')}]\"\n",
    "        # For any other object it doesn't know, raise the default error\n",
    "        raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Process for JSON output\n",
    "        # ======================================================================\n",
    "        print(\"Processing for JSON output...\")\n",
    "        # We only need to specify the output format.\n",
    "        # The custom_serializer will handle the image objects.\n",
    "        json_config = {\n",
    "            \"output_format\": \"json\",\n",
    "        }\n",
    "\n",
    "        json_converter = PdfConverter(\n",
    "            config=json_config,\n",
    "            artifact_dict=create_model_dict(),\n",
    "        )\n",
    "\n",
    "        # The rendered object will be a pydantic model for JSON\n",
    "        rendered_json = json_converter(str(pdf_path))\n",
    "        \n",
    "        # Convert the pydantic model to a standard python dictionary to save\n",
    "        output_data = rendered_json.model_dump()\n",
    "\n",
    "        output_json_path = main_output_folder / \"output.json\"\n",
    "        with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            # Pass the custom serializer to the json.dump function\n",
    "            json.dump(output_data, f, indent=4, ensure_ascii=False, default=custom_serializer)\n",
    "        print(f\"✅ JSON metadata saved to '{output_json_path}'\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Process for Markdown and Image output\n",
    "        # ======================================================================\n",
    "        print(\"\\nProcessing for Markdown and Image output...\")\n",
    "        # Use a default converter for the standard markdown output\n",
    "        md_converter = PdfConverter(\n",
    "            artifact_dict=create_model_dict(),\n",
    "        )\n",
    "        rendered_md = md_converter(str(pdf_path))\n",
    "\n",
    "        # Save the markdown content\n",
    "        output_md_path = main_output_folder / \"output.md\"\n",
    "        with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(rendered_md.markdown)\n",
    "        print(f\"✅ Markdown content saved to '{output_md_path}'\")\n",
    "\n",
    "        # Extract and save images from the markdown-rendered object\n",
    "        _, _, images = text_from_rendered(rendered_md)\n",
    "        if images:\n",
    "            print(f\"\\nFound {len(images)} images. Saving them into '{image_subfolder}'...\")\n",
    "            for img_filename, img_object in images.items():\n",
    "                save_path = image_subfolder / img_filename\n",
    "                img_object.save(save_path, format=\"PNG\")\n",
    "            print(\"✅ All images have been saved successfully!\")\n",
    "        else:\n",
    "            print(\"\\nNo images found in the document.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b78dca",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3425ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CLI command for JSON output...\n",
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "\n",
      "Running CLI command for Markdown and Image output...\n",
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "\n",
      "✨ All files have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# 3. Define the path to your uploaded PDF\n",
    "pdf_path = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation.pdf\")\n",
    "\n",
    "# Check if the PDF file exists before proceeding\n",
    "if not pdf_path.exists():\n",
    "    print(f\"❌ ERROR: The file was not found at '{pdf_path}'.\")\n",
    "    print(\"Please make sure you have uploaded the PDF file to the correct path.\")\n",
    "    sys.exit(1) # Exit the script if the file doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 5. Automatically create the folder structure based on the PDF name\n",
    "main_output_folder = pdf_path.parent / pdf_path.stem\n",
    "# The CLI will create its own images folder, so we just need the main one.\n",
    "main_output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # ======================================================================\n",
    "    # 1. Run the CLI command to generate JSON output\n",
    "    # ======================================================================\n",
    "    print(\"Running CLI command for JSON output...\")\n",
    "    json_command = [\n",
    "        \"marker_single\",\n",
    "        str(pdf_path),\n",
    "        \"--output_format\", \"json\",\n",
    "        \"--output_dir\", str(main_output_folder)\n",
    "    ]\n",
    "    # The 'capture_output=True' and 'text=True' arguments help in debugging if needed\n",
    "    result_json = subprocess.run(json_command, check=True, capture_output=True, text=True)\n",
    "    print(\"✅ JSON file generated successfully by CLI.\")\n",
    "    # Print stdout from the command to see progress\n",
    "    print(result_json.stdout)\n",
    "\n",
    "\n",
    "    # ======================================================================\n",
    "    # 2. Run the CLI command to generate Markdown and Image output\n",
    "    # ======================================================================\n",
    "    print(\"\\nRunning CLI command for Markdown and Image output...\")\n",
    "    md_command = [\n",
    "        \"marker_single\",\n",
    "        str(pdf_path),\n",
    "        # Default format is markdown, so we don't need to specify it\n",
    "        \"--output_dir\", str(main_output_folder)\n",
    "    ]\n",
    "    result_md = subprocess.run(md_command, check=True, capture_output=True, text=True)\n",
    "    print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "    print(result_md.stdout)\n",
    "\n",
    "    print(f\"\\n✨ All files have been saved in the '{main_output_folder}' directory.\")\n",
    "    print(\"Note: The files will have names based on the original PDF.\")\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"\\n❌ An error occurred while executing the CLI command.\")\n",
    "    print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "    print(f\"Return Code: {e.returncode}\")\n",
    "    print(\"\\n--- STDOUT ---\")\n",
    "    print(e.stdout)\n",
    "    print(\"\\n--- STDERR ---\")\n",
    "    print(e.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0214463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: 2Q24_performance_summary.pdf ---\n",
      "Running CLI command for JSON output on 2Q24_performance_summary.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:35:36,686 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 34/34 [02:46<00:00,  4.90s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 9/9 [00:00<00:00, 10.46it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "Recognizing Text: 100%|██████████| 10/10 [01:28<00:00,  8.87s/it]\n",
      "Recognizing tables: 100%|██████████| 6/6 [00:31<00:00,  5.31s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 04:40:37,940 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary/2Q24_performance_summary\n",
      "2025-10-14 04:40:37,940 [INFO] marker: Total time: 300.4548120498657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q24_performance_summary.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:40:45,582 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 34/34 [02:43<00:00,  4.82s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 9/9 [00:00<00:00, 12.12it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "Recognizing Text: 100%|██████████| 10/10 [01:28<00:00,  8.89s/it]\n",
      "Recognizing tables: 100%|██████████| 6/6 [00:31<00:00,  5.31s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 04:45:42,333 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary/2Q24_performance_summary\n",
      "2025-10-14 04:45:42,333 [INFO] marker: Total time: 296.0889530181885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q24_performance_summary.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q24_performance_summary.pdf ---\n",
      "\n",
      "--- Processing file: 3Q24_CEO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 3Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:45:49,993 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 4/4 [00:20<00:00,  5.07s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 04:46:11,397 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation/3Q24_CEO_presentation\n",
      "2025-10-14 04:46:11,397 [INFO] marker: Total time: 20.737711191177368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 3Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:46:18,165 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 4/4 [00:19<00:00,  5.00s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 04:46:39,091 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation/3Q24_CEO_presentation\n",
      "2025-10-14 04:46:39,091 [INFO] marker: Total time: 20.36851406097412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 3Q24_CEO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 3Q24_CEO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 4Q24_CFO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 4Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:46:45,726 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 30/30 [02:21<00:00,  4.73s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 19.60it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "Recognizing Text: 100%|██████████| 6/6 [00:22<00:00,  3.78s/it]\n",
      "Recognizing tables: 100%|██████████| 3/3 [00:10<00:00,  3.60s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "2025-10-14 04:49:52,733 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/4Q24_CFO_presentation\n",
      "2025-10-14 04:49:52,733 [INFO] marker: Total time: 186.4445309638977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 4Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:50:00,214 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 30/30 [02:21<00:00,  4.72s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 20.33it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Recognizing Text: 100%|██████████| 6/6 [00:22<00:00,  3.67s/it]\n",
      "Recognizing tables: 100%|██████████| 3/3 [00:11<00:00,  3.72s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n",
      "2025-10-14 04:53:06,868 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/4Q24_CFO_presentation\n",
      "2025-10-14 04:53:06,868 [INFO] marker: Total time: 185.98559284210205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 4Q24_CFO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 4Q24_CFO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 4Q24_performance_summary.pdf ---\n",
      "Running CLI command for JSON output on 4Q24_performance_summary.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:53:14,386 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 45/45 [03:35<00:00,  4.80s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 12/12 [00:01<00:00, 11.49it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 7/7 [00:37<00:00,  5.36s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 04:57:41,501 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary/4Q24_performance_summary\n",
      "2025-10-14 04:57:41,501 [INFO] marker: Total time: 266.4516339302063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 4Q24_performance_summary.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 04:57:49,413 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 45/45 [03:35<00:00,  4.79s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 12/12 [00:00<00:00, 12.48it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 7/7 [00:38<00:00,  5.44s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:02:17,076 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary/4Q24_performance_summary\n",
      "2025-10-14 05:02:17,076 [INFO] marker: Total time: 267.0025990009308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 4Q24_performance_summary.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 4Q24_performance_summary.pdf ---\n",
      "\n",
      "--- Processing file: 4Q24_CEO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 4Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:02:25,030 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:29<00:00,  4.85s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00,  4.90it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:02:55,569 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation/4Q24_CEO_presentation\n",
      "2025-10-14 05:02:55,569 [INFO] marker: Total time: 29.88025712966919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 4Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:03:02,167 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:29<00:00,  4.87s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 23.10it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:03:32,437 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation/4Q24_CEO_presentation\n",
      "2025-10-14 05:03:32,437 [INFO] marker: Total time: 29.720725059509277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 4Q24_CEO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 4Q24_CEO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 3Q24_trading_update.pdf ---\n",
      "Running CLI command for JSON output on 3Q24_trading_update.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:03:39,100 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 7/7 [00:34<00:00,  4.97s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00,  5.40it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:04:18,414 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update/3Q24_trading_update\n",
      "2025-10-14 05:04:18,414 [INFO] marker: Total time: 38.744577169418335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 3Q24_trading_update.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:04:25,490 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 7/7 [00:34<00:00,  4.98s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 10.60it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:05:04,673 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update/3Q24_trading_update\n",
      "2025-10-14 05:05:04,673 [INFO] marker: Total time: 38.63216805458069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 3Q24_trading_update.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 3Q24_trading_update.pdf ---\n",
      "\n",
      "--- Processing file: 3Q24_CFO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 3Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:05:11,890 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 21/21 [01:38<00:00,  4.71s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 6/6 [00:00<00:00, 10.23it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Recognizing Text: 100%|██████████| 13/13 [00:24<00:00,  1.91s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Recognizing Text: 100%|██████████| 42/42 [00:08<00:00,  5.05it/s]\n",
      "2025-10-14 05:07:35,561 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/3Q24_CFO_presentation\n",
      "2025-10-14 05:07:35,561 [INFO] marker: Total time: 143.1232190132141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 3Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:07:42,498 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 21/21 [01:39<00:00,  4.72s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 6/6 [00:00<00:00, 20.88it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Recognizing Text: 100%|██████████| 13/13 [00:24<00:00,  1.89s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Recognizing Text: 100%|██████████| 42/42 [00:07<00:00,  5.28it/s]\n",
      "2025-10-14 05:10:05,592 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/3Q24_CFO_presentation\n",
      "2025-10-14 05:10:05,592 [INFO] marker: Total time: 142.55411195755005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 3Q24_CFO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 3Q24_CFO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 1Q24_trading_update.pdf ---\n",
      "Running CLI command for JSON output on 1Q24_trading_update.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:10:13,522 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:30<00:00,  5.01s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 11.23it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:10:47,628 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update/1Q24_trading_update\n",
      "2025-10-14 05:10:47,628 [INFO] marker: Total time: 33.436007022857666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 1Q24_trading_update.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:10:54,362 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:29<00:00,  4.96s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 11.82it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:11:28,311 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update/1Q24_trading_update\n",
      "2025-10-14 05:11:28,311 [INFO] marker: Total time: 33.350996017456055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 1Q24_trading_update.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 1Q24_trading_update.pdf ---\n",
      "\n",
      "--- Processing file: 2Q25_CFO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 2Q25_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:11:34,852 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 29/29 [02:18<00:00,  4.76s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 15.43it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Recognizing Text: 100%|██████████| 4/4 [00:15<00:00,  3.97s/it]\n",
      "Recognizing tables: 100%|██████████| 4/4 [00:13<00:00,  3.36s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Recognizing Text: 100%|██████████| 60/60 [00:21<00:00,  2.80it/s]\n",
      "2025-10-14 05:14:53,649 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/2Q25_CFO_presentation\n",
      "2025-10-14 05:14:53,649 [INFO] marker: Total time: 198.24586987495422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q25_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:15:01,146 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 29/29 [02:17<00:00,  4.75s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 21.84it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Recognizing Text: 100%|██████████| 4/4 [00:15<00:00,  3.86s/it]\n",
      "Recognizing tables: 100%|██████████| 4/4 [00:13<00:00,  3.36s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "Recognizing Text: 100%|██████████| 60/60 [00:20<00:00,  2.90it/s]\n",
      "2025-10-14 05:18:18,305 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/2Q25_CFO_presentation\n",
      "2025-10-14 05:18:18,305 [INFO] marker: Total time: 196.49770402908325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q25_CFO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q25_CFO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 4Q24_press_statement.pdf ---\n",
      "Running CLI command for JSON output on 4Q24_press_statement.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:18:25,917 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 8/8 [00:41<00:00,  5.15s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 10.23it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:19:08,797 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement/4Q24_press_statement\n",
      "2025-10-14 05:19:08,797 [INFO] marker: Total time: 42.21142911911011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 4Q24_press_statement.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:19:15,689 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 8/8 [00:40<00:00,  5.12s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00,  9.98it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:19:58,063 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement/4Q24_press_statement\n",
      "2025-10-14 05:19:58,063 [INFO] marker: Total time: 41.82271409034729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 4Q24_press_statement.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 4Q24_press_statement.pdf ---\n",
      "\n",
      "--- Processing file: 1Q25_CEO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 1Q25_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:20:05,018 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:29<00:00,  4.89s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 11.28it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:20:35,501 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation/1Q25_CEO_presentation\n",
      "2025-10-14 05:20:35,502 [INFO] marker: Total time: 29.932474851608276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 1Q25_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:20:42,092 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:29<00:00,  4.89s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 26.59it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:21:12,529 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation/1Q25_CEO_presentation\n",
      "2025-10-14 05:21:12,529 [INFO] marker: Total time: 29.852996110916138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 1Q25_CEO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 1Q25_CEO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 1Q25_trading_update.pdf ---\n",
      "Running CLI command for JSON output on 1Q25_trading_update.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:21:18,952 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 7/7 [00:34<00:00,  4.93s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 10.15it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:21:57,199 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update/1Q25_trading_update\n",
      "2025-10-14 05:21:57,199 [INFO] marker: Total time: 37.68496298789978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 1Q25_trading_update.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:22:04,370 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 7/7 [00:34<00:00,  4.94s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 10.52it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 05:22:42,499 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update/1Q25_trading_update\n",
      "2025-10-14 05:22:42,499 [INFO] marker: Total time: 37.57768511772156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 1Q25_trading_update.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 1Q25_trading_update.pdf ---\n",
      "\n",
      "--- Processing file: dbs-annual-report-2024.pdf ---\n",
      "Running CLI command for JSON output on dbs-annual-report-2024.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 05:22:49,701 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 111/111 [12:46<00:00,  6.90s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 28/28 [00:02<00:00, 11.98it/s]\n",
      "Detecting bboxes: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "Recognizing Text: 100%|██████████| 863/863 [19:34<00:00,  1.36s/it] \n",
      "Recognizing tables: 100%|██████████| 26/26 [02:03<00:00,  4.77s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Recognizing Text: 100%|██████████| 230/230 [01:52<00:00,  2.04it/s]\n",
      "2025-10-14 06:00:02,050 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024/dbs-annual-report-2024\n",
      "2025-10-14 06:00:02,051 [INFO] marker: Total time: 2231.8023879528046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on dbs-annual-report-2024.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 06:00:09,935 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 111/111 [12:44<00:00,  6.89s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 28/28 [00:02<00:00, 11.89it/s]\n",
      "Detecting bboxes: 100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
      "Recognizing Text: 100%|██████████| 863/863 [19:35<00:00,  1.36s/it] \n",
      "Recognizing tables: 100%|██████████| 26/26 [02:03<00:00,  4.76s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Recognizing Text: 100%|██████████| 230/230 [01:50<00:00,  2.08it/s]\n",
      "2025-10-14 06:37:20,071 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024/dbs-annual-report-2024\n",
      "2025-10-14 06:37:20,072 [INFO] marker: Total time: 2229.460083961487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for dbs-annual-report-2024.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: dbs-annual-report-2024.pdf ---\n",
      "\n",
      "--- Processing file: 1Q24_CFO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 1Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 06:37:28,234 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 17/17 [01:19<00:00,  4.67s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 5/5 [00:00<00:00, 22.28it/s]\n",
      "Detecting bboxes: 100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n",
      "Recognizing Text: 100%|██████████| 15/15 [00:47<00:00,  3.17s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 06:39:40,481 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/1Q24_CFO_presentation\n",
      "2025-10-14 06:39:40,481 [INFO] marker: Total time: 131.58736491203308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 1Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 06:39:48,054 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 17/17 [01:20<00:00,  4.71s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 5/5 [00:00<00:00, 19.95it/s]\n",
      "Detecting bboxes: 100%|██████████| 2/2 [00:01<00:00,  1.67it/s]\n",
      "Recognizing Text: 100%|██████████| 15/15 [00:47<00:00,  3.18s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 06:42:01,071 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/1Q24_CFO_presentation\n",
      "2025-10-14 06:42:01,071 [INFO] marker: Total time: 132.39466285705566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 1Q24_CFO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 1Q24_CFO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: dbs-annual-report-2023.pdf ---\n",
      "Running CLI command for JSON output on dbs-annual-report-2023.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 06:42:08,499 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 115/115 [12:57<00:00,  6.76s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 29/29 [00:02<00:00, 12.05it/s]\n",
      "Detecting bboxes: 100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n",
      "Recognizing Text: 100%|██████████| 2068/2068 [57:10<00:00,  1.66s/it] \n",
      "Recognizing tables: 100%|██████████| 27/27 [01:59<00:00,  4.44s/it]\n",
      "Detecting bboxes: 100%|██████████| 8/8 [00:07<00:00,  1.03it/s]\n",
      "Recognizing Text: 100%|██████████| 894/894 [22:34<00:00,  1.51s/it] \n",
      "2025-10-14 08:18:04,221 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023/dbs-annual-report-2023\n",
      "2025-10-14 08:18:04,221 [INFO] marker: Total time: 5755.154972076416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on dbs-annual-report-2023.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 08:18:12,348 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 115/115 [12:51<00:00,  6.71s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 29/29 [00:02<00:00, 12.04it/s]\n",
      "Detecting bboxes: 100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n",
      "Recognizing Text: 100%|██████████| 2068/2068 [57:11<00:00,  1.66s/it] \n",
      "Recognizing tables: 100%|██████████| 27/27 [01:57<00:00,  4.36s/it]\n",
      "Detecting bboxes: 100%|██████████| 8/8 [00:07<00:00,  1.02it/s]\n",
      "Recognizing Text: 100%|██████████| 894/894 [22:28<00:00,  1.51s/it] \n",
      "2025-10-14 09:53:55,064 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023/dbs-annual-report-2023\n",
      "2025-10-14 09:53:55,064 [INFO] marker: Total time: 5742.058867931366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for dbs-annual-report-2023.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: dbs-annual-report-2023.pdf ---\n",
      "\n",
      "--- Processing file: 2Q24_CEO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 2Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 09:54:03,470 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 4/4 [00:19<00:00,  4.93s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 09:54:24,173 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation/2Q24_CEO_presentation\n",
      "2025-10-14 09:54:24,173 [INFO] marker: Total time: 20.045726776123047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 09:54:30,057 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 4/4 [00:19<00:00,  4.94s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 17.52it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 09:54:50,673 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation/2Q24_CEO_presentation\n",
      "2025-10-14 09:54:50,673 [INFO] marker: Total time: 20.069514989852905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q24_CEO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q24_CEO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 2Q25_performance_summary.pdf ---\n",
      "Running CLI command for JSON output on 2Q25_performance_summary.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 09:54:56,533 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 35/35 [02:48<00:00,  4.80s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 9/9 [00:00<00:00, 11.81it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\n",
      "Recognizing Text: 100%|██████████| 8/8 [01:16<00:00,  9.60s/it]\n",
      "Recognizing tables: 100%|██████████| 6/6 [00:31<00:00,  5.27s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 09:59:45,105 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary/2Q25_performance_summary\n",
      "2025-10-14 09:59:45,105 [INFO] marker: Total time: 288.0213711261749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q25_performance_summary.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 09:59:52,726 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 35/35 [02:47<00:00,  4.79s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 9/9 [00:00<00:00, 11.87it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n",
      "Recognizing Text: 100%|██████████| 8/8 [01:16<00:00,  9.58s/it]\n",
      "Recognizing tables: 100%|██████████| 6/6 [00:31<00:00,  5.29s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 10:04:40,720 [INFO] marker: Overflow in columns: 5 >= 5 or rows: 1 >= 8\n",
      "2025-10-14 10:04:40,885 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary/2Q25_performance_summary\n",
      "2025-10-14 10:04:40,885 [INFO] marker: Total time: 287.4945089817047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q25_performance_summary.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q25_performance_summary.pdf ---\n",
      "\n",
      "--- Processing file: dbs-annual-report-2022.pdf ---\n",
      "Running CLI command for JSON output on dbs-annual-report-2022.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 10:04:48,599 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 115/115 [12:51<00:00,  6.71s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 29/29 [00:02<00:00, 11.97it/s]\n",
      "Detecting bboxes: 100%|██████████| 4/4 [00:03<00:00,  1.16it/s]\n",
      "Recognizing Text: 100%|██████████| 919/919 [21:36<00:00,  1.41s/it] \n",
      "Recognizing tables: 100%|██████████| 27/27 [02:04<00:00,  4.60s/it]\n",
      "Detecting bboxes: 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n",
      "Recognizing Text: 100%|██████████| 338/338 [10:34<00:00,  1.88s/it]\n",
      "2025-10-14 10:52:53,074 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022/dbs-annual-report-2022\n",
      "2025-10-14 10:52:53,074 [INFO] marker: Total time: 2883.814812898636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on dbs-annual-report-2022.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 10:53:01,363 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 115/115 [12:58<00:00,  6.77s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 29/29 [00:02<00:00, 12.20it/s]\n",
      "Detecting bboxes: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]\n",
      "Recognizing Text: 100%|██████████| 919/919 [20:56<00:00,  1.37s/it] \n",
      "Recognizing tables: 100%|██████████| 27/27 [02:13<00:00,  4.94s/it]\n",
      "Detecting bboxes: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]\n",
      "Recognizing Text: 100%|██████████| 338/338 [10:54<00:00,  1.94s/it]\n",
      "2025-10-14 11:41:05,211 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022/dbs-annual-report-2022\n",
      "2025-10-14 11:41:05,211 [INFO] marker: Total time: 2883.168110847473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for dbs-annual-report-2022.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: dbs-annual-report-2022.pdf ---\n",
      "\n",
      "--- Processing file: 1Q24_CEO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 1Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:41:13,606 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:29<00:00,  4.84s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 10.53it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:41:43,894 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation/1Q24_CEO_presentation\n",
      "2025-10-14 11:41:43,894 [INFO] marker: Total time: 29.62621283531189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 1Q24_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:41:50,397 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:28<00:00,  4.76s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 25.36it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:42:19,940 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation/1Q24_CEO_presentation\n",
      "2025-10-14 11:42:19,940 [INFO] marker: Total time: 29.029495000839233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 1Q24_CEO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 1Q24_CEO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 2Q24_CFO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 2Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:42:26,322 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 30/30 [02:20<00:00,  4.68s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 18.41it/s]\n",
      "Detecting bboxes: 100%|██████████| 2/2 [00:01<00:00,  1.66it/s]\n",
      "Recognizing Text: 100%|██████████| 12/12 [00:53<00:00,  4.44s/it]\n",
      "Recognizing tables: 100%|██████████| 2/2 [00:09<00:00,  4.88s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Recognizing Text: 100%|██████████| 44/44 [00:19<00:00,  2.28it/s]\n",
      "2025-10-14 11:46:20,408 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/2Q24_CFO_presentation\n",
      "2025-10-14 11:46:20,408 [INFO] marker: Total time: 233.56195712089539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:46:28,276 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 30/30 [02:20<00:00,  4.70s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 8/8 [00:00<00:00, 17.31it/s]\n",
      "Detecting bboxes: 100%|██████████| 2/2 [00:01<00:00,  1.55it/s]\n",
      "Recognizing Text: 100%|██████████| 12/12 [00:55<00:00,  4.64s/it]\n",
      "Recognizing tables: 100%|██████████| 2/2 [00:09<00:00,  4.88s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Recognizing Text: 100%|██████████| 44/44 [00:17<00:00,  2.50it/s]\n",
      "2025-10-14 11:50:23,906 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/2Q24_CFO_presentation\n",
      "2025-10-14 11:50:23,906 [INFO] marker: Total time: 234.9698028564453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q24_CFO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q24_CFO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 2Q25_CEO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 2Q25_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:50:31,878 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 5/5 [00:26<00:00,  5.40s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 18.55it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "Recognizing Text: 100%|██████████| 32/32 [00:38<00:00,  1.21s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:51:39,258 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation/2Q25_CEO_presentation\n",
      "2025-10-14 11:51:39,258 [INFO] marker: Total time: 66.73066711425781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q25_CEO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:51:46,014 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 5/5 [00:26<00:00,  5.36s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 18.31it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "Recognizing Text: 100%|██████████| 32/32 [00:38<00:00,  1.21s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:52:53,059 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation/2Q25_CEO_presentation\n",
      "2025-10-14 11:52:53,059 [INFO] marker: Total time: 66.51663303375244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q25_CEO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q25_CEO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 1Q25_CFO_presentation.pdf ---\n",
      "Running CLI command for JSON output on 1Q25_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:53:00,729 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 18/18 [01:24<00:00,  4.69s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 5/5 [00:00<00:00, 20.33it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:54:35,126 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/1Q25_CFO_presentation\n",
      "2025-10-14 11:54:35,126 [INFO] marker: Total time: 93.85541987419128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 1Q25_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:54:42,842 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 18/18 [01:24<00:00,  4.68s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 5/5 [00:00<00:00, 23.86it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:56:17,103 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/1Q25_CFO_presentation\n",
      "2025-10-14 11:56:17,103 [INFO] marker: Total time: 93.51765608787537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 1Q25_CFO_presentation.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 1Q25_CFO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 2Q25_press_statement.pdf ---\n",
      "Running CLI command for JSON output on 2Q25_press_statement.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:56:24,922 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 7/7 [00:36<00:00,  5.25s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 10.63it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:57:03,259 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement/2Q25_press_statement\n",
      "2025-10-14 11:57:03,259 [INFO] marker: Total time: 37.77143216133118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q25_press_statement.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:57:10,432 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 7/7 [00:36<00:00,  5.20s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 10.94it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:57:48,233 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement/2Q25_press_statement\n",
      "2025-10-14 11:57:48,233 [INFO] marker: Total time: 37.25265312194824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q25_press_statement.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q25_press_statement.pdf ---\n",
      "\n",
      "--- Processing file: 2Q24_press_statement.pdf ---\n",
      "Running CLI command for JSON output on 2Q24_press_statement.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:57:55,748 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:30<00:00,  5.05s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00,  9.48it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:58:27,456 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement/2Q24_press_statement\n",
      "2025-10-14 11:58:27,456 [INFO] marker: Total time: 31.14157009124756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 2Q24_press_statement.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 11:58:33,811 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 6/6 [00:30<00:00,  5.01s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00, 11.79it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-14 11:59:05,097 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement/2Q24_press_statement\n",
      "2025-10-14 11:59:05,097 [INFO] marker: Total time: 30.739354133605957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ All files for 2Q24_press_statement.pdf have been saved in the '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement' directory.\n",
      "Note: The files will have names based on the original PDF.\n",
      "--- Finished processing: 2Q24_press_statement.pdf ---\n",
      "\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Automatically create the folder structure based on the PDF name\n",
    "    main_output_folder = pdf_path.parent / pdf_path.stem\n",
    "    # The CLI will create its own images folder, so we just need the main one.\n",
    "    main_output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(main_output_folder)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(main_output_folder)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ All files for {pdf_path.name} have been saved in the '{main_output_folder}' directory.\")\n",
    "        print(\"Note: The files will have names based on the original PDF.\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        # Since we are not capturing output, stdout/stderr will be None here,\n",
    "        # but the error will have already been printed to the console.\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740304a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/\")\n",
    "\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # Create just ONE main output folder (no nested same-name)\n",
    "    main_output_folder = pdf_path.parent / pdf_path.stem\n",
    "    main_output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Run JSON output\n",
    "        print(f\"Running CLI for JSON on {pdf_path.name}...\")\n",
    "        subprocess.run([\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(main_output_folder.parent)  # ⬅️ Use parent folder, not the folder itself\n",
    "        ], check=True)\n",
    "        # Move generated files into your single main folder\n",
    "        generated_sub = main_output_folder.parent / pdf_path.stem\n",
    "        if generated_sub.exists():\n",
    "            for f in generated_sub.iterdir():\n",
    "                f.rename(main_output_folder / f.name)\n",
    "            generated_sub.rmdir()\n",
    "\n",
    "        print(\"✅ JSON generated in single folder.\")\n",
    "\n",
    "        # Run Markdown + images\n",
    "        print(f\"Running CLI for Markdown on {pdf_path.name}...\")\n",
    "        subprocess.run([\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_dir\", str(main_output_folder.parent)\n",
    "        ], check=True)\n",
    "        generated_sub = main_output_folder.parent / pdf_path.stem\n",
    "        if generated_sub.exists():\n",
    "            for f in generated_sub.iterdir():\n",
    "                f.rename(main_output_folder / f.name)\n",
    "            generated_sub.rmdir()\n",
    "\n",
    "        print(\"✅ Markdown + images generated in same folder.\")\n",
    "        print(f\"✨ All files saved under: {main_output_folder}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ Error processing {pdf_path.name}\")\n",
    "        print(f\"Command: {' '.join(e.cmd)}\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Unexpected error: {e}\")\n",
    "\n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDFs processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e03d122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement/2Q24_press_statement\n",
      "✅ Moved 2Q24_press_statement_meta.json\n",
      "✅ Moved 2Q24_press_statement.json\n",
      "✅ Moved 2Q24_press_statement.md\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_2_Picture_0.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved _page_4_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement/2Q24_press_statement\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary/4Q24_performance_summary\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved 4Q24_performance_summary.md\n",
      "✅ Moved 4Q24_performance_summary_meta.json\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_38_Picture_3.jpeg\n",
      "✅ Moved 4Q24_performance_summary.json\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary/4Q24_performance_summary\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary/2Q25_performance_summary\n",
      "✅ Moved 2Q25_performance_summary.md\n",
      "✅ Moved 2Q25_performance_summary_meta.json\n",
      "✅ Moved 2Q25_performance_summary.json\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary/2Q25_performance_summary\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary/2Q24_performance_summary\n",
      "✅ Moved 2Q24_performance_summary.json\n",
      "✅ Moved 2Q24_performance_summary.md\n",
      "✅ Moved 2Q24_performance_summary_meta.json\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary/2Q24_performance_summary\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement/2Q25_press_statement\n",
      "✅ Moved 2Q25_press_statement.json\n",
      "✅ Moved 2Q25_press_statement.md\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved _page_6_Picture_0.jpeg\n",
      "✅ Moved 2Q25_press_statement_meta.json\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_2_Picture_0.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved _page_4_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement/2Q25_press_statement\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement/4Q24_press_statement\n",
      "✅ Moved 4Q24_press_statement_meta.json\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved 4Q24_press_statement.json\n",
      "✅ Moved _page_6_Picture_0.jpeg\n",
      "✅ Moved _page_7_Picture_0.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_2_Picture_0.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved _page_4_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "✅ Moved 4Q24_press_statement.md\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement/4Q24_press_statement\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/2Q24_CFO_presentation\n",
      "✅ Moved _page_16_Picture_3.jpeg\n",
      "✅ Moved _page_17_Picture_2.jpeg\n",
      "✅ Moved _page_12_Picture_5.jpeg\n",
      "✅ Moved _page_23_Picture_21.jpeg\n",
      "✅ Moved _page_10_Picture_2.jpeg\n",
      "✅ Moved _page_18_Figure_1.jpeg\n",
      "✅ Moved _page_18_Picture_2.jpeg\n",
      "✅ Moved _page_19_Picture_3.jpeg\n",
      "✅ Moved _page_19_Picture_2.jpeg\n",
      "✅ Moved _page_23_Picture_20.jpeg\n",
      "✅ Moved _page_6_Picture_5.jpeg\n",
      "✅ Moved _page_4_Figure_1.jpeg\n",
      "✅ Moved _page_29_Picture_0.jpeg\n",
      "✅ Moved _page_9_Picture_2.jpeg\n",
      "✅ Moved _page_28_Picture_1.jpeg\n",
      "✅ Moved _page_14_Picture_2.jpeg\n",
      "✅ Moved _page_21_Picture_0.jpeg\n",
      "✅ Moved _page_13_Picture_2.jpeg\n",
      "✅ Moved 2Q24_CFO_presentation.md\n",
      "✅ Moved _page_27_Picture_1.jpeg\n",
      "✅ Moved _page_7_Picture_2.jpeg\n",
      "✅ Moved _page_15_Picture_2.jpeg\n",
      "✅ Moved 2Q24_CFO_presentation_meta.json\n",
      "✅ Moved _page_8_Picture_2.jpeg\n",
      "✅ Moved _page_11_Picture_4.jpeg\n",
      "✅ Moved 2Q24_CFO_presentation.json\n",
      "✅ Moved _page_17_Figure_1.jpeg\n",
      "✅ Moved _page_8_Figure_1.jpeg\n",
      "✅ Moved _page_7_Picture_1.jpeg\n",
      "✅ Moved _page_13_Picture_1.jpeg\n",
      "✅ Moved _page_27_Picture_2.jpeg\n",
      "✅ Moved _page_26_Picture_3.jpeg\n",
      "✅ Moved _page_10_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_1.jpeg\n",
      "✅ Moved _page_28_Picture_2.jpeg\n",
      "✅ Moved _page_14_Figure_1.jpeg\n",
      "✅ Moved _page_1_Picture_16.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_6_Picture_6.jpeg\n",
      "✅ Moved _page_22_Picture_2.jpeg\n",
      "✅ Moved _page_5_Figure_1.jpeg\n",
      "✅ Moved _page_20_Picture_5.jpeg\n",
      "✅ Moved _page_25_Picture_2.jpeg\n",
      "✅ Moved _page_6_Figure_1.jpeg\n",
      "✅ Moved _page_24_Picture_2.jpeg\n",
      "✅ Moved _page_2_Figure_1.jpeg\n",
      "✅ Moved _page_24_Figure_1.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/2Q24_CFO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022/dbs-annual-report-2022\n",
      "✅ Moved _page_98_Picture_3.jpeg\n",
      "✅ Moved _page_36_Picture_69.jpeg\n",
      "✅ Moved _page_8_Picture_9.jpeg\n",
      "✅ Moved _page_9_Picture_12.jpeg\n",
      "✅ Moved _page_2_Picture_20.jpeg\n",
      "✅ Moved _page_5_Picture_21.jpeg\n",
      "✅ Moved _page_5_Picture_37.jpeg\n",
      "✅ Moved _page_5_Picture_17.jpeg\n",
      "✅ Moved _page_36_Picture_65.jpeg\n",
      "✅ Moved _page_53_Figure_3.jpeg\n",
      "✅ Moved _page_19_Picture_41.jpeg\n",
      "✅ Moved _page_36_Picture_73.jpeg\n",
      "✅ Moved _page_55_Picture_32.jpeg\n",
      "✅ Moved _page_49_Figure_13.jpeg\n",
      "✅ Moved _page_54_Picture_58.jpeg\n",
      "✅ Moved _page_18_Picture_2.jpeg\n",
      "✅ Moved _page_21_Picture_39.jpeg\n",
      "✅ Moved _page_54_Picture_18.jpeg\n",
      "✅ Moved _page_19_Picture_2.jpeg\n",
      "✅ Moved _page_35_Figure_1.jpeg\n",
      "✅ Moved _page_4_Picture_11.jpeg\n",
      "✅ Moved _page_55_Figure_29.jpeg\n",
      "✅ Moved _page_46_Figure_49.jpeg\n",
      "✅ Moved _page_5_Picture_41.jpeg\n",
      "✅ Moved _page_54_Picture_34.jpeg\n",
      "✅ Moved dbs-annual-report-2022.json\n",
      "✅ Moved _page_26_Picture_15.jpeg\n",
      "✅ Moved _page_55_Figure_44.jpeg\n",
      "✅ Moved _page_54_Picture_14.jpeg\n",
      "✅ Moved _page_23_Picture_20.jpeg\n",
      "✅ Moved _page_31_Figure_25.jpeg\n",
      "✅ Moved _page_7_Picture_22.jpeg\n",
      "✅ Moved _page_20_Picture_48.jpeg\n",
      "✅ Moved _page_2_Picture_3.jpeg\n",
      "✅ Moved _page_55_Picture_13.jpeg\n",
      "✅ Moved _page_99_Picture_3.jpeg\n",
      "✅ Moved _page_16_Figure_11.jpeg\n",
      "✅ Moved _page_47_Figure_13.jpeg\n",
      "✅ Moved _page_97_Picture_62.jpeg\n",
      "✅ Moved _page_11_Picture_5.jpeg\n",
      "✅ Moved _page_5_Picture_11.jpeg\n",
      "✅ Moved _page_10_Figure_2.jpeg\n",
      "✅ Moved _page_44_Figure_5.jpeg\n",
      "✅ Moved _page_3_Picture_9.jpeg\n",
      "✅ Moved _page_55_Picture_7.jpeg\n",
      "✅ Moved _page_13_Figure_27.jpeg\n",
      "✅ Moved _page_36_Picture_75.jpeg\n",
      "✅ Moved _page_55_Picture_34.jpeg\n",
      "✅ Moved _page_14_Figure_11.jpeg\n",
      "✅ Moved _page_15_Figure_51.jpeg\n",
      "✅ Moved _page_15_Figure_47.jpeg\n",
      "✅ Moved _page_14_Figure_27.jpeg\n",
      "✅ Moved _page_22_Picture_6.jpeg\n",
      "✅ Moved _page_3_Picture_5.jpeg\n",
      "✅ Moved _page_54_Figure_8.jpeg\n",
      "✅ Moved _page_39_Figure_34.jpeg\n",
      "✅ Moved _page_36_Picture_79.jpeg\n",
      "✅ Moved _page_10_Picture_16.jpeg\n",
      "✅ Moved _page_5_Picture_27.jpeg\n",
      "✅ Moved _page_5_Picture_31.jpeg\n",
      "✅ Moved _page_54_Picture_12.jpeg\n",
      "✅ Moved _page_98_Picture_75.jpeg\n",
      "✅ Moved _page_54_Picture_45.jpeg\n",
      "✅ Moved _page_12_Picture_2.jpeg\n",
      "✅ Moved _page_8_Picture_12.jpeg\n",
      "✅ Moved _page_114_Picture_16.jpeg\n",
      "✅ Moved _page_13_Picture_12.jpeg\n",
      "✅ Moved _page_5_Picture_9.jpeg\n",
      "✅ Moved _page_16_Figure_17.jpeg\n",
      "✅ Moved _page_22_Picture_7.jpeg\n",
      "✅ Moved _page_47_Figure_15.jpeg\n",
      "✅ Moved _page_3_Picture_57.jpeg\n",
      "✅ Moved _page_47_Figure_5.jpeg\n",
      "✅ Moved _page_1_Picture_14.jpeg\n",
      "✅ Moved _page_14_Figure_10.jpeg\n",
      "✅ Moved _page_49_Figure_14.jpeg\n",
      "✅ Moved _page_16_Figure_21.jpeg\n",
      "✅ Moved _page_104_Figure_5.jpeg\n",
      "✅ Moved _page_54_Picture_24.jpeg\n",
      "✅ Moved _page_9_Picture_3.jpeg\n",
      "✅ Moved _page_5_Picture_47.jpeg\n",
      "✅ Moved _page_13_Figure_26.jpeg\n",
      "✅ Moved _page_2_Picture_11.jpeg\n",
      "✅ Moved _page_39_Figure_2.jpeg\n",
      "✅ Moved _page_21_Picture_2.jpeg\n",
      "✅ Moved _page_44_Picture_3.jpeg\n",
      "✅ Moved _page_23_Picture_29.jpeg\n",
      "✅ Moved _page_97_Picture_106.jpeg\n",
      "✅ Moved _page_5_Picture_29.jpeg\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved _page_49_Figure_17.jpeg\n",
      "✅ Moved _page_36_Picture_77.jpeg\n",
      "✅ Moved _page_13_Figure_25.jpeg\n",
      "✅ Moved _page_5_Picture_13.jpeg\n",
      "✅ Moved dbs-annual-report-2022.md\n",
      "✅ Moved _page_22_Picture_8.jpeg\n",
      "✅ Moved _page_8_Figure_1.jpeg\n",
      "✅ Moved _page_54_Picture_11.jpeg\n",
      "✅ Moved _page_5_Picture_33.jpeg\n",
      "✅ Moved _page_3_Picture_19.jpeg\n",
      "✅ Moved _page_114_Picture_15.jpeg\n",
      "✅ Moved _page_5_Picture_25.jpeg\n",
      "✅ Moved _page_99_Picture_6.jpeg\n",
      "✅ Moved _page_3_Picture_7.jpeg\n",
      "✅ Moved _page_111_Picture_2.jpeg\n",
      "✅ Moved _page_22_Picture_5.jpeg\n",
      "✅ Moved _page_97_Picture_82.jpeg\n",
      "✅ Moved _page_98_Picture_36.jpeg\n",
      "✅ Moved _page_54_Picture_51.jpeg\n",
      "✅ Moved _page_114_Picture_14.jpeg\n",
      "✅ Moved _page_24_Figure_21.jpeg\n",
      "✅ Moved _page_54_Picture_10.jpeg\n",
      "✅ Moved _page_98_Picture_20.jpeg\n",
      "✅ Moved _page_103_Picture_2.jpeg\n",
      "✅ Moved _page_5_Picture_45.jpeg\n",
      "✅ Moved _page_9_Picture_1.jpeg\n",
      "✅ Moved _page_5_Picture_7.jpeg\n",
      "✅ Moved _page_20_Picture_2.jpeg\n",
      "✅ Moved _page_14_Figure_12.jpeg\n",
      "✅ Moved _page_97_Picture_6.jpeg\n",
      "✅ Moved _page_15_Figure_44.jpeg\n",
      "✅ Moved _page_47_Figure_7.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_55_Figure_30.jpeg\n",
      "✅ Moved _page_39_Picture_26.jpeg\n",
      "✅ Moved _page_5_Picture_35.jpeg\n",
      "✅ Moved _page_2_Picture_34.jpeg\n",
      "✅ Moved _page_114_Picture_13.jpeg\n",
      "✅ Moved _page_5_Picture_23.jpeg\n",
      "✅ Moved _page_7_Picture_37.jpeg\n",
      "✅ Moved _page_55_Picture_10.jpeg\n",
      "✅ Moved _page_5_Picture_19.jpeg\n",
      "✅ Moved _page_55_Picture_26.jpeg\n",
      "✅ Moved _page_5_Picture_39.jpeg\n",
      "✅ Moved _page_35_Figure_2.jpeg\n",
      "✅ Moved dbs-annual-report-2022_meta.json\n",
      "✅ Moved _page_36_Picture_71.jpeg\n",
      "✅ Moved _page_36_Picture_67.jpeg\n",
      "✅ Moved _page_5_Picture_15.jpeg\n",
      "✅ Moved _page_98_Picture_51.jpeg\n",
      "✅ Moved _page_8_Picture_6.jpeg\n",
      "✅ Moved _page_5_Picture_43.jpeg\n",
      "✅ Moved _page_97_Picture_26.jpeg\n",
      "✅ Moved _page_16_Figure_25.jpeg\n",
      "✅ Moved _page_16_Figure_9.jpeg\n",
      "✅ Moved _page_15_Figure_54.jpeg\n",
      "✅ Moved _page_19_Picture_39.jpeg\n",
      "✅ Moved _page_6_Picture_11.jpeg\n",
      "✅ Moved _page_48_Figure_11.jpeg\n",
      "✅ Moved _page_22_Picture_13.jpeg\n",
      "✅ Moved _page_20_Picture_50.jpeg\n",
      "✅ Moved _page_22_Picture_33.jpeg\n",
      "✅ Moved _page_23_Picture_2.jpeg\n",
      "✅ Moved _page_22_Picture_25.jpeg\n",
      "✅ Moved _page_7_Picture_20.jpeg\n",
      "✅ Moved _page_54_Picture_16.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022/dbs-annual-report-2022\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/3Q24_CFO_presentation\n",
      "✅ Moved _page_17_Picture_2.jpeg\n",
      "✅ Moved _page_7_Figure_1.jpeg\n",
      "✅ Moved _page_10_Picture_2.jpeg\n",
      "✅ Moved _page_18_Picture_2.jpeg\n",
      "✅ Moved 3Q24_CFO_presentation_meta.json\n",
      "✅ Moved _page_18_Picture_3.jpeg\n",
      "✅ Moved 3Q24_CFO_presentation.md\n",
      "✅ Moved _page_11_Picture_2.jpeg\n",
      "✅ Moved _page_16_Picture_2.jpeg\n",
      "✅ Moved _page_4_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_2.jpeg\n",
      "✅ Moved _page_14_Picture_2.jpeg\n",
      "✅ Moved _page_19_Picture_5.jpeg\n",
      "✅ Moved _page_15_Picture_3.jpeg\n",
      "✅ Moved _page_13_Picture_2.jpeg\n",
      "✅ Moved _page_11_Figure_1.jpeg\n",
      "✅ Moved _page_12_Picture_2.jpeg\n",
      "✅ Moved _page_16_Figure_1.jpeg\n",
      "✅ Moved _page_20_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_8.jpeg\n",
      "✅ Moved _page_9_Figure_1.jpeg\n",
      "✅ Moved _page_2_Picture_11.jpeg\n",
      "✅ Moved _page_13_Figure_1.jpeg\n",
      "✅ Moved _page_17_Figure_1.jpeg\n",
      "✅ Moved _page_8_Figure_1.jpeg\n",
      "✅ Moved _page_12_Picture_1.jpeg\n",
      "✅ Moved _page_3_Figure_4.jpeg\n",
      "✅ Moved _page_10_Figure_1.jpeg\n",
      "✅ Moved _page_1_Picture_16.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_5_Figure_1.jpeg\n",
      "✅ Moved _page_6_Figure_1.jpeg\n",
      "✅ Moved _page_8_Picture_6.jpeg\n",
      "✅ Moved 3Q24_CFO_presentation.json\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/3Q24_CFO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation/4Q24_CEO_presentation\n",
      "✅ Moved _page_3_Picture_11.jpeg\n",
      "✅ Moved _page_1_Picture_9.jpeg\n",
      "✅ Moved _page_4_Picture_9.jpeg\n",
      "✅ Moved 4Q24_CEO_presentation.json\n",
      "✅ Moved 4Q24_CEO_presentation_meta.json\n",
      "✅ Moved _page_2_Picture_7.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved 4Q24_CEO_presentation.md\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation/4Q24_CEO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023/dbs-annual-report-2023\n",
      "✅ Moved _page_48_Figure_32.jpeg\n",
      "✅ Moved _page_16_Figure_10.jpeg\n",
      "✅ Moved _page_37_Picture_15.jpeg\n",
      "✅ Moved _page_22_Picture_26.jpeg\n",
      "✅ Moved _page_27_Picture_7.jpeg\n",
      "✅ Moved _page_14_Figure_8.jpeg\n",
      "✅ Moved _page_114_Picture_11.jpeg\n",
      "✅ Moved _page_54_Picture_15.jpeg\n",
      "✅ Moved _page_8_Picture_5.jpeg\n",
      "✅ Moved dbs-annual-report-2023.json\n",
      "✅ Moved _page_5_Picture_40.jpeg\n",
      "✅ Moved _page_37_Picture_19.jpeg\n",
      "✅ Moved _page_48_Figure_28.jpeg\n",
      "✅ Moved _page_20_Picture_45.jpeg\n",
      "✅ Moved _page_96_Picture_63.jpeg\n",
      "✅ Moved _page_1_Picture_13.jpeg\n",
      "✅ Moved _page_37_Picture_23.jpeg\n",
      "✅ Moved _page_54_Picture_18.jpeg\n",
      "✅ Moved _page_40_Figure_2.jpeg\n",
      "✅ Moved _page_4_Picture_11.jpeg\n",
      "✅ Moved _page_96_Picture_3.jpeg\n",
      "✅ Moved _page_16_Figure_27.jpeg\n",
      "✅ Moved _page_54_Picture_22.jpeg\n",
      "✅ Moved _page_103_Figure_2.jpeg\n",
      "✅ Moved _page_21_Picture_43.jpeg\n",
      "✅ Moved _page_5_Picture_16.jpeg\n",
      "✅ Moved _page_4_Picture_2.jpeg\n",
      "✅ Moved _page_54_Picture_14.jpeg\n",
      "✅ Moved _page_13_Figure_8.jpeg\n",
      "✅ Moved _page_5_Picture_36.jpeg\n",
      "✅ Moved _page_97_Picture_53.jpeg\n",
      "✅ Moved _page_14_Figure_9.jpeg\n",
      "✅ Moved _page_5_Picture_20.jpeg\n",
      "✅ Moved _page_2_Picture_3.jpeg\n",
      "✅ Moved _page_22_Picture_27.jpeg\n",
      "✅ Moved _page_46_Figure_12.jpeg\n",
      "✅ Moved _page_4_Picture_5.jpeg\n",
      "✅ Moved _page_97_Picture_35.jpeg\n",
      "✅ Moved _page_5_Picture_46.jpeg\n",
      "✅ Moved _page_53_Picture_32.jpeg\n",
      "✅ Moved _page_5_Picture_50.jpeg\n",
      "✅ Moved _page_96_Picture_4.jpeg\n",
      "✅ Moved _page_53_Figure_35.jpeg\n",
      "✅ Moved _page_37_Picture_25.jpeg\n",
      "✅ Moved _page_0_Picture_3.jpeg\n",
      "✅ Moved _page_22_Picture_6.jpeg\n",
      "✅ Moved _page_3_Picture_5.jpeg\n",
      "✅ Moved _page_16_Figure_16.jpeg\n",
      "✅ Moved _page_37_Picture_13.jpeg\n",
      "✅ Moved _page_5_Picture_8.jpeg\n",
      "✅ Moved _page_6_Picture_2.jpeg\n",
      "✅ Moved _page_37_Picture_87.jpeg\n",
      "✅ Moved _page_23_Picture_31.jpeg\n",
      "✅ Moved _page_37_Picture_91.jpeg\n",
      "✅ Moved _page_97_Picture_14.jpeg\n",
      "✅ Moved _page_5_Picture_30.jpeg\n",
      "✅ Moved _page_8_Picture_12.jpeg\n",
      "✅ Moved _page_114_Picture_16.jpeg\n",
      "✅ Moved _page_5_Picture_26.jpeg\n",
      "✅ Moved _page_45_Figure_49.jpeg\n",
      "✅ Moved _page_13_Figure_10.jpeg\n",
      "✅ Moved _page_24_Figure_19.jpeg\n",
      "✅ Moved _page_22_Picture_7.jpeg\n",
      "✅ Moved _page_3_Picture_20.jpeg\n",
      "✅ Moved _page_4_Picture_8.jpeg\n",
      "✅ Moved _page_40_Picture_47.jpeg\n",
      "✅ Moved _page_0_Picture_2.jpeg\n",
      "✅ Moved _page_1_Picture_14.jpeg\n",
      "✅ Moved _page_3_Picture_16.jpeg\n",
      "✅ Moved _page_54_Picture_24.jpeg\n",
      "✅ Moved _page_31_Figure_54.jpeg\n",
      "✅ Moved _page_21_Picture_45.jpeg\n",
      "✅ Moved _page_5_Picture_10.jpeg\n",
      "✅ Moved _page_21_Picture_2.jpeg\n",
      "✅ Moved _page_45_Figure_50.jpeg\n",
      "✅ Moved _page_22_Picture_14.jpeg\n",
      "✅ Moved _page_37_Picture_89.jpeg\n",
      "✅ Moved _page_16_Figure_22.jpeg\n",
      "✅ Moved _page_102_Picture_2.jpeg\n",
      "✅ Moved _page_19_Picture_45.jpeg\n",
      "✅ Moved _page_5_Picture_52.jpeg\n",
      "✅ Moved _page_10_Picture_6.jpeg\n",
      "✅ Moved _page_5_Picture_6.jpeg\n",
      "✅ Moved _page_5_Picture_44.jpeg\n",
      "✅ Moved _page_43_Figure_10.jpeg\n",
      "✅ Moved dbs-annual-report-2023_meta.json\n",
      "✅ Moved _page_37_Picture_93.jpeg\n",
      "✅ Moved _page_114_Picture_15.jpeg\n",
      "✅ Moved _page_2_Picture_24.jpeg\n",
      "✅ Moved _page_13_Figure_13.jpeg\n",
      "✅ Moved _page_37_Picture_11.jpeg\n",
      "✅ Moved _page_3_Picture_7.jpeg\n",
      "✅ Moved _page_46_Figure_5.jpeg\n",
      "✅ Moved _page_5_Picture_48.jpeg\n",
      "✅ Moved _page_14_Figure_25.jpeg\n",
      "✅ Moved _page_111_Picture_3.jpeg\n",
      "✅ Moved _page_14_Figure_24.jpeg\n",
      "✅ Moved _page_3_Picture_6.jpeg\n",
      "✅ Moved _page_5_Picture_24.jpeg\n",
      "✅ Moved _page_114_Picture_14.jpeg\n",
      "✅ Moved _page_5_Picture_32.jpeg\n",
      "✅ Moved _page_103_Picture_25.jpeg\n",
      "✅ Moved _page_97_Picture_16.jpeg\n",
      "✅ Moved _page_5_Picture_12.jpeg\n",
      "✅ Moved _page_54_Picture_26.jpeg\n",
      "✅ Moved _page_43_Figure_7.jpeg\n",
      "✅ Moved _page_10_Picture_19.jpeg\n",
      "✅ Moved _page_5_Picture_28.jpeg\n",
      "✅ Moved _page_96_Picture_66.jpeg\n",
      "✅ Moved _page_22_Picture_15.jpeg\n",
      "✅ Moved _page_18_Picture_43.jpeg\n",
      "✅ Moved dbs-annual-report-2023.md\n",
      "✅ Moved _page_96_Picture_27.jpeg\n",
      "✅ Moved _page_37_Picture_95.jpeg\n",
      "✅ Moved _page_8_Picture_17.jpeg\n",
      "✅ Moved _page_114_Picture_13.jpeg\n",
      "✅ Moved _page_48_Figure_26.jpeg\n",
      "✅ Moved _page_37_Picture_17.jpeg\n",
      "✅ Moved _page_46_Figure_3.jpeg\n",
      "✅ Moved _page_35_Figure_20.jpeg\n",
      "✅ Moved _page_4_Picture_24.jpeg\n",
      "✅ Moved _page_98_Picture_1.jpeg\n",
      "✅ Moved _page_37_Picture_21.jpeg\n",
      "✅ Moved _page_2_Picture_38.jpeg\n",
      "✅ Moved _page_97_Picture_1.jpeg\n",
      "✅ Moved _page_20_Picture_47.jpeg\n",
      "✅ Moved _page_22_Picture_28.jpeg\n",
      "✅ Moved _page_9_Picture_6.jpeg\n",
      "✅ Moved _page_5_Picture_42.jpeg\n",
      "✅ Moved _page_2_Picture_14.jpeg\n",
      "✅ Moved _page_5_Picture_14.jpeg\n",
      "✅ Moved _page_9_Picture_7.jpeg\n",
      "✅ Moved _page_14_Figure_7.jpeg\n",
      "✅ Moved _page_96_Picture_60.jpeg\n",
      "✅ Moved _page_5_Picture_38.jpeg\n",
      "✅ Moved _page_18_Picture_45.jpeg\n",
      "✅ Moved _page_40_Picture_43.jpeg\n",
      "✅ Moved _page_5_Picture_18.jpeg\n",
      "✅ Moved _page_22_Picture_33.jpeg\n",
      "✅ Moved _page_47_Figure_11.jpeg\n",
      "✅ Moved _page_5_Picture_22.jpeg\n",
      "✅ Moved _page_7_Picture_36.jpeg\n",
      "✅ Moved _page_114_Picture_12.jpeg\n",
      "✅ Moved _page_97_Picture_51.jpeg\n",
      "✅ Moved _page_5_Picture_34.jpeg\n",
      "✅ Moved _page_52_Figure_3.jpeg\n",
      "✅ Moved _page_7_Picture_20.jpeg\n",
      "✅ Moved _page_23_Picture_22.jpeg\n",
      "✅ Moved _page_54_Picture_16.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023/dbs-annual-report-2023\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024/dbs-annual-report-2024\n",
      "✅ Moved _page_42_Picture_23.jpeg\n",
      "✅ Moved _page_10_Figure_8.jpeg\n",
      "✅ Moved _page_47_Figure_12.jpeg\n",
      "✅ Moved _page_99_Picture_2.jpeg\n",
      "✅ Moved _page_7_Picture_19.jpeg\n",
      "✅ Moved _page_38_Picture_74.jpeg\n",
      "✅ Moved _page_2_Picture_2.jpeg\n",
      "✅ Moved _page_11_Picture_56.jpeg\n",
      "✅ Moved _page_19_Picture_36.jpeg\n",
      "✅ Moved _page_7_Picture_35.jpeg\n",
      "✅ Moved _page_42_Picture_19.jpeg\n",
      "✅ Moved _page_7_Picture_23.jpeg\n",
      "✅ Moved _page_7_Picture_5.jpeg\n",
      "✅ Moved _page_5_Picture_17.jpeg\n",
      "✅ Moved _page_10_Figure_4.jpeg\n",
      "✅ Moved _page_53_Figure_3.jpeg\n",
      "✅ Moved _page_93_Picture_5.jpeg\n",
      "✅ Moved _page_49_Figure_9.jpeg\n",
      "✅ Moved _page_11_Picture_60.jpeg\n",
      "✅ Moved _page_21_Picture_54.jpeg\n",
      "✅ Moved _page_1_Picture_29.jpeg\n",
      "✅ Moved _page_41_Picture_10.jpeg\n",
      "✅ Moved _page_7_Picture_15.jpeg\n",
      "✅ Moved _page_4_Picture_10.jpeg\n",
      "✅ Moved _page_7_Picture_39.jpeg\n",
      "✅ Moved _page_42_Picture_15.jpeg\n",
      "✅ Moved _page_1_Picture_13.jpeg\n",
      "✅ Moved _page_12_Picture_32.jpeg\n",
      "✅ Moved _page_7_Picture_9.jpeg\n",
      "✅ Moved _page_19_Picture_3.jpeg\n",
      "✅ Moved _page_94_Picture_36.jpeg\n",
      "✅ Moved _page_22_Picture_47.jpeg\n",
      "✅ Moved _page_47_Figure_3.jpeg\n",
      "✅ Moved _page_99_Picture_54.jpeg\n",
      "✅ Moved _page_3_Picture_10.jpeg\n",
      "✅ Moved _page_94_Picture_21.jpeg\n",
      "✅ Moved _page_1_Picture_53.jpeg\n",
      "✅ Moved _page_46_Figure_49.jpeg\n",
      "✅ Moved _page_23_Picture_16.jpeg\n",
      "✅ Moved _page_24_Picture_17.jpeg\n",
      "✅ Moved _page_7_Picture_43.jpeg\n",
      "✅ Moved _page_5_Picture_3.jpeg\n",
      "✅ Moved _page_10_Figure_10.jpeg\n",
      "✅ Moved _page_10_Figure_5.jpeg\n",
      "✅ Moved _page_23_Picture_36.jpeg\n",
      "✅ Moved _page_5_Picture_20.jpeg\n",
      "✅ Moved _page_20_Picture_48.jpeg\n",
      "✅ Moved _page_99_Picture_23.jpeg\n",
      "✅ Moved _page_110_Picture_7.jpeg\n",
      "✅ Moved _page_94_Picture_4.jpeg\n",
      "✅ Moved _page_1_Picture_39.jpeg\n",
      "✅ Moved _page_8_Picture_3.jpeg\n",
      "✅ Moved _page_38_Picture_68.jpeg\n",
      "✅ Moved _page_5_Picture_11.jpeg\n",
      "✅ Moved _page_93_Picture_3.jpeg\n",
      "✅ Moved _page_2_Picture_51.jpeg\n",
      "✅ Moved _page_7_Picture_13.jpeg\n",
      "✅ Moved _page_49_Figure_15.jpeg\n",
      "✅ Moved _page_4_Picture_16.jpeg\n",
      "✅ Moved _page_42_Picture_13.jpeg\n",
      "✅ Moved dbs-annual-report-2024.md\n",
      "✅ Moved _page_17_Figure_21.jpeg\n",
      "✅ Moved _page_7_Picture_29.jpeg\n",
      "✅ Moved _page_15_Figure_10.jpeg\n",
      "✅ Moved _page_3_Picture_21.jpeg\n",
      "✅ Moved _page_47_Figure_14.jpeg\n",
      "✅ Moved _page_23_Picture_7.jpeg\n",
      "✅ Moved _page_16_Figure_57.jpeg\n",
      "✅ Moved _page_38_Picture_72.jpeg\n",
      "✅ Moved _page_2_Picture_4.jpeg\n",
      "✅ Moved _page_11_Picture_50.jpeg\n",
      "✅ Moved _page_7_Picture_33.jpeg\n",
      "✅ Moved _page_24_Picture_30.jpeg\n",
      "✅ Moved _page_7_Picture_25.jpeg\n",
      "✅ Moved _page_11_Picture_46.jpeg\n",
      "✅ Moved _page_10_Figure_21.jpeg\n",
      "✅ Moved _page_12_Picture_2.jpeg\n",
      "✅ Moved _page_93_Picture_92.jpeg\n",
      "✅ Moved _page_6_Picture_3.jpeg\n",
      "✅ Moved _page_13_Picture_3.jpeg\n",
      "✅ Moved _page_2_Picture_5.jpeg\n",
      "✅ Moved _page_23_Picture_6.jpeg\n",
      "✅ Moved _page_95_Picture_3.jpeg\n",
      "✅ Moved _page_44_Figure_8.jpeg\n",
      "✅ Moved _page_15_Figure_11.jpeg\n",
      "✅ Moved _page_0_Picture_2.jpeg\n",
      "✅ Moved _page_100_Figure_5.jpeg\n",
      "✅ Moved _page_47_Figure_5.jpeg\n",
      "✅ Moved _page_1_Picture_14.jpeg\n",
      "✅ Moved _page_41_Picture_7.jpeg\n",
      "✅ Moved _page_7_Picture_45.jpeg\n",
      "✅ Moved _page_10_Figure_16.jpeg\n",
      "✅ Moved dbs-annual-report-2024.json\n",
      "✅ Moved _page_10_Figure_3.jpeg\n",
      "✅ Moved _page_11_Picture_48.jpeg\n",
      "✅ Moved _page_36_Figure_20.jpeg\n",
      "✅ Moved _page_1_Picture_17.jpeg\n",
      "✅ Moved _page_3_Picture_15.jpeg\n",
      "✅ Moved _page_20_Picture_3.jpeg\n",
      "✅ Moved _page_7_Picture_11.jpeg\n",
      "✅ Moved _page_25_Figure_17.jpeg\n",
      "✅ Moved _page_42_Figure_27.jpeg\n",
      "✅ Moved _page_4_Picture_7.jpeg\n",
      "✅ Moved _page_7_Picture_27.jpeg\n",
      "✅ Moved _page_11_Figure_22.jpeg\n",
      "✅ Moved _page_7_Picture_31.jpeg\n",
      "✅ Moved _page_11_Picture_52.jpeg\n",
      "✅ Moved _page_38_Picture_70.jpeg\n",
      "✅ Moved _page_17_Figure_15.jpeg\n",
      "✅ Moved _page_2_Picture_6.jpeg\n",
      "✅ Moved _page_16_Figure_55.jpeg\n",
      "✅ Moved _page_32_Picture_53.jpeg\n",
      "✅ Moved _page_110_Picture_11.jpeg\n",
      "✅ Moved _page_93_Picture_52.jpeg\n",
      "✅ Moved _page_15_Figure_24.jpeg\n",
      "✅ Moved _page_3_Picture_7.jpeg\n",
      "✅ Moved _page_38_Picture_66.jpeg\n",
      "✅ Moved _page_4_Picture_22.jpeg\n",
      "✅ Moved _page_12_Picture_16.jpeg\n",
      "✅ Moved _page_11_Figure_19.jpeg\n",
      "✅ Moved _page_3_Picture_6.jpeg\n",
      "✅ Moved _page_110_Picture_10.jpeg\n",
      "✅ Moved _page_4_Picture_19.jpeg\n",
      "✅ Moved _page_3_Picture_18.jpeg\n",
      "✅ Moved _page_41_Picture_35.jpeg\n",
      "✅ Moved _page_10_Figure_22.jpeg\n",
      "✅ Moved _page_4_Picture_6.jpeg\n",
      "✅ Moved _page_44_Figure_6.jpeg\n",
      "✅ Moved _page_5_Picture_7.jpeg\n",
      "✅ Moved _page_7_Picture_47.jpeg\n",
      "✅ Moved _page_41_Picture_5.jpeg\n",
      "✅ Moved _page_93_Picture_24.jpeg\n",
      "✅ Moved _page_41_Picture_39.jpeg\n",
      "✅ Moved _page_9_Picture_21.jpeg\n",
      "✅ Moved _page_23_Picture_28.jpeg\n",
      "✅ Moved _page_21_Picture_3.jpeg\n",
      "✅ Moved _page_22_Picture_49.jpeg\n",
      "✅ Moved _page_23_Picture_23.jpeg\n",
      "✅ Moved _page_7_Picture_7.jpeg\n",
      "✅ Moved _page_7_Picture_21.jpeg\n",
      "✅ Moved _page_7_Picture_37.jpeg\n",
      "✅ Moved _page_11_Picture_54.jpeg\n",
      "✅ Moved _page_28_Picture_9.jpeg\n",
      "✅ Moved _page_38_Picture_76.jpeg\n",
      "✅ Moved _page_16_Figure_45.jpeg\n",
      "✅ Moved _page_17_Figure_25.jpeg\n",
      "✅ Moved _page_42_Picture_17.jpeg\n",
      "✅ Moved _page_19_Picture_38.jpeg\n",
      "✅ Moved _page_23_Picture_39.jpeg\n",
      "✅ Moved _page_3_Picture_13.jpeg\n",
      "✅ Moved _page_49_Figure_11.jpeg\n",
      "✅ Moved _page_11_Picture_58.jpeg\n",
      "✅ Moved _page_7_Picture_17.jpeg\n",
      "✅ Moved _page_23_Picture_15.jpeg\n",
      "✅ Moved _page_110_Picture_8.jpeg\n",
      "✅ Moved _page_15_Figure_9.jpeg\n",
      "✅ Moved _page_10_Figure_13.jpeg\n",
      "✅ Moved _page_95_Picture_25.jpeg\n",
      "✅ Moved _page_16_Figure_49.jpeg\n",
      "✅ Moved _page_2_Picture_15.jpeg\n",
      "✅ Moved _page_5_Picture_14.jpeg\n",
      "✅ Moved _page_21_Picture_57.jpeg\n",
      "✅ Moved _page_10_Picture_1.jpeg\n",
      "✅ Moved _page_110_Picture_9.jpeg\n",
      "✅ Moved _page_7_Picture_41.jpeg\n",
      "✅ Moved _page_24_Picture_2.jpeg\n",
      "✅ Moved _page_23_Picture_14.jpeg\n",
      "✅ Moved _page_4_Picture_13.jpeg\n",
      "✅ Moved _page_94_Picture_62.jpeg\n",
      "✅ Moved _page_108_Picture_2.jpeg\n",
      "✅ Moved _page_3_Picture_24.jpeg\n",
      "✅ Moved _page_4_Picture_25.jpeg\n",
      "✅ Moved _page_22_Picture_3.jpeg\n",
      "✅ Moved _page_93_Picture_79.jpeg\n",
      "✅ Moved dbs-annual-report-2024_meta.json\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024/dbs-annual-report-2024\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/1Q24_CFO_presentation\n",
      "✅ Moved _page_3_Figure_1.jpeg\n",
      "✅ Moved _page_7_Figure_1.jpeg\n",
      "✅ Moved _page_10_Picture_2.jpeg\n",
      "✅ Moved _page_5_Picture_2.jpeg\n",
      "✅ Moved _page_14_Picture_4.jpeg\n",
      "✅ Moved _page_15_Picture_5.jpeg\n",
      "✅ Moved _page_11_Picture_2.jpeg\n",
      "✅ Moved _page_4_Picture_2.jpeg\n",
      "✅ Moved 1Q24_CFO_presentation.json\n",
      "✅ Moved _page_4_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_2.jpeg\n",
      "✅ Moved _page_6_Picture_2.jpeg\n",
      "✅ Moved _page_13_Picture_2.jpeg\n",
      "✅ Moved _page_7_Picture_2.jpeg\n",
      "✅ Moved _page_12_Picture_2.jpeg\n",
      "✅ Moved _page_12_Figure_1.jpeg\n",
      "✅ Moved 1Q24_CFO_presentation.md\n",
      "✅ Moved _page_14_Figure_3.jpeg\n",
      "✅ Moved _page_9_Figure_1.jpeg\n",
      "✅ Moved _page_8_Picture_2.jpeg\n",
      "✅ Moved _page_13_Figure_1.jpeg\n",
      "✅ Moved _page_1_Picture_17.jpeg\n",
      "✅ Moved _page_8_Figure_1.jpeg\n",
      "✅ Moved 1Q24_CFO_presentation_meta.json\n",
      "✅ Moved _page_6_Picture_1.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_5_Figure_1.jpeg\n",
      "✅ Moved _page_2_Figure_1.jpeg\n",
      "✅ Moved _page_16_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/1Q24_CFO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update/3Q24_trading_update\n",
      "✅ Moved 3Q24_trading_update.md\n",
      "✅ Moved 3Q24_trading_update.json\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved _page_6_Picture_0.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_2_Picture_0.jpeg\n",
      "✅ Moved 3Q24_trading_update_meta.json\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved _page_4_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update/3Q24_trading_update\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation/1Q24_CEO_presentation\n",
      "✅ Moved 1Q24_CEO_presentation.json\n",
      "✅ Moved _page_1_Picture_8.jpeg\n",
      "✅ Moved _page_3_Picture_11.jpeg\n",
      "✅ Moved _page_2_Picture_10.jpeg\n",
      "✅ Moved _page_4_Picture_9.jpeg\n",
      "✅ Moved 1Q24_CEO_presentation.md\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved 1Q24_CEO_presentation_meta.json\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation/1Q24_CEO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation/2Q24_CEO_presentation\n",
      "✅ Moved 2Q24_CEO_presentation_meta.json\n",
      "✅ Moved _page_2_Picture_10.jpeg\n",
      "✅ Moved 2Q24_CEO_presentation.md\n",
      "✅ Moved 2Q24_CEO_presentation.json\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_1_Picture_11.jpeg\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation/2Q24_CEO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/4Q24_CFO_presentation\n",
      "✅ Moved 4Q24_CFO_presentation_meta.json\n",
      "✅ Moved _page_22_Picture_0.jpeg\n",
      "✅ Moved _page_13_Picture_4.jpeg\n",
      "✅ Moved _page_24_Picture_20.jpeg\n",
      "✅ Moved _page_7_Figure_1.jpeg\n",
      "✅ Moved _page_10_Picture_2.jpeg\n",
      "✅ Moved _page_18_Figure_1.jpeg\n",
      "✅ Moved _page_25_Figure_1.jpeg\n",
      "✅ Moved _page_18_Picture_2.jpeg\n",
      "✅ Moved _page_19_Picture_2.jpeg\n",
      "✅ Moved 4Q24_CFO_presentation.md\n",
      "✅ Moved _page_6_Picture_5.jpeg\n",
      "✅ Moved _page_17_Picture_3.jpeg\n",
      "✅ Moved _page_16_Picture_2.jpeg\n",
      "✅ Moved _page_29_Picture_0.jpeg\n",
      "✅ Moved _page_9_Picture_2.jpeg\n",
      "✅ Moved _page_28_Picture_1.jpeg\n",
      "✅ Moved _page_20_Picture_1.jpeg\n",
      "✅ Moved _page_14_Picture_2.jpeg\n",
      "✅ Moved _page_1_Picture_15.jpeg\n",
      "✅ Moved 4Q24_CFO_presentation.json\n",
      "✅ Moved _page_7_Picture_2.jpeg\n",
      "✅ Moved _page_12_Picture_2.jpeg\n",
      "✅ Moved _page_3_Figure_6.jpeg\n",
      "✅ Moved _page_15_Picture_2.jpeg\n",
      "✅ Moved _page_8_Picture_2.jpeg\n",
      "✅ Moved _page_11_Picture_4.jpeg\n",
      "✅ Moved _page_8_Figure_1.jpeg\n",
      "✅ Moved _page_26_Picture_2.jpeg\n",
      "✅ Moved _page_12_Picture_1.jpeg\n",
      "✅ Moved _page_27_Picture_3.jpeg\n",
      "✅ Moved _page_10_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_1.jpeg\n",
      "✅ Moved _page_28_Picture_2.jpeg\n",
      "✅ Moved _page_20_Picture_2.jpeg\n",
      "✅ Moved _page_14_Picture_1.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_6_Picture_6.jpeg\n",
      "✅ Moved _page_21_Picture_4.jpeg\n",
      "✅ Moved _page_5_Figure_1.jpeg\n",
      "✅ Moved _page_25_Picture_2.jpeg\n",
      "✅ Moved _page_6_Figure_1.jpeg\n",
      "✅ Moved _page_2_Figure_1.jpeg\n",
      "✅ Moved _page_23_Picture_2.jpeg\n",
      "✅ Moved _page_24_Picture_19.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/4Q24_CFO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation/3Q24_CEO_presentation\n",
      "✅ Moved 3Q24_CEO_presentation_meta.json\n",
      "✅ Moved _page_2_Picture_11.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_1_Picture_11.jpeg\n",
      "✅ Moved 3Q24_CEO_presentation.json\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "✅ Moved 3Q24_CEO_presentation.md\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation/3Q24_CEO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/2Q25_CFO_presentation\n",
      "✅ Moved _page_16_Picture_3.jpeg\n",
      "✅ Moved _page_17_Picture_2.jpeg\n",
      "✅ Moved _page_7_Picture_5.jpeg\n",
      "✅ Moved _page_23_Picture_21.jpeg\n",
      "✅ Moved _page_7_Figure_1.jpeg\n",
      "✅ Moved _page_26_Picture_6.jpeg\n",
      "✅ Moved _page_10_Picture_2.jpeg\n",
      "✅ Moved 2Q25_CFO_presentation.json\n",
      "✅ Moved _page_18_Picture_2.jpeg\n",
      "✅ Moved 2Q25_CFO_presentation_meta.json\n",
      "✅ Moved _page_1_Picture_13.jpeg\n",
      "✅ Moved _page_19_Picture_3.jpeg\n",
      "✅ Moved _page_14_Figure_5.jpeg\n",
      "✅ Moved _page_23_Picture_20.jpeg\n",
      "✅ Moved _page_12_Picture_4.jpeg\n",
      "✅ Moved _page_6_Picture_5.jpeg\n",
      "✅ Moved _page_4_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_2.jpeg\n",
      "✅ Moved _page_21_Picture_0.jpeg\n",
      "✅ Moved 2Q25_CFO_presentation.md\n",
      "✅ Moved _page_13_Picture_2.jpeg\n",
      "✅ Moved _page_19_Picture_4.jpeg\n",
      "✅ Moved _page_15_Picture_2.jpeg\n",
      "✅ Moved _page_28_Picture_0.jpeg\n",
      "✅ Moved _page_11_Picture_4.jpeg\n",
      "✅ Moved _page_3_Figure_5.jpeg\n",
      "✅ Moved _page_3_Picture_6.jpeg\n",
      "✅ Moved _page_13_Picture_1.jpeg\n",
      "✅ Moved _page_27_Picture_2.jpeg\n",
      "✅ Moved _page_10_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_1.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_22_Picture_2.jpeg\n",
      "✅ Moved _page_5_Figure_1.jpeg\n",
      "✅ Moved _page_14_Picture_6.jpeg\n",
      "✅ Moved _page_20_Picture_5.jpeg\n",
      "✅ Moved _page_25_Picture_2.jpeg\n",
      "✅ Moved _page_6_Figure_1.jpeg\n",
      "✅ Moved _page_24_Picture_2.jpeg\n",
      "✅ Moved _page_24_Figure_1.jpeg\n",
      "✅ Moved _page_7_Picture_6.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/2Q25_CFO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/1Q25_CFO_presentation\n",
      "✅ Moved _page_3_Figure_1.jpeg\n",
      "✅ Moved _page_10_Picture_2.jpeg\n",
      "✅ Moved _page_5_Picture_2.jpeg\n",
      "✅ Moved _page_5_Picture_3.jpeg\n",
      "✅ Moved _page_11_Picture_2.jpeg\n",
      "✅ Moved _page_4_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_2.jpeg\n",
      "✅ Moved _page_14_Picture_2.jpeg\n",
      "✅ Moved _page_16_Picture_5.jpeg\n",
      "✅ Moved _page_6_Picture_2.jpeg\n",
      "✅ Moved _page_13_Picture_2.jpeg\n",
      "✅ Moved _page_7_Picture_2.jpeg\n",
      "✅ Moved _page_12_Picture_2.jpeg\n",
      "✅ Moved 1Q25_CFO_presentation.md\n",
      "✅ Moved _page_15_Picture_2.jpeg\n",
      "✅ Moved _page_1_Picture_14.jpeg\n",
      "✅ Moved _page_8_Picture_2.jpeg\n",
      "✅ Moved _page_8_Picture_1.jpeg\n",
      "✅ Moved _page_7_Picture_1.jpeg\n",
      "✅ Moved 1Q25_CFO_presentation.json\n",
      "✅ Moved _page_10_Figure_1.jpeg\n",
      "✅ Moved _page_9_Picture_1.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_17_Picture_0.jpeg\n",
      "✅ Moved _page_5_Figure_1.jpeg\n",
      "✅ Moved _page_6_Figure_1.jpeg\n",
      "✅ Moved _page_2_Figure_1.jpeg\n",
      "✅ Moved 1Q25_CFO_presentation_meta.json\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/1Q25_CFO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update/1Q25_trading_update\n",
      "✅ Moved 1Q25_trading_update_meta.json\n",
      "✅ Moved 1Q25_trading_update.json\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved _page_6_Picture_0.jpeg\n",
      "✅ Moved 1Q25_trading_update.md\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_2_Picture_0.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved _page_4_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update/1Q25_trading_update\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update/1Q24_trading_update\n",
      "✅ Moved 1Q24_trading_update.json\n",
      "✅ Moved 1Q24_trading_update_meta.json\n",
      "✅ Moved _page_1_Picture_0.jpeg\n",
      "✅ Moved 1Q24_trading_update.md\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_2_Picture_0.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved _page_4_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_0.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update/1Q24_trading_update\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation/1Q25_CEO_presentation\n",
      "✅ Moved _page_4_Picture_10.jpeg\n",
      "✅ Moved _page_1_Picture_9.jpeg\n",
      "✅ Moved _page_2_Picture_10.jpeg\n",
      "✅ Moved 1Q25_CEO_presentation_meta.json\n",
      "✅ Moved _page_2_Picture_6.jpeg\n",
      "✅ Moved 1Q25_CEO_presentation.json\n",
      "✅ Moved 1Q25_CEO_presentation.md\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_13.jpeg\n",
      "✅ Moved _page_5_Picture_0.jpeg\n",
      "✅ Moved _page_2_Picture_1.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation/1Q25_CEO_presentation\n",
      "🧩 Found nested folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation/2Q25_CEO_presentation\n",
      "✅ Moved 2Q25_CEO_presentation.json\n",
      "✅ Moved _page_3_Picture_26.jpeg\n",
      "✅ Moved _page_3_Picture_17.jpeg\n",
      "✅ Moved 2Q25_CEO_presentation_meta.json\n",
      "✅ Moved _page_2_Picture_9.jpeg\n",
      "✅ Moved 2Q25_CEO_presentation.md\n",
      "✅ Moved _page_3_Picture_34.jpeg\n",
      "✅ Moved _page_3_Picture_14.jpeg\n",
      "✅ Moved _page_0_Picture_0.jpeg\n",
      "✅ Moved _page_4_Picture_0.jpeg\n",
      "✅ Moved _page_3_Picture_28.jpeg\n",
      "✅ Moved _page_1_Picture_10.jpeg\n",
      "🗑️ Removed empty folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation/2Q25_CEO_presentation\n",
      "🎉 Cleanup complete — all nested Marker folders flattened!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Root directory where all your PDF output folders live\n",
    "root_dir = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All\")\n",
    "\n",
    "# Loop through all subfolders (e.g. 1Q24_CEO_presentation, 2Q24_CFO_presentation, etc.)\n",
    "for folder in root_dir.iterdir():\n",
    "    if folder.is_dir():\n",
    "        inner = folder / folder.name  # e.g. All/1Q24_CEO_presentation/1Q24_CEO_presentation\n",
    "        if inner.exists() and inner.is_dir():\n",
    "            print(f\"🧩 Found nested folder: {inner}\")\n",
    "\n",
    "            # Move all files and folders from inner to outer\n",
    "            for item in inner.iterdir():\n",
    "                dest = folder / item.name\n",
    "                # Handle name collisions safely\n",
    "                if dest.exists():\n",
    "                    print(f\"⚠️ Skipping {item.name} (already exists in {folder.name})\")\n",
    "                    continue\n",
    "                shutil.move(str(item), str(dest))\n",
    "                print(f\"✅ Moved {item.name}\")\n",
    "\n",
    "            # Remove the empty inner folder\n",
    "            try:\n",
    "                inner.rmdir()\n",
    "                print(f\"🗑️ Removed empty folder: {inner}\")\n",
    "            except OSError:\n",
    "                print(f\"⚠️ Could not remove {inner} (not empty or permission issue)\")\n",
    "\n",
    "print(\"🎉 Cleanup complete — all nested Marker folders flattened!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e2aac",
   "metadata": {},
   "source": [
    "## Finalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d73130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: Demo PDF.pdf ---\n",
      "Running CLI command for JSON output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 12:17:18,288 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.17s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 12:17:25,667 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 12:17:25,667 [INFO] marker: Total time: 6.414623975753784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 12:17:33,520 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 12:17:40,272 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 12:17:40,272 [INFO] marker: Total time: 6.147237777709961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "--- Finished processing: Demo PDF.pdf ---\n",
      "\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        # Since we are not capturing output, stdout/stderr will be None here,\n",
    "        # but the error will have already been printed to the console.\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f6815",
   "metadata": {},
   "source": [
    "Advanced MD5 Verification (Use This)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20f648c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: Demo PDF Merge.pdf ---\n",
      "⏭️  Skipping Demo PDF Merge.pdf: outputs up-to-date (md5 match).\n",
      "    → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "--- Processing file: Demo PDF.pdf ---\n",
      "⏭️  Skipping Demo PDF.pdf: outputs up-to-date (md5 match).\n",
      "    → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # If outputs exist and the checksum matches, skip re-parsing\n",
    "    if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "        try:\n",
    "            saved_md5 = checksum_file.read_text().strip()\n",
    "        except Exception:\n",
    "            saved_md5 = \"\"\n",
    "        if saved_md5 == current_md5:\n",
    "            print(f\"⏭️  Skipping {pdf_path.name}: outputs up-to-date (md5 match).\")\n",
    "            print(f\"    → {dest_dir}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"♻️  Detected content change for {pdf_path.name} (md5 mismatch). Re-parsing…\")\n",
    "            print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        # Write/update checksum sidecar to record the source PDF state used for these outputs\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)  # ensure it exists in case Marker changed behavior\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e08b31",
   "metadata": {},
   "source": [
    "## OCR Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98a37be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Backend: easyocr ===\n",
      "Extracted NIM (Commercial vs Group):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Quarter",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "NIM (%)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "021b7d05-07a3-48fc-8ef6-718623c585e3",
       "rows": [
        [
         "0",
         "2Q24",
         "2.19"
        ],
        [
         "1",
         "3Q24",
         "2.75"
        ],
        [
         "2",
         "4Q24",
         "2.13"
        ],
        [
         "3",
         "1Q25",
         "2.77"
        ],
        [
         "4",
         "2Q25",
         "2.14"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>series</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>NIM (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2Q24</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3Q24</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4Q24</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Q25</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Q25</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "series Quarter  NIM (%)\n",
       "0         2Q24     2.19\n",
       "1         3Q24     2.75\n",
       "2         4Q24     2.13\n",
       "3         1Q25     2.77\n",
       "4         2Q25     2.14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Net interest income ($m):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Quarter",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "Net interest income ($m)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9054678a-7953-4956-bb00-4c4f63920c45",
       "rows": [
        [
         "0",
         "2Q24",
         "3684.0"
        ],
        [
         "1",
         "3Q24",
         "3434.0"
        ],
        [
         "2",
         "4Q24",
         "3637.0"
        ],
        [
         "3",
         "1Q25",
         "3505.0"
        ],
        [
         "4",
         "2Q25",
         "3647.0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Net interest income ($m)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2Q24</td>\n",
       "      <td>3684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3Q24</td>\n",
       "      <td>3434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4Q24</td>\n",
       "      <td>3637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Q25</td>\n",
       "      <td>3505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Q25</td>\n",
       "      <td>3647.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter  Net interest income ($m)\n",
       "0    2Q24                    3684.0\n",
       "1    3Q24                    3434.0\n",
       "2    4Q24                    3637.0\n",
       "3    1Q25                    3505.0\n",
       "4    2Q25                    3647.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHUCAYAAAAOWbTgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnXd8FMX7xz+719N7gYSEXkIHAQVEeleaiH4VFEUQUeCHIKCIAkpRekdFmjRpgvQq0kTR0EvokIT0fsnd7e78/jh22bvckaAUo8+b15G73dmZ2dnZ3fnM88wMxxhjIAiCIAiCIAiCIIgSCv+kM0AQBEEQBEEQBEEQfwcStgRBEARBEARBEESJhoQtQRAEQRAEQRAEUaIhYUsQBEEQBEEQBEGUaEjYEgRBEARBEARBECUaErYEQRAEQRAEQRBEiYaELUEQBEEQBEEQBFGiIWFLEARBEARBEARBlGhI2BIEQRAEQRAEQRAlGhK2BEH853j99dcRHR39pLPxRDhw4AA4jsOBAwceeVrR0dHo1KnTI0/nv8qSJUvAcRyuX7/+pLNCEI+d5557DtWrV3/S2SAI4h8ECVuCIIgHYN68eViyZMkjT+eLL77Apk2bHnk67jhy5Ag+/fRTZGZmPrE8EMTD5HHduwRBEMSTgYQtQRDEA/BfErafffYZCVviXwMJW4IgiH83JGwJgigRFBQUQJKkJ50NgvjbCIIAq9X6pLPx2Pmv38N5eXlPOgvEAyJJEgoKCp50NgiCKCYkbAmihBEfH4++ffsiNDQUBoMBMTExWLx4sUMYq9WKTz75BPXq1YOvry88PT3RtGlT7N+/v1B8q1evRr169eDt7Q0fHx/UqFEDM2fOBABcvXoVHMdh+vTphY47cuQIOI7DqlWrlG1//vkn2rdvDx8fH3h5eaFly5Y4duxYoWMzMzMxdOhQREdHw2AwICIiAr1790ZqaiqAe+NAV69ejY8//hilS5eGh4cHsrOzYbPZcOHCBSQmJharvDZt2oTq1avDaDSievXq2Lhxo8twkiRhxowZiImJgdFoRGhoKPr374+MjAwlTHR0NM6ePYuff/4ZHMeB4zg899xzDuc1ZMgQREZGwmAwoEKFCpg8eXKhxrwkSZg5cyZq1KgBo9GI4OBgtGvXDr///jsAgOM45OXlYenSpUo6r7/+unJ8ceoAANy+fRtdunSBp6cnQkJCMHToUFgsliLL7NNPP8Xw4cMBAGXLllXyII/lFAQB48ePR/ny5WEwGBAdHY3Ro0cXK+6lS5dCq9Uq8QPAr7/+inbt2sHX1xceHh5o1qwZDh8+XChPHMfh8uXLeP311+Hn5wdfX1+88cYbMJvNDmF3796NJk2awM/PD15eXqhcuTJGjx5dZN4eBdevXwfHcfjqq68wY8YMpczOnTsHALhw4QJ69OiBgIAAGI1G1K9fH5s3by4Uz9mzZ9GiRQuYTCZERERgwoQJD1UkchyHQYMG4fvvv0flypVhNBpRr149HDx4sFDY4tS/+93DgP2ad+jQAf7+/vD09ETNmjWV545MccpGHmd8+PBh/N///R+Cg4Ph6emJrl27IiUlRQlX1L1bXCRJwqeffopSpUrBw8MDzZs3x7lz5xAdHe1wj8r5+vnnnzFw4ECEhIQgIiJC2b99+3Y0bdoUnp6e8Pb2RseOHXH27NlC6T3MMvg7yPVDfp7K133Hjh0O4dzNXyDfv67i/OGHH1CtWjWYTCY8/fTTOH36NABg4cKFqFChAoxGI5577jm3Y8lPnDiBZ555BiaTCWXLlsWCBQsKhbFYLBg7diwqVKgAg8GAyMhIjBgxotAzS30fxMTEwGAwFDpHgiD+wTCCIEoMd+7cYRERESwyMpKNGzeOzZ8/nz3//PMMAJs+fboSLiUlhYWHh7P/+7//Y/Pnz2dTpkxhlStXZjqdjv35559KuF27djEArGXLlmzu3Lls7ty5bNCgQezFF19UwjRu3JjVq1evUF4GDhzIvL29WV5eHmOMsTNnzjBPT08WHh7Oxo8fzyZNmsTKli3LDAYDO3bsmHJcTk4Oq169OtNoNKxfv35s/vz5bPz48eypp55S8rZ//34GgFWrVo3Vrl2bTZs2jU2cOJHl5eWxa9euMQCsT58+RZbXzp07Gc/zrHr16mzatGnso48+Yr6+viwmJoZFRUU5hH3rrbeYVqtl/fr1YwsWLGAffvgh8/T0ZE899RSzWq2MMcY2btzIIiIiWJUqVdjy5cvZ8uXL2a5duxhjjOXl5bGaNWuywMBANnr0aLZgwQLWu3dvxnEcGzx4sENar7/+OgPA2rdvz2bMmMG++uor9sILL7DZs2czxhhbvnw5MxgMrGnTpko6R44ceaA6YDabWaVKlZjRaGQjRoxgM2bMYPXq1WM1a9ZkANj+/fvdltvJkyfZyy+/rMQp5yE3N5cxxlifPn0YANajRw82d+5c1rt3bwaAdenSxSGeqKgo1rFjR+X3woULGcdx7KOPPlK27d27l+n1evb000+zqVOnsunTp7OaNWsyvV7Pfv31VyXc2LFjGQBWp04d1q1bNzZv3jz21ltvMQBsxIgRSrgzZ84wvV7P6tevz2bOnMkWLFjAPvjgA/bss8+6Pd9HiVxfq1WrxsqVK8cmTZrEpk+fzm7cuMHOnDnDfH19WbVq1djkyZPZnDlz2LPPPss4jmMbNmxQ4khMTGTBwcHM39+fffrpp+zLL79kFStWVK7ltWvXCqWbkZHBzp8/z3Jyclzm6/bt2w6/AbDq1auzoKAgNm7cODZ58mQWFRXFTCYTO336tBKuuPXvfvfwrl27mF6vZ1FRUWzs2LFs/vz57P3332etWrVSji9u2Xz33XdKvWjRogWbPXs2GzZsGNNoNKxnz55KuPvduw/CiBEjGADWuXNnNmfOHNavXz8WERHBgoKCHJ5Jcr6qVavGmjVrxmbPns0mTZrEGGNs2bJljOM41q5dOzZ79mw2efJkFh0dzfz8/Byu5cMuA8bsz9+UlJQiP5mZmQ7HAWC1atVSnu8zZsxg5cqVYx4eHiw1NVUJ16dPn0LPVsbu3b/OcdasWZNFRkaySZMmsUmTJjFfX19WpkwZNmfOHFatWjU2depU9vHHHzO9Xs+aN2/ucHyzZs1YqVKlWEhICBs0aBCbNWsWa9KkCQPAvv32WyWcKIqsTZs2zMPDgw0ZMoQtXLiQDRo0iGm1WvbCCy8UylPVqlVZcHAw++yzz9jcuXMd3pkEQfyzIWFLECWIN998k4WHhzs0JBhjrFevXszX15eZzWbGGGOCIDCLxeIQJiMjg4WGhrK+ffsq2wYPHsx8fHyYIAhu01y4cCEDwM6fP69ss1qthRpyXbp0YXq9nl25ckXZlpCQwLy9vR1ExSeffMIAODTMZCRJYozdaxSXK1dOOSeZBxG2tWvXZuHh4Q6NNFnMqxtfv/zyCwPAvv/+e4fjd+zYUWh7TEwMa9asWaG0xo8fzzw9PdmlS5ccto8cOZJpNBp28+ZNxhhj+/btYwDY+++/7/b8GWPM09PT5TkWtw7MmDGDAWBr165VwuTl5bEKFSoUKWwZY+zLL790KZpiY2MZAPbWW285bP/ggw8YALZv3z5lm1rYzpw5k3Ecx8aPH+9wvhUrVmRt27Z1OHez2czKli3LWrdurWyTG8bq+ssYY127dmWBgYHK7+nTpzMALCUl5b7n97iQ66uPjw9LTk522NeyZUtWo0YNVlBQoGyTJIk988wzrGLFisq2IUOGMAAOQj85OZn5+voWuka3bt1i3bt3ZzzPMwBMp9Oxdu3asaVLl7IrV66wc+fOsY8++og1btzYIS8AGAD2+++/K9tu3LjBjEYj69q1q7KtuPXP3T0sCAIrW7Ysi4qKYhkZGQ5xqOtAcctGFnWtWrVyOH7o0KFMo9E43Pvu7t3icufOHabVagt14Hz66aeFnklyvpo0aeLwfM3JyWF+fn6sX79+heL29fV12P4oykDulCrq41xOAJher2eXL19Wtp08eZIBUDrk5PgfRNgaDAaH+iu/b8LCwlh2drayfdSoUYXqerNmzRgANnXqVGWbxWJhtWvXZiEhIUqH5PLlyxnP8+yXX35xSH/BggUMADt8+LBDnnieZ2fPni10DgRB/PMhV2SCKCEwxrB+/Xp07twZjDGkpqYqn7Zt2yIrKwt//PEHAECj0UCv1wOwu86lp6dDEATUr19fCQMAfn5+yMvLw+7du92m27NnTxiNRnz//ffKtp07dyI1NRWvvvoqAEAURezatQtdunRBuXLllHDh4eF45ZVXcOjQIcUFcf369ahVqxa6du1aKC1nV7U+ffrAZDI5bIuOjgZjrMhJYBITExEbG4s+ffrA19dX2d66dWtUq1bNIewPP/wAX19ftG7d2qFc69WrBy8vL5cu3M788MMPaNq0Kfz9/R3iaNWqFURRVFw6169fD47jMHbs2CLP35kHqQPbtm1DeHg4evTooRzv4eGBt99+u8hzuR/btm0DAPzf//2fw/Zhw4YBALZu3VromClTpmDw4MGYPHkyPv74Y2V7bGws4uLi8MorryAtLU05l7y8PLRs2RIHDx4s5G47YMAAh99NmzZFWlqaUr/8/PwAAD/++OM/ajxn9+7dERwcrPxOT0/Hvn370LNnT+Tk5CjnnpaWhrZt2yIuLg7x8fEA7GXeqFEjNGjQQDk+ODgY//vf/wql89lnnyEvLw/r16/H4cOHMW3aNOTl5eH1119H+fLlUa1aNaxevRpjxowpdOzTTz+NevXqKb/LlCmDF154ATt37oQoig9U/2Sc7+E///wT165dw5AhQ5RrJSPX/wcpG5m3337b4f5p2rQpRFHEjRs33F6TB2Xv3r0QBAEDBw502P7ee++5PaZfv37QaDTK7927dyMzMxMvv/yyQ/lpNBo0bNhQedY8qjIYMWIEdu/eXeRn6tSphc6lVatWKF++vPK7Zs2a8PHxwdWrV4tZgoVp2bKlg+tyw4YNAdjvF29v70LbndPSarXo37+/8luv16N///5ITk7GiRMnANifzVWrVkWVKlUcyrxFixYAUOj53qxZs0LvCIIgSgbaJ50BgiCKR0pKCjIzM7Fo0SIsWrTIZZjk5GTl+9KlSzF16lRcuHABNptN2V62bFnl+8CBA7F27Vq0b98epUuXRps2bdCzZ0+0a9dOCePn54fOnTtj5cqVGD9+PADg+++/R+nSpZWGQUpKCsxmMypXrlwoT1WrVoUkSbh16xZiYmJw5coVdO/evVjnrM7rgyI35ipWrFhoX+XKlR0a4HFxccjKykJISIjLuNTl6o64uDicOnXKQby4iuPKlSsoVaoUAgICiozTmQepAzdu3ECFChUKiWVX1+hBuHHjBnieR4UKFRy2h4WFwc/Pr5CQ+Pnnn7F161Z8+OGHDuNqAXuZAXbx446srCz4+/srv8uUKeOwX96XkZEBHx8fvPTSS/jmm2/w1ltvYeTIkWjZsiW6deuGHj16gOfd9+Wmp6f/5QmdAgIClI4kdzjX5cuXL4MxhjFjxrgUmYD9WpYuXRo3btxQGvZqXF3L//u//0PVqlWV38888wwGDRqE+Ph4nDlzBv7+/qhXrx4EQSh0rKt7pVKlSjCbzUhJSQHP8w/0DHJ13leuXAGA+64/+iBlI3O/evGwkOu2c90PCAhwqKNqnM9frvPys9MZHx8fAI+uDKpVq/aXRZtz/HIaf6eMneOUOyEjIyNdbndOq1SpUvD09HTYVqlSJQD28e2NGjVCXFwczp8/X+SzWebvvHcIgniykLAliBKCbH169dVX3QqBmjVrAgBWrFiB119/HV26dMHw4cMREhICjUaDiRMnKg1LAAgJCUFsbCx27tyJ7du3Y/v27fjuu+/Qu3dvLF26VAnXu3dv/PDDDzhy5Ahq1KiBzZs3Y+DAgfcVCg8DZ2vto0KSJISEhDhYpdW4axA5x9G6dWuMGDHC5X65sfV3eJA68KgpyrosExMTg8zMTCxfvhz9+/d3aDTK5/Pll1+idu3aLo/38vJy+K22fqlhjAGw15mDBw9i//792Lp1K3bs2IE1a9agRYsW2LVrl9vju3Xrhp9//rlY5+TM/v37i5yIyLkuy+f+wQcfoG3bti6PcRZQxSE8PBwffvghVq5cicTERERFRaFDhw7o0qULnnnmGVitVnz99dfYvHmzYn0vLn+l/v2Ve/ivlE1R9eJJ4e66L1++HGFhYYXCa7Vah3APuwyysrKQn59fZL71en2hzrfixO/uuSCKosvt7uJ8mNdTkiTUqFED06ZNc7nfWUQ/rvcOQRAPHxK2BFFCCA4Ohre3N0RRRKtWre4bdt26dShXrhw2bNjg0NBw5f6q1+vRuXNndO7cGZIkYeDAgVi4cCHGjBmjNJzatWuH4OBgfP/992jYsCHMZjNee+01h7x5eHjg4sWLheK/cOECeJ5XGg/ly5fHmTNn/lIZPAhRUVEA7llI1Djns3z58tizZw8aN25cZKPGXcOtfPnyyM3NLfLalC9fHjt37kR6evp9rbau0nmQOhAVFYUzZ86AMeYQl6trVNz05XglSUJcXJyDZTApKQmZmZlKucsEBQVh3bp1aNKkCVq2bIlDhw6hVKlSAKC4Nfr4+BR5Pg8Cz/No2bIlWrZsiWnTpuGLL77ARx99hP3797tNZ+rUqX/Z8lSrVq0HPkZ22dfpdMW6lsWpx4Dd1fTkyZMYN24cQkNDceLECaxatQpz5sxRwoSEhGDWrFmFjnWVxqVLl+Dh4aF07hS3/rlDvuZnzpxxG8eDlM2DUNzOGHfIdfvy5csOHTRpaWnFrjvy+YeEhNz33B5VGQwePNih09IdzZo1w4EDBx44fn9/f5drXz9Ml3A1CQkJyMvLc7DaXrp0CQAUF+fy5cvj5MmTaNmy5d+uAwRB/LOhMbYEUULQaDTo3r071q9f71IYqpd1kHu71b3bv/76K44ePepwTFpamsNvnucVi4t6GQStVouXX34Za9euxZIlS1CjRg0Hy4xGo0GbNm3w448/OizJkJSUhJUrV6JJkyaKi1337t1x8uRJl8vuFKc3vrjL/YSHh6N27dpYunQpsrKylO27d+9WllqR6dmzJ0RRVFyt1QiC4NBQ8/T0dNlw69mzJ44ePYqdO3cW2peZmam4fnbv3h2MMXz22WeFwqnP31U6D1IHOnTogISEBKxbt07ZZjab3bqQOiM3FJ3z0KFDBwDAjBkzHLbL1pCOHTsWiisiIgJ79uxBfn4+WrdurdS7evXqoXz58vjqq6+Qm5t73/MpLunp6YW2ydbg+y1HVK9ePbRq1eovfdy5od6PkJAQPPfcc1i4cKHLuux8LY8dO4bjx4877HflYdCvXz8cO3YMb7zxBjp06IAxY8bg3LlzOHPmDFavXo2dO3fixo0beOmllwode/ToUQcX/Vu3buHHH39EmzZtoNFoHqj+uaNu3booW7YsZsyYUahuyfX/QcrmQXB37xaXli1bQqvVYv78+Q7b1Z0GRdG2bVv4+Pjgiy++cBgiIiOf26Mqg78zxrY4lC9fHllZWTh16pSyLTEx0e0ya38XQRCwcOFC5bfVasXChQsRHBysjBfv2bMn4uPj8fXXXxc6Pj8/n9YXJoh/EWSxJYgSxKRJk7B//340bNgQ/fr1Q7Vq1ZCeno4//vgDe/bsURr1nTp1woYNG9C1a1d07NgR165dw4IFC1CtWjUHAfHWW28hPT0dLVq0QEREBG7cuIHZs2ejdu3aDtY4wO6OPGvWLOzfvx+TJ08ulLcJEyYo64cOHDgQWq0WCxcuhMViwZQpU5Rww4cPx7p16/Diiy+ib9++qFevHtLT07F582YsWLCgSOtXfHw8qlatij59+hQ5gdTEiRPRsWNHNGnSBH379kV6ejpmz56NmJgYh3Jo1qwZ+vfvj4kTJyI2NhZt2rSBTqdDXFwcfvjhB8ycOVOZhKlevXqYP38+JkyYgAoVKiAkJAQtWrTA8OHDsXnzZnTq1Amvv/466tWrh7y8PJw+fRrr1q3D9evXERQUhObNm+O1117DrFmzEBcXh3bt2kGSJPzyyy9o3rw5Bg0apKSzZ88eTJs2DaVKlULZsmXRsGHDYteBfv36Yc6cOejduzdOnDiB8PBwLF++HB4eHvctMxm5UfjRRx+hV69e0Ol06Ny5M2rVqoU+ffpg0aJFyMzMRLNmzXD8+HEsXboUXbp0QfPmzV3GV6FCBezatQvPPfcc2rZti3379sHHxwfffPMN2rdvj5iYGLzxxhsoXbo04uPjsX//fvj4+GDLli3Fyq/MuHHjcPDgQXTs2BFRUVFITk7GvHnzEBERgSZNmjxQXI+auXPnokmTJqhRowb69euHcuXKISkpCUePHsXt27dx8uRJAHYxsnz5crRr1w6DBw+Gp6cnFi1ahKioKAcBAQBPPfWUy7RiYmIQExNz3/xUr14dbdu2xfvvvw+DwYB58+YBgEMnTHHrnzt4nsf8+fPRuXNn1K5dG2+88QbCw8Nx4cIFnD17VukYKm7ZPAju7t3iEhoaisGDB2Pq1Kl4/vnn0a5dO5w8eRLbt29HUFBQsayBPj4+mD9/Pl577TXUrVsXvXr1QnBwMG7evImtW7eicePGilB+FGXwd8bYFodevXrhww8/RNeuXfH+++/DbDZj/vz5qFSpUqGJxR4GpUqVwuTJk3H9+nVUqlQJa9asQWxsLBYtWgSdTgcAeO2117B27VoMGDAA+/fvR+PGjSGKIi5cuIC1a9di586dqF+//kPPG0EQT4DHOgczQRB/m6SkJPbuu++yyMhIptPpWFhYGGvZsiVbtGiREkaSJPbFF1+wqKgoZjAYWJ06ddhPP/1UaCmGdevWsTZt2rCQkBCm1+tZmTJlWP/+/VliYqLLtGNiYhjP84XWwJT5448/WNu2bZmXlxfz8PBgzZs3V9ZfVZOWlsYGDRrESpcuzfR6PYuIiGB9+vRRlhCRlwr54YcfCh37IMv9MMbY+vXrWdWqVZnBYGDVqlVjGzZscLskxaJFi1i9evWYyWRi3t7erEaNGmzEiBEsISFBCXPnzh3WsWNH5u3tXWhZjJycHDZq1ChWoUIFptfrWVBQEHvmmWfYV199pSw9wZh9yZMvv/ySValShen1ehYcHMzat2/PTpw4oYS5cOECe/bZZ5nJZCp0vsWpA4zZl2t5/vnnmYeHBwsKCmKDBw9WljAqarkfxuxLGJUuXVpZOkZeasNms7HPPvuMlS1blul0OhYZGclGjRrlsCwJY4XXsWWMsV9//VVZAkpeBubPP/9k3bp1Y4GBgcxgMLCoqCjWs2dPtnfvXuU4ebkQ52V85KVO5Lzt3buXvfDCC6xUqVJMr9ezUqVKsZdffrnQMkyPC7m+fvnlly73X7lyhfXu3ZuFhYUxnU7HSpcuzTp16sTWrVvnEO7UqVOsWbNmzGg0stKlS7Px48ezb7/91u06tg8KAPbuu++yFStWsIoVKyrPDVf1pDj17373MGOMHTp0iLVu3Zp5e3szT09PVrNmTYdlY4pbNvL1/+233xyOldNX5/9+925xEQSBjRkzhoWFhTGTycRatGjBzp8/zwIDA9mAAQOKzJc6f23btmW+vr7MaDSy8uXLs9dff91huaVHUQZ/Fbl+OBMVFVXoWbxr1y5WvXp1ptfrWeXKldmKFSvcLvfjHKe7+8VVfWrWrBmLiYlhv//+O3v66aeZ0WhkUVFRbM6cOYXyabVa2eTJk1lMTAwzGAzM39+f1atXj3322WcsKyuryPMkCKJkwDH2hGdWIAiixFCnTh0EBARg7969TzorBEE8RDiOw7vvvvtAbrWEnczMTPj7+2PChAn46KOPnnR2CIIg/rPQGFuCIIrF77//jtjYWPTu3ftJZ4UgCOKJ4GpGYXm8eVEzYxMEQRCPFhpjSxDEfTlz5gxOnDiBqVOnIjw83OWkMwRBEP8F1qxZgyVLlqBDhw7w8vLCoUOHsGrVKrRp0waNGzd+0tkjCIL4T0PCliCI+7Ju3TqMGzcOlStXxqpVq2A0Gp90lgiCIJ4INWvWhFarxZQpU5Cdna1MKDVhwoQnnTWCIIj/PDTGliAIgiAIgiAIgijR0BhbgiAIgiAIgiAIokRDwpYgCIIgCIIgCIIo0ZCwJQiCIAiCIAiCIEo0JGwJgiAIgiAIgiCIEg0JW4IgCIIgCIIgCKJEQ8KWIAiCIAiCIAiCKNGQsCUIgiAIgiAIgiBKNCRsCYIgCIIgCIIgiBINCVuCIAiCIAiCIAiiREPCliAIgiAIgiAIgijRkLAlCIIgCIIgCIIgSjQkbAmCIAiCIAiCIIgSjfZxJMIYc/mb4zgwxsBxnMt96r/FjdvdMXI4Ob0HScdVGsXJ2+NGfY5A8cvwn4wkSQAcz+HvnI+7a+kcxrluOh+n3q7+zhgDz/N/O58EQRAEQRAEQRSfxyJsAUdhwBiDKIrgOE75OIfleb5YwkAWEzKyqHCVthxW/fthpvNPQRRFAHZhpdFonnBu/jqMMUiS5CAyH5ZYlOMG7t/BIv91lQ939UiSpH90/SAIgiAIgiCIfxuPTdgKgoC4uDiYzWb4+voiKioKGo1GEQcpKSm4ceMGTCYTKleuDAAPJMpkkeJOUEiShIyMDFy/fh08z6NKlSowGAwPfB5FpfOkUQvwf2oeH4Tc3FxcvnwZPM+jUqVK8PT0/MtxOXeuXL16Ffn5+ahYsSK0Wi1u3ryJEydOQKPRoG7duoiMjHQow6NHj+LKlSto27YtQkJCANg7ES5cuACj0Yhy5cqB5/l/RbkTBEEQBEEQREnisbXAc3NzMXDgQLRt2xYvv/wyrl+/DuCeu+bWrVvRoUMH9OvXD9nZ2cpxaiurqw/HccjLy8PmzZuxZs2aQvtlOI7D3r170b59e7z00ku4c+dOIQudu49MRkYGli5digMHDhQrb4/7AwBZWVlYsWIFdu/e7fLciluuj+IjSdIDn09sbCyef/55dOnSBefPny923tXh1MjbLl++jJdeegkTJkyAIAj4888/0a1bNwwaNAgDBgxAt27dcOrUKaUjIy0tDUOHDsV3330HrVYLjuPA8zxEUcS0adPQrVs3nD17VkmDIAiCIAiCIIjHx2M1LZnNZmRkZCA2NhZz5syB1WoFYBedFosFmZmZyMnJAWMMGo0GkiQpH1EUIYqi8l3ebjabMWLECPTt2xenT59WBJQsSGRkIaLT6RRLrdrNVI7flQgDgNTUVPTt2xdDhgzBzZs3HcJIkgSbzeaQXzl9dRg533Kc6vNw93EWaXK86vOUP6mpqejXrx8GDx6Ma9euKeeuPs45LlEUIQiCcu7qbfJ2+be6PJzTlsO6266Ox/n8GGNuy4Lneej1euh0OvA8r8SpLld1HIIg3LcOMsZgtVoxf/58XLx4EZ06dYLJZMLq1asRFxeH8ePHY/To0bhw4QLWrFmjdH5s2bIFly5dwhtvvAF/f38lPoPBgE6dOuH69euYNWsWLBZLse8HgiAIgiAIgiAeDo/NFVmNJElYuXIlOnfujFatWhU5cVNaWhri4+Oh1WoRHh4Of39/Rcykpqbi119/hdlsRkFBAdLS0uDn5wetVlsonmbNmmHdunXQ6XQIDw8Hx3HIyclBfn4+TCYTjEYjbt26hbS0NAQFBSE8PBwajQaCICAhIQG///47bDYbcnNzkZaWpggcOY9JSUngOA7h4eEIDAxURKAgCMjKyoIgCPD19UVKSgpycnJQunRp+Pr6gjGG3Nxc3L59G/n5+QgJCUFISAh0Op2DFdJsNiMpKQmZmZkwGAwICQlBYGAgNBoNbDYb7ty5g99//x0WiwVms1nJo6txxAUFBcjJyYFWq4W3tzeSk5ORlJQEf39/hIWFQavVIjMzE/Hx8dDr9YiMjFTcgGUxmZ2djTt37iA7Oxuenp4IDg5GcHAwOI5TOh3MZjN0Oh10Oh1u3rwJT09PlCpVClqtFqIoIjExEampqUp55+bmwmazwcPDA0ajETVq1MCqVavAcRwqVqyo5F2O18vLC0lJSUhJSYGPjw9Kly4NrVZ7X6vppUuXsG7dOkRERKB58+aw2Wy4evUq9Ho96tWrh9zcXGi1Wly5cgWSJCE9PR2LFi1CjRo10KFDB4dJuRhjaNy4McqXL48tW7bgrbfewtNPP/2AdwRBEARBEARBEH8L9hiQJImlpaWx+vXrMwCM4zjG8zx77rnnWFJSEpMkic2dO5fxPM+qVq2qbDObzezbb79l1atXZ76+vszf35899dRTbOXKlSw/P58lJSWxtm3bMi8vL8bzPAsKCmINGjRgp06dYqIoMkmSlPRFUWSbN29mNWrUYE2bNmXXrl1jFouFjRo1ilWrVo2NGjWKffLJJ6xMmTLM19eXlSlThn366acsJyeHnTt3jjVo0IAZDAbG8zwrVaoUa926Nbtz5w4rKChgy5YtY7Vq1VLyWK9ePbZ8+XJWUFDABEFgN2/eZM2aNWN169Zln3/+OatcuTILDAxkH374IbNYLOzIkSOsXbt2LCgoiPn6+rJy5cqxTz75hKWnpzNBEJjFYmG//PILa9OmDQsODma+vr4sKCiI1alThy1btowVFBSwuLg41qhRIyWP4eHhrEWLFuzmzZtMEAQmCIJDeaxfv57VqFGD9ezZk82cOZNVrlyZ+fr6ssjISDZ58mS2a9cu1rRpU+bn58eCg4NZr169HOLat28fe/bZZ5U8+/v7s1q1arEVK1Ywi8XCbDYbmzJlCqtRowbr27cve+ONN1hAQACrVq0aO3PmDEtLS2Njx45l0dHRzNfXl5UvX55NnDiRvfrqq6xatWps/vz5TBAEdvjwYVanTh1Wv359FhsbywRBYNOnT2dVq1Zl77zzDps8eTIrX7488/PzY6VLl2aDBw9m6enpTJIk5aOuhzabjX3++edMq9Wy3r17M4vFwvLz81mPHj2Yt7c3++WXX9jOnTuZh4cH69WrF7NYLGzevHnM19eXfffdd8xmsyllKYoiE0WRWa1W9t577zGNRsOGDx/uUNYEQRAEQRAEQTx6HqvFVp5NtmrVqrh27RqOHTuGJUuWYMiQIQ4T7rC7bqXr16/HBx98gPz8fMTExECn0yE2NhZDhgyBj48P6tWrh5ycHMX91GazITs726U7qmydPX/+PIKCgpRZbhMTE3HhwgUkJSXBYDCgcuXKuHXrFq5du4Zp06ahUaNGiIiIQG5uruLOa7FYFAvsli1bMGTIEOTm5iImJgZ6vR6nTp3CkCFD4OHhgeeffx42mw1xcXFISUnBlStXYDabodFoEBkZiStXruDtt9/GhQsXEBkZiejoaJw+fRqTJ0+GIAgYM2YMsrOzMWLECBw/fhwVK1ZE+fLlcePGDZw5cwbDhw9HVFQUwsLCkJubC8aY4tqdl5dXyCVbJjMzE+fPn8fVq1fx888/o1KlSuA4DpcvX8a4cePg4+ODoKAgVK5cGadOncL69etRrVo1jBo1Crdv38bgwYNx4cIFVKpUCdHR0bh48SLOnj2LMWPGoH79+ihfvjySk5Nx7tw5XL9+HTabDYIgICoqCgEBAViwYAG+/PJLSJKEKlWqwNvbG9OmTUN+fj7MZjNSU1PBcRzMZjMuXboEjUaD/Px8cByH5ORkXLhwAYmJiTAajahUqRL0ej0uXbqERYsWoW7dunj11VeV664mPz8fu3fvBsdxaNiwIXieh1arRcOGDbF161YsW7YMBQUFkCQJDRo0QGpqKr777jtUq1YNHTt2VCY8Y8xx/HbDhg2xcOFCHDhwAJmZmQgICPh7NwtBEARBEARBEMXmsYyxdRYXnTt3RosWLWCxWDBv3jycPXu20BIpOTk5WLhwIXJzc9GxY0ds3rwZGzduRNeuXZGWloZvvvkGnp6eWLFiBapUqQIA6NOnD/bv349q1ao5iA9Xy7ioYcy+XMv8+fOxceNGfPPNNwgICEBeXh7Onj2LChUqYPny5QgKCoJGo8GYMWOwefNmmEwmzJ8/H1lZWWjdujW2bNmCzZs3o2fPnsjKysKiRYuQn58P4N6YVD8/P0yfPh2zZs1C27ZtsXLlSly4cAHR0dFYu3YtNm3ahHHjxoHneSxfvhzXr1/HrVu3EBcXBy8vL0yYMAHLli3Djz/+iNdeew0tWrRAfn4+ypQpg+XLlysu1h988AE2b96M8PDw+14bm82GESNGYPPmzZg/fz68vLxQUFCASpUqYdOmTdiwYQMaNGgAURQRGxuruGLXr18fL774ItatW4dVq1Zhzpw58PLyQnJyMm7duuWwNE9BQQF69uyJJUuW4OOPP4YgCPj+++9hsVjQqVMnbNmyBZs2bcKIESOUTglX7unOy/1IkoQJEyZg8+bNWLlyJSIjI2Gz2XDixAm3gv7OnTu4fPky9Ho9qlSpotS5V155Ba+88gp27dqFgwcPok+fPujVqxd++uknXLhwAW+++SYCAwMhiiJsNpvDGGeO41CuXDmYTCbcuHEDCQkJ9y1zgiAIgiAIgiAeLk9kjK23tzdGjBiBEydO4Pbt2/jqq69Qp04dZT/Hcbh58yYuXrwIjUaD1q1bQ6fTAQDatm2LjRs3IjY2VhlPq9FowPM8jEYjgoKClLGPxV12heM4lC9fHk2bNoWHhweqVKmC0NBQpKenIz8/HzzPIyAgQBFWXl5eCAwMRFxcHM6dOwee59GmTRvo9XowxtCuXTusXbsW58+fR3JysjJxFcdx6Ny5M/r166dYI48ePQpJklCnTh2ULl0aFosFTZo0QUhICJKSknDq1CnUr18fvr6+uHbtGoYMGYK6deuiSZMmePnll1GnTh34+vqC4zgEBQUp5eTn54fAwEBFCLoT9D4+Pmjbti28vLwQFRUFX19f5OTkoFWrVoiMjIQoioiMjARgt1QzxlClShXMmTMHN2/exOnTp7FixQrs378fZrMZPM/DZrMp5coYQ1BQEIYPH650QPz222+Ij4+HTqdDjx49EBoaCgDo3r075s+fr8yYXRRhYWFo164dPDw8UKFCBZQpUwY3b95Efn6+Yrl2JiUlBRkZGTAajco4aI7jEBISglmzZuHOnTsAgPDwcGRlZeGbb75B1apV0bFjR5w6dQrLli1DamoqGjRogFdeeQU+Pj4AgJCQEJhMJmRnZyMxMRHVq1cv1jkQBEEQ7hEEAWfPnkVAQAAiIiKQmZmJS5cuoUqVKrh58ya8vb0RFRX10NY4JwiCIEouT0TYchyHBg0a4I033sDUqVOxZcsWpKSkOLyYZFEpCAKmTJmCefPmgeM4xd02NzcX2dnZ8PPzU6xnaoveg64l6uvrC4PBAI1GA51Op4gyURQdJiOS09FoNMjOzkZeXh4YY5g+fTq+/fZbRbAKgoCcnBykpqYiODgYABRRqNVqldl9MzMzwXEcDh48iPbt2ytppqWlQZIkJCQkIDIyEiNHjsS4ceNw584dbN26Fdu2bYOHhwcaNWqEKVOmoEaNGsrMwwCUv/J5uHrpM8ZgNBrh6ekJnueh0WiU8IGBgUoZymJZLoOcnBxMmjQJK1euRFpaGhhj8PDwcLm0DgAEBQUhJCQEPM+DMYa8vDzYbDbodDqEhoYq6fj4+MDX17dY14sxBk9PT5hMJmXtWLljwZWIl5Hds/V6PQwGg0MniMlkQtmyZRVr75YtW3D+/HlMnToVZrMZffr0QXJyMsqWLYv169cjPj4en332GTQaDQwGgzIhVk5OTrHOgSAIgrg/f/zxB8aOHQvGGNatW4fx48djy5YtqF+/PjIzM2G1WrF+/Xr4+fk96awSBEEQT5gnImwBu1gaMGAAdu/ejT/++AP79+93WLrFaDRCq9VCo9GgSZMmKFu2rLLcC2MMBoMBQUFBDsvhAHCwUBa3B1eSJEXUqT/OcajTYoxBq9VCp9PBbDajSZMmKF++vENYo9GIsLAwRWQyxmAymRzEtzxms1y5cmjbtm2htOrVqwcAeO211/DMM8/g0KFD+Pnnn/HHH3/gxo0b2Lt3LyZOnIglS5Y4nLuzsHcuC3V5Obv4ynlz3ia73v7444+YM2cOdDodXn/9dbRt2xY8z+PNN99EXl4eNBqNQ5pGo1ERx7KA1Ov1sFgsSE1NdRDM6jWMi0LuYFDn31nUOp+DXq9XwskCVi4r+ZoD9uWdvv32W1SpUgWdO3fGvn37cPHiRQwePBivv/462rdvjx07dmDo0KHKmG253OU0CIKwwxiDzWZDTk4O/P39wXEcsrOzwfO8MvzBaDSS1Y0oRPXq1dG1a1dcuHABjDGkpKQgNDQUvr6+aNeuHY4fPw4PD48nnU2CIAjiH8BjXcdWDWMMYWFhGD58OLy8vAqNsY2IiEBwcDBEUUSFChUwatQojBw5EuXKlVPcWL28vBxEjVoYP+wGkuxOLOddkiSEh4cjPDwcPM+jTJkyGDlyJD766CNUqVIFt2/fBgDFAinnSS3wPDw8ULlyZQCAh4cHBg4ciNGjR6Nz5864ffs2cnNzERISghMnTuCDDz7A7Nmz0bp1a3z77bfYs2cPunTpAgC4fv16Ifdbq9VaaP3av4sc34kTJ2CxWBATE4Nx48ahY8eO4HleyYNzmmrxyRhDmTJlEBYWBpvNho0bNyI9PR1msxkbN25EfHz8Q8uvK/z9/eHh4YGCggLk5eW5rSebN2/G2bNn0a9fP4SGhiIlJQWSJCEsLAyBgYHw9vZGVlYWzGaz4kFgtVqh1+sREhLySM+BIEoakiTh008/RdeuXbFjxw7Ex8fj+eefR7du3bB9+3a88cYbynwEBCHDGMPpM6cxffZ0SJyEEaNGICMnA74Bvrh95zYmT50MjV6DPEsebMz2WD8CE+7rHUQQBEE8fh6LxdaV0JSFTocOHdClSxesXLnSIVxoaCief/55zJo1C3PnzkVeXh68vb2xaNEiJCQkoH///tDr9RAEQVlf9dChQ5g7dy46d+6MqKgoh/TV6aq3u3OflcPKYlmv18NoNEKSJPz000+wWCzo2bMnnn/+eXz55ZdYsGABrFYrgoODsWjRIly/fh1vvPEGDAaDw/mq09RqtejevTs2b96MI0eO4P3338fTTz+NDRs24NChQ6hVqxaGDBmCnJwcbNiwASkpKbh69So6d+6MnJwcHD9+HABQq1YtmEwm5Ofnw2AwgDGGXbt2Qa/Xo1u3bggJCSl0DdxZOe/XKSC7/IaFhYHjOJw9exYTJ06Ev78/Vq5cCYvFAp7nUVBQ4LD+rnM6ISEh6NGjB7766its2rQJ165dg6enJ06ePFlkp8T9rpfzNXY1eVhISAjCw8MRFxdXaJIn2c08JSUFixcvRsWKFdG5c2cwxpT1gFNTU5Gbm4v8/HzFFZrjOMTHxyM/Px/h4eGIiIhwm3+C+C/CcRy6dOmirPWdkZGB+Ph48DwPHx+fIocQEP9ddgTtQIU5FRCvi4fJw4QQbQiyMrPg4+MDbaYWCdoEjEkZAz7t8fbT50l5mBw5GUG6oMeaLkEQBOGex+qKrNVqFaEH2Bs7JpMJw4YNw9GjR3H79m3FjVWr1eK9997DrVu3sG3bNkybNk0RmO3bt8fw4cMVV+VmzZrhxIkTOH78OE6fPo2KFSsiKirKQSSpBapGo3FwHTUYDMr4TwCKm7E6rI+PD55++mnEx8djy5YtOHr0KJ577jkMGjQI169fx5YtWzB9+nQAdjfrNm3aYOTIkYpbqk6ng16vd3BxZoyhVatWGDFiBGbPno3169fjhx9+AM/zqFKlCiZNmoTQ0FAEBwdj/PjxGDduHH7++Wfs3bsXPM9Dp9OhefPmGDp0KHQ6Hfz9/fH000/j+vXr2LVrF44fP46nnnoKwcHBLl2N9Xo9tFqtQ/mor5Hc2JTTki3WXbt2xcaNG3Hy5EnMnDkTJpMJbdq0gZeXF86ePYvY2FjFiiuXrRyfHNf777+PtLQ0rFu3Dn/++SdCQkLw9ttvY/369bh06ZISXrZyq5fZ4ThOcVV3vmbqa+lKJPv5+aFevXo4f/48YmNj0alTJ6UDQ/77008/4ezZs/jiiy+U8dENGzZEVFQUVq9ejVOnTiE5ORlvvvkm/P39wRjD+fPnUVBQgFq1aiEwMPBv3ysE8W9CkiRs3boVN27cQFJSEn788UeUKVMGkiRBq9XCx8eH3JAJl2RpsrCk8RJ4895POisOTEyYiDwpD0EgYUsQBPFPgWOPoZucMQar1YqTJ08iNzcXZcuWVSyqsuvq2bNnkZaWBg8PD9SpUwc6nQ6iKCI/Px9Hjx7FH3/8AZvNhtq1a6NJkybw9fVVhFJWVhZ27dqF8+fPo1SpUujcuTNCQkKUMZjyhEzJycm4ePEidDodatasCQ8PD1y8eBFJSUkICAhATEwMNBoNBEHAn3/+iby8PERHRysiOSkpCdu3b8etW7dQvnx5dO7cGV5eXsjNzcWvv/6KP/74AxaLBXXr1kXjxo3h7+8PADCbzTh58iSsVisqV66sWDxl92ur1YqzZ8/i4MGDyMzMRNmyZdGsWTNlNmKO4yAIAq5du4ajR4/i6tWr8PDwQExMDJ555hn4+fkpjcKUlBRs3boVN2/eRLly5dChQwdlTJs8bpYxhsTERFy8eBFarRZ169aF0WhEfn6+ks8KFSqgdOnSkCQJly5dwp07d+Dn56fM9nvr1i3s3bsXCQkJqFevHpo0aYLbt28jJSUFISEhqFSpEq5fv47bt2/D29sbtWrVUoSozWbDyZMnwfO8MtFSqVKlYDKZ0KFDB1y6dAlTpkzB4MGDkZaWhrNnz4LjONSqVQve3t64evUqbt26BS8vL9SqVUux3J85cwYZGRkIDQ1FpUqVXI6/ZYxh/fr16NOnD5o3b441a9Yo47MYY8jPz8dnn32GhIQETJkyBWFhYUodPXz4ML777jtkZGSgdu3aGDhwIEJCQmCz2dCnTx/8+OOPWLhwIV577TUlTWqsEwRwx3IHb257E2mpaShVqhQMBgMyMjKg0WhQu05tJCQkoExkGXD847lfvDXeGBQ6CAbeUHRg4onBGMOwm8PwacSn8NH4POnsODA+fjx6B/VGlCGq6MAEQRDEY+GRCVu1xSw/Px+XLl1SJlFSEldN1iMf404IyOHkCaSKO1mQu0mTinsOriaPck5bHU7915Xb7JMUOkWt53u/49xdJ1euxvebiRmwTxL13nvv4c6dO6hUqRI+//xz+Pj44Ny5c3jvvfeQl5eHKVOmoGnTpg+UP1dlLu9X5y89PR0DBw5ETk4Ovv76a5QuXVrZzxiDxWIBAIdZk+U4BEGAKIoO1vfU1FQMGDAAkiRhwYIFCA8PR7ly5ZSlgNR5IIj/IifyTmBP1h78L+h/AAMYGDjcvSfUt4bz7ava5zBMBJx9nyo8g9Mzhzkeq943KXESxkeMh7/W/y+fE/HoUQtbZ4ttXl4eMjMzAQCBgYHK8xoo/MyXkVcjSEtLgyAI8PPzU+bqcA5nNpuRmZmpLPenjh8AJiRMIGFbAmCMQRAE5Ofnw9vbG5IkKZNUGgwGFBQU2N3atU9sLlXiHwpjDFlZWdi3bx/q1KmDyMhI7Nq1C2lpaQgICEBGRgYCAgLQpk0bqj//IB7plZCFwqVLl9CxY0flJUQQBQUFkCQJaWlp6NixIziOgyiKyqRXo0aNeuAlmx4Ei8UCSZLw0ksvKcsvPWgfj9rN3WKxgOM49OzZEzqdDuvXr0ezZs0APPjSUwTxb8RX44sIfQREUVSEps1mg2AToNPpoNPpHMbaymP61eP11R+r1aoMd5C9crQarcOwBTmc1WpVluTieR4m3vSES4P4K0iShPz8fKxfvx5Lly7FzZs3wfM8ypcvj7fffhsdOnRQln1z9tSRJAnHjx/HzJkzcerUKdhsNoSFhaFXr154/fXXFc+d/Px8rFixAitXrkR8fDy0Wi0qVaqEd999Fy1atFDqJVEykCQJ48ePx8GDB/Hxxx+jfPnyGDt2LC5duoQKFSrgypUrmDNnDurWrUsd0EQhtm7dii1btmDTpk34+uuvYbVasXLlSrRq1QpZWVm4evUqWrVq9aSzSah4pMJWbpT4+fmhU6dOyMvLe5TJESUAdaM1KysLt27dQk5ODhizL4UUGRmJgIAAJfzDftGorewpKSmwWCyIiIhQGsMPguwifufOHfA8j9DQUGi1WnAch9DQ0EeSf4Io6XAch8zMTPz444/Yu3cvEhMTERoaijZt2uCFF16At7d3oYnuACji9eDBg/jhhx9w9epVmEwmNGjQAL1790apUqUKHWexWDBx4kQcOnQIAwYMQPfu3R/7+RIPD0mSsGzZMowePRq5ubmKiL169SpOnDiBb7/9Fh06dHCY1wGwv2+uX7+OgQMH4vz58/D394ePjw/++OMPxMbGQhRFDBo0CIwxLFy4EGPHjkVBQQH0ej0kScLVq1fxxx9/YOnSpWjevPmTLALiAeE4Dm3atEFCQgIKCgoQFRWF4cOHY968eTCZTEhOTsZvv/2GunXrPumsEv9AOnTogOPHj6Nhw4bIz8/HU089hZ9++gkDBgzAl19+if79+yurnRD/DB65xZbjOERGRmL27NmPMimihCH3oNtsNuTm5kIURXh5ecFoNCoTiD2O9OXJa/6KAJUbTbKLvdyTr14X+Um7nxPEPwnGGPLy8jB69GgsW7YMNptNsaht3rwZx44dw5QpU1y6hzLGsG3bNgwaNAh37tyBh4cHBEHA7t27cejQISxevBjh4eEO9+VPP/2EefPmITMzE506dXoSp0w8JBhjyMjIwOLFi5Gbm4smTZpg+PDhyMjIwNixY3Hjxg189913aNWqFYxGI4B7w1QYY9i3bx/Onz+P0NBQLF++HBUqVMCECRPw7bffYs2aNejTpw/y8/OxePFiWCwWtGzZEkOHDsWdO3cwZswYJCYmYtmyZWjatCm5HZYgGGM4cOAAbt68iZycHKxduxZxcXF48cUXsWfPHlSsWLHQCgkEIbNuyzrsPrwbnBeHfcf2oUnTJmjZuSUyrBnIkXJQtV5V5Eg5fz8hBsdhOW7CGHgD9Jx9UlpqW7rmkT6d5UIn1x3CHUajEd7e/6zZLh8m9OAhCNjH1d7tTDpy5AhWrVoFSZLQo0cPNGjQAHv37sWuXbuwatUq9OzZ08EqJgtVi8WCBQsWICkpCS1btsQnn3yCa9euYcSIEThw4AB27dqF3r17Q5Ik5ObmYvXq1Rg3bhwyMjKUifPofiy5yMtEGQwGlCtXDkOGDEH79u0hCAIOHz6MRYsWITU1FTabDSbTPVdzeZJGec3x0qVLo06dOvDy8kLjxo2xZMkSWK1WiKKIlJQUeHp6onz58vjggw/QokULiKKIffv24fvvv0dCQoLd5V2rLTwenPhHkiqk4miFo0j3Tcda41r7eNpwLVgUQ2LrRFy5cgVPP/00JidOfmx5kpiE7gHdUdlU+bGlSTw4FmbBzw1+xjOLn4FFZ4FJa8Kf/J/geR6/Zf0GoY+AL5K/cDjG3Vw2xVnGsqgwNmZDkDYIH5f6mDTVfXhkwpYaEATx78LdEkpq6L4nnGGMQfnHGE6cOAGNRoOqVati8uTJKFWqFFq2bIkTJ04gLS0N165dw3PPPVeogWCxWJCSkgKO49CtWzc0atQINWvWxLJly7Bv3z7cuXMHwL3J4bZv3w7G2F8aZkD8M4mOjsa2bduQl5enrH9stVqRkJAAjuMQHR2tjLlWd6wzxtC4cWNlDfOlS5eiUqVKWLlyJXieR7NmzeDt7Y0qVapg165dyMvLc1jVIDk5GQBQoUKFx+JRRDw8btluoXHTxngp8KXCO8MAPP3Ys4SjuUfxR94fJGz/4YhMRLApGF9V/gpMYsrws/T0dMTftq/DHhERAf8Af/CcY+cpA4MoiABnf4ZIouS6fcQBRoMREpNgtVjd5oXX8CjQF+CrO19RO6sIyJ+GIIgiYYxh+/btWLNmDd555x089dRT+O6773D+/Hk0bdoUu3btwoABA1CjRg166BKF4O7+A4C+ffuiY8eOEEURISEh4HleEZ8ajQaBgYEuZ7f38PBA7dq1cerUKfzyyy9o0aIFbt68ibi4OHh6eqJmzZoA7LPl/v777/Dz80P//v2xZMkS3Lx587GfM/FwYYwpa5rLruo2mw3r16/Hzz//DG9vb2XyPjVyXapZsybGjRuHYcOGYfjw4dBqtbBarWjdujX+7//+T5lE0MvLS4lfFEWsWbMGR44cQWBgIF566aV7wpYecyWGIF0QyhnKFdpenI7a4ljT1PHdL6y8/7rlOpJtyUXGR/wz4GBfnjMjMwMLFizA999/r3SyRkREYMCAAXjttddgMBiUYWhg9nqQlZWFvn374vLlyy7jNhqNmD9/PpKTkzFq1ChIkuQy3DPPPIPPpn8GwGlVAaIQJGwJgigW2dnZCAwMxMGDB1GuXDlMnToVPj4++PXXX1G+fHl8/fXXmDVr1pPOJvEPg+PsS/PI64oHBwcjKChIaVQWFBTgm2++QUZGBqpVq4annnqqUByy6B0xYgSuX7+OdevW4cCBAzCbzbBarRg6dKgyC7ler8eLL76I7t27IyIiAsuWLSOL7b8Aee132Spis9mwdu1ajBgxQqkDLVu2LHScfO3v3LmDVatWwWw2o0KFCggODsbJkyfx22+/YcOGDejfv7/DDPmSJGH58uX4+OOPIQgC3n//fTRu3Jg8AEog6pmxGWM4ffo0Dh06hMTERISFhaFJkyaoUaPGPVECR3GakJCAkydPOkw+KQ9vEEURQUFBqF+/PjiOQ3JyMmJjYx1WWuA4DgaDAY0aNYKnp+fjLwDibyNJEubOnYspU6bAarUqS0edO3cOI0eOhNFoRO/evR2Okd2Fr1y5gvPnzwO4V3fk95+npycEQUBOTg4uXrwIQRCUcPKzTvZGkbcXazzufxgStgRBFIvQ0FBcuHABXbt2xaFDhxAUFKSMjz548CBeffXVJ5xD4p8Ox3EOa5EXFBRgypQp+Pbbb+Hl5YWRI0ciLCzMrSUlNTVVWYNSnrtBFEVcv34dmZmZMJlMCAkJwYQJE6DT6ZCUlPS4T5F4DFitVixevBiffPIJ8vPz8e677+KDDz4otNasjCRJ+O6777Bv3z7UqFEDK1euROnSpbFkyRKMHDkSX331FVq1aoXKlSsr7oYLFizA+PHjYbPZMGzYMAwdOhQ6nY7GapdQ5Os6f/58TJkyBenp6RBFETzPIzAwEKNGjVI6N+TwMkeOHEGfPn1gs9mU669+RjVv3hzr1q2DXq/Htm3b8O677yrCVg4THh6Offv2oWzZso//5Im/TVpaGn744QdYLBZ069YNH330EXJycvDuu+/i7Nmz2LBhA3r27Okwvh+wr5X8xhtvICkpyaFTbtOmTbh58yZat26NypUrQ6/XY9iwYYrFVpIkJCQkYOPGjTCZTHjllVeU5w+Nr70/JGwJgigSq2TFirMrcKvULcz5bQ6MJiMq/K8CEhMTUbVqVWQcy0BE9wjsytr1WPNVw6MGSulLPdY0ib+Oep3anJwcTJo0CbNnz4bRaMSECRPQpUsXx3FKKstYZmYmRo8ejVOnTuHVV1/Fxx9/jMTERAwcOBDr1q1DqVKlMGHCBMW1mfj3wXEcrFYrvvvuO4wZMwaCIGDUqFEYPHhwoQalmoKCAhw/fhySJKFhw4YoW7YseJ5HixYt4Ovri5SUFFy4cAGVK1eGKIpYsGABPv30U/A8j7Fjx+Kdd95RZloma23JQ37uxMbGYsqUKUhJSUFMTAwqVqyIkydP4vr165gyZQqaNm2KWrVquRwKIbuZyqjXrw8ICIBGowHP8zh37hwEQYBWq3Vwi9fr9dQpUoLJz89HTEwMgoOD8c4776B69eoQRRFNmzbF2bNnkZ2drVhb1ZhMJrz//vvKtZckCdu2bcOSJUtQuXJlTJgwAX5+fqhTpw7q1aundPrm5ORg4MCBYIyhf//+6NatG3KR+wTOvORBwpYgiCJJFBIhthcxptcYZZt6/NHTrZ4GOCBLyLK7nbrxk3GeJVCeWAjs3iQv6l5ujuOU8SQSk+wjNe/uu2W9hYsFF/F+2PuP6rSJh8Xdy64WtZ9++ikWLVoEf39/TJw4ES+99JJiLRFFUWlEytf76tWrOHPmDPR6PV577TVEREQgKioKHTp0wNmzZ/HLL78gPz8f3t7etMzWvxTGGHbs2IFPP/0Uubm56Nu3L7p3765YQwwGA0JDQyGKIu7cuQPGGIKCgqDRaKDT6cDzPJKTk2G1WuHh4YGMjAxYrVbwPA+DwQBRFLFhwwaMGzcOBQUFeOedd9CpUydlYjKTyYTQ0FC7xYT0bYlCFEX8/PPPSE1NRZkyZbBs2TJUrVoVR44cQY8ePRQX4lq1ahU6tnnz5ti3b5+DS/OuXbvwxRdfoGzZshg1ahQMBgOsVivOnTsHwD6XwJtvvgng3vjw8PDwx3rOxMOjbNmyWLFiBaxWq9JhkZ+fj4sXLwIAqlatqnR+ycjvIPXwhaSkJEyYMAFWqxUjRoxAxYoVHTo8ZPG7YcMGbNy4ETVr1sTAgQPtHSNiYW8BojAkbAmCKBLGGCoZK6FHQI9CD1X1uCMZ9VgldTjGGARBcOj5Vo8lcbaGqOOQXXTkuE+bT2Nf9r6Hd5LEY8Fms2HWrFlYtGgRTCYTJk6ciBdeeAE2mw02m00RIFarFYIggOd56PV6CIKgrHtrs9kUl2bZ5U/uLSeryL+X1NRUTJo0CampqeA4DqtWrcK6deuU/XXq1MHatWuRkJCArl27Ijc3FwsWLECHDh3QrFkzbN++HXv27MHEiRNRr149zJ8/Hzk5OahYsSKqV6+OpKQkTJo0CdnZ2eA4DkuXLsWKFSuU+Bs1aoQ1a9bAaDTaO+SIEgPHcWjVqhVCQ0Oh1+tRsWJF8DyPUqVKwWAwgOd5mEymQhNAcRyHwMBABAYGKu+wmzdvYv369dBqtRg7diyqVKkCxhgyMzNx69YtcByHKlWqIC8vDzqdDhUqVIC/vz89l0o4Op0OWq1WmaV/4cKFOHLkCMLCwtC7d2+X61urvY8YY1i1ahVOnTqF5557Dp07d3ZYik6ueykpKZg3bx4YYxg4cCBKlbJ7pckuyFSP7g8JW4IgHhhJkiAIAhITE3Hu3DlIkoTo6GhUqFCh0Kykzsii5erVq7hy5Qr8/PwQExMDX19fh/GXZrMZly5dws2bNxEWFoaqVav+q9c8/rfCGAM4KAL00KFDmD17tmIpmzZtGmbMmKG8rIcNG4YXX3wRCxcuxLJly1CpUiXMnz8fZcqUQVRUFC5cuIB58+YhKCgISUlJ2LRpEwC7qPHw8HDpxkyUfBhjOH78OM6ePat4d+TmOrrm5eTkKGGzsrKQnZ0Nq9W+hMYrr7yCEydOYMOGDZgyZQo0Gg0kSUJYWBg++eQThIeHY8OGDYiLi1PqUE5OjsMspXL8RMmB4V5HbO3atVGnTh3l2SCKIn766SekpaWhVKlSqFu3bpHxiaKIuXPn4syZM3jxxRfRvn17RZwkJycjKSkJkiRh4sSJyMnJgUajQYMGDTB+/HjUr1//kZ4r8ehQW0rz8/Mxa9YsTJo0CTqdDiNHjiw06aFz5z/Hcbhz5w5WrFgBjUaDN954A76+vi7T2rlzJ06fPo06deqgQ4cObvNDuIaELUEQxUZuEGRnZ2Pq1Kn4/vvvkZaWBkmS4O3tja5du+KTTz5BaGioy+M5jkNSUhLGjRuHH3/8EdnZ2dDpdKhTpw4mT56M+vXrg+d5xMXFYfTo0crMt0ajEY0aNcLEiRNRq1YtEi0lDLmzQhAErFy5EmlpaQDsYx9PnjwJ4N7EUhkZGeA4DikpKco+WYAMHToUI0eOxLZt23Dw4EHYbDYUFBSgatWqGDhwoOIJ4MqLgCjZcByHcuXKYe7cuW6va0BAAAwGA8LCwjBjxgzYbDbUrVsXjDEEBgZi9uzZ6NKlCw4fPoyMjAyUK1cOnTp1Qo0aNcDzPKpVq4b58+c7WE/UaYWFhSkTuBAlA3lYjGztkq+nJEnYuHEjpkyZAp7n0b9/f0RHRxfy+HCuaxcuXMDq1avh7e2NAQMGwGg0Ksdcv35d6WwRBAGhoaFITEzEgQMHMGjQIKxdu1aZ3ZYoWcj1IC8vD5MnT8b06dNhMBjw8ccf48033yxUv9SWf9la+8svvyAuLg7lypXDs88+69KlOD8/H2vXroUoiujYsSP8/PyUmZSJ4kHCliCIYiOP/1iyZAmmTZumCA6O45CQkIBvvvkGXl5e+OKLL1y65ZjNZnz00Uf4/vvvodfrER4ejoyMDBw+fBiffPIJVq9eDZ7nMXLkSGzduhWenp6IiIhAamoq9uzZA7PZjNWrVyM0NNTtem/EPxPZXbhatWoYNGiQyzAcx6F69ergOA7169fHwIEDERERoaxf+r///Q+RkZFYuXIlLl68CL1ej7p16+KNN95A1apVCzVIPTw88OqrryI9PR3Vq1e/10glvVvi4DgOMTExiImJuW84xhiMRiN69eql/Jbx8/ND9+7d0bVrV4clW2Rq1qyprIfsLm51foiSgVqsSpIEURSxatUqjBw5EllZWXjrrbcwYMAAB28jV9dXEASsX78eiYmJ6NSpE+rWreswrCYwMBBvvvkmdDodXn31VQQFBWHTpk0YPXo0Tp8+jf3796Nv376P/oSJh448WdjEiRMxY8YMeHl5YdKkSejVqxf0er0SRi1kZeRO3Z07d6KgoAANGzZ0uV47YJ9L4s8//4SnpyeaNWtW6BlFFA0JW4IgHoicnBxs2LABVqsVHTp0wMyZM8FxHIYMGYKffvoJ27dvx/DhwxEcHAzAsefy+PHj+PHHHxXx2rdvX+zduxfDhg3DtWvXcP36deTk5GD//v3Q6/WYPn062rRpgx07dmDYsGE4fvw4du7cWWi9OOKfjWw10el0GDJkiMvx1MC9SaM4jkPnzp3RqVMnh5e6Xq9Hy5Yt0axZMxQUFIDjOJhMJqU3W5Ikh4amt7c3Pv74YyU9ueFB/HtxNaOtM3911myqOyUX9TNg6dKlGD16NPLz8zF48GCMHDkSXl5eSjhn5OdSVlYWfvrpJ/A8j44dOyozcctx169fH7Vq1YIoivD09ARjDC+99BLmzZuHuLg4XL58mbxISiiyt9GcOXNgs9nwwgsvICoqCsePHwfHcfD29ka1atVgtVpx+vRpiKKIypUrIygoCIC93XTixAloNBo0bNhQ8fxwrg+xsbFIS0tDhQoVUL58+SdxqiUeErYEQTwQjDE899xziIqKQq9evVCmTBkwxvDss89i27ZtEATBYQ0/dYPiyJEjyMvLQ2RkJF577TUEBQXh+eefR/Xq1eHh4YHIyEisX78eZrMZkZGRePbZZxEaGooXXngBCxYswJ9//okDBw7gf//7H3iOXHNKChzH4Yb1Bo6bj9tFqBt9wCSnWbPvzpjNwMBzvPKb4zhw/N2xtAX3XAs5jnOoF5IkORwr18k0Mc3tzN3EPwsLs2B56nIYOWPRgR8jF/IvgAc9g0oC6tmMf/jhB4waNQpWqxUjR47E0KFDHWazVbuSOs9Ue/HiRcTFxcHPzw8NGjRwSEMURUyfPh0//vgjYmJiMGPGDJhMJhQUFCiT4Mluy0TJIykpCdOnT0deXh4AYOnSpVi+fLmy/6mnnsKPP/6I27dv48UXX0Rubi6WLl2qdM4mJSUhKSkJBoMBVapUAVDYzZ0xpsxZUqZMGfj7+xdycSaKhoQtQRDFhuM4+Pv7Y/z48Q6z0FosFqXnsnr16vDz8ys0iY8gCIiLi4MgCAgKCsLevXtx8OBBaLVatG/fHm3btoXJZIKHhwd4nkdubi5SU1MRFRUFi8WC/Px8SJKE69evw2azuRVHxD8LjuNQwVgB1Tyq4aL14pPODgCgo19HeGm8nnQ2iGIwPHw47ljvPOlsFKKuZ12E62n5lpIAYwyiKOLs2bMYM2YMsrKyEBgYiCtXrmD48OEA7M+pF198EU2bNsWWLVuwa9cuREZG4r333lMss7GxsTCbzahYsSJKly7tkAbP89BqtYiNjcWFCxdQs2ZNNGnSRJml28vLC88888xjP3fi4XDs2DEkJCRAr9crw6CcZ9C+H2lpaRBFET4+PoXckNVu8klJSdDpdChVqpTDcC7qECk+JGwJgig2arEqr81WUFCAefPmYdu2bfD398c777wDg8HgMIug3LDIyMgAYJ+AY+jQocjLywPP81i7di2GDRuGkSNHomrVqggJCUFiYiI+/PBDdO/eHYcPH8bly5cB2CdvsNlswP0nXyb+QfhqfdEnuM+TzgZRwuA4DtGGaEQbop90VogSjiRJWLFiBW7dugXAvnTUsmXLFHGi0WhQs2ZNPPvss/j111+xaNEi1KtXD++8844Sh+xKHB4eDk9PT4f4OY5Djx49sHbtWvz555/48MMPYTQaYTabwfM8Xn75ZTz99NOP74SJh0qTJk2wZcsWt/u9vb3h4eGB6OhorFu3DqIoolKlSorFtXr16ti0aRM0Go0ygZizWOV5Hh988AHeeOMNBAcHu1w2kSgaErYEQRQbZ3eYgoICzJ07FxMnTgTP8xgxYgSaNGniMqwscHmeR15eHpo0aYI2bdrgwIEDOHDgAObPn4927dqhTp06GDRoED7//HMcOnQIhw4dglarhV6vh8VicRDLBEEQxcHV84Iajf8dLBYL0tPTUadOHZdLgvE8r6xVGxERgfr166NKlSpKWFEU4efnh7p166JWrVoux2lHRERgwYIFmDRpEn799VeYzWaULVsWzz//PIYNG6ZYfomSA2MMAhMQHBaM4LDge+7pd13GGOwu7jzHQ5REGEwG1HuqHiRmt+raJBs4joOHtweeavSUvQ3E8RAhupzEsGLliqiIivZ4ISnxAIDAhEd/wv8CSNgSBFFs1A0Bs9mMSZMmYfr06TCZTBg7diz69+8PnU6njGlSNyB4noePjw9EUURYWBhmzpyJ6tWro0ePHmjXrh1u3bqFX3/9FfXr18d7772H6OhobNy4EWazGY0bN8bBgwexbds2eHl5KetYEgRBFBdXy2sQ/344joOnpyfmzp3rMHOtM/Ls6/3790ffvn3B8zz0ej04joNGo8GoUaMwfPhwaLVaZQZldX3ieR61a9fGsmXLkJCQgLy8PAQFBSEoKIisbyUQLaeFlVnxwc0PigzL4d6cEMDd9ZPBFR4yxQD7Ztd1ganUrnMYG7OhrKHsg5zCfxIStgRBPBCMMVgsFkyZMkWZIOPLL7/Eyy+/rMz0J4qiw7T3sutymTJllJls/f39AQDBwcHw8/PDzZs3YTabIYoikpOTERMTg5YtW8JkMiEvLw/r168HAFSsWNHeqLA9yVIgCKKkIUmS4hpIIuO/Q7wtHqfyT93b4K5P1Hr3IyMCyHcRzoai3z93l3JPQhKSrEkOu65YrsCb9y4iAuJJo+f0mBk908Fq+qTRclp6dhUBCVuCIB4Ixhg2bdqEWbNmQRAENGrUCBqNBuvXrwfHcTAajWjTpg04jsOePXuQk5ODunXromrVqmjYsCFMJhOSkpKwZcsW9OrVC7GxsUhMTIRWq0V0dDQSExPRq1cvXL9+HR9//DFeeeUVbN++HefPn4der8ezzz5LwvY/CrmTEg+Kus5kZ2cDAHx8fJQ5AmSoHv07KWcsh3BdOA7lHHrSWXGgkW+jJ50Fogg4joMOOpqosoTBMfLnIwiiCK4VXMOqtFUYGT4SqampeP755/Hbb78Vcu3jOA6RkZH45ZdfoNPp0LhxY9y4cQOTJ0/GkCFDkJ6ejldffRV79+6FyWRCdHQ0kpOTkZaWhpo1a2LTpk0ICAhAnz59sGnTJvj4+CAiIgK3b99GTk4OmjZtipUrVyI4OBhnC85if85+DA4b/ARLhnjUqJffsNlsuHHjBqKiohSXd1rAnnCH7C0CALdv38aQIUMgiiJmzZqFyMhIxYIrL0tGEARBlGxoETaCIIoNx3G4dOkSEhIS4OvrCz8/P/j6+jp89/b2VsbAent7w8/PD3q9HgDg6+uLKVOmoHXr1gCAixcvIjc3F/Xr18eMGTMQHh4Og8GAUaNGoVGjRrBYLLh48SIEQUDr1q0xffp0BAcHU0P0X47ahR2wu5BaLBYsXLgQrVq1wtdffw2bzUbjrIkiYYwhPj4eAwcOxI4dO7B9+3a88847uH37NiRJUpYtIwiCIEo+ZLElCKJI1Bbb3NxcJCUluZ2IRaPRICIiAgAQHx8Pm82GoKAg+Pr6gjH7DIK5ubk4efIkbt68ibCwMNSpUwf+/v4O8aWlpeHEiRNITk5G+fLlUb16dfj4+ChhzuSfIYvtvxTn15LVasWCBQvwySefoKCgAJ6envjss8/w9ttvK5O7EIQauWMkPj4eAwYMwK5duxzG+7dp0wbz589HWFgYNBqNMvaWIAiCKLnQGFuCIB4ILy8veHp6FrKayo1GuYHIGEN0dHShcWwcx8HPzw/NmjVTwqtnqpQFc3BwMNq3b+/gikqW2sfPk+r7lNO1Wq34+uuvMWbMGOTm5gIAcnNz8cknn4AxpszETfWCcCYhIQHvvPMOdu7cCcBu+QcAQRCwY8cODBgwAAsWLEDp0qXJ+v8A/JfuNfX7BwC9g4hi4bwyhHq7smQQ1aNHAglbgiCKhOM4XLFcwdasrU86Kwo3LDeedBb+MzivHezciaHulFCPW1TvU8el/lgsFhQUFKCgoAAWiwUWiwU5OTlITU1FSkoKTp8+jW+//RY5OTlKHKIoIicnB2PHjsX58+cRGhpa4oTJP3XpGefOqsd9fFFxFydOuW4dP34c+/fvd6if6rh2796Nt956C40aFT2Rz4Osnc1xHAwGAzw8PODh4QFPT0+lQ9DT0xMeHh7K0jI6nQ5arVZZQkb+aLVaRUTJabv6Lp+v+hzVnYvOa7Y6dyCq86wuP+e4/8uIoqh0vmq11GwmiofNZlM67teuXYuIiAg888wz0Gg0LtdBJh4O5IpMEESRWCQLDuYcRIFU8KSz4kBtj9qINEQ+6Wz8q1ELAudGsSxkRVFUPoIgIC8vD7m5ucjJyUFWVhbMZjOys7ORmpqKtLQ0pKamIj09HXl5ecjOzkZ2djZycnKQm5sLq9XqEJ8kScpHRt2od2XxV+ddnW9XqPc5N+CdRUFx4nUXh6t999vvKl/3i9vV9qLSK26crsK421bUR+70cJ60yXm/83f19Xa1z11aiYmJuHHD3gkmiqKSX61Wi6CgIOh0OmWZMVEUlTokf5fr3v3uA6CwRU89sRnHcQ6NWZ7nlY/JZILBYIDBYIDJZILRaFQ+er0eOp0OHh4e8PHxUYSxj48PvL294enpCYPBAJ1OB71er8SljsdkMjmIZDldV2Xt6rq7mjn6vyR05boA2IWKwWAgt3WiSORnh81mw6JFi/DJJ5/A19cX8+bNQ9u2bWld40fIYxG2zg2NB7mY/+ULX9SlKaps7teQK246j6L8i1Pl/svXnfj38zj7E92JL1cCUG6sFxQUwGq1KpZUq9WKnJwcpKenIz09HampqcjOzkZeXh7S0tIUsZqRkeFwXEFBAfLz8yEIQiGXcnW6cp7k7VqtFh4eHtDr9dDr9cjMzHSw2MrhAgIC0LRpU3h4eLgVTeptzvtd7XMWUs6/AdxXVDmLGVfxO39X50M+5mGEcxdGHlPq7njn6+H83d3fosI7C9TixnO/uFztV9eT27dvY/DgwThw4IAiUDiOQ8uWLTFlyhT4+/srnSmCIMBiscBsNiM3N1fpkMnLy4PZbEZ+fj5sNhsKCgqUbXl5eQ4fi8UCm80GQRAgCILyXb1NfT+ocXZ7lfMq/1YLKvW5ytdUbfGVP3q9HhqNBlqtVrEie3l5KX9lC7J8vxmNRmWbHE7+bjQaFeuy2sqs/qtusDvn0fna3O9c/wrqNB7mM1YURRw9ehQrV67EiBEjEB0d/dDiJopPcevHX6lHf7fuucJqtWLhwoUYO3YssrOzwRhDeHg4Fi1ahPbt29/3/iD+Oo9V2Mo9GMC9hoG7Xnhnd7b/IuoeYlc998URtupeZVc3kav41YvYq8M+LO73QpfT+y9fd+Lfiysx6bzfVaPQnRhUh3N28ZUtTbIlSraOms1m5OTkKBbS1NRUJCcnK8JUbszL1tbs7GyHhr/akuqcP3WeZQuVLLT0ej18fHzg5eUFLy8veHt7w8PDA/7+/ggODkZwcDCCgoKU/T4+PvDz84OnpycOHTqE4cOHIyUlBYwxaLVa+Pr6YubMmejatWshkeRcNs6/iwr3X8WdMFA3+tw1AIvTMLxfORfVEVucjlpXYQRBwK1bt/DOO+9g3759YIyhefPmWLBgAcqWLVtkvtzhbNGV7zX1PSeLZLmTx2w2K673VqsVVqtVEcTy/ai+Ty0WiyK28/PzHdz2Zdd9OU05L0VZmV2Vk7xPfR/JnSfqThL5u06nc7Asm0wmByux3CHl4eEBb29v+Pj4KOJYFtMGg0ER2/JxamuzXq9XLM2uOm7cWU2dr6X8bFK3PdXbnb8DUMpP3nb48GG8/fbbuHbtGp599lksWrQIkZGRigXeVZrOZe4qjKvn5v3y5u6+c3Xcg+Aqj8WJyzmM83k759tVfO7SuV/6zu9Rdx417jx43L2HXYV3dYyzJ5H8LHD2Mvrxxx8xceJEZGdnO3iLREREYNGiRWjVqhUAKPWceDg8NmGrbgRJkoSsrCykpKQgLy8Pvr6+CAkJgZeXl9ve4P8i8qURBAE5OTmwWq3KeJ3iiH7GGPLz85GbmwuNRgM/P79CglW+cXNzc1FQUACNRqMsXi+HeRTXQF3tbDYbsrKywBiDj48PDAbDf/q6E/9enK2W6r/3EwuyS5NzozgnJwcZGRlIT09HWloacnJykJ2djbS0NGVbRkaGYjnNz8+H1WpV/gIo9GyW05X/ys8MnucVl0mDwaC4Pvr5+cHf3x8BAQEICAiAh4cHAgICEBQUpPz18PBQrEVyw1V26XO24qmtavJfQRCwfv16DBs2DElJSQgKCsL06dPx4osvUqOAcIvc6ATsM7T3798fkiRh3rx5KFeu3AN1FBcXV/eyqwa+u8a1c4eR3GC2Wq2w2WzKR/4tW4ALCgqQm5uriGNZLMsCWb7v8/Pzle1y+0AOI3deyR9RFJX01G7a9+ugk8tSLdzUZaAOw3GcYu2Vhazsfq0ea2w0Gh1Esfxdfq7IlmZZSJtMJgeLsxy3bLl2tjirRbt8TnLHwK+//op+/frhypUryn5Z3EZHR7s1GNxPsLmqA+o4nMvXWTw6d2C6236/366Ol6+xq/jUH0EQFPEm1xPGmFJP1Nvl7/Ixch2Tj3d1jJwvdZ1Td9bYbDaH4+X41B2vct11TtO5g9b5GNmbojhl6NyhpC5DSZKQkZHhkFf1NY6MjMTixYvRvHlzMuY8ZB67sM3MzMR3332H1atX49q1a5AkCTqdDjVq1MDAgQPRqVMnmuHSCbPZjEGDBuH48ePo1asXRo4cWewJDNatW4fx48cjNDQUy5cvR0hICADHl48kSZg+fTqWLFmC6tWrY9GiRfD09AQAt72iRVGc3nt5/+nTp9GvXz+Iooh58+ahQYMGRcZNlBwe5BHzV69tcdN4FO5GxUVtyZG/y9ZTuUEq/05JSUFaWhqSk5ORkZGB/Px8ZGdnIzMz08GKKr+U1Q0HNc4C2tmKKotNHx8f+Pj4KJaXwMBAxYIaHBysNCjVaxV7eXkVaiQ6T4jhytLn6hq42ufc4y+KIjZt2oQvvvgCH374IXr06AGAersJ98iNXY1GA1EUkZGRAcaY8h4EHn4n+v2EbVHHFOWa6HxPMMYKvaNdWcrU95azddnZ8iS7Wufn5yvWZvm7bEGWrc+ym7ZsZc7NzVU6zeR45Anh1N9lDxBnUaAWAO7KUf08UW9ztjKrP/JzT6vVKs84dSebLH51Op2y39fXFwCwatUqZYy2uiwbNWqEAQMGKB1vzkJJFmzuRJf62e38Vy3inDsUnK+dWkCqy1Adj/OcBerj1WPLZRHm3IHh7rv6d1Fhnb/LuBLm6uvr7no713ln3L17inuM83bn6++8z5UXkDoutcWW53kEBwfjm2++Qfv27f/z3qkPm8c2vRvHccjMzMSwYcOwZs0aCIKgTIaQmZmJn3/+GSdPnsTkyZPRu3dvhx58wLEyyS4iriqS2n1EfRPJDS5XldZVY8uda4j8935uPc55kvOlPgd5whN1Wq7yID+oEhIScOXKFSQnJyv71efq7LYix5OZmYlz584hKysLgiC4vXHT0tJw7tw5eHp6QhTFQmXtfJ48zzu8jOUXrKuHh7xPXQbqsszPz8fFixdhtVphNpsLNc6dy50oOag7teTf6peNRqMpVGceVrrO94T83VWYorbJ+XV+IcuWU3lcnc1mQ05OjmIpzcjIcHD5lSdNkl1+5bF6siVF3UBRl53zi1n+q9FooNfr4enpqbj/GQwGxYoaGBgIf39/RZTKgjUwMBDe3t6K65+np6cy8Yy7saauyqA4FKcR4Gqf83E8z6N79+5o2rQpQkJCaAIXokg4zu42C9jfWWpB+6jTfZB7pbjvNldWz6LCOP8t7n3zIJ3TrgSMbE1TW5hdWZ3lccqyFTknJ0cZv6y2NMvPSXmffJzauuxsbZYFtPPkcq7Ek/q78zhztSVT3nfs2DEcO3bM7fvBlfhy9R5S73NX3sURXOp4i2rPPiju6p26Pjm/M9Rizfmd4uzyXlRczh+5o8L5o+7EuN9H3eGhtuQ7d4w4z1Hg3FkiH+scj7ztzz//xPLly2Gz2Ryuj+xx1Lp16791XQjXPDZhK0kSlixZgtWrV4PjOPTt2xdvvfUWAgMDceLECYwZMwZxcXGYOnUqWrZsiYiICIeHkNzwU0+TLyP3asmVT14KQnZh0Wg0EAQBubm5kCQJXl5eDhMcyK4Hcq9ufn4+OI5TZhOUJEnphZR79tQvB8YYrFYrcnNzlR4/+WUqn7vNZgNjDDqdTmnAyi7FckNWPke5gSnfYEajEaNHj8Zbb72FcuXKKWnKeZfH3qjTdtWT6wrnl6Nc3rKbkjwWRg4rpyv3CObl5QGAcl3kcOr4JUlSenLl8TjOM8K5emjLLyf5YUGUfBhjOHz4MDQaDRo1alTIovB343aOy13PrroeO1swZFc9eWZf2V0vJSUFqampSEpKQmZmpmKlyMrKUgSsbEVVTxajfo45n6PzhD6yK556eRDZnU526w0MDERgYKDSMejr6wt/f3/4+voqzzbniV1kitMYLoon2bmk0WgQHh7+xNInShZPoq66EpYllaLyX9R+o9Hodp+zEHYXlyyS5Xaes7VR/q4exyy3peTOQ1kgW61WxbKsfsZnZ2crnZOy+LZYLIrXjCuRKLe33E3oph4f7G6ssvo7z/OFZq92/i6LKlk8yd+dhZY8p4H8XW4zq98Nzvucj3E3wZ6z+JPTd/6oBZ7zMTqdrlBczqJTLmu1OFZfg/t11rgS1+rtzsYVVx256jb0X+1wyM/PR1hYGL766isUFBSA4zgEBQVhxowZ6Nq1K3kbPSIem1pIT0/H999/D0EQ0KJFC0yYMAH+/v7gOLuveUFBAcaOHYvw8HAkJyejdOnS4DgOd+7cwXfffYetW7ciKysLPj4+aN68Od5++21ERkaC4zicO3cOU6ZMgbe3N15++WUsWbIEv//+Ozw8PPDmm2+idevW+Oabb7Bt2zaIoojnnnsOI0aMQHBwMDIzM/HJJ58gJycHr7/+Ovbs2YPdu3cDADp16oS3334bmzZtwqpVq5CdnY3q1avjo48+QrVq1QDY3Qv27duHOXPm4MqVKzAYDHjqqafw/vvvo0qVKuA4DnFxcZg4cSL0ej3atWuHefPmISsrC0OGDMHLL7+MxMREfP3119ixYwdyc3Ph7e2NVq1a4Z133kGpUqUgCAL27NmDc+fOoU2bNqhZsyYkScL169cxa9YsHDlyBGazGTqdDhUrVsTgwYPRsGHDv2TRkAe8f//990hOTkZoaCj69++vuIgD9pne9uzZg++++w5XrlwBYwzlypVD//790axZM5hMJuVmv3HjBhYtWoS9e/ciJycHPj4+6NChA958802Eh4e7vKkZY9i3bx8WL14MSZLQoUMHvPLKKyRuSzByo2TXrl149913wfM8FixYgFatWhV6mbjCXc+0+rf8ka0B6oZKbm6uMhY1PT1dadTIs/mmpKQgMzNTaRipP84uvnInmtxp42xJlcWpyWRS3NuMRiP8/PwQEBDgIEJlq2pISAgCAgIUy6k8E6nsKqd+2csva3cvXrWXhHqbOs/FtRARBEE8SorzLFILIvXklq4slGrLrPO7RX7+yb9dWZzlTsn8/HwkJydj9OjR2LFjh4P3jMFgwFtvvYW+ffs6CFh3M4+7EofujlG/S1y995y3O5+fu+3uytjd8ep99+PvWobv1xHt7r1/v3N1jtddHM7H3K+83MWhfpe6ikev12P48OEAgC+//BLe3t6YOXMmunXr5vIY4uHw2JTCtWvXcPXqVXAchw4dOiAwMFCpQBqNBj169ECLFi2U2fM4jkN8fDzefPNNHDx4EFqtFiEhIbh9+zZOnDiBQ4cOYfHixShbtizS09OxefNmpeEsW0TT0tJw6dIlfPvtt7h48SK8vLxw584dXLhwAVqtFhMnToTZbMaOHTsQHx+P33//Henp6dDr9UhJScG5c+ewZ88eXLx4EZ6enkhNTcX58+eRlZWF1atXw9PTE1u3bsWAAQOQnp6O4OBgCIKA7777DidOnMDKlStRvnx5pKenY9OmTRAEAdu3b0diYiL0ej0AICUlBe+88w52794Ng8GAoKAg3Lp1C3/++ScuXbqEr7/+GhqNBocPH8aBAwcQFhYGwO5iPHToUGzfvh3e3t4IDg5GYmIiTp8+jbNnz2Lz5s2Kdfd+qB/oAHD+/HkMGzYM3t7eyMvLw9mzZ3Hy5EkwxtCtWzdIkoTFixfj448/Rk5ODkJDQ8EYw4ULF3Do0CGMHz8e/fr1A8dxuHHjBt544w0cO3YMBoMBwcHBOHfuHGJjY3H48GF8/fXXKFWqFADHh/iJEycwePBgXLlyBa1bt0aLFi1oza8SDmMMu3fvxjvvvIP4+HhwHIf+/ftj3rx5aN26tcP1dR5fJFtR1ZOiyGNO09PTkZycrAhTs9msjEOV/8rjwmRrqjyOyDl/6vrl3KMuL4GhXh7DZDIpVlTZvVc9m69sSfX09HRYEsOVFfVBy/J+L151T7Sr/fKQAYIgiCeNO6uXer/z80u9z913dyKtqA5/uW3m4+ODsLAwLFy4EP3798fOnTsVr7t+/frh008/hbe39z+2XVKUFdxV+fwVz6m/e/73E5DqfKn3FyXSixumOL/vF8f90pM7Ljw8PPDhhx/C19cXZcqUQefOnZUOjYfhqUYU5rEJ24SEBGXWXdnSqr6gJpNJETmAvdfs66+/xs8//4yAgAB89dVXaNy4Mf78808MGTIEx44dw8yZMzFt2jSl4ufn56N69eoYN24c0tPT8eqrryIhIQE3btzA4sWLUbVqVYwYMQJbt27FL7/8orgGyA1ok8mEDRs2wNvbG/369cOJEydw8uRJfP755+jYsSMWLFiAWbNmITY2FgkJCQgODsZXX32FlJQUtG3bFpMmTYLZbMa7776L06dPY/Hixfj888+VB2lBQQEkScKAAQMAAM888wzWrVuH3bt3w9vbG9OmTcOzzz6Ln3/+GR9++CGOHTuG3377DU8//XShh3l8fDyysrJQrVo1fPHFF6hduzaOHj2Kt99+Gzdu3MDly5dRoUKFYl8f+cFhs9kwYMAADBgwAElJSXjvvfdw6tQpzJ49G23atMHNmzcxZcoU5Obm4pVXXsGIESPAGMPkyZOxZs0aTJ48Gc8++ywqVKigWJPDw8Px1VdfoUGDBjh27Bg++OAD7N27F/PmzcO4ceMcrF7Xrl3DokWLEBcXh0aNGmHmzJkoXbr036p7xJNn9+7dGDhwIBISEgDY69utW7fw7rvvYvjw4fDx8VGWoJGtqPLMvup1JWX3Mtm1H7A/K+Q43b2wZXcrg8EAHx8fxYoqi1B/f39FhMpWVXk8qre3t8Pajh4eHjAajYV65dUW0Uc5GcSDvHj/ThwEQRCPiuKIkCeJnKfSpUtjwYIFGDBgAH7++Wf0798fY8eOhclkKhT2n8T98lRc0fdP4Z+ar6KQ8200GhVPNbUFv6Se1z+dxyZsrVarYrZ3NXOmjBwmKysLW7ZsgSiK6NatG7p37w6tVotSpUrht99+w5QpU7Bjxw6MHDlSOVav1+O1115DTEwMsrOzERERgYSEBDRu3Bjt27eHVqtFnTp1sG3bNuTm5sJqtTo0SDt16oRGjRpBEATUqFEDJ06cQHR0NHr16oXAwEA8++yzmD9/PqxWKwoKChAXF4ezZ89Cp9Ohb9++qFy5Mhhj6NmzJ06fPo0DBw4gNzdXyR/P8+jbty/GjBkDwC4i9+3bB5vNhgYNGqBbt24wGAzo0aMHoqOj4eXlhejoaEV4q6lSpQo2bNigWLFiY2Nx4MABZVyq2Wwu1nVxvrFKly6NgQMHIioqCtHR0ejTpw+GDx+OCxcu4ObNm9i9ezcSEhIQGhqKESNGoHLlyuB5HsOHD8e+ffuQkJCA3bt3w8fHBzt37oQkSejZsye6dOkCnufRtWtXHDlyBHPnzsWWLVvw/vvvK6LdZrNhwoQJuHnzJkJCQjBt2jSHMcXUu1UyOXDgAAYMGIDExESH7YwxxMfHY9iwYWCMOYxHde6ldeWqJY9FlT+y6JSXnVHP6Ovt7Q0/Pz9FxMpWVPUyE+rxTfdzjXIep+tsAXA14R1BEARRMgkPD8eiRYtw8OBBdOjQAUajkdokxAOh1j2PuvP7v85jE7ZBQUHQ6/WwWCxISUlxeChIkoTs7GycO3cOlStXho+PD9LT05GSkgKO41C1alWHCZFiYmKg1WqRkZGBO3fuKGno9XoEBQU5DIjnOA6lSpVSxoeqe9nUDWnAvmiy3Jsihw8NDYWnpyc0Go0yvkM+5s6dO4rb84IFC7Bu3ToAwK1btwAASUlJyMrKUhrDPM+jTp06Sjxmsxl37twBx3GIiopSJqUyGo1o3LgxAHtDWp6gyZm9e/di4cKFOH/+vLKMgTzZEvBgy6zIBAcHw9/fH4C9gV6+fHloNBrk5+cjKysLFy9ehCRJCA8PR+nSpZWbs3Tp0sr46CtXriAjIwMpKSnQaDSoXbu2g2tnjRo1wPM80tLSkJ2draTFGMPNmzfBGENOTg6uXLmC+vXr00OgBMMYw8WLF5GWluZ2hl8A8Pb2hlarVWb0VX/kGX1DQkKUiZNkK6p6giX1WFT12CVXebqfi5Y6jDvXKPVfgiAI4t8Lz/MIDw/Hiy+++I+3NBP/TGgI0OPjsQnb6OhoBAQEID4+HocPH8b//vc/Zb1axpgyqUy5cuUwdepUZWIhZ2slz/OKG6I8k5oMx3EOVhf1MWoLjKvJVQAos7LJMMaUGd+crcpyejJqK2lwcDDat28PPz8/aDQaJbxWq4Wnp6eDVUj+mM1m5XxdLQ3kbOU+fPgwBg0ahLy8PNSpUwfPPfccQkJC8Pnnnyti+q88dOVxiPL5y3mXxb48/kQ9DlLunJDLVLaAyTeyHJ9cZvLU5+oZBOVzj4iIQNmyZXH48GHMmjULzZs3R1BQECRJonG2JRCO49CnTx8kJSXhyy+/hNVqdajber0egwcPxksvvQQ/Pz9lsiWdTgeDweDy/lPHrcaVpdfVPndji5yPcSeKnY9xd94EQRBEyUb9LHduhznvJwhXuGp7UL15dDy2hQBLly6N9u3bg+M4bNu2DWvWrEFOTg4sFgvOnTuH6dOnIyMjA8nJyYrVUF7y59ixY8oSPPn5+Th27BgkSUJERMQTGX8pV8iIiAh4enpCq9Xi7bffxurVq7F69Wq8/fbbaNOmDV566SUEBQU5HCNPGsNxHDw8PBRX47i4OOTk5IDjOOTk5OD9999H//79sX///kITPDHGsH//fqSnpyM6OhqrVq3CZ599hsaNGz+wa4xz4zw+Ph5xcXHKjRgbGwtJkhAQEIDg4GDExMRAp9Phxo0buHjxIgC7qL9w4QKuX78OnudRo0YNBAYGKmOmDx06pHRG5Ofn4/Dhw5AkCWXKlEFwcLAioLVaLT766COlYyM2NhYrV64E4OjeSZQsTCYTPvzwQ4wYMULpGAEAg8GADz/8EB999BFiYmIQGRmJ4OBgBAQEwMvLS/FgcNURVJQl1ZV4Ve9zjqc48TvH7S5f9MIiCIL490DPeuLvQvXm8fHYLLZ6vR5DhgzBr7/+ilOnTuH999/HN998g4CAAJw6dQqJiYkwGAx4++23lXGVL774ImJjY7FlyxZ88cUX6NixI/bv3481a9aA53n07NlTcZt1tsiqKU4lUlsN1TiPp1OnUbFiRdSvXx979uzB1KlTlQllRo0ahStXruDtt99GixYt3FqKtFotOnfujM2bN+P06dOYOHEiunTpgt27d2PFihXQ6XTo2bOny3MwGAzgeR6pqanYtWsXypQpg7lz5yIzM1Oxav8VMjMzMXbsWHzwwQdISkrCt99+C1EU0bhxY4SHh6NFixaIjo7G5cuXMWrUKAwfPlyZPCorKwt16tRBixYtEBAQgC5duuDChQvYuHEjypQpgxYtWmDXrl346aefYDAY8Oqrr8LX11dJm+d5VKhQAdWrV8fLL7+MqVOnYuHChejUqRMqVKhA41lKMAaDAcOHDwfP85gyZQokScLIkSMxbNgwh3WhNRqNS28KgiAIgiAIgrgfj03YMmZf63Tx4sUYN24cDhw4gOPHjyuN2JCQELz11lsYOHCg0qh97bXXcO7cOaxZswZffvklZsyYAZvNBoPBgN69e+Ott95ym5azy6A8KZU7caR2p3V2NVZvU2MymTB69GjcuHEDsbGxePnllxVRWa9ePQwaNAh6vb5QL43ahbd9+/Z47bXXsGzZMsycOVOZnEqv16NPnz5o0qSJkgf133bt2mHZsmW4du0aBg0aBI1Gg+joaERHR+PatWu4cOGCslSKukzcuWLK41+rVKmCpKQkdOvWDaIoQhAEVK9eHUOHDoVOp0PZsmUxYcIEjBgxAkeOHFGEtyiKqFy5MiZPnqxYavv374/Lly9j48aNmDBhAiZNmgRBEGAwGNC3b1+8+uqryjVRrwum0WjQt29fbNq0CVeuXMGCBQvw+eefw2AwFF3RiH8ccv3y8PDABx98oCx38+677zqMeVeHJwiCIAiCIIgHgWOPwbdTPW4UAMxmM06ePImTJ0/CarUiKCgI9erVQ8WKFZUxDLLQNJvN2L9/P3bs2IHbt28jNDQUrVu3Rtu2bZX1bhMSErBx40YAQLdu3RAREQGbzYZ169YhMTERtWrVQosWLQAAv/76K44cOQI/Pz/06tULgiBg9erVyM3NRcuWLVG9enUA9omZTp8+jcjISHTp0gUajQbXr1/Hli1boNFo0LNnT2Xd2suXL+OHH37AuXPnIEkSnnrqKbz00kuIiIgAz/NITEzE+vXrIUkSunTpgsjISIeB5Hl5edi5cye2bt2K1NRUhIaGok2bNmjfvj1MJhMEQcCmTZtw+/Zt1KxZE61atYIkSfjtt9+wYsUKJCQkoFatWujZsyeuXbuG8+fPo1y5cujUqRPOnj2Lffv2wcvLC6+88gq8vLyU8lWLyoMHD+K3335DhQoVULlyZaxYsQLnzp1DTEwMevfujejoaOXaSJKEuLg4bN68Gb///jsA4KmnnkLXrl1RtmxZh2uYk5ODnTt3Ys+ePbhz5w7CwsLQsWNHtGrVCiaTCZIk4c6dO1i3bh0YY+jSpQvKlCkDQRCwd+9enDt3Dv7+/njxxRfh5eVFbhwlGLmuyevIyhOy0fUkCIIgCIIg/i6PVdiqLaDOkzHJllu1VdPZvVgURWW2UzXq3/IMukXlx/lY59lQnZHTVudJ/iuLVHkcqXoGZ3eNdlfpyEv1qM/ReUyf8zlIkgRRFKHT6ZRjZTiOcxDQzpPkqH+7+isIgrJOp/PkO/J3eWIoeWInV7PJytdfFEUlT/JfdRmqw7rKr7pMiJKHfA9zHAdRFF1O9EYQBEEQBEEQf4XHImyB+0/6Q2MnHz7FKdOiZnb9p0J1pWTiPE7dVYcNQRAEQRAEQfwVHpuwJQiCIAiCIAiCIIhHAU09ShAEQRAEQRAEQZRoSNgSBEEQBEEQBEEQJRoStgRBEARBEARBEESJhoQtQRAEQRAEQRAEUaIhYUsQBEEQBEEQBEGUaEjYEgRBEARBEARBECUaErYEQRAEQRAEQRBEiYaELUEQBEEQBEEQBFGiIWFLEARBEARBEARBlGhI2BIEQRAEQRAEQRAlGhK2BEEQBEEQBEEQRImGhC1BEARBEARBEARRoiFhSxAEQRAEQRAEQZRoSNgSBEEQBEEQBEEQJRoStgRBEARBEARBEESJhoQtQRAEQRAEQRAEUaIhYUsQBEEQBEEQBEGUaEjYEgRBEARBEARBECUaErYEQRAEQRAEQRBEiYaELUEQBEEQBEEQBFGiIWFLEARBEARBEARBlGhI2BIEQRAEQRAEQRAlGhK2BEEQBEEQBEEQRImGhC1BEARBEARBEARRoiFhSxAEQRAEQRAEQZRoSNgSBEEQBEEQBEEQJRoStgRBEARBEARBEESJhoQtQRAEQRAEQRAEUaIhYUsQBEEQBEEQBEGUaLRPIlHGmMvtHMc95pwQBEEQ/zgYwCC/Jzj7BtUvyFscfsg/uXvb/0b6hX5yql/s7k/OKagc0Dl9h/wVzjvnHJQrvN1t5lxS+EjmerMSX6FdSjIPEpe7I1C8bBc6xG0huNzsfC04523uuBsZ5zawY2r3KRoAzHFzoTjdVI77wt0LqaqHTtXf6QhqTz0c7j2J3N2cVNZEIZjqj/pB5FBviEfBYxe2sqiV/3IcB8aY8lfeRhAEQfw3sTclGWx3WwQ6yf7O4HiASQDAARpAZIAEBg0AXgLAPQRRe9984W6b1p4/uY+W3RW4HHh78nbtq3w4ADwrLGjZ3ewyBod8M/l/SZV4IbWk3ilv5mB3xHIhdXhAcrGZg/18mMtyc1eY7N6JudxbpOwstMulOOAAMNFlvpjLDgwO1rvJ6JkIJjFIAEROA04QkHH6BCROh9AatWDTamEDA8eJ0DMOGudOCiUDrstTgmMRqP8yd+fKOMBlxz4DOMExWeWLtlBQxjFwDGCQlA4WKPnhQE3mhwgDABESZ68L/N2NAiRw4KGhsiZcwMAAEWAaQGActHefitLd5z7Vm0fHE7XYSpIEnucdtpGoJQiCIGxg0EgAxziwu4NmJFGElQc0nBY6EeA5gPGACLumfRjGWmeY6q+Eu0JQrVC5u7+5u4JXUuXDOT8qAcJg1zi8nHfVdumuQYjjFYmryNh74kVTOLNyHlygZXZx7eoYiXMhkgFwrtJQkFxqVc6NELzbFeA6HY5zuc9ezm5GTHEulSi0skaUeEg6CWZYobNYkPnL7/h92P8hjzegxaQv4Nf8GfA6DbQiA6/lwfh7V0ptCXWZL3m7ahdTbXe2aMtfRY5XOhDU9YIDB+amOaaB4zVlDv+pKg5c1zXi72KvBRxTXQUGaNTdVlTWhAskXgIHzv5MkgCAgdPY65JDjxTxUOGYO7/gR4ScnCAIEAQB+fn54HkeRqMROp1OEbokcAmCIP6bMMZgA4NWZOAEHoIeEDkGnSRAECUwrQ4GiberPS0gcHYxoQVn//cQXh/MSbTIVlkwBo0LtzLZ9MruSlBFjN4VvhpJdYBT/hwstmpB5CIdpljk3KhUsMI+tcwuON0dcX9chGDMjeXx/tEwzoVrMQNEt7lwbX3kYbfQu3LqlTi7pQQA8rQMkpSDgp+PIPbdj6C/Ggcd9LCUjUbtGRMQ0LwpGGcCx/PgNPdEolLs3N2r6Kgf7xaxa2Ht3mvASSarwzAenJvylLs2ChnsOQ6FKroscB+x58J/CmbvrGK83LnEgb+7DbzcoUaFTTgiQkI+LDBJGvCCDoDdestxAsBx9k5DqjePhMcibBljykeSJJw9exarVq3C0aNHkZ2dDY1Gg7CwMLRv3x49e/ZEcHCw4p7sKi7A0YX5QfLhLs6/Eh+Jb4IgiIcPYwyQmL0xybi7jn8CbBev48Kyjaj8ajd4VoqCTaOFHlqAATaegec4aB7SiDdl2AwKy0i1FVdt3ePhqCnltysHe8OYwTEeOV5X2zjgnoAuhAhwrlx0eYC5tvwxJXZH3Lsh3zuwkIB0o+lcp1A0nOTCF/uuaZxxhW2mnCqQc3o2SBDB2Z1GbTZkHf0Fh98fDL9LV2DhGIwiIHFa5JUvi0YzvoL3c80ArR5aOLqPy+nomF1Aqq+5vE9dL2TXZB73LONKXHczyauMfMqpcvLRQmHxCkDkdIqslR2jgXsujXLHidqu7Vwm1Fb56zBm76rimL3TxHrXj0Ev3a17PKgTgSiExCRYYYOeaQHGo4AHBABGxqC7a62l+/LR8NiErSRJsFgs2LhxI0aPHo3ExESIogidTgdJkpTvbdq0wezZsxEREaEcz/M8JOmeq5S6MqizL3+Xrb6utssCWx2H2iVafYx63K/zfud8EARBEA8HxuxmMwkMAieBYwWwnr+M4+9/jNyjf8KjQW00mP85DJUrQseM4AQeTIe7XoF/3WLr3HHKJHY3Lk7lH8xB5O7JRLUDq2zIAewNYcbuGfAc8qSkA8CVoLv7WhPUFk5ZvHC4q2juCT6VFy04SVK5u6qEn1phqd+bnKOwZYoE5gBJtlGp4DhIYJDYPQnIGFNSKmR5vHsdOSaBZ5I9bVEEJMlu+BVFcFbRXnYSgyTZx8aKkgQIFjDJBkmS7n7s6TJRAhNEMEkCmARmEwBJBBNEaM0WcDYRkihBvJ2MS4sWQbp5EbxYAJ3EIU9nL2QN84AUXQFVPhwKTYVo8DodNFoNeA0PrU5r9yDT6wGDEVqtFrxWA+h1gEajCF2Os7tqS5z9kkjM7nqo53VKGJFJ4Hh73dAIDBzH31OhHAeJ2c+J4zhwPG8vByYp3zWMs7vcK1XnrqDnVTXAySuZZ47tE2qr/DUYAIkxWCQJOkEEzyQIBg0E8DCCv1fOVLyEE4wxMIHdfV6KsNoEMI4Dz/PQaTXQcCRsHxWPVdgePHgQ//vf/5CSkoLo6Gi8/PLLaNSoEVJTU7Fs2TIcPHgQADBkyBBMmDABPM8rolb+K0kSNBr7y0RdKUTR3nutdmV2Fr0ajUYJpz5eFrGuBLMsqDUaTaFKSJWSIIpCdQ+CAxgr1Ei271Pbk+i+ely4toQ9nPg4pz3u9xV2p7Q7gN5VhqIFBZfi8Md7I2E9fBhgFtg0eqBJIzSe9iW8qlaFxOvAM87uGvg3TsThdehsonWYeUme6Ie765YLu5DhGQSeKYJSHnsLBoiczW5ZY7DfB4yBk+QRmZz9O5PA7lovGWOQmAB2VwxKzD5hEBjAJA6ykGaM2cWsJIITBXDWXDDRLvoEQVDem6zACmYTIYkiBFGEeHcfE0Qwiw2SaA8nCAKYJIKJInirDZxNABNs4CQJEEWINgFaiw1Gsw2SzT6kSBRFZXgRLwgQBQGCzWbfLoqwWa2QBAEaSQAkyW6hlZhd3Ep2YcrkfKpErEawQSPczRtjd/fZ/4qize767dSE0YscOMYgcCKMogAPQYLAbBA5EZ4SkK3jIHE8PCQNAC3SdTxErR5aTgNeqwW0PDitBhq9HrxOB05ngEanA6fXguk0YBotdHoDtAYP6I1GGD1M0BkM0Jr04ExGCJ4mWL09wBmN4Ax6aA066Ix66A0GwGSExmiAwWiARq+FRq8HDDpA5wFO42Fvv/C8vadCw4PnOWg52IWxhgPjODDePk5XI/LghLth5Q4Qud7zWoeelPu2VYrTBCxmW0dtzS7OPlcp/5Oe/vZblcEq2qDPs8GamwdDoAcEgw48NHenjiJhSxSGMQZJBCBZYLsTj6NfzYFvaARqvfsW4OMJniusKYiHw2ObPCo/Px+zZs1CSkoKIiIisHjxYjRq1EgRoM899xx69+6N33//HSdOnEB2dja8vLywadMmJCYm4plnnsGpU6fw66+/on79+njttddgMBgQHx+PzZs3IzY2FqIoonLlyujSpQsqVqyoxH306FH89ttvCA8PxwsvvAC9Xg9BELBlyxbcunULtWvXxrPPPovMzEysW7cONpsNHTp0wLFjx7B//35oNBp06NABrVu3htFofFxFRhAlD5UB4Z6lSQQYD4EDeEgQM7MhSQwGfz97I52D3XmQkx0L7R/7hCqOuH0NsCL2uz3IWb24m3rHMRfOrqkc4LqVVkQ8zGkspNqt1VWE99K9F1K2lLnwclRROB1292j70E/OqW1cWIg65s3xm3ytJDAlLnVuGJhyrrx6D1PFelcfQhZ+IoPISbDGXcWJ9z6G7fBRcFwBBK0IvchgPXQcR4d8jEYzvoC+fDloBbvAAxMB0W7Jg8TA7loHITFIomjvrGT2iahESbxrIZQgiZIiLBmT7FMuiwJgE8AEERAECDYBks0G2PIhCjaINruIEwW7sIPNCk6wQbAJ9n2iBMFmF4CczQqIIjhBACdK4AS7hRGiAIj2NJggQhRFSII9XYPVAiYIkAS7IJUEu7BkkhWSZIMo2sUp7gpknnHQCdxdrcLunov9WvKSbCVlDh8wBl66JxDt4e0XgxdFu1WK5xT9w3McJM5uTZYbZpIk2TuHAegkATzslknGJMWay0E1jzN3z5GYcYAIu1hjqoYez3GwcUDB3fqp1Djubn262yHN8zw4cOB5u8VTNOohanhwGglmpkVebh68C7QwCFpk6CVoGQcPm/3YHK0AyagHb7OAFxiY7d59ZAOgZRI8hLsdC3fvCcZxsAAwS3cdg3n7PSRxd+s+OGiku/Nm83Y3ZtzNG3jt3fG8dz88bxeqGg5My0GrN0Br1EFnNEJr0EFjMED08AMMRjC9HpJRD86oh85kBDN5gHl4wmgyQm80wGAywmA0QGcyQfL0AWc0ADodNBoNNFrtXauzFrxOC61WB06rBdSfu5ZoRahxsjXy7kct4DhOuWcVBwL5+jJHt2im+qs8J1XXk3HyEwL3OoPg/BxTy2K1W4P6iXfvWejOt97hveQK9YP97iRwjJOgsxbg2qbtOL5qFVp+NBjBT9eDxHvcTUq6zzJRrrrz5BOUzfDq946LiO7bKYF7ExEV9/3DOf11lVU4lrj6YLczfrtKyk3PhTynwP06sv+fvfMOjKLYH/hny5X0Tugl9CodRAVElGbBh9gL8GzYfSoqCojYQCxYEFFEBcsPnyhYERCQoiKgCEiRHhICCQmkXtud3x93u7lLQXhPKc/54Jm73Z3Z2d3ZmfnOt4yo6leV11k5faSVSmRuIlSwqupCxK052nmqmaWtOJrwKiZq/kHWPP4YJR9+SqkjFh0vre+5HTM6PuirHboXVnms0Y/kP+eEaWy3bdvGeeedR3Z2NnfffTcTJ05E1/WIzvTXX3+lqKiIhg0bUrt2bcrKyrjwwgv54Ycf6Nq1Kxs3bqSoqIi+ffvy4YcfsnnzZu666y42bNiApmm2ZrhRo0Y8++yzDBgwACEEY8aMYfLkyXTt2pWvvvqK+Ph4SkpKuPjii1m2bBkjR47kxRdfZPv27Zx33nkUFhbSs2dPli9fjmEYeL1eYmJiePDBB7nvvvuCHUUVGlyJ5G9PBcHWFALV9BIIKHh1B8q+Pfz04GP4UDjr6ceIrlkXw2FiqEYwaisaKFpQM0HlLut437jKgmDY8EIQFHgUQoOMyAGTUCp0MPbgLaw7rjTGUip3iEKEOlJRPuizBnZqaMAYNvgPHiYQiuW1B1bQWgUQqmqnDw5s7K+YKmH5iPLnoYQOFGECZch3LKAEtYiqpUkTAmEIhBLUFgrDtB36gua5BoKgwEIgJKD5AxAIgN8LAQMlYGD6/EFBLWBg+D0EAn7MQCD48ZuYgQCG6ccI+FB8fvD6EP4Aps9PwOvH6/ejlBRz6PtVlG3aiMsIoJugmwqGAj5NpUTXiGrYAC09PahQ9fuCWkHDRDGCAq4IaRoVwwhpIoNCLIaJMAw0ww+GUW7aaorgMDNkJgqhZX3stX0EqjCDx1gDNBFmcyCsBUFC99J6TkrYcD9se6VZg1B9UghF+LWTlFcsU1UxseJChAQQEXqsumYPklVVs0qCqTsRilp+ytA7ZioKhq4FBTeBbSmlqCrCoYOm2n2epmnBPHUd0+FAVTW00H5VDZrxmm4dRVNDx2mgaSEBLphOcziCApamooV+K44YFIcDzaGjahqqrqHrOopTR3U4wKEH83LowTLpOobDERIONVTVKoMKqgtTd6I4VTS/h90f/h/73nqbGiVleHEgFD9RpqAoyk3asOuoNfgfBAiaPSulHijzQpkXo9SD4SnF9BThK/PgL/Pg9/gwPF4Mrxfh9aH4fJgeL6bfj+EN4Pd6Cfi8CG8ZAZ8PwxdANU1UMzh5oJheFNNAMYLad9UU9iSMGQqhpRE0P7be6zJdwVSU4Dsa9gloJgFNBH16UdBFaLEpBcpUBaEEhW5V14P32amjOJwIhxPV6cR0OjAcLkynA9PpAkdQA+2IdqNHudGjXDijo3C4o3G6o3FER0GUC1xOVIeO5nShuaJxuFw4XU40pwPF6QS3E5xucDpRHDoiJMRbdUpRgs9e0RSEammgQxNrISFaCdVrzNC7pwaX0Qq6BoTaTtMITRgotuuCEtYuWlKC9S4I6x1S1IjVOKz3IHzdbGEChomqCkx/GXvm/B+bH36K1NyDHGrbkM6vvkRq514oqopaVajxYOdi5xchJlbqxMpfelNYL3wFkS/kTB0uC1tuDKJSQHPruiOFfvuXElGaSAE2XOAMT1CxxGGR3621pisJY4KIEth+GeHf/0C4Dr8kez5ERD4rhQoTC+F5ht+bsPMLpepnEz6krzT+ECqWCwhUuG+h+hsu9AcCfvwHc/j14Qnkf/IxuijFNBVEVBIN772XjH/djoh24TCCk3MBNdinaEjZ4r/lhGlsd+zYQUFBAZqm0bFjRxyOYJSwsrIyDh48iBCChIQEEhISghEx/X4g2PAEAgFWr15N06ZNiY6OZuDAgfj9fh5++GHWr19Pq1atuPvuu4mLi2Pq1KmsXLmSBx98kObNm5ORkYFhBGfBK8rwtolW+Ey1EJSUlPDTTz8xZswYmjRpwowZM1i4cCEvvvgiffr0oWvXrifqtkkkpwci4o/9QwXwO4P+dXuz+OW+h9E//5KAqvK96aXrc88QU7MmwnQiUIMBWBRQCIR+ReaPomCE1goNlweCVD4++EdFKGrkfHmol/Rr5cKGYnVOQgkNFsMSRHSchr1BCeUjBAQUMxgoU7EEVVBFcIbbHxp92GOgkCmqGlBRTSWoSTOCfoFmSOAy/X7bNNMIaRpNw0AE/EHhLJQGv4Hw+VF8HjRvGcLvszWJAZ+fgM8HHg+mz4ff78fw+wn4Avj9PlS/F6e/FPx+8AdQ/AFbExnwBfMJBALBdAGDgN8PvpAJqj9YDiUU6AnTwGX4UAyBpS3FDE42OgIGakgjGjRDJSg0E8BUfUBwgI4o19l7NRdxfoVY04/hFKgCogI6ZigUaZQpAIPSXTvQd24nyafgVQU+zaxiVBLSFFcYbClK+cSArUkOuaWYStDsVFE0VE0JbQ+aipY5ozE1DVUpH7CrqoKhaZiaBoplIhr6qCoBTQsKbZqGQ9dx6Dq6Q0foLoTDga470HUNTQtuVxwafrdmCyZ6SOCzhDqhO1A1HUVR0VQVXXcE9zu0YD6hNFrou9/lCJ1HR9NUFE1D0TSEriNCWjtF10DVUFQFlOAxKEpI6aiiqKHnowbNdcv3KeXaPUd08PoVggJJaLtAKQ86ZQ3KCfa5DrtvtmcKglrzMBchk+DkT9DCI7RkhiUAhGkQEaAGlKDjq+InqWEtTF1h75vvEuUpwC2cFDliqDFiGM3G/AsSU3EooCgiqGkWoUG6AIFCQAlOFChCENQNh+p7oAzFDE7eBE2/wTCCEzbCDGAaQQsBPD7wesHjQfWUITw+fB4vhteH3+fDU+bF7/Vg+r2YXg94vZhlPrweD/5SD+7iYgIeD95SD36PN/gu+vyIgA8t4IdAsH0I+AOIgIli+HB5DoPhwwyYCF+w3gdC91YRCoHQxJ3dtAmBywjezYAKPlGu0VJtWSvSKkPoOgE9OqiJDmmfCQmqPl3H1B2hiQsdh8uFO8qN5nIh3C5cUS4cLhea04lwuxDuKAw9Fs0VgysmGj3KiR7lwhUdheaKQnHFQHRU8NgoB6ozJKxrDjQ9NCGia6gODdUZrMtC14J1RRGhPiB4Hc6Q6X7wV/CvYk0SCQUFFa8GftUkuthH9pyv2DR2Is78Q/gxUX/bw/I7R9PrhedI7dYFvxocy0Y0N0pwgqtcqCNCYKzUPIXaIdVeT4zyPscqZthP64tQBIZavjPcP952cYgsQrB+i/ISKGHCtD1ZZ5+givNamdnbRPmEqVUGEZwwM5UKZw8dZ71n9ulEmMae6rCurtwKJVz8Dxd1rd9GWEphl1NBN9VQ+xEuiobeiYjof2HXL4ywCclyYdoKdKhY30VwMsZTkM/6xx+ncP7nxAYCmAbECI2yQAk7n5uCUAwy7r0JMzoZVYAuVKoOCCg5Xk6YYFtcXIxhGOi6TmxsrC1Mbtmyheuuu47i4mIgKGxGR0fz1ltv0a5dO9ucuGHDhnz00UfUqlULh8PBokWL+Omnn4iOjuaJJ55gwIABKIpC48aNufDCC/n999/57LPPuPvuu4Mzv8cxA+JwOLj22mu566670HWdZs2asWHDBrKysli8eLEUbCWSo6GEdY4CPA6B2LOfHx94gMJFn5OkenCbOkWff8MvpqDrU4+jNGqAV3fiQqCaAUxFIxBawjz8I0KDTUG5kGgJVmboAMUMCo1W8B8hBIY1GBXlH2GaCOEFvx/F7w9qTgIGhs8fNC81Qmam/kBI6xjA9AcwfV57O9bH50fzelF9PvD7EV4/hs9HwOdH+HyonuJgvv4Ahs9PwBfUVGJ4gmaoIY0igaB5rDBMhD84WDWNUDCdkA+jCHgRRsCOFxAcIASNijURqKRdRIBmqiGhXUTMbqtCQRPla2saYA8AdTOom7YECUFQgBEiuLi8qhDUrFuT8ArBga39XQ0NviCgBgU6SxuPapmeapiOKLSQb6Oq6yiahubQcLnAcGp4DhWi7shEEQb5USamYhDl14jxaXiEE3eXNqjN62NqDlxqLFG6G80RHFBruhYa9AY1g5pufdfQHQ5UhwPhcga1gXpQyFM0PSiQqTqK5ggKcaqCQ9NtH0jFqdtaKE0LaioVyz8ydA2EzEyxNOwOjfDhn90nqTqomv2+KKH7pggREiRDo1xb22GG8tTKB8Bhg9OqrDCtIa4iQubvosLYuaruUYARbgIcRlBrGD7qq6gmqZgi9A4rhHyGQ/UjtENYkZzDBvNCKW9KgoPh8nLZwlYVhTM0AU5QDSUodKSk0emBB1CEg9zXp6IZMaTcNIxWj96HEhUHhoamBzWiVvOAWj7g1kOWE0KIoIYYEKqCqcbYhVBDmkSd4DtmqiFhOzSBoykqCIFfDQrrUQS1kqpiCdGheyYI+XJb1hHByR9C1mgIgr7YhhGykLAmmvwE/EFf5oDPh+ktRQQCGH4/wu9DeLz4ysoQxV5EiQdPaSl+bxl+jwdvWSn+Mg96WRmq14/i9aH6gm1YwOtD8xaBtwy/12tPeAWtFgSK6Q8O+AMETfdDE3bOUNkJtTcChbJQG2KGbnTwmVouEAJHyHjGVMFQFQJq8DuKhoKOUBR7Ow4N1eHAqThxOJyoTgeKK+gHrTqdqLoTRXOjOZ1oTicOtwun24Ue5cYfH4/ujkKLCvo843YhotzgcqFrLlxON2qMA6dLY++6jWyaOJXaOTkUOQw8qkKSoeH4dSs/3H0n3Z95nPimLULV3iz/a5p2/Qk+O0sYE+VaaERod/C5WhYwQpRvL3cXCAVJEyEhzUpnmihmwJ4gMi2LG2GG6p5Vh6xmIiSEWfvsehXpmhB+HdY1BAW70DWFbVcDRvkxVl6miWoE1yG3y29Y5wEllCa8DMGyGaHrDNseuo/CCNtuGEHttgiOF4RpIES5okoIgWqCbt13yzc/9AxM02ffXzsgHaHJZvucwTauvJ0J2JYBtppcEHoGoSXeQpNfphCUFRUS2L2TKJ9BSWhC0uEReDQ/Qhxi7wuTMU2F5g/cg+FyofnB54RQDETJf8EJE2zj4uLQdR2fz0dRUZEdlMnv93PkyBGKiorsdW2jo6MjNLYA7dq1o0mTJrYJ8MaNG/F6vdStW5f27dvbs+xNmjQhIyODnJwcfv311+BAMKwDDn+JKgaMslAUhU6dOuF0OjFNk/r161OnTh0yMzPZvXt3RAAriUQSif26GSZKwCSQs5P1ox4l8OUXOHQPXjR0nKiGj8CXn/MTXlrdcjO4o/F4yhCeEkwfoYFa0F8x4Pfj9/kxfV6EzxscwPkDiEAAxR8McqP6vKj+4GDPDPk4BvwBVK8HzVta7vfoD/lAGgEQZWAaocA4ljbRxBQGhghqS8vNc81QtNZQmxHSSKqhzloNidyWr6oGwYGogOBIWYS2l7c5hmrYa3tag4+guZnAwAhNryu2FZUKGKGAJY6QKZdiadJUHUVzhbSHqi1sBbVrqi2gWaahqCqm5sB0RKM7HGhOHd0ZFPY0pxPFGRMcGDp0TMsE1OnAcDoxXE4ImYjqjpDQ6NDR3NFoDoedn+bQgwNPlwPVFTSBxKEhdA1Fd4DiAJyo4aaKqhL8bRoIp8Cfd4ifH3qGoq8X4DKKMHUTFJVDbgfxF/Sj86THcTaui6Eo6KJ8sZ9wgVuxTDvDVAKWP6cSus3WvgjBsLJ8VmF7ud4gOBIK+p9WhVpVflZZqjj+aIMbq67YByphX6vILFxTVG4qbe2r7iJDyw2Fm9eHMhJKudBb8TzB96CSfWSkEK2AtXptUCsqELZKKyy/sOuq8oLCMw8dpIvgs/VqwdI4hAs1IY1Oo0bxq+IkYDpoOeoORFICTq8A/MEJF7SI9zAUiwxFBCWuYADkMBNGVcO0ph20yOgAWvgDUjX7xXaE1hK2n5F9U0JrDCuglMv7EZMPEcK8RdgySa7we62GHRtWluDSz5Y1iaU1C05bBRSC5rcBEzVkxm8GDEwzgGmE/LzNoFUJATNksn0E0+PF7/Xi83jxeX34PB4CpcUY3jJ8Hi/C40X1+lC8XtRSD47CkqDm2esLmnh7ffi9Hvz+IhTDB4EASsDAGQhqv00j6LIgAgZqIIDTZ6CWBSd+TNXES0iIAVuQMk0NTAc+pfxZWpNwftUM+T6DISwtHSioKGow6rWmQJQqUMtKiQ/48egGhqIBDgxhEmMaaBt+45drhqNGxwQVMCE/83KtnnXbRbngSmgiNkywtfcHt2DpHIWdTzCieEhXbnewwe+hNy70fIUw7fTBuhF2jlDSsNYqVNZy32RrAtPucIQlrAlUpdwPXwn1SSJ8wq0CugDdEmwVK2ZGMH14GxkexBVh2O1RMEq4Yk/UqsIKCCtCK5wEr8JEw0SNGNMLEbTwcYTSChEKLBu6Xl0YwTbKunGh+ACmIvCp4W1X+fulKjrCNkVW7HsrFIIm9WF5IYKm9G4MdKBUmBihcYCqgGYE0H3F7FqxnMZ33ILucpU/E8l/zQkTbDMyMkhISODAgQP8+OOPXHnllSiKQosWLfj4448RQrBs2TLGjBljp7EqvKIopKWl2T40pmni8XiCM6S6HuHvqoeCJFgmzFDeoNizU6Hv1v6K57MiKIe/KLoevFXhUZUlEkllBIRmMaGssJhVDz+J8/OviQ94KREaib5oPIpKcZSPmIBB6fwFrP16BZrQMRUTr2qgCZ89c2qZEQkBmjBxGuXbFcsPMiS8QKivUkKdpwANE00R9narc1VRMXAEB5UhMzsr0ItQFMyQKamwVE2KgtA1DEUPplGDvjGEzEtx6Ch6UEuo6iF/xNAyIcKt29+tQC1C01H1aFSHG6fTGRQInUFBUHM5Md1ROJxB3zXV4UBxOlAcTgKuKITDFfqt2RpDVQ/6uAX9HjWczqBpqqppqC4Xih7yQXSElizRFHv0rISu0zYnJXgPLD+ooNARXOZGE6Bj+fkKwrWEavgaqpagKMB2Fw4TwiJG3mHL2oSGNShmSDxKSqf9lGfYcCeYX36G5i8jz+XCMagvnSZOwF2/YfBp+gHdADWAPbizTlPFee3Tq4rtN21VAbsiVRMVRqgOu5yRF1wxk9BPezBbMSMrZXXSaPVUtbuivBeOWeE6w9OokaJyGCED7YoCJwLNGnhXyEsoGqaoPPEbvvZtuACuAJoisAwH7Wuw3lfreYULg4plYhqWYViZFRRComownaagJCXQ7JH78TsdKIqOwwCfy0QoJk7KfVq1sEyFomDiKC9L2Ok0gpqx8KFu+cVhC6rl5QtpJyvL/MFDqnzeSqUqGD6hIbSqK4lK5DjFfj8VEfYqhOp36PHqqoKiq+BUIbQ2tCZAUyvUjZCwgFARitPeFv46C8XAngQQ1qmsVjtkVWJaAl9oGSdE0Bfe48P0+TF9AfxeH4bPi+H3Bic5PT5MXwA8fkSZByWkTTZKyjDKfBhlXjwlpZhlRzC9hwl4fZgh/3/TFzT/ji8J+v/7fF783vKJU8Mw8CvBuANOw8TweFANgU8Bv66hGwoO0ySgCAwlGBxNKS7DKPWECY9WZVUQVbxroScaVlfCTIWV8oBsluAY9kAJSxL2BJWgwG21nUKLEO4iTxwSXhUwrPyEPecS7EsjDg+6XljLGZkKdt6KqqIqCqqioIe9MQJC21UCWlDzblmdBAO9BfsRJRThG8rdGBS1/N6plgsDYedEKf8e6qNUtdwv1vbPDn1MVcGvl5ffnjJQFAw1GG8g6HISeipqsNzOsCelhyaBg/dBt9Nb5VOs8YIebHPsa1UVAh4P+xcuIjZzP0nCT0AxcJoCza/jM2Mo69iKbpMfRU+MQlcAB7giZqQk/yknTLCtU6cOXbt2Zd68eXz++edcffXVdO/enbi4OLp06YJhGKxfv77a9JZPriVsNmrUCEVRyM3NJTs7m5o1awJw8OBBsrKy0DSNRo0a2YIvQGlpKYZhoKoqZWVlHDlyJOIcVkNgGAabN28OzvqoKoWFheTm5qIoCrVq1Tous2aJ5O+EPQQSQZNgw+fHzC0igIZH1TGFi0JNRxceYvx+StRo/LqBThlOVUPRdFSnjqLEh4RGFVNTMTUFNBVD1SlRHAhNxdBVCJmaak4nuu5GdzjQXcGIn6pTR3M6cDpcOHU3mtMBTgfCqSOcDtAdoAaX9NAcDhwuh6151HUnDj0UEMWhg9MJTh0cDkyX0w5mozisjk8J+U9aAW0I+jCqasgP0xHyXwyuYSk0DVMNroNoBZOyBsLCGgCj2IMRYY8cQ/ssOUkJmzEXhLRLSsSgOtihV1in2+7og9q18CGQPSsfGrCED9r0kDBrIOzBRflUASi2Fo5yTYCCpSSMGEhZKSxTxYo1KaAaKKaCW2iYdWpxxpTxrHZ4yV2whMQ+fekyaTyiQW0CiooeEJi6iakqoQFImKwcGm8a5XJ8xNlMxQ6AGhmx+aiD06PtsW9a5BVVI9EoWEFJKt2C4x7khJQCVaIS5uNdqWyVhVfCnntlgnexqj3BwGfVbQ8T8BWr9igEDfi0yPxCg2lLRFOVkAbVEtKqkeD9ikDDQA8EXy5/KECbjooWE4NmChwBgalDqaIRHRLCA1XUDwGY4UHc7O1Bidt6rxTCLytMEAyfrBGhSNEREzjlh0W49kXMl5TnFy5ilscBqDBTU96Q2NrI8jTlgrKwriN0wSoiolBWWjXsWUcI1baUXu6/aGu+UBGh5xmSZ4OW5wIs0UGElnEEUEwTjWDAKxErCDb3wUlLIQSaGqon4cGjCJnDKwqI0HJQtnVB8NkrQoRcPIIWOYZhQMAbjLsSMDB9gfJ4Bf4AeLwIjwfTV4pZXMTeeV+TOedz4nyFqMKPZgZ9K70OJ0VJsTS56mrcDRvbFida2HKTiuaw76Wu6+VzHGFCm+XKEEoU8m0P+a1revkzVYNxIkDY/QqAUFVMR9gkkhoSchUlFOU6tD3kGhF8rkFhrPycqiXZRkQlV9Rwi8byvkhRCAWlKy+bdSJL5lYIvaxqefpy64swITZ0r8rTWmUJO86WvNVK5whOxpaf37oO+0C1wm/ruJC7R+XmTan48oV9D+tQKr68YVlZwcgIGNT4/EvW3z+W6OydmI4AfgRCqBgdOtD55UkktmweSm4SUILB36ppviXHwQkTbKOiorjtttv4/vvvycrK4p///CcjR46kbdu2FBcXs3jxYj766CN7zVoLa1bE0qBadOvWjbp165KVlcXkyZN5/PHHcbvdPP/88+zdu5fk5GQGDBgAQGJiIqqqsn//flavXk3nzp354IMP2LVrV5VCqmmafPjhh/Tu3ZuWLVvy7rvvsnfvXmJiYujRo0dE+SQSSTmWcICqojggtmYK50wZx4p7y/As/xHN8FGmm6imQbQImgWqPbvT+vZ/4o5PRtND2kndiRq2RIViaTp1B2iOULCbYLASe+a00l9rFlcN67yJ7PyqGByX93XlA6jwAaVmf7MGm9bRwU7YGluFizGqsDricCGw3Hy58l20c7RnmkXEbmELBZHJKrdnYUOTiHPbHbCIFCgimsRyKS8yx6q2WQKuQigIS+j+KeFCQbi2InQKpar2NKRxUBU7qIq7fn06vzCZjfMX0HbQQNx1a+BT1KD4rVvXpkbmTfnzqLQ9tNEef0VI9+H3ouI9DV1PFdrccFO/qq6pGkkwYkBZIcVxbT/qAUcRlI8+nKo6UVXCa1BEtU52vCgR3wQhQRaBx+PhQE4OderUweFw4Pf58fp9uJxOcnNzSa9Z0xYq7ABPIdtdxf4HLqsNcCooKsSgBM0VlZCmVokUMBWCJpiVL0fYA+2qpzgihf7wamTtiUgVJgeLiGoSURErnaniq2qfQZRHlY9430IbI6u61bqEJpnCZQTrUu1cRIXrsFqn8qXLhBKM6lx+YNhLoZSnVMLcuVRNKxdIrc2KCMlF5deuaOVtshJxdeXxGMLbaiAoYDrLi2GGrsvyZbTTidD/lGAlMH1+kjqfjT8mjbI3XsXEj18zcAd0fHHJtH30IZqOuA7FHUX1VPciVre/6pe0GiV/qOzVTbL994TXqeN9o//sMlV1lX90jmpartA+M+wXYbderfIpCLtmVe5RlQrHKwBOB3UGDEBgsv6hUeiZezGcboy2HTn7ledJbtcWyzqKkPa76rdccrycMMEWoFevXjz11FM8+uijbNu2jfvvvx+n0xk0AQn51CYkJHDllVfSqlWrCEE23ARYURSaNWvGfffdx7hx4/j3v//NypUrcTgc7N+/n6ioKO699146deoEQI8ePUhNTSU3N5dhw4aRlJRESUkJKSkplJWVlTvNh9A0jYKCAq644gri4+PJzs7GMAwuvfRSzj777ErCt0QiCaGUDziCAoUgpklLur8wmRX/GoW+7Afi/SV4NSjUwH1mF858/imiWzVHUd1BBYAaGrZUHOxXoQU77sJFZhi5rcLu8KGp/U1YZQtujchBKOX9FFUrzhT7vlQuV9i4M/g7JCVWvA0RES0r9YHVdI1WXmE77cFhVfJWuARcJeGJyi9IUTR7U2SJqs6vfPCtVNquKWFGoaoCQiM6vR5dbv5n0GSScL9CJex4JeKP9bWScWzF6w4bux99bFHxSVXM4vikSkuQqVJIOaqgfJTiHc/26naUj9sqYU0YVJ2s4tVUc7rqxvehWxV+l5+bPJmFCxdy7bXXcuONNzL5uckEAgEURWHp0qVcf/31XH/99aAETZARIf88CJr5hWkT0SyhOSTOW3MhSuTfcrTKl2PJukrFmhu6A8fRVNmvWuVqW+nX0Yisy5UnkKzvFYfmFXcoVaQp/1rxQalVHXb0l75aqnhHKtZBpeJRle9/VWdTwhKpVZzCnpAMWaQIFBTdgZ6cSOeH72Yj+ex8+31SvBq5ybG0evQ+mlx3LYoruJbt8RnxHe3gqvep1aaxooP/iVTRdpdPJFR/eFVV/s8qWaVJmv8qs1ClCtcAR3ypqj+y/JArWC5Ue1eClvYel5O6/fuhGV5WPvoErtRanP3CJJLbtgvGugg73iqNFGv/e06YYGv5rV577bW0bNmSWbNmsW7dOvLy8gCoXbs2HTt2ZMiQIXTo0IGoqCg8Hg9du3YlISGBli1b2mbIlmA5YsQI6tWrx8yZM9myZQtCCHr27MmwYcMYPHhwUNujqnTu3Jmnn36aN954gwMHDlCvXj1uueUWdu/ezXfffUerVq0iBtGapjFq1Ci2bdvGsmXLyMjIoF+/ftx///1ER0dX9l2QSP7uVByUhfV2AUPH3bQ5PV6axLqR9+Ff/j1oBu4zO9BlylNEtWiGR3XiJmQKas2aVzrHn93kH72jrvJ3hTIcbfx2bPv+g/z+k/tQ1e08zuP/OP/qE3k8HlavXk2DBg2oX78+gUCA3bt306hRIzZu3EhMTAxNmjSJaIfLtdTWsEYgFLPKrv9PdQ85pqyOIgweZ6ZVDsSPqyx/Icd7mcdT4GMQwBWCc0lXXHEF+/fvJzU1FSEE3bt3Z+nSpeTn5yOE4Mcff+T6668vn1iorj0K/fgPxcWIzX/W+/MHr87xZXYMh/8HVfTPSvAH2R1bZTuGalPtzmMpseWcoSigOFS01ARaPDYav+lm37xvaPevG2n4z6vxu4O+kRXEo7+Eo75vJ6CNOJZT/JXF+FPz/uMXrookxz/dJBAYqoLpjibt4ks4p0YGrvhE4ltnYGpqxHr2x18iydFQxAmQ0sI1ouHCaXFxMUVFRUDQXDg62pr9UuxjrLRKyGHb+g5ERFYuKCjANE2SkpJwu90ReViO9IWFhRQVFZGUlGQLqOEBorZt20afPn0oKChg5syZ/OMf/yAvLw9d10lOTo4whw53bpdIJFUjhAhG+cdEU3yUbt7Csn89hioMzp40lph27fEpGpbnVdAUzkBRtOMafkpObRYsWMCrr76KqqrMmTOHpUuXMmnSJJ544glGjBhB165dmT59Ok5nyP+OME2W1XdY/nVVznnIuvK/immaPDPxGebPm891111HaWkpffv25euvv8btdjN9+nRGjRrFsGHDTnjZZL37H0FE/MEIGZ5a+mhTCDhUyJGtv5PctgUi1o1P1dEJLvEkq4GkIkIIAiKAqagIVLSAQDUFhiNohaVThVWa5E/hhGhsI2bhQ981TSMxMZHExER7X0UZuypz34qaVetv7dq1j5qHoigkJiaSlJRU6RjDMMod2MPydzqd1KlTJyLfqo6TSCTVo6lWhEyVmOYtOXvGKwhDEFujJuDAVcHUzCS0XIZ8xf5nOOuss1i7dq295Fu3bt2oU6cOO3fuJCEhgaysLIqLi0lOTrbTRGiohQgLOKLYmyX/+xQYBazpsQZ3MzffpnyL2+0mMzaT0kGlKCg0atGIn5v8zKbMTSesTH7Tz8VJF3Newnkn7JySvx7LzFStsE0VCiQlkNKjM/7Q3JrbcnyVXmmSatBNE0MDzVTw6kFfdIdpBiMxyw7sL+OEmSIfiyD4ZwiLx3seK/Kxhcvlwu1243A4IrTDUpCVSP5TFAzUYFAXRcFRuw4Rq+eFIu5YrkKaHCn8TyGEYNmKZbz74bsMGDCAex+8l4ceeoiUWik0bdWU6MRoUmukIhwCj+kpT1cxH8qNkqtcE/Y/QEXFoThk+34Kc9g4TLvG7bj3rHurPqDViS0PwMayjawrWScF2/8VlMgQDpV8iVUj5AxvReAV5fusDCT/k1jLhBqGEbE6CxDhGllVH2JojtCa1gKnCK6/LkLRj/84loPkP+WEmCKfyljmyEIIysrKWLt2LV6vl7Zt21KzZk054JFIQgghyMrKIjs7m/bt2+NwOGxTfY/Hw549e2jfvj1ut7s8DYIAdoBSDCHQDAGKQUBV0BUrgIIg6D2poJiElj04Odcp+XMxhME92+/hYP5BXE4XTqeT6OhofD4fTpeToqIinA5nRL2piqPFEv1PKTKKmNJwCnFa3J+Uo+TPZodnB3Py5/BQrYciJpsrEj7YrOqYcNej6vij/RYbSjewrGgZd9a88xivQnKyEEJw8OBBdu3aRfv27XG5XLbrWllZGb///jutWrUiPT2dCJHWMk9WBOAPTcTqoXXDBKYanJzVkIqP/2UCgQDjx49n/fr1PP300zRt2pTJkyfTvXt3unbtyqOPPsojjzxCWlpaRDoD8AqIskLlC4GpKAQguG42yDHOX8QJjYp8KhKukY2JiaFnz562T65EIinH5/MxZswYdu7cyYMPPkifPn248847GThwIKtWrWLr1q2MHDmSoUOHRqx/V97IiOA6qHpQ52av8hdq4S0tnFIxbKXktEYgUBwKb3d5G6fiPNnFieDhzIfxCd/JLobkGLGEU6/Xy969e9m+fTuaptG8eXNq166NqqroerDFqU64tWJzrF69mpycHDp37kzdunUjjiktLWXLli1kZ2eTnp5Os2bNiI+PL4/dIapbgEVyqmEYBk888QS//fYbw4cP54orrmD06NG0atWKM844g9tvv50nnniCf/zjH5EJwwJOCcURsi4CJSyqtpRO/vcRQtCpUye2b99OXl4ezZo1o6ysjIMHD/Laa68xb948br31VlJTUyPaHBWIgpDJcTAgpkpQqAVktfkLkTZ/lM/whs/0VjfrK5H8XXE6ndx9992kp6fTqFEjVFVlwIABOBwO7rrrLtLT02nZsmVEGsX6KJXfM/sT/s9ea/ZkXKHkr0JBQUNDU06dT8g4/mTfGslxIITgwIEDPPDAA5x77rlcfvnlXHbZZfTu3ZvHH3+ckpKSY8pn27ZtjBgxgmHDhvHTTz9FWG7t2LGDESNGMHDgQK666ioGDhzI1VdfzYYNG+wyyLHB6YOmadxxxx2kp6fTokULhBAMGjQIRVHIyMjg4osvZu3atQD2cm2Rn8r9U2TfJflfZ/369RiGQVFRET/88APNmzfHMAwMwyAuLo6tW7dWSlM+7qk49pHutX81f3uNrUQiOTY8Hg9PTnyS/CP5fPjvD6lTpw4pKSn4/X6eee4Zsg9mk1+Yj1/4/xT/x2NBQUFXdDnQPA0QiEqWMGVlZUGTZKeTqKioSmms51qVBY1hGBQXF6OqKnFxVZsSG4ZBaWkpqqoSHR0t68lpjmEYPP/887z99tsYhkGtWrXwer1kZ2czZcoUateuza233moHlqxYb4QQtsXJ9u3b7VgaFsXFxdx///188cUXxMTEULNmTXJzc1m0aBElJSX83//9X8hkVXK6EAgEmPzCZPZm7+WLb75g6YqldOjQAWe0k0kvTGL779u55JJLTmi/BUjf/tOEHF8O3yV+R37rfN4ueJta7loktkhE1VRq963NOR3PIbNlJm/kvnHCyqSicnHSxdRw1Dhh5zydkIKtRCI5JrYYWyi5u4REI5E9sXvIdmbj0B1BP9qGAdI8acxOns3Hez8+YWU6Yhzhnpr30CGmwwk7p+T4sYRa6++hQ4d47733WLhwIfn5+SQnJ3Peeedxww03kJSUFGExE65NC9+2fPlyxowZQ926dZk+fTpxcXH2EnGBQICff/6ZmTNnsnnzZlwuF3379mX48OGkpqZWGXFfcmpj+UrOmzcPn8/H8OHDGTNmDEVFRQwfPpyffvqJzz//nOHDhxMTExORDoKTKJ988gmTJ09m8+bNtlmytSQgwC+//MKyZctwuVw899xzDBo0iC+//JJ//etfrF69mgULFnDNNddIV6XTiD3GHrJHZJPuS2dn3E4cDgc7nTsxa5oEzgwQXxjPhrQN3L/3/v/8JNUEAqpOu19kFHFD2g30ju/9n59TckLY6N9Iv6H96BnbM2J5UIt2XduVa/JRqnWlslwgqgpKG55feHtk/Q5f3QVg0ZFFbCjdIIPXVYMUbCUSyTGRa+RyfdPrGZI85GQXxWZu/lwO+g+e7GJIjoPi4mLuvfdePvroo4jOfsmSJWzYsIEpU6ZU0sBW1Nzu3buXCRMm8OOPP1JSUkIgEIgQNhYuXMhtt93G/v37URQFwzBYsWIFO3bs4IUXXogQfCSnD6ZpcuGFF3Lw4EFGjBhB7dq1MU2Trl27smbNGjwej12nLKyVD3bt2sW//vUvjhw5whlnnMHmzZvx+XwRx+3atYuSkhLq1avHeeedR1paGpdccgnTpk1j3bp1rFixgmuuuUZq2k4jDgcOc2GDC7mxxo3BDaFmwhRmcG1stdyg+A/jOwgwTMM2Qw5vc2yBJ+RSKaxo/2Zo5Y2wrJcULmG/b/+feJWSv5Im7iZ0ieliP+9AIIDX60VRFFxRLjRNixA+K7YP1sSsNZFWWloKQHR0NLqu22ms/KuazA03Z97p3XmiLv20RE5bSySSY0ZDQ6/wz6E4qtxW1aficdWlryqvqvZpaCf7lkiOk2XLljFv3jw0TWPYsGFMnz6doUOHYhgGc+fO5fvvv6+Uxurg/X4/K1euZPjw4axYscKe3Q4fYObl5fH444+TnZ3NGWecwYsvvsgtt9wCwNy5c21fScnphaIo1KlTh2effZa33nqLjh07IoTg8OHD/Pzzz6iqSocOHYiKioqoD9aA0zAMkpKSuOeee5g0aRLR0dGV8o+KikJRFEpKSigoKEBRFLxeLx6PxzZj9vl8UmN7mqEpYf2WoiMCgsN5h8ncncnhvMNggK5U3X9F9DhKcJ+v1MfuHbvJzclFFSoO1YFDddh5GD6Dg/sPsm/3Pnxlvoi8Zb91+mKaJsuWLeP222/nwgsv5OKLL+a+++7jl19+sZcECscSTi0UReHgwYMMGzaMSy65hK1bt1Y7SWaaJu+//z533XUXc+bMqTRhJ6keqbGVSCTHTPhMommaHDhwgF27dmEYBvXr16du3bpHjUpq5QHBgeaGDRvIy8ujXbt2pKen2wKMaZr4/X6ysrLYu3cvLpeLhg0bkpaWZgsyUmtyemGaJgERYMuWLURHR9OkSRMef/xx0tPT6d69OytXruTAgQPs3bu3yvSBQIC3336bsWPHcvjwYdxuN6WlpZVMtVavXs3GjRuJiopi3LhxDBo0iEOHDpGQkICu68THx5/Iy5b8iVjvvMPhwO/3U1JSwjPPPMPatWupX78+1113XbVm5hkZGXzyySc0adKE33//PWKf1Sa1bNmS9PR0cnJyePDBBxkyZAjfffcdW7duRdd1ioqKgoNXqRI4rQjvt7Zv386LL77IihUrKCoqIj4+nh49enD//ffToEEDdF2PWDoqPD2A3+9nxowZPPfcc/Ts2ZM333zT7vMMw+Dnn39m0qRJrF+/Hp/PR6NGjbjzzjsZMGAATqdTukGcpgghmDdvHnfccQd5eXn2OGT58uV89dVXzJo1i27dukUcH66BBSgpKeGll17iyy+/xO12VxnszjCCFgHfffcdDz74IAcOHEAIwRVXXCHHPMeIFGwlEslxYZomJSUlvPrqq8ycOZPc3FyEECQkJDB06FAeeughUlNTK6WzGnqr4d65cyfDhg1j7969zJw5k0suucTOPy8vj6eeeoq5c+dy5MgRVFWlZs2a3Hjjjdxyyy2VtC2SUx9VVVGFyk033cSQIUMIBAL22n9+vx+/34/D4aBmzZpVTlyEm4pee+21OJ1O3nzzTXsfBAeiGzZswO/3U6tWLRo2bMjKlSsRQnDHHXdQo4YMtnE6Ey5oFBcXM2HCBF5//XXi4+OZMGECbdu2jag34d9jY2Np0aKFvb3icaZp0rx5c2677Taefvppli1bxpIlS9B13R6EVvR1k5weWH3PwYMHufnmm1m1ahUOhwNVVcnKyuK3335j586dzJo1y162paKfo/X322+/5bnnniMrK4v8/PyI8+zevZtbbrmFDRs2oGkaiqKQk5PD5s2bmT59OoMGDTqh1y358zhy5AhTpkwhLy+P1q1bc8stt5CXl8fUqVPZvXs306dPp1OnTjidkUvaWebH2dnZTJw4kdmzZ1fS7EYsE6SqZGdnM2bMGA4cOGBvkxw78m5JJJLj5oMPPuDJJ59k9+7dREVFER0dTU5ODlOnTuXll1+u1HBbWALIvn37ePjhh9m0aRMej4eysjK7cQ8EAkycOJHXX3+d3Nxc4uLi0HWd7du3M378eD755JMTdp2SPxER7MDj4+Np1KgRTZs2RdM0SkpKmDp1Kvn5+bRr1y5i1jscVVVp06YNM2bMYMqUKaSlpdmaEgvTNMnJycEwDHw+H7fddhuDBg1iwIABDBo0iK+//lqakZ7mmKZJfn4+Dz30ENOmTSM5OZkXX3yRyy67LGKAGK6lq2gOWHGbNZGiqip33nkn06dPZ/DgwfTr14+xY8dyzjnnABAfH1+pzklOD4QQLF68mJ9++gm3282jjz7KV199xd13342u66xcuZJVq1ZVmdaqc6+++io333wz2dnZqKpaSfidP38+GzdupHbt2sycOZM5c+bQrFkzO1heIBA4UZcr+ZPJzc0lNzeX5ORkHnzwQW6++WYefPBBBgwYAMCOHTsoKyurMu3atWu5+OKLmTlzpj3hEU54e+TxeHj22WdZu3ZttdHdJUdHCrYSieSYsTQl7733Hh6Ph969e7No0SKWLl3K+eefj9/vZ/78+Rw+fLjKQaXP5+OLL77giiuuYP78+fZ+TdPsiLaZmZnMmzcP0zS57rrrWL58OV988QVt27altLSUTz75BL/fL2cxTzMswcESLEzTpLCwkAkTJvDOO++QlJTEo48+Wknbb2lPVFXlmmuu4fLLL7eX7vH7/RHHmqZpBwTav38/v/zyC/Xr1yc2NpZNmzZx7733VjJDlZw+WO3PI488wqxZs6hTpw6vvfYaQ4cOrVS3qmp/rDyAKjW7hmFQUFDAGWecwbRp0/joo4+46aabyMvLA6hkqio5PbDqRW5uLk2bNqVPnz7ceuut9OjRg1tuuYW0tDT8fr/tV22lsTBNk3HjxvHQQw9RWFhISkpKlfWqVatWjBw5kgceeIDLLruMvn370rp1a9vKyaqXktOPRo0a8c0337B48WIGDBiAqqoR/U16enolba0VuC4vL49du3bRqVMnHn74YVwuV6XjrHZr/vz5vP3227Ro0YJ27doB0kLkeJFTjxKJ5JixllLp1KkTiYmJ3HDDDTRr1gxN0zj33HP55ptvKCsrq3ZmeufOndx6660cOnSIli1bsmfPHnw+ny28WMGAevbsyaFDh7j55ptp2LAh9erVo0OHDqxfv14OEE5DFMojOlrm6IWFhYwdO9YWaidOnMgFF1xQZVRJqLpzr1gHFEWxo0y6XC4ee+wxhg0bxvr16xk2bBiZmZl88cUXtG7d+i+7Vslfh2EYvPnmm8yePRuAnj17UlRUxEcffYQQgpSUFHr16kVZWRlLlizB5/PRvXt36tatW229gvJ6lJWVxbXXXsvOnTsZO3YsV155JQsWLGDr1q24XC569+6Npmmy7TnNsCZPb731VoYNG4bP57OXBztw4AClpaW43W4aNGhgCyMV3SHy8vKoVasWDzzwAMuXL2fOnDkR51BVlQsuuIA+ffoAsH37dhYvXszy5cuJiYnhkksuweGQa9eerjidTrt+WOOP7777jsWLFxMdHc3ll19epRmyoiikp6czduxYrrrqKrZu3Vopb6s92bp1KxMmTMDhcPDYY48xc+ZMfv7554hjJH+MFGwlEslxkZSUxLPPPovP57PNakpLS+3IgC1btqw2QI9hGMTExDB06FAGDx7MtddeG7HkhqIoNGzYkNdffx3DMOxB5KFDh+wIgh06dJADhNMYRVEoKipi9OjRzJ49m5o1a/Lss89y4YUXRpheVecrebQO3vLFtkye+/fvT1JSEt27d6dVq1ZkZWWxZ88eu25JTi/27t3L66+/jt/vRwjB7NmzmT17tl1fOnfuzJdffklWVhYjR46kuLiYd999l3r16h21vbD21ahRg1q1arF69WrGjBnDG2+8we7duykpKeGcc87hvPPOizhecuojKA/go+s6sbGxtnY/JyeHSZMmceTIES644AI6dOhgHxv+jDVN4+qrr2bMmDE0bdqUNWvWVH2u0Dksd5r3338fVQ3GFRg6dGiVFgSS04Pw+mAYBsuXL+eOO+7g8OHDXHvttfTr16+SFZmVpkOHDpxxxhkoilKlYAtQWFjI+PHj2bFjBw888AB9+/Zl5syZf90F/Q8jBVuJRHLMWAMCTdNwu9229m3WrFl89tlnJCYmcuONNxIVFVVl+vr16zNnzhxat27Nzp3la7FVXJRc0zRb8CgpKeH5559n7dq1NGjQgKuuuqrSEi+SUxtBuamV1+vlqaee4t133yU+Pp6nnnqKXr16UVJSYi+54nA48Hg8eL1eNE2zB6PhVCdctGnTBpfLRVlZGXv37qVly5Z4vV6OHDkCQFxcnDRjP01Zu3YthYWF9sRZuFmxEMI2UVdV1V4L2dLghx9v7bcEEYuYmBgeeeQRsrKy2LhxI7/99htut5u+ffvyzDPP2MHOpGB7+hBuLRLu8rJ//37+9a9/sWDBAjIyMhg3bhwJCQm2tjYcTdO4+OKLURSFQCBgB0Csqg+y+sRatWpx7rnnsmbNGubMmUOjRo249dZbpY/2aUp4ADHLN/vgwYNcdtllPPHEE8TGxtoTItWtQVvdag5CCN577z0+++wzWrduzcCBA8nMzLR9dgsLC9m5cyf16tXD5XLJsc8fIN8wiURyzJjCtBtnRVHw+Xy8+eabjBs3DtM0ueeee2ytRlUkJCTQsWPHCLPAih0AlAu6RUVFTJgwgddee43Y2FgmTJhAq1atpGB7GmKYBrqqs3TpUmbMmIHf76e4uJgxY8YwduxYIChwjB49mquuuoqpU6fyxhtv0KpVK95++20SEhLsvCoOHMJN07t27UqzZs3YtGkTDz/8ML/88gs7duzg119/JS4ujp49e0rB5DTENE3OO+88vvvuu2qfn8vlIioqioyMDL7++msMw4iIsm3VkQYNGvDVV19hmqYdKdvKs3379nz66aesW7eOvLw8GjVqRLt27YiPj6/S/1JyehDe3+zdu5c77riDhQsX0rRpU1577TU6d+5cZdTris+8quBjFpYZs8PhYNy4cRiGwYwZM3jggQd49tln6d27t60VlpxeWM983rx53HPPPRw6dIjrr7+eCRMmkJKSEnFMxfXVLYVAde2Gz+djwYIFeDwetm3bxmWXXWav0a0oCp988gk//fQTc+bMoVWrVghTjn2OhhRsJRLJMaMqwY5fCIHH4+Hll1/mmWeeQQjBgw8+yF133VXtOrbHMhi0OgNVVTl8+DBjx45lxowZJCYmMmnSJIYOHVplVEHJqY9CMNjT+++/T2FhIQBlZWVs377dfp6qqtr78vPz2bFjB7GxsVVG2Q5fsD5cc5eamsq4ceO466672LRpE+PGjUMIgcvl4rrrrqNnz55/9aVK/gJUVSUhIYGkpCSASpNjFSMfZ2RkVNLoWse7XC57f/hEnXV8jRo17GinFYNNybbn9CY7O5uRI0eyZMkS2rZty+uvv0779u0rHVeVcHu0yVRrDdu9e/fSoEEDOnbsiMPh4MwzzyQmJoaCggK2bNkiBdvTmB9++IH77ruPnJwcrrnmGkaPHo2u6xQWFqJpGlFRURiGQWlpKRBsZ5xOpz2mqQ4hBE6nk4SEBEzTpLS0NGJpxEAgQGlpabWrTUgikYKtRCI5Zix/Ja/XyyuvvMJTTz2FruuMHz+eG2+8MULorG4QcLSBoZWmsLCQRx55hLfeeouaNWvy0ksv0a9fv2P2tZScYghACQqj55xzDhkZGVUeZvlJqqpK7969cTgc1K5du5JpuxCCnj17omka6enpREVFRQjHAwcOJDU1lQ8//JAtW7aQkpJC//79GTx4cLVm8pJTE13R+aXkFybvn2y/8xUHiqZp2r8ramfDg9JZvysdQ5iQHOaTaaGgEPwveMyBwAGauJr8lZct+QsoLCzkoYce4ttvvyU1NZXRo0cTFxdnT67VrFmTxMREcnNzKSgowOVyUa9evUpL+1TVhwUCASZNmsS8efPo378/77zzDrGxsWzcuJHS0lJ0Xbc1e5LTD8sHNisry17PePXq1XY7ccYZZ/D666+TnZ3NiBEjKCkpYdKkSZx//vmVLIwq4nK5eOGFFyguLra3+f1+7rvvPpYuXcqQIUN49NFHqVev3gm51tMdKdhKJJJjxtLYfvXVVzz77LOUlZUxaNAg6taty+LFiwFwu9306NEDRVFYtWoVZWVltGjRgoyMjD/0M7FmKadPn86sWbMAGDhwIAALFy4EgsGrunXrJoP/nEZYfo/OKCc33XTTMaU5//zzOf/886vMS9O0avdbFgNnn302Z555ph3krGLESsnpQV1nXZ6q9xQBcWqtAVrbWftkF0FyjFjmoZ999hnz5s3DMAzy8vK46aabIibEJk6cyLBhw3j11Vd5+eWXad++PXPnzq3kBmFp+MOXl3I6nfTv358FCxbw7bffctVVV5GWlsa3335rryRgLd8iOf346aef+PHHHzFNE9M0yczMtPcpikJiYiKmaRIIBNi+fTvFxcW25jZ8YiR8/BO+3KEltFqCst/vJzo6GtM0SUxMpGnTpvbknYwRcXSkYCuRSI4Zy+9jypQpHD58GIAvv/ySr776ym6k69evz7Jly3A4HNx2223s2bOHp59+mrvuuuuoJjlWg75r1y6mTZuGx+MBYMaMGcyYMQMIdiA9evTgs88+k5q304xwrdh/ndcx5qPrerXBWqTG//RAUzQauxuf7GJITmOEEHi9Xj799FN7ogugqKjIPkbTNHtdbL/fT1FRkS2YhFNxcjbcMuCyyy7jl19+Yfbs2fZEr6qqtGnThqeeeqrSGt2S04eYmBjuvPPOSoEuLerUqYPD4SAlJYW7774br9dL06ZNgXKrEYB69epx33332RYCFhXrlaZpDBkyhDZt2tC1a9dIH13pDXFUpGArkUiOi23btrFjxw47Amm4eSAQoRlzOp04nc5KfrFWAx4VFUVMTEzE/tWrV1NQUEBMTExEEAbrr4wqefohrH9SmJRIJCcQgbAtRqxld6qjQ4cOCCG4/PLLOeOMM0hMTMTtdlc67tZbb2XQoEGkp6fbPpRCCGJiYnjmmWfo378/3333HcXFxbRu3Zr+/ftTv3596Z99GtOtWze6desWoa2Hyv79breb0aNH2/ugPB6Eoig0adKEsWPH/mFd0DSN6667LsJCQHJsyBGiRCI5ZhRFoVWrVnz55ZdV7reCINSoUQNFUZgzZw4+n49atWpV8nFr2LAh8+fPxzCMiE7/ggsuYOnSpRF5hjfq0dHRREVFSXOc0wQFBUMYjM4cbZuynypk+bJw4DjZxZBIJH8RlqWIy+XiggsuCG77g6j6Z5xxBmeccUaV+3Rd58wzz6RHjx5V5qHrOgMHDrSDj0mh5PTnUOAQWYGsY36OIlC9P+3xYNevMP9+qzxpetp/nf//KlKwlUgkx0V8fPwx+wq1aNGi0jarsXa5XLRu3brS/ho1athLcEhOf1RUnq3/LD7hO9lFqYSmaMSqsSe7GBKJ5C9CV3S+L/4ev/Cf7KLYbPdu5+y4s092MSTHQIuoFqwuXs27h9492UWxMYVJ08SmJ7sYpyyKkLZhEonkGPi+6HtePfAqdZx1TnZRbLJ8WdyWfhs94nqc7KJIJBKJ5BTDZ/rY6tmKIU6dpVIUFBq7GxOryUk1ieTPRgq2EonkmDCEwRHjyMkuRiUStAQ0RUZIlkgkEolEIvk7IwVbiUQikUgkEolEIpGc1pxakTwkEolEIpFIJBKJRCI5TqRgK5FIJBKJRCKRSCSS0xop2EokEolEIpFIJBKJ5LRGCrYSiUQikUgkEolEIjmtkYKtRCKRSCQSiUQikUhOa6RgK5FIJBKJRCKRSCSS0xop2EokEolEIpFIJBKJ5LRGCrYSiUQikUgkEolEIjmtkYKtRCKRSCQSiUQikUhOa6RgK5FIJBKJRCKRSCSS0xop2EokEolEIpFIJBKJ5LRGCrYSiUQikUgkEolEIjmtkYKtRCKRSCQSiUQikUhOa6RgK5FIJBKJRCKRSCSS0xop2EokEolEIpFIJBKJ5LRGCrYSiUQikUgkEolEIjmtkYKtRCKRSCQSiUQikUhOa6RgK5FIJBKJRCKRSCSS0xop2EokEolEIpFIJBKJ5LRGCrYSiUQikUgkEolEIjmtkYKtRCKRSCQSiUQikUhOa6RgK5FIJBKJRCKRSCSS0xop2EokEolEIpFIJBKJ5LRGCrYSiUQikUgkEolEIjmtkYKtRCKRSCQSiUQikUhOa6RgK5FIJBKJRCKRSCSS0xop2EokEolEIpFIJBKJ5LRGCrYSiUQikUgkEolEIjmtkYKtRCKRSCQSiUQikUhOa6RgK5FIJBKJRCKRSCSS0xr9RJxECHFc2y0URUFRlOPOu2IaIQRCCHu79d00TVRVrTLNsZTzj8p2oqju+iz+6H5Ud9z/MtYztf5Wd++OJz9FUarN7z+9t1WV8+/0nCQSiUQikUgkkmPhhAi2EByYm6YJVC1AVSVsaZp2THmbpmmntQTVqjAMI+K3qqoRwu2fdZ4TiXXfKmLd6+rKaV0LBO/z31FYCq8PllCqqmpEXTVNE7/fbz9zTdNQVRXDMCLqp6Io5OXlsWjRIvr27UtSUpJ9T/+beyuEIBAI2ALtsb4TEolEIpFIJBLJ34kTJtiWlpby6quvsn//fpo0acKIESNwuVxAcPD+/fffM3fuXNLT07ntttuIjY09pnwtwc7r9XLkyBFq1apV7bFr167l//7v/4iNjeXOO+8kJSXlmMtvCYHFxcX4/X5SU1OPOe1fjSWUWWUsLCzE4/EctYw7d+5kxowZANx8881kZGSckLKeSljCYmZmJtOnT+eMM85g8ODBaJpGQUEBn3/+OV999RW5ubkoikLNmjUZPHgw/fv3Jyoqyp7k8Pl8rFu3jrlz5/LOO+8wfPhwhg4dSvv27f/rCRAhBB9//DGbNm3i1ltvpU6dOn/S1UskEolEIpFIJP9DiBOAaZoiLy9PdOrUSSiKIpKSksRnn30mAoGAMAxDGIYhXn31VaHrumjZsqU4cOCAMAxDmKb5h59AICC+//57MWTIEPHYY49VSmed3zAMMXv2bKHruqhZs6bYvn278Pv9x3QewzCE1+sVX3zxhejbt6949913jynNsZT/z/oYhiF8Pp/45ptvRP/+/cW0adNEIBCodJzFkiVLRFxcnIiLixPLly8/KWU+UZ/q6mQgEBBlZWXinnvuEbGxseKjjz4SgUBAHDhwQFx55ZXC7XYLTdPsj6IoIjY2Vtxzzz2isLDQTj916lSRnp4udF0XmqYJh8MhateuLd566y3h8Xj+6/J/+OGHIjY2Vjz00EPC5/P94bVJJBKJRCKRSCR/N06YPa2qqrZm8ciRI0ycOJG8vLwI82MzZP4JQW2aYRgRHzNkPitCpqJCCIqKirj//vuZO3cuJSUl9r7wvCwyMjIYNmwYl19+OTExMUC5qadpmhiGYf8OP49hGOTk5HDHHXewZMkSvF6vnaeVRghRqZzh5bW2W9sMwyAQCNjbK/6t+L1ieQzDwO/322U1TZOcnBzuueceFi1aRCAQAIi4FgshBOnp6Vx11VVcddVVpKWlRZwzvFzWvbHysPKx7lMgEMDv90eUv+KzsspnHV/xmqy8rHtZ8dqt67TyDr+34c8t/D6HH1MdiqKwYcMGPvzwQ5o1a0bPnj0B+Prrr5k3bx66rnP11Vfz1ltv8eKLL9KtWzfKysp46623WLZsGYqisHv3biZNmkRhYSEDBw4kNTWVXr16cejQISZOnEh2dnbEPajuHle83+H3sWfPnjRu3JhZs2axYcOGP7wuiUQikUgkEonk78YJMUWuKnjR6tWrefPNNxk1alS15ppCCAoKCvj666/59ddfUVWVrl27ct555xEfH09ZWRlfffUVOTk5AGzZsoWPPvqIPn36kJKSUslnNzU1lbPOOguXy0V0dDRCCFatWsXOnTtp2bIlKSkpzJ8/n127dtGoUSMGDx5MvXr1KCws5LPPPqOwsBCA1atXk5yczPnnn09UVBT5+fksXLiQNWvWoGkanTp14vzzzychIQEImi8vWLAAr9dLly5dWLJkCbt27aJfv36cc845+P1+Vq1axZIlSygqKqJZs2YMGjTINjtVFAWPx8PKlStZtWoVhw4dIjo6mrZt23LBBReQlJREcXExX331FYcOHUIIwU8//URaWhr9+/cnNja20r1ISEjgrLPOQlEUEhMTURSFX3/9lV9++YWGDRvSrFkzPvvsM7Zu3UqNGjW46KKLaNGiRYQP6t69e5k/fz579uzB6XTSoUMHLrjgAhITE23ByzAMNm7cyDfffENWVhbJycmcddZZnHXWWbjdbhRFoaCggG+++QZN0zj77LP56aefWLFiBTExMVx00UW0atWKn3/+mQULFlBcXMzZZ59t33uLzMxM5s+fz86dO4mPj+ecc86hR48euN3uauulYRh88MEH5ObmMnz4cJKSkjBNk3Xr1uHz+Wjfvj2TJ08mJSUF0zTp1q0bl112GXl5eaxatYr+/fvz+++/c/DgQZo1a8Ydd9zBpk2bePDBB2nfvj0JCQlomoZpmqxevZrff/+dZs2akZKSwueff05mZiZt2rTh0ksvxTAMvvjiC3799VfS09O5+OKLady4Mbquk5qaynnnncdLL73EBx98QNu2be2JIolEIpFIJBKJRMKJMUUWQoj8/HzRuXNnAQiXyyVUVRX16tUTq1evtk2RVVW1TZFN0xS7d+8WF110kXC73ULXdeFyuUR0dLS4+uqrRU5Ojti/f79o1aqVUFVVqKoqNE0TKSkpYvXq1cLv91cyRX7//fdFVFSUqFu3rti+fbvwer1ixIgRwul0igsuuEC0b99euFwu2/T0zDPPFLt37xZr164VqampQlVVoSiK0HVdNG3aVGRmZoq9e/eKIUOGiKioKKHrunA6nSI2NlZceumlIisrS5imKXbu3Cnq168vEhISxPnnny+io6OFqqq2Seu4ceNEcnKy0DRNOJ1O4XK5RIcOHcSqVatEIBAQpaWl4sknnxSJiYlC0zThcrmEw+EQbrdbDB06VOTm5orNmzeLWrVq2SazmqaJjIwMsWPHDhEIBGyzZIulS5eKpKQkkZSUJFasWCEMwxDjxo0TDodD9OjRQ/Tu3ds2xXU4HKJVq1bi559/tk3HFyxYIFq2bGlfs67rwu12i0svvVTs27dP+P1+UVZWJp577jlRu3Zt4XA47OPi4+PF7bffLg4dOiQCgYBYt26dSE9PFzVq1BBDhgwR8fHxwuFwCEVRROPGjcWjjz4qateuLZxOp1BVVcTHx4sXX3xR+Hw+4ff7xapVq0THjh3t+6LrukhKShJjx44VJSUlVZomm6Yp9u3bJ1q2bCliY2PFwoULhWEYIhAIiCeeeELoui4SEhLE+PHjxYYNG8SRI0dESUmJWLFihViwYIHYuHGjCAQC4uuvvxYxMTGiVq1a4qWXXhKNGjUS69atEx6PR/j9fhEIBITf7xe33nqrcDqdomfPnqJdu3YiKipKaJomoqKixLBhw8TFF18sYmJihK7rQtd10aVLF7Fjxw47j88//1y43W7Rpk0bkZ2dXel5SiQSiUQikUgkf2dOmCmyCFv25MILLyQ9PZ19+/YxceJEiouLI5ZLEULg8/l4/vnn+frrr0lNTeXJJ5/kiSeeIDk5mY8//pg33ngDl8vF0KFDqVGjBkIIOnfuzC233EJqamolU00rb5/PFxFl1jJ1XbZsGfXq1WPatGmMGDECh8PBmjVr+Pbbb6lRowZXXXUV0dHRKIpC3759ueGGG3A4HLzyyivMnz+fxMREHnvsMZ5++mnS09P54osvmDZtmm0KHAgEKC4uZvny5dSuXZsmTZrQt29fFi9ezAsvvEBZWRk33ngjr776Kt27d2fDhg2MGzeOwsJC9u3bx+uvv47X6+XOO+/knXfeYfTo0cTFxbFw4UIWLlxIQkIC11xzDXFxcWiaRp8+fRg2bJgdhKvi/RBC4Pf78fv9Efc+EAiwZs0aTNNkypQp/Otf/8LtdvP7778zb948AHJychg9ejRbt26lS5cuvPrqq4wfP57ExES++OILZs+ejRCCxYsXM2HCBPLy8rj00kt54403uPPOO1EUhTfffJPXXnvNLpff7ycvL481a9YwZswYJkyYQHJyMrt37+aFF17gggsuYOrUqXTq1ImSkhJmzZrF4cOHKSwsZOzYsaxfv56WLVsyZcoU7r//fgzDYMqUKSxcuLDaOvnbb7+RmZlJSkoKTZo0sevEJZdcQpMmTSgqKuLJJ5+kb9++9O/fn7Fjx1JWVkb37t1p0aIFiqLQrl07WrVqRV5eHuPGjePQoUN8++23tgmypVW1TMdXr15N8+bNmTp1Kv369cPn8zFr1iw2b97M008/zb333ovT6eTnn39m8eLFdt1t2rQpycnJ7Nmzh61bt1Zpai+RSCQSiUQikfxtOVES9KFDh0SXLl2Eoiji8ccft7WD0dHR4p133hFTp04VmqaJFi1aiJycHLF3717RpEkToeu6GDNmjPD5fMLr9Yqnn35a6LouunbtKvLy8kR+fr7o2LGjUFVVPPDAA8Lv99va2nCNlmma4r333hOapomaNWuKHTt2CJ/PJ4YNGyYURRFNmjSxtbg7duwQDRs2FKqqigkTJgi/3y927NghatWqJRwOh3jjjTdEIBAQmZmZolWrVkLXdfHggw8Kj8cjfD6fmDJlinA4HKJdu3YiNzdX7Ny5U9SpU0eoqip69eoldu7cKTIzM0V+fr645pprhKZp4uyzz7Y1mCtXrhQpKSkiMTFRLF++XKxbt06kpqaK6Oho8cgjj4jVq1eLnJwc8eWXX4qvvvpK7NmzRwQCAbF7927RuHFj4XA4xCuvvGLfi6o0tkuWLBGxsbEiNjbWDh41duxYAYi0tDTx/fffC5/PJ3Jzc0XHjh2FoijixhtvFH6/X8ydO1dER0eLxMREsWjRIuHz+URpaal4/fXXxSOPPCLmz58vioqKxGWXXSZUVRXnnHOOrWUsLCwUt912m1BVVbRo0ULs3btXrF271tZYP/bYY8Lv94vDhw+LXr16CUB06dJF5OTkCJ/PJyZOnCgcDodo0KCB2L17t1iyZImIj48XUVFR4t///rcIBAKiuLhYXHHFFULXdXHDDTcIr9cbERjLqg8vv/yy0DRNdOvWTeTn59uafa/XK5YtWybOP/98kZCQYGvBFUURiYmJ4pprrhGZmZm2Nvbbb78VnTp1Ei6Xy7YsaNq0qZg2bZooLi4Wfr9f3HTTTQIQjRs3Ftu3bxeBQEB89NFHIioqSjidTjFt2jTh9/vF3r17RbNmzYSiKGLs2LG2hjwvL0906NBB6LouXn/9dft6JBKJRCKRSCQSiRAnbLmfcDRNY/jw4Xz99desXr2aSZMmcdFFF9n7FUVh37595Ofno6oqJSUlfPTRRwAUFRWhqip79+4lNzeXmjVrRqSz/ooKPqVHQ1VVGjRoQI0aNVBVlfj4eOLj421/0vD8RJjmOTc3l/3796MoCl6vl08++QSA3NxcVFXlwIED5OTk2P68qqpy/vnnU6dOHVRVpaioiJ07dwLgdrv55ptvUFWVgoICHA4HhYWFbN26lcGDB9O5c2cWLlzIpEmTmDp1KvXq1bN9PmvUqGFr8ERYgCfLd/l47gUEfZEbNWqEqqq43W7S0tJQVdUOcrR582Z8Ph916tShWbNmmKaJw+Fg+PDh9nkPHDjApk2bUFWVnj17kpqaimEYuN1u+vbty1tvvUV2djZ79+4lOjoaAKfTSbt27ew6Ehsbi6qqNGzYkISEBBRFITk5OeIat23bRmlpKdHR0ezZs4d///vfEde6ZcsWPB5PpeWjhBAcOHAACPobW0tPWevVnnnmmXz00Uds2rSJlStXsnbtWr7//nuys7OZM2cONWrU4IknnsDhcHDOOefw6aef8sEHH/DEE0/gcrnYvXs3jzzyCE2aNKFXr172eevUqUNaWhpCCPv6dF2nRYsWAMTExNj3w9L2W/cmLi4O0zTZv3//cT9TiUQikUgkEonkf5mTItgKIahVqxYPPvggw4YNY+vWrRw5ciQi4q7X67UjxM6ePZsPP/zQFjSTkpKIiYnB5/PZx1t/LaHzeAb+pmnidDrRNM0WbKA84rGiKGiaFiHcAhFRft9//31b+AZITEwkJiaGsrIyW1ARQlCjRg00TbPzLy0ttYM9bd68GVVVMQzDFuK8Xi+JiYm88MILTJkyhcWLF5OVlcVvv/3Gxo0b+fe//81TTz3FjTfeaF97+D2B4xf0nU4nuq7b122VycKKCm0JZbquY5pmpXtnPR9LKLXKEhsba0e99nq99pqw1nNQVTVCKLcEQOv5h+P3+1EUhdLSUiZPnmw/Q9M0SU5OxuVy4fV6iYmJibh+ETJLN00TXdfteuD1elm1ahXbtm2jbdu29OjRg+7du+P3+9mzZw8jR45k6dKlfPvtt5SWlhIXF0cgECAhIYE+ffowbdo0Jk2axMsvv8yKFStYvHgx55xzToSAqut6xDWqqorL5bLLbhF+Laqq2nXQ4/HY2yQSiUQikUgkEslJFGyFEJx//vkMGTKEd9991/ZJBOxIvW63G6/Xy8MPP8z555+Pqqrk5+dTWFhIfHw8GRkZtr9sVRrV4ymPlaZitNmKeVnHGoZBdHQ00dHReL1eHnjgAQYOHGgvZ1RYWEhMTAzNmzcnLy/PLpvL5bIFNJfLZWvvLrjgAsaOHYuu65SWlnLgwAGcTifNmzentLSUmJgY7rnnHu6//3527tzJqlWr+OCDD9ixYwcffvghV199dYTwGH6fgeMWgqzjwwV563d6ejqKonD48GHy8/Pta1izZo0dUbpx48akpKSwZ88eNm/ebAvriqLw+++/4/f7SUpKIj093RaAw+93xWuoqI23ypSUlISmaURFRTF9+nQyMjKAoB9wIBAgNTWV+Pj4KvOxtPJer9eexDhy5Aj3338/mzZt4sILL6Rdu3bExcWh6zoNGjSgefPmLF26lNLSUgzD4O2332bmzJm0adOGG264AUVRaNiwIT169GDlypWUlZVVeX+rmoCoar/1LEzTxOfzoSgKKSkpUlsrkUgkEolEIpGEcVJUPpbg4na7+de//kWjRo0i9gshaNCgAU2bNsXv97N8+XJiY2NJTk5mxowZDB8+nBdeeMHW1jkcDhRFobi4mMLCQnw+35++zqemabZmr7CwkOLiYmrVqkXr1q0JBAIsW7YMp9NJjRo1mDVrFsOGDWPSpEm2ptPSaIYLNFFRUZx55pmoqsqaNWsoKCigVq1a/Pzzz9x0003cc889HDp0iKVLl9KrVy/69+/P2rVr6dq1K7fccottthsujFt/CwsLKSwsxO/3/2n3wLqWLl26kJiYSEFBAbNnz6agoIDs7GzGjh3LiBEjeOWVV4iKiqJXr16oqso333zD119/TWlpKb/88gtvvfUWQgjOPvtsGjRo8B+VxbrODh06kJaWRmlpKStXrrSFvscff5xhw4bxySefVBKWrfSNGjVC0zQOHTqEx+MBIDk52V7PdtGiRTzxxBP8+OOP/PLLL8yYMcM2N2/WrBkxMTHExMSwfv165syZw4cffojH4+Gnn37iyy+/RNd12rVr919pVq0yl5SUcPjwYXRdJyMjQ2prJRKJRCKRSCSSMP4yjW1V5sFQLtRaGrQWLVpw991388ADD+D1eu3j4uLiuO2229i0aROff/45GzduxOVysXXrVqKjo7nkkkuIj4/H6/VSq1YtFEXh//7v/1izZg0vvPACXbp0qWS6WpUmMHxfOOFRkwGioqJIS0sjOzub5557jvnz5zNz5kxGjhzJr7/+yjfffEP//v2JiYnh999/x+FwcMkllxAXF8ehQ4cqCSLWPbj66quZN28emzZt4vLLL6du3brs2LGD4uJiBg4cSOPGjUlPTycjI4OlS5dy66230rhxYzweD7///jtOp5PLLrsMt9ttC/+7d+/mlVdeYcGCBUyfPp2mTZtWMqMOfw7hz6vitvD7ZJknt2rVimuvvZZp06bxyiuv8OWXX+L1etm9ezeJiYlcc801REVFccstt7BixQpWr17NiBEjaNSoETk5ORw4cICMjAxGjRplm2lXpakNfy4VJyqscjVq1Ihrr72WF154gRdffJHPP//cLku9evUYNGiQXe6KdbNZs2YkJCRw4MAB8vPzSUxMRNM0u9wbNmzgxRdfZNq0aei6TklJiW1Gf/vtt9v+wueccw5LlixhxowZGIbBvffei2EY9OnTh4EDB1ZZx8LfC2u7VdfCf1vbDh48yIEDB0hKSqJp06aYpmmbtEskEolEIpFIJH93/lJT5PCARoqi0LZtWxwOB3Xq1IkQrK666irWrl3Ltm3bqF+/vq2BvfTSSwGYNm0au3btori4mI4dO3LLLbdw2WWXoSgKTqeTESNGsHfvXrKysigsLLQF5HDTU8MwiI+Pp3v37sTHx+NwOGzBqEePHjRr1iyirJYJat26dTFNk7i4OG6++WamTJlCQUEBJSUleL1eLrroIkzTZOrUqezatYu8vDzatWvHiBEjuOKKKwBwuVx07NiRgoICkpKSIsyDmzZtyowZM5g8eTKrV68mKyuLmjVrctFFF3HvvfcSFRWF2+3mtddeY/LkyXz33XdkZmbicDho37491113HTfccIMd9GrkyJFMnjyZ/Px8ioqKKCsrwzCMiEBYANHR0XTp0gUIBiwyTZM6derQo0cPO3CUdXzz5s0pKiqiQYMGmKaJy+Vi9OjRpKWlMWfOHHJycnA4HJx55pnceeed9OnTxw769Pbbb/PSSy+xZMkSsrKyiIqKYsiQIdx999107NgRIQRut5vOnTvj9XqJi4uzzZabN29OQUEBDRs2tH1wU1NT6d69OykpKba/6v33309iYiIffPAB+/fvx+Vy0adPH+6//346d+5crdlukyZNaNmyJT/99BO//fYbTZo0wTAMmjRpwqxZs5gyZQqrVq3i0KFDmKZJjRo1aNeuHbfddhtnnXUWQgiSk5N59dVXmThxIgsXLiQnJ4eaNWsycOBA7rvvPjvYVaNGjTjzzDNp2bKlfS1xcXF07doVXdeJjo62tfpt2rQhKiqKOnXq2M9g69atFBUVceaZZ9KgQQOpsZVIJBKJRCKRSMJQxJ9tsxvCGryH/7ai6loBhyxM07SDMKmqagudViThoqIiDh48iGma1KxZk5iYGDu9EALDMCgoKCA3N5eEhAQ7QFO4RswwDPs8ENQ+apqG3+/HMAw0TbM/hmHYZbWEJyt9bm4uhw8fJiUlhdTUVPsaSkpKOHjwIIFAgFq1atkRbK2AP5YfqXXecE2kaZoYhkF2djYej4fExERSUlIqBRMyDMM+v6ZppKen24GYwgX4gwcPUlhYSGJiIsnJyTgcjuDDDsvLCnwVXibrusPNu63nZj0bS/tplbugoIC8vDwcDgfp6emVgjQB+Hw+CgoKKCgoIDo6mpo1a+J0OiM095b5uLVdVVU7uJMVwMrSoFvltszDrbIcOXKEgwcP4nQ6qVWrFlFRUUf1RTUMg5deeonRo0czcuRIJk2ahKZpBAIB+29+fj5HjhzBNE0SEhJITU21zxmet8/nY9WqVfzzn/9kxowZnH322RHHGYZhTzCE1/2K9SL8XQgPzHXPPfcwY8YMJk2axO23316lebVEIpH8L+D3+zl8+LAdx6KkpMTuG0tKSoiJiUHTNDweD263W7aDEonkT+GP2p7o6Gg7xkpSUpJse05B/lKNrSUzZ2dnM3XqVEpLSyP2VwxMZAmyluaqIhWPr25b+L6qynM8HC3/ox1TUfCpaAZ8tHJVDIZV1faK6ao6tqpjKlJd/hUDT1Vlqnw8VLz+is/4P73Pf3RsdY2OVddycnJQVZV58+bh9/sr+Ssf7f5XvAYrsNnMmTOZP3/+H5bPKkdV5wq3cujbty+LFy+mcePGXHLJJZWOkUgkkv8VhBD89ttv3HHHHfTt25fRo0dz2223sW/fPq677jo++OADevfuzYUXXsjzzz/P9OnTcTqdJ7vYklMEIQRFRUX4/X7bvciaLPZ6vfh8PhITE6ucaJb8vRFCsGnTJu644w769evHQw89xK233sr+/fu55ppr+PDDD+ncuTM//PADKSkpzJgxg/j4+JNdbEkF/vI32lqXdfbs2eTn5x/12P9UaPpP+G/O9VcJYacip2LZ/ooyZWZm8sYbb9ja7f+mblgBpv5TwoVVK9J2bm4uEyZMoF69elKYlUgk/9O0aNGCPn36kJmZic/ns5fje/XVVxk9ejTTp09nyZIldmT+8PXsJX9vAoEAkydP5ssvv+Tjjz+mXr16vPHGG/aqGnPmzOG9995j1qxZnHfeefTt2/dkF1lyCtGyZUvOPfdc9u7di8/ns1cyefXVV3n00Ud56aWXiImJIT8/n927d9tBXCWnDn+pYGsNwC1fyz8zQq9E8t9iaVwDgQAHDx4kKiqKpKSkKtfLPZGEC66pqal4vV5mzpxJz549pfmxRCL5n2fmzJkcPnyYffv28eSTT9rxFQzDYO7cucTExNCtWzc+++wziouLT3ZxJacQuq5z+eWXs3DhQnJzczl06BDPPvssl112GcOGDePzzz/n3Xff5Z133qFBgwZ2TBCJBOCtt96isLCQzMxMnnzySYQQdtvz8ccf43A4qFGjBgcPHqSoqOhkF1dSBX+pj2342qFyMC45VTlVTXorRqyGyKWdJJJTlepcII7VbUTy98Vv+hm/cTzfrf2Ouul1WfvFWlpc0IKSkhJat27Nhl830LRZU2rVqkVmZiYNGjSouv5YVa3CLtv9AyViX0Q/IELpRIX04b+rOcYQBtekXkNTd9P/6Pol/x379+9nwoQJZGZmkpGRQbNmzVi/fj2HDh0iKSmJ/Px8mjVrxvbt22nfvj0PP/ywXGFAAoDP9DF+w3iWr1tO3fS6rPtiHc0vaG63Pb/++iuNGzcmJycHgE6dOp1ypuxCCJq6m3JlypV/2371L9fYVvSjlEhOBf7I9/hk1tWKvtjyvZGcTggh2L9/P9OmTaNJkyZce+21CCGYN28ebdu25f3336dmzZrExsayadMmRo4cSb169U52sSWnCGWijPy4fGZdPQsEiN4ClLB2sHm5EGqmmahK1ZN9VcW0CI8dUdWES3j8BysOw7FMzITnt6RwCRtLN0rB9iSRFZPFnr57EIZg3bZ1ZKdl0+jeRjhLnWRlZVFaWoqzm5Pah2tzxHWEp3OePtlFjqC2szbDUoehKlKLfKLxCA8F8QXMunpWcOKrD5ETWy1OVsmOnTKzjJcPvMwVKVcEr+FvyF8m2MrBuORU5lSun6dy2SSSYyE+Pp6cnBz279/P1VdfzYoVK3jooYf49NNPOXz4MJs3b+bGG29kwoQJXH311VKwlUQQpUZR31nfjhIfHrVf13V0R3DoEj75V1UAPmtfuPVL+O9wtxO/34/f70fTNDs6f8VAgtax1ioBVp7Wd0VRSHOk4TW9f+n9kVTP2rK13HrurbSNbltZa98m7MDaJ7hgx4AhDCbtn8S1KdfiVGRAtJOB1facruOwUqMUXTm1tMgnmr/31UskEonkT2fnzp3069ePl156iZ9//pm3336bkpIS3nnnHXr27MnEiRM5cOAAvXr1Ys2aNbRu3fq0HUhI/lpM02TZsmX8+9//Zs+ePfY67/37969ySbdwIXbVqlUsWrSokmBbs2ZNhg0bhsvlwjRN1q5dy3vvvcfWrVupWbMm//jHP+jXrx9Op7NK/8sDBw4wa9YsAK699lpq164t6+8pgqIo1HLUooGzwTEffzT+LG+9qlaqqEiAAC7F9aecT/LfUdVzqu4ZHq0O/dFqJRXzOZ76dioGdz0VkIKtRCKRSP5UNudu5sU5L9K8Z3NueuAmJr02idrda5NWI41n/+9ZWvZryUc/fsQR7xH+0f0fbPNsO9lFBsCpOmngbCDNAE8RTNPk//7v/xg1ahSHDh2yhcxPPvmE++67jwcffLDSUj+WObFpmnz88ce8/PLLlTS0nTp14qqrrsLlcrFq1SpGjBjBrl277IHn/PnzefLJJ7n55psjBFvTNPH5fDzzzDO89tprJCQkcMEFF1CnTp0TdEckx4IgUrNurXXv8/lQVRWHw1GlqXl1mKZZ7T4rvd/vxzRNNE2zfXat84avthAee0ZyamMYBhB8/rm5uezfvx+Xy0XDhg2Jjo6uZK0RjhCCQCBAaWlplct/RkdH28ubAhw6dIjMzEycTieNGjUiKioqon4ahkFJSYntKhGeX/ixAvG3NUG2kIKtRCKRSP40AiLAFw2/4OLnLkYTGo0vacz6+PUkXZxEgACDuw5GUZWg/ySCDcoGNhRsONnFBmB1yWqmNpxKqiP1ZBdFAhQUFPDSSy+Rn5/P2WefzaBBg1i0aBHffvstb7zxBpdddhktWrSo5AdrRbvfsmULiqKQnp5OXFwcEBxU1q1bF0VR8Hg8vPjii+zZs4emTZty9dVXs2zZMpYtW8ZLL73EwIEDadiwYUSZ5s2bxzvvvGMPemUshFMQEbnqwc8//8x7773Hjh07SExMZMCAAVx00UXExsYec5Y5OTm8//77CCG47rrrSEtLA4LLC/3www/MnTuXnTt3kpqaSv/+/Rk4cGCVFgUQXPP+/fffp7S0lKFDh9KgQQMZwOoURFEUSkpKmDZtGm+99Ra5ubnous4ZZ5zBuHHj6NKlC0C1z2758uXcd999eL2Rrgmpqam89dZbNGzYkEAgwAcffMALL7xAdnY2uq7Tvn17nn76adq1a2drZTdu3MhNN91EWVlZxERLdHQ006ZNo0OHDsENUoErBVuJRCKR/HkIBIlaIvfXuR8dHer+cZqjBf+puL8q38n/lIp5jNk3BgPjv8pT8udRWFhI/fr1cTgcPPfcc5xxxhl06tSJ77//nsOHD3PgwAGaN28ekcaqK4cPH2bv3r1omsYzzzzDhRdeGHFMbGws27ZtY/Xq1aiqyp133smtt95K3759ueiii9izZw8//vgjDRs2tOvItm3bGD9+PKWlpVKQPcWxJjgWLVrELbfcQnZ2NhB89p9++ilr1qzhqaeewu1222mqMxW1tPTTp0+3tfQ1atRACMH8+fO56667yM3Nta0FPvroI+69914eeeQR26Ig3Jd72rRpPPXUU+i6Trdu3cjIyJD16RRECMHs2bN5/PHH8Xq9xMfHU1JSwuLFi9m/fz9z586lSZMmldJYrF+/nk2bNmEYRoSPfnp6Oj6fDyEEy5YtY9SoURQUFBAXF4fX62Xp0qXcddddfPTRR9SoUQNFUdi8eTMbN260l021JtZiY2PxeDyy/oQhBVuJRCKR/OkIUyCUYEdeUlLCpk2byMzMJCUlhTZt2pCaGtSKVtchVwwEVFZWxoEDB9B1nTp16kQE7ykoKGDDhg3k5ORQr149WrduTXx8vL1fURQMw2DXrl1s3LgRRVFo06YNDRs2tGfbLTMuyalDRkYGH3zwAYWFhcTExJCdnc3ChQvxer00bdqUxo0b25MTlnmeaZoIITh48KC9PnleXh5vvfUWqamp9OnTxzYd3rt3LwUFBTgcDlq3bo2qqmRkZJCamsqOHTvYsmULhmGgqipFRUWMHz+e3bt3c8EFF7BkyZKTfHckR0NRFIqLi3nhhRfYv38/7du3Z/DgwaxZs4YvvviCd999l8svv5xu3brZx4cT7pf92WefMWvWLPx+v13XVFUlPz+fKVOmcODAAbp27cqFF17Id999x9KlS3njjTf4xz/+Qbt27ew8LX/xV155xQ5UFrGsn5RNTimKiop4//338Xq9XHnllYwaNYpff/2V22+/nW3btrF8+XK7DYLIPsswDDZv3oxhGHTu3JnevXvbbVVMTAwpKSkYhsHs2bPJz8+nffv2TJ06lc2bN3P33Xfz008/sWjRIq688kpUVWXz5s34fD5atmzJoEGD7PM4nU7q1KlTblovZCWSgq1EIqlERW3Z0QIpSCRVIQj6l+3atYtRo0axbNkyPB4PmqbRqlUrnn32WXr06FGlGZe9nEvInNDv9/P888/zyiuv0Lx5c+bOnUtSUhIAP/74oz3g8Pv9OBwOzjnnHCZPnkyzZs1sofjll19m6tSpHDp0CEVRSE1N5a677mLkyJFERUVZhZacQiiKgtvtxul0sm7dOq6//np2795N7dq1eeqpp6hVq1aEn1u4Nn/79u22T9ojjzyC3+9H13WaN2/Oiy++SM+ePTl06BCBQAC32018fDyKouB0OomJibGFYyEEhmEwY8YMPvvsM3r37s3NN9/Md999dzJvjeQoCILasSNHjpCYmEjbtm2ZNGkSPXv25Ndff2XlypUUFxeTlZUVmS7MF9KqS1u2bOGxxx6jtLTU9te1jiksLCQtLY0OHTrw3HPP0b17d3r37s3atWspKioiKyvLFmyFEGRmZjJu3Djy8/MrrVMv+9NTD13Xue+++1i/fj2XXnoprVq1IioqioSEBDweT5W+0tbzLC0tZevWraiqyqWXXsodd9yBoii4XC57THXgwAHWrl2LEIL+/fvTuXNnmjZtytSpU1mzZg0rVqzgiiuuwOfzsXXrVhRFoV+/fjz66KMAuN1uNE2LqLPWv78zUrCVSCQRmKbJV199xZYtW7jqqquIj49nzpw51K5dm/3795Obm8u5555LaWkp7dq1swUMiSQchaBA+uSTT/L5558TExNDo0aNyMnJYd26ddx3333MmzePWrVqVZuHZb61dOlSXnrpJQoKCigsLLQHFIcOHeKhhx7ixx9/JDk5mXr16rF3714WLFhAdHQ0M2fOJCoqigULFvDMM8/g9XqpV68ehmGwf/9+nnzySRo1asQll1wSFI7k2PKURFEU8vLybCG0uLiYH3/8kbPPPpu4uLhKkyOGYbBt2zaEEDidTtq1a0dcXBxr1qzht99+44EHHmD+/Pl4PB4g6COn68HhkKqq9nfLn2316tU899xzpKen22aJMhrpqYtCUKNas2ZN3n33XQoKCoiPj+fAgQN8++23lJSUkJKSEmHGXpWQUlhYyPjx49m5cye9e/dm1apVEfvr16/P7NmzKSwsJDY2lv3797N8+XJKS0upVasWTZs2tfP0eDxMnjyZn3/+mV69erF69eqjBqWSnHyio6O55JJLuOiii/B4PHz88cfMmTOHvLw82rVrR+/evasVbo8cOUJmZiaKorB48WI+++wznE4ngwYN4vrrryc5OZnDhw/bQfEaNWpkB5WqU6cOa9asYd++ffj9fjweD9u3b0dRFNasWcOFF16IaZr069ePYcOGVYrK/ncPHiVDP0okkgisWcXXX3+dvLw8tmzZYvsj1axZk1WrVrFz507GjBnD3r17T3ZxJacwe/fuZcWKFbjdbp588kmWLl3K888/j8vlYsuWLWzcuLHatJYmLjs7m0cffZSCggI7yqi1/5dffmHLli2kpKTwzjvvsGzZMu699140TeP7779n//79BAIBPvvsM3w+H4MGDWLJkiV8/vnnNGnShCNHjrB48WLbfFVy6mE9lx49erBs2TJmz55NVFQUL7zwAjNnzrSFWqteWCbJAwYM4NVXX+Xdd9/l888/59///jdPPfUULpeL3377jZ9++gmHw2EPCK1IytZHVVVcLhd5eXmMGTOG/Px8hg0bRs2aNe26KIQgLy+PgoICO52sR6cASrDe6LqO0+mkRo0aZGdnM2jQIMaMGUN8fDxPPPEELVq0KE8SrvUKfd555x2++OILevbsyciRI+0Jj/BnHBUVRVpaGrt27WLQoEFMmDCB5ORknnzySds/2zRN5s6dy+zZs2nbti33339/RDRvWWdOTcLdHPLy8hg1ahSffvop8fHxjBo1qtr11xVFITMzk8OHD2OaJkuXLmXNmjUsW7aMRx99lH/9618UFxdTUlKCx+NBVVU7kFn49/z8fHw+nx2R2TRNVqxYwQ8//MCqVauYMGECt912G7m5uRHn/7trbKVgK5FIIvD5fDgcDvr06cPixYupW7cuKSkpDB48mKZNm1KrVi0GDx5Mz549q1zjUSKB4GCtdu3azJo1i+nTp3PFFVeQkJBAcnKyveTG0aKSKopCWVkZTz/9NBs2bKB27dr2div/9u3b8+GHHzJ16lR69uxJfHw8iYmJCCGIjo7G4XCgaRoPPvgg7733HqNHj6Z27dokJyfjdrtRVdX2xQ1m+pfeEslxUlpaSmZmJjt27MDlcpGens55551Hly5d8Hq9LF68GI/HYwdSCZ/4qFmzJj179qRr167ExcURFRXF2WefTXx8vK2xt+qi3++3zZb9fr+9REeNGjXYvHkz69atw+/38+abb9KnTx9uv/12O82IESN48sknCQQCQYHIlJXoZGNpbKF8ouPQoUOUlpYSExODz+fjp59+ipigsLC+r1q1iueee460tDRbWLWCABmGYbtJQFDjf/DgQUpKSnA6nXi9XtasWWNbl2zevJknn3wSl8vFE088UWl5qIplkJw6WPVHCMHgwYMZNGgQRUVFjBo1igULFlT73PLz80lJSaFJkyY8/PDDvP766wwZMgQhBJ9++ilLly496kRYuCY4Ly+P5ORkGjRowL333svrr7/ONddcg6IofPPNN3zyySflJu2hf39npCmyRCKJoMxfxiv/9wp5+Xkc2XKEL27/gqzcLDp27Ej0L9H0uqwXeUoecRlxFLmLyPJl/XGmJwAFhTQ9DYfqONlFkRCceY6KiqJLly5069aNrKwsJk2axPz58zFNk8svv5zWrVtXmdYK9vTvf/+b999/n/bt23PBBRfwzDPP2IMBVVVJSkqiV69e9uBx2rRpzJs3D5fLxfDhw20z56ZNm9KsWTMCgQAzZ85kzpw5bNq0iRYtWnDVVVeVT9D8vccDpxxLly7ljjvuQNd1PvroI9q0aYPH4+HIkSMAtsbVNE07MqjL5cLj8XDPPffw7bffMmDAAF555RWioqLIysqipKQEVVVJS0ujXr16xMfHc/jwYTZt2kT37t3JysoiNzcXh8NB8+bN7XVI3W43+fn59iDXWqfy0KFDHDlypDyAVWgpK8nJpaKvbMuWLVm8eDFbt27ljjvu4I033iAxMZHHHnsswpRdURQOHjzI+PHjyc3N5eGHH6ZWrVqsXbvWPqagoIAjR46QkJBg14fOnTvz7bffsmnTJm6//XamTp1KcnIyt956K48//ji7d+/mpptuonnz5hGWTlZeiYmJJ+bGSI6ZcKGzXr16TJ48meLiYm677TbmzJnD888/T69eveylxKw0Qgj69OnD8uXL8fMxM/MAAOihSURBVHq9tqnwOeecw/r169m+fTsrV67kqquusgOI+f1+uy5ZLhLR0dFomkanTp1YvHgxZWVl1KxZE03TGDBgAL/99hvr1q1j5cqV/POf/wzmJX1spWArkUgi+THwIzH3xtDc0Rz/IT/1tfp0ie+Cqqhk69nsZz9bDm7B7GvyjfoNHKw+LxFcrPSogTH+0wXFK6bb7d3NdanXcV7Cecedl+TPxzRNHKrD1qBt27aNadOmUVZWRpMmTRgyZIi91EZVs9a//fabbTr6+OOPs2PHDoDyhejDIuFCcM3AN998EyEEXbp0YdCgQXawF+uv1+vlzTffZN26dbhcLoYMGUKDBg3KT/r3Hg+ccjRp0gRFUdizZw8PPfQQl19+OevWrbPNiHv16oXb7WbBggWMHz+ehIQEXnvtNerXr0+zZs34+OOPmT9/PjVr1qRx48a8++67lJSU0KxZMzp16kRSUhKtW7fmu+++4/XXX0cIwcKFCzly5Ah169ala9eupKam8s0330SYwG/YsIG77roLt9vNK6+8Qrdu3dB1XWrdTiGEEPh8PvLz8ykpKaF27drUrl2b9PR0+vTpw7Zt2/j222954IEHiI+Pj9CQbd68mR9//BHTNHnrrbeYPXs2Ho+HsrIyPB4PI0aM4Morr2Ts2LEcPnwYj8dDnTp1iI+Pp0aNGpxzzjnMnj2bRYsW0bt3b5YtW0YgEOCTTz7hq6++wu/325Mh9957L/369eOVV15Bd8kh+amC5Wbw1VdfkZeXx9ChQ6lXrx6xsbF2BPV9+/Zx5MgR4uLiIoKBCSFYu3YtP//8M0lJSQwdOhRN04iLi7OD1JWVlZGYmEhcXByFhYXk5ubak2X5+flAcFkgp9PJxo0bWbVqFU6nk2uuuQZN04iJiSExMRFFUSgtLcU0TbkWcgj5FkkkkghKzBKuSLuCAYkDEA2EbXJldfzhgzdLyAjHMtUKTxNOxe0VBRRrG2A31uF+cBUHj5bg8vmRzyk1S/+8GyH5rwg3BRRCkJ6ezlNPPcUvv/zCBx98wD//+U9mzJjBeeedF3GcEILCwkLGjh1LZmYmDz30EOecc44t2FrmphXrUJs2bXj22WdZvHgxX3/9Nddddx3vvfee7Udn1dUbb7yRrKwsZs6cyaRJkygpKWH8+PERPm+SU4OMjAzuuusuxo8fz8KFC21/aF3XGTBgAFdffTUQDPLzyy+/kJiYiM/nQ1VVbrjhBr799lt++OEHnn/+edsKIC0tjYceeoi6desihODuu+/mt99+Y/369dx1110YhkFMTAw333wzDRo0wOFw0LFjR6B80Orz+ewlX1q2bEmjRo3sMv/dzQBPBayoyGvXrmXEiBF4vV7effddunXrht/vtzXvVptjGIa9PqjT6bS19EIIe31aywzZ0ugWFBTwww8/cNNNN6EoCh9++CEdO3bE5/Nx+PDhiMjulq+vFZHd8se2fDfDoyRLTg0URSE/P58xY8Zw4MABSkpKuO+++ygqKmL58uUAJCYmEhUVxZEjR9i0aROmadK8eXOSkpJYtGgRTz/9NHXq1KFp06a0a9eOn3/+mczMTHRdp2XLlqSkpNC4cWOysrJYtmwZ119/PXv37mXbtm3ouk7Hjh1xOBysXr3anoBp0KABPXv2ZNOmTezYsQNN02jdunWk1cHfvA2Sgq1EIjkqQghKS0vZsWMHOTk5pKam0rx5c6Kjo6tNY2nIDMMgMzOTnTt32mtE1qlTB03TME3TDqBQUbC1zhsbG0tcXFzEvrKyMn744QcCgQBnnXUWMTEx9vFyyYRTByEEpijXcrVo0YIWLVpQXFxMZmYmixYt4o033uCcc87B5XLZxwF8+eWXLFiwAJfLRU5ODo899hjr16+3l2B54oknGDJkCGeffbatSevevTvdu3fn4osvZsCAAWzatImPPvqIMWPG2MdER0dz/fXXI4QgMTGR+++/nw8++IDhw4cHBWBZfU4pFEXhpptuomHDhrz//vts376dlJQUzj//fK677jpq1KgBQKNGjbjooov48ccf7balXr16zJw5k5kzZ7Jy5UrKyspo0aIF119/PWeddZZd1/r168c777zD22+/ze+//05qaiqXXnopV199td2eVJzYS0lJ4Z///CcOh4Pk5OSI8qIgNf+nAEII6tevj9Pp5Pfff2f06NEMHz6cHTt2sGDBAjRNo0ePHkRFRbFu3TpGjRqFpmlMmTKF9u3b8+WXX0YsxbNhwwbuu+8+HA4HL7/8Ml27dkXTNDRNY9euXTz88MNcd911bNq0iSVLltjLjrVt25ZPP/3U9gOHYFC92267DZ/Px8SJE+nduzcOh3ShOdVo0KCB3T68+OKLLFu2jOLiYtavX4/D4WDo0KEkJCSwceNGLrvsMkpKSvjggw/o378/AwYM4I033mDfvn1cc801NGvWjA0bNpCXl0erVq0YOHAgMTExDB48mFWrVvHNN99wySWXUFBQwIEDB6hXrx79+vUD4Nxzz6VBgwZs376dm266iTZt2vD777+TlZVF3bp1GTJkiD1xK9exlYKtRCKpBqtT3759O2PGjGHp0qV4PB6cTidnn302EydOpHnz5lWuw2eaJvn5+UycOJE5c+ZQUFCAoiikpKRw/fXXc8899xATE8OLL77Im2++WaVWV1EURo4cyYMPPhgxm/3NN99w8803Ex8fz9dff02TJk1OwN2QHC9CCDZt2sS7776L1+tl1KhR1K5dm6ioKGrUqIGiKGRnZxMIBGzB1tKMHDx4EL/fj9frtU1EIThhkpuby2uvvUZGRgaBQIC5c+eSnJzMqFGjiIqKIj4+nvj4eEzTZN++fRQWFjJ9+nR+//13hgwZwgUXXABA7dq10XWdkpISO4iM5NTC8pm96KKL6NevH2VlZTidzvJ1h0O0b9+ec889l127dtmmfoqikJGRweOPP05JSQmGYRAdHR0R2VZRFBwOB+eddx69evWitLQUh8NBVFRUlZNkVh1p1qwZzz//vF3G8L+SU4f09HTuu+8+7r//fr7//nt++OEH28Kne/fujBw5EofDQUlJCWvXrkVVVUpKSkhMTKRbt24RFiHhWvrWrVuTkZGBaZrce++9PProo3z33XesWLECwzBQVZWePXty4403EhsbS+fOnSPqh1VHIViXrGWHTOTyP6cSTqeThx9+mNzcXBYvXsyKFSsAiI2NZcSIEdx88822RZnlJ2tp4zt06MDjjz/OhAkTyMzMZN++fSiKQuvWrXnuueeoV68eiqJwzTXXsG7dOj7++GNWr14NQFpaGqNHj7bHVxkZGTz99NM8+OCD7Nmzh4MHg/5fDRo04IknnqB169blptByVk0KthKJpDKWKVdJSQljxoyxA/KkpqaSl5fHF198gWmazJ49u5JGFYLrSL744ou8+uqrANSoUQOfz8e+ffuYPHkyKSkpjBw5kiNHjpCTk1OlGbKmaXi9XnvpDcMw+P7773nkkUc4fPhwpcGnHFieWiiKQnFxMW+99RYej4e6desyYsQItmzZwsqVK4GgD6Wu6+zevdvWcgwYMIBWrVoxfPjwiCVctm7dyqpVq0hMTGTQoEG0atWK7OxsZs6cSXR0NO3atePcc89lyZIl/P7776iqSrNmzezIkcuWLWPfvn00bdoUl8vF3Llz8fl8pKenl6+lK8cEpxThUdfdbrftkx2OEIJFixYxZcoUbrvtNjvScbh/dUTk6yoQQuByuewJlnAqtjGynTk9sDRYV111FcnJycyePZvt27cTExNDr169+Oc//0ndunWBoAB88cUXs3DhQtuks+JzrlmzJjfccAOappGQkGDXrREjRlC7dm07/4SEBHr37s2NN95oRz+u2L8lJCRw7bXX4vf7qVmzZpXnk5x8NE0jIyODt99+m1WrVrFhwwZcLhdnnnkm7du3x+Vy2YLn1KlTuffee4mLi7PbnxtuuIEzzzyTlStXkpubS0ZGBmeddRZ169a1n3dSUhIvv/wy1157LWvXriU2NpazzjqLNm3aRNTFiy++mLZt27J8+XKysrKoU6cOPXv2pGHDhpFmyFJjKwVbiURSBSLYAW/dupWVK1cSHR3Ns88+y6BBg5g5cyYTJkzgxx9/ZMeOHbRv376SGfChQ4eYP38+hmFw9dVXM378eIqKirj11lv54Ycf+OyzzxgxYgSXXHIJjRo1sgUY0zRZvnw5n3/+OS1btrTD4x84cIB33nmHV199lezs7GARpYbtlKdt27b069ePuXPn8sQTTzBr1izy8vI4fPgwNWvWZPjw4TgcDn755RfuvPNO4uLiaNeuHeeddx59+/aNyOuNN97g+++/p27dujz33HMkJyezf/9+zjjjDNatW8dtt91Geno6+/fvp6ioiBYtWjB48GDi4uK4/vrrWbduHcuWLaNfv3524A9VVbniiiuoU6dOuRmp5JThWAf7LVq04IUXXqBXr14Rg8FjTX8sx0nB4/RBQbGfv+WP3bdvX0pLS9F1nZiYGNs6RNM0mjdvzqWXXsrPP/9MSkpKRN2xfPobN27Miy++GGE9AtgWBeeffz5lZWX2MmYVl8ILj09Rq1YtnnvuucoBf2QVO2UIf98TExMZMGAA/fv3r7JdMU2Tbdu2kZCQQMOGDe30uq7TqlUre4JVVVV7rGMdo6oqcXFxnHfeefTu3RugUpRuwHblaty4se2fHV7HZPtUjhRsJRJJJSxzmnr16jFt2jT279/PkCFDiI+Pp1GjRqiqiq7rESak4cJtIBCgd+/etGzZkptuuol69ephmiZdu3blhx9+oKysDCEEvXr1olevXiiKQiAQYPv27cycOZP4+HiefvppWrZsCcAXX3zBuHHjcDqdtG/fng0bNlQKZCU59YiKiuLpp58GYNGiRezatcsOnDFmzBi6d++OEAJd123Nf3UaE6fTSVpamr3EBgS1KC+//DKjRo1i/fr17Nq1yzaVf/zxx2ncuDGKojB06FDy8/N5+eWXbQuB1NRUrrnmGh544IHygYSsTqclDRo0oF69ehEBfiQSKG9HXC4XTqczIkgdBPu6tWvX8vjjj/OPf/yD2rVr21ZC4WbmFZcPsvKwTFGjoqJwuVyVgiKGlyH8e8Xgd5LTA6tuWBYhiqKwb98+PvvsM0aPHk3dunXtfdZ+a0kfqDxWsrAEVWt/xYmR8HpXsd7I9i4SKdhKJJJKqKqKpmmkpaUxaNAgALKysnj55Zd5//33EUIwZMgQe3ayYkNdt25dXnrpJQKBgD0zXlRUxPr164GgT1xFs8JAIMDkyZPZtm0bN910E+eeey6AHUWyQYMG3HPPPei6zh133CEHsKc41mCwQYMGvPnmm2zdupXdu3eTkJBAmzZt7MA/QgjOPfdcnn/+ecaPH29rUyo+26FDh9K3b190XbeXOVBVlY4dOzJ37lw2btzIwYMHSUtLo23btiQkJNhp3W43d955J4MHD7ajV7Zo0YJGjRrZ0U+lmempg0BgYByzWZ1QBIoWfH62n+JJkhWsgGmSU4eKGrCKwkPdunUZN24c/fr1w+FwVBIqwoUYa194eqvdqGq5leralKq0bdLH9tQlvM5UfKbNmjXjk08+ISUlxa4r4WnC+5aj+e5XrE/hx1ask1Y62WdVRgq2EomkElUN8n/66ScmTZqEz+ejTZs2DBs2zPYxqS74k8PhIBAI4PV6+X/27jtAjrJu4Pj3eWZmd6+X5C6990ISQiiBhF6kKyhNBQQEQVQ6iCgqIviiiCAiVXqTKr2GXkMCCSmkkJ5cyvW6uzPP8/4xu3t7KZRw5O7g93nfyJXd2dnZuZnn9zy/5/dcffXVmVTSE088sU3RhfT2H3/8cXr16sXPfvYzPM/LbHe//fZj3333pV+/ftx3333b5iCIr0a1NvTy8vKYOHFiZtmUbEEQsHbtWh566CHGjRtHeXn5Jjf47ArZ6e/TtNYUFxczZcqULe9KqkE6aNCgNkuzZP9edA6e8qgP6jl32bkdvStbpTqo5tTyUzt6N0TK5kZIs38OYSG5I488crPP21xwsqXfp21pJG1Lo3Wic9u4I2Tjz97zPMrKyto8fuOvs9s6n1cbZHPnzca2lBEgJLAVQmzBxilbPXv25IILLuCdd97h1Vdf5ZRTTuE///kP48aNazNXaOM0mebmZq644gquvfZacnNz+cMf/sC4cePavE4ymeSOO+6gtraWo446KjMnJT3a279/f2kQdEGf93mlz5GVK1cSiUT43e9+RywWy6R7bWk7ch50QpnOhq/22cRUjOsHXt+lR68iKtK+I8bKZm1P5oJ/lpiKcfuG23mm9pkv9gQbZgioTnBcjTXUBXVyffsy2jkzoy6oY3bz7C67FmyLaSFu4uE3W3VsPuNJXeS8lMBWCLGJdECbXdRpl112Yeedd2bNmjUcfvjhzJo1izvvvJO//OUvbdJvstXV1fG73/2Om266iYKCAq688kqOO+64TVK2li5dyosvvkhOTg7f/e53iUQiW0zPEd8sWmt23XVXdtppJyKRSEfvjvhCbNb/hgu3qja/2/q/VYUKA0NBppFps76m9bjLFXFTP+j2A/Yo3OMLP76zzVPM1bm40jT/Yto5qM1ROUwtmMq02mntu+Ft7JDiQ7by6mA3+m+29ALdnePv5LPIX48QYhPWWoIgYNasWTzxxBMopTjzzDMpKiqiuLiYnj17MmvWLD799FOCINgkDctaS1NTE5deeik333wz3bt35+9//zvf/e5324zEpUdh3377bSoqKhg6dGhmNFfSbLquZtPM/Ob5uOpL3mISX8/+fFE1QU3H7kAXsblmT2uoK3+v7c/StvOg6zQyt7UcncOA6IAv9NiNO2PlXtP1tGds6yqPH3c/vh232LG27tjYLT6zq3SlSWArhNhEej7JsmXLuOqqq/A8j6FDh3LwwQczc+ZMZs2aBZCpOrts2TI+/PBDcnJymDJlCrFYjDvuuIObb74Z3/fZZ599sNby+OOPA1BQUMDUqVOJRqP4vs97772XmbtbXFwMfHaRBdF5ucpln6J9eKH2hY7elS9tu5ztKHKKPv+BIiUMsFqbQoqu0/zpChQKG6YAWhUeYwXK2vQXSHC79SSQ7dqkNfB1UGzpmtJVrjYS2AohNssYw6677sqkSZN44403OPPMM7nmmmtYvXo1a9eupWfPnhx11FG4rstLL73Er371K3r37s2LL74IwPXXX09LSwsA99xzD/fcc0+mITFu3DheeOEFIpEI8XicefPmobVm1KhRXyodVQLdzkcrzTHdjuno3RBfJ5tu5BhIz08MQzBUm5FF8dXZ1P+Hx1dn5oQCtuPnhQqxLW32ni9/A+2o7cG0WdMguko/mgS2QohNOI6D4ziUl5fz17/+lfPOO4/p06cza9YstNaMHDmS3//+92y//fYAbda0tdYya9YsKisrKSwsbHMjSge2OTk5mZ8lEgni8ThFRUX07NnzM+c8pdcNLCwszKx7KsGtENtWurFjgzjYJEorlNIoHMBkFZISX5kNsLhY5aEcN2vUpIu0MoVoZ20LSVppA7Qb1fbanZ7xkPm+a1xvJLAVQmxWOmjcfvvteeihh5g+fTrLli2jR48e7LDDDvTo0SOzptthhx1GbW0td9xxB7m5uUyZMoWXX355kzXf0jegaDRKXl5eZhmXO++8k3g8To8ePT63+vGBBx7IhAkTcByHfv36bbIYuhDi66UUYC3xploa1izBMQlAYZTOjOKKdmIVOq+Eor5DAYfPShUU4tsge8UGrYLUNUd8dYo21xdjW4NZpekq1x0JbIUQn0kpRWlpKfvtt99mfx8EAdXV1bz44ouMHz+eoqIiIpEIxcXFbRa0h03TiNIjsAMHDvxCAapSiuLiYoqLizOPk6B260jo8fXIjKNlV7JNF0LrmF1qV611Mw1BsplEdQVR4uG8T6WxBN+I99k5WIx1wqWP7AAgkjqXNh5K6Sps615bAINNVd5XXfL9dF42PT8bsGiUzl6JQHWVwTcgqzDdxqeINbQ01qLwt/1OfWNlBbDpaQ9KEc0rQumuUa1eAlshxBZ93kLiQRCgtWbGjBnk5ORw0UUXEYlEMkHq560/urnvPy9A3Vy1ZAlqt4bFWqSvux0ZwmmP2rYGsTbVIHOhy6RyfZ6wiJFCKYujDI5JorAYqzdac1V8FQqLQ4CvFCg3DFAAMFlfdxWt50WgQGPw6ypoWDYPbX2UkitRezJK4VofUPixbhQPHo/VOV32EmQIz5lwZn8YtAfxOmoWvIsbNHf07n1jKOtinBaUddB+BOO2kMgppeeIPXD05z+/M5DAVgjxmbY01zU7cD3ssMM48MADyc/Pzzwme6T269wXsZVs2ERwjPR2txetDDYV1Kr0PFSVGqVS6XnlXfscVoTBe1aJXrLGVMLHdO232GlYm27Mg1VOpjhXq652oMN9Nyg0YP04pqkaTAKVdR6Jr84ohTUJwjPIA5s6j+h6Z02r1r+A8BoT4AQtuEYC23ZhFcp6GJpQ1sEJDEY3kTR5dKUpEBLYCiG2SvbIaSQSwXVdjDFfS0Arvh7xuvUk1i/r6N34xrDKpkZsbSqwhUApooXFxLqn50gKIdLCUEVhrczNbk+ZbgL7zc+gSJ9D4uvQ9Y6rBLZCiDY85fFMzTMsiS/5zMdlijdsYW7sth5dnds8l0OKD9mmr9nV+U21xNd9KiNs7aR1RltYGdgojY+DUv2Jdf+Gty6F2ArpS4/aqCCr+ArURutJy/VdfItIYCuEaGPvwr3pF+mXXeajS9g1f1eGx4Z39G50KdoaXJJh4R/xFaUbkxaFj8USoLFEv8HH95v6vsS2Eo4shuvyylST9iF/leLbTAJbIboU2+Y/QLt3defpXCbkjm+37W1z7XQsrIKNu7q/ac0uSzgXS9K42oeyrSuMoiwGhVEOBpdv3tkjhBBCdC4S2ArRJWXKtGRGVmW5hPbTekRbS22k6+V8o8ITJb377UmlCkUZ3LB2Z2oZQKtk3rkQoY2vohakIrIQop1IYCtEl5FdNbI1nG39zTcq5OpgNhPU2syR/QaOa9pwaZpv3hvb9hQWZQ1WKYxycazCsUmM9ZFFlYQgVUE7XLillQUC2qyfKYQQW0kCWyG6knQmstJthtqsCpsGon1oVGq1PBs2wVIppmwmPfmb4Jv3jjqWHE8hhBBi25PAVoiuIr0uZnb+qDVgDRqLlrTSdqNIjyykl0rQoFywTvgJSJETIYQQQohORQJbIbqcVFBlDfWVa0jWV+KRBJvs2N36xlAEWmPRqQDXIZJXSm633ljtyGicEEIIIUQnJIGtEF2EVYDNnpuUJKhbS3L9MiCBlWTkdmPRmTnMPh6qp4JuPbFWlqQQQgghhOiMJLAVoitJx1TWgvFxSaBtE8omCbRUXm0vjjVoDNYqkiqGY33AblL2RIhvN+nkEUII0XlIYCtEl6RAu1gcAqtx0K0FjsRX5uOg0OhUbeT06K0M1gohhBBCdE4S2ArRRYTrqKaXoAkXn7Gpf5kFSSXy+sqyA1mrTOsySvYbWxRZiK0k5eqEEEJ0HpJVJ4QQQgghhBCiS5PAVgghhBBCCCFElyaBrRBCCCG2guTlCyGE6DwksBVCCCHEVpA5tkIIIToPCWyFEEIIIYQQQnRpEtgKIYQQQgghhOjSJLAVQgghhBBCCNGlSWArhBBCCCGEEKJLk8BWCCGEEEIIIUSXJoGtEEIIIYQQQoguTQJbIYQQQgghhBBdmgS2QgghhBBCCCG6NAlshRBCCCGEEEJ0aRLYCiGEEEIIIYTo0iSwFUIIIYQQQgjRpUlgK4QQQoitoDp6B4QQQogMCWyFEEIIsRVsR++AEEIIkSGBrRBCCCGEEEKILk0CWyGEEEIIIYQQXZoEtkIIIYTYCjLHVgghROchga0QQgghtoLMsRVCCNF5SGArhBBCCCGEEKJLk8BWCCGEEEIIIUSXJoGtEEIIIbaCzLEVQgjReUhgK4QQQoitIHNshRBCdB4S2AohhBBCCCGE6NIksBVCCCGEEEII0aVJYCuEEEIIIYQQokuTwFYIIYQQQgghRJcmga0QQgghhBBCiC5NAlshhBBCCCGEEF2aBLZCCCGEEEIIIbo0CWyFEEIIIYQQQnRpEtgKIYQQQgghhOjSJLAVQgghxFZQHb0DQgghRIYEtkIIIYQQQgghujQJbIUQQgixFWxH74AQQgiRIYGtEEIIIYQQQoguTQJbIYQQQgghhBBdmgS2QgghhBBCCCG6NAlshRBCCCGEEEJ0aRLYCiGEEEIIIYTo0iSwFUIIIYQQQgjRpUlgK4QQQgghhBCiS5PAVgghhBCdgrWWmvpGFixdTX1jM9ZaahuaqNhQQ1NznCUr1xJPJEn6PjX1jVgra+kKIYQIuR29A0IIIYQQaR/MWcxvrr2XX59yBPvuMo6f/+kmGppa6N+zO+/NXsQJh+9JUUEu8z5dxR/PPKajd1d0MtmdHUqpz+38UEp93bskupCNz5fscyh9rmx8jonOQwJbIYQQ7cpaiwWyb/cbf59NGgYi2/ajBrPb9iNZsHQ12w0fwIKlq+lWXMgnS1fjeQ5vffgJ85esZGj/XtQ3NlOYn9vRuyw6CWst85es4slXP2C37UcwefwIps9ZzNzFK5gwchAvvP0RA3qVsXp9NcYYfnjw7pR3K+ro3RadSNIPeODZN6lraOKEw/fCWssjL77D2KH9GTmoD2/MnI8fBMxdvIJRg/ty8O47yD2sE5FUZCGEEO3GWsuKikp+dcWtXHfP0xhjuePxVzjzTzcz7b2POevK27j9sWnMnL+E+595o6N3V3wl7d+YC4zh6jv/R3VdAwuXr+GWh19kQO9yXFeDgsH9epCfF+On39+P0qJ8tNbYTvh/ouMU5efy2vQ5zFm0gsbmOL/5xz3c9b9XaW6J8+5HC/hk6WpGDurDmzPno7UEJKItR2u0Ujz47Fu0xBM8/foMrr7jCZ567QPu/N8r/PuBZ+nfqzu19U2sWV/d0bsrNiIjtkIIIdqNUooe3YooLsjjk6Wr8YOA12fMZfHyCp5+LcKL78zik6WriUU93p21kGMOnPK529w0TLAom0oJy2qXfm4TNb0hlQ491NcQmn2btH8AV+00su74WuqrmskNYsxc+il9f9SdRDJCfm6MivU1lPTKZ0l0HU6zw1/yHkk9c3Of5Mb793mfdvbjv8iZsenjfQJ2t6M5kIlf4Pni67BmQzXf338yL7/7MTuPG461lrLSQl6dPpcj95vMU699wKjBfTlw6vZ0Ky5ovSyk/vtZZ/WmWSgWLNisETtlw9+G16ZNz6ONt7H5R4mOUtfYRO/yUnqVFfPu7IUsWbWW7UcN4tXpczDGUNvQTGNznNr6Jr63z86bHa1t+7laNv7P5z1nkytLVsrT5s5PlfXT9L2t9X+/XSSwFUII8dVlzTn6YO5iRg3uyz1Pvsa09z5mzJD+DB/Qm9sfm8buk0azfM16Rg3tx0efLNv8prb4s/TN2qJSt3KrwhEybdVmn2hbn4ZGoazFKJvaQjh3SrLIOo9qGhhV1JdTivbFomCoxSEAIEBDYdgZYZVC5wcQGKx2U5+nQYcnBVaB1RZlLcoaAAwOOnWSGOVgbHguaQwWi1IKbS3WGoxysNoF2zoCq1L/rDHoTGsTUOEZaVEsZz0v8JEEth3EYnnl09m8MGMWIwf34cKb72LkbgNYtnod62P1vPzubA7YawLzm1dy4J4TWaEqt7Cd1qDAqPCcU+l5lqnPPX0VUoTnZvpxDia8zmSuVKntZB5vNwqiW69rZRQSI9Leh0V8Eak/5+pEI9e+9BSRnh63vPAiI0f2YV20likHj+bg3Sfx5LT3aC5qYfCO5TSWxGliwxY2qMJ7U+ozB7BKZ7/UZmjAZD0mdc5s5vbWem6lt2+J4lFGUeZ3nzUF6JtKAlshhBDtQmMwKFYWVnHbuy8x7LDeXPzYPYzepR/rqmv5/iW78M5HCxgwqZxFvdYSmeLxqpqz2W2lR0CyG4UWDcqgrY9rIhgFSeVjlcEL3EzQkoptUhQmHEIhYjTaGpLKJ1AaZSIoFQAGF4eJDCaX6Nd2fMQXE8ElnxwsCkdZnKAFtEOL9dCOgw0C0A4R04zGkLBRAu3iWh/PGrCaQFkCLEpZtDFo5eJrDzdoASwBEYzSuBiMSWK0i0HhKR9tfXw8fBtNNRgNKJMKbhRagVUGbBA2Oq3GKI1Fk0fOt64h2ZlUqQZmH7KCvQ7aDpLQraqQWK8I/WwJWkGPYDvQlhge09TsNiOtmw8dsnM7bOrx6TBCoTE4Fnyl8ZXGtQGeDQiUxigHAG3Dq5fJCmDbvEJqm2upZic7lB+w69d1eMTn0Bae7/4hoy7qRxG5xNcmiZQ47BMZiUHzup5D8Q/ymMmnBAMVD/J2eN/ZXHKIVWBNOF3Chp1zWimMZfOj+RbARREAQeqaonBS50/rFIfW51nV2s2rrGGuWs0/OJkYuWDtt/JaJIGtEKINay0Llq5mXVUdE0YOJOK5zJy3hFjUo7Qon3VVtYwbNoCG5hashW7FBR29y6IzUGDQ+Pi8MmQ2pw/eF8dq9psyBl0A6b7jiTsPTN1sAybu2I9qGja/Pdu2AZhuZBqrMErjqSbA4tuwUeGk07zS6Vqq9dnhKwd4SmOVwkdhAIfGzNbfUp+Qa6NMZHB7HZFvga+v2aSwONZgjSWp86isb2F9dSW5sQjl3UrQjoejkmAThIMg4acdoECl2pTWIY7HhroWausaKS6I0KMkjwg+ygR4BFgscR1jTU2cmoYmcmMRepXkE9MGhyAcpVMGrEk1SD185dJsFChLTFscmz6jREcLMAzR/fil8wMiThyvVwJNgFUKgwM6SnokTVkywULYGaZSo7LpsDUcbXNNElAEysGQ/qewyuJYi2fC8y7QARGTIBoYmpxcrA0DX9cm0anAJlAugUqP/afG1Gz4au+rJcxjZUccNpFiFMRJcorah0GUY3uF50LEJgAXP/BQSmPSHWeAttnj8ukNWRybBOXiGxerNdoGaD+B0jrTyZHKY88Ewso6aHxQfngtQ4c/T3ewkc5YSj3bKhLaTe2Dz295MKzYrL698/wlsBVCtGEtfDh/CX+57THuuuJX9O3ZjbuffI2Vazfg+wGr11fz+zOO5vk3P2TyhBEcd/BUqQgospKhoMjmcKTdARcHm6/CRE8VNhOVVSjbOorhK5dNcoFT6cHWhqlbyoaBqSbAoEmqCFEbx8GSNA5GObg2wGhSjcbWhqnNND58PKvx8YirKBaDRxyFBjQNNo75jAQxsY2lht2bkpr/PPo8/33qZaqqqolFo4wfM4wzTv0hY/p3w3VM5nwBMDr85I3SrK9u4pb7H+bpV6dTU99IcV6U7+y9Kz87/kjKchysDaioruNv/7mX196fQ119PV40xoRRgzn3pCOZMKQX2HBE3yqLVZpAOcz8eDF/ueE+XAcuO/80hvXrjjbJMACWc6hTCK82QRhQKodmG6E+AS6a3EgERwUo66euQ0GYep4KNDUmtQWHQDk02yjN8QSuGyEWDUfUtPVR1kfh4usoLSagOd5MVHvkeDlAgGcTgMHXMQLlojBYRTiaiwNolE2mAl+/Q4+XaFuvQWPQWAKr8K3m0/VJli39FBfNoMFDKeteTNQ24ZDE4rRuI7MsEBjr0BS4LFxVxfI16ynKizJ6UB9KCiJo64fnmQ1QKAKrQTk0xi31TQkiEUtRfgSFpqbZ0JAIz0mygukw0LUU5Cryom7qXkbq92S+/raRwFYI0Ya1lomjh7D9yEF8vHA5fXuUcsS+O3P5jQ/R2BKne3EBDzz7Ju/NXkjEc/n+/pOJRryO3m3RCdjMjdfiKIWxikB7JJVDZW0DdfVN5OXk0a0wn5gKcFNzJzfZTioITlhNgIdBowlwrY+1EOAQcRMEgcFXuSSNx9qqCupamojl5dG9tAhXGbRJ4mDQgLKaJIa4clm6pgHjxxlQ5hGLRL6VN//28fUFcVYpkjjc+fgLXHnT/cSTAYUxl+rGFpa88j4V1TX8+/Jz6FscJT3qFT7P4gO1jQGX/f02nnnlfZIovIjH8oZ6brzvCZQX5dyTjsSaJFfc+F/uf+Z1CmJR+vfrw5r1lTz72vvUbdjALVeeR3lxLulxPaM81tXF+dtN9/H2jDkUF+TRHDepFrEEtJ2FZ31ygxYUiqTN473ZS7jjsZdYuKKCfFezy4RRHHvkgfTslk9Epa4PWZ1h4TirR3OgefnNGdz/3FusXlNBcWEBB+65Iz84aCrFEYMOkjQHmhfenslDz05j5do15BWWsPuuUzjx4EmUxQwBDjc//BIffroWhcUjwJCaL47CI8n3D9iVXcaN4NsZhnQmqa5ZZVAWAqtoChxuuedRbvnf69TV1BAByrp34/QTj+K4/ScS1T5JnE2zipXDijqfv994G8+/Pp36ljieVowc3J9LzzmZiSP6gkniKAXKweLSmLD85d/38sTLb7HDuGFc84ez8BzN32+9i/8+/1ZWKnsrT8FZPzyAnxx7ODYwpCfjqvTs2m/hKSWBrRCijcaWFq64/WFqmpt4deYcnnl7Bk3xOKXdC8hPxtBas9uOI9ltx5G4jsa6kKBz9Ta7aLSsZtZB0tVhNUbHqGryuf2//+PJF9+isrqOgrwcdtthDL848Uj6lRWhUglXG0sqjzv++yRPvPwuvtJgbRikWhg/eiC//sUPiLpRlqxu4F93PMS7Mz6gvrmJnJwcJm8/kjNOPIpBvUtx8FHWEgQaFVHM/3Qdv7rkHyRaGrnxip8zdtigbXt4xBdWU9/IY8++QiKZ5PsH7cVJRx3E2x9+wpU33MOMOYuZMWchPSePwdEqU7xMBwbHjfLq+zN5+rUZWKX5+QlHcsBeu/Cfex/l0efe4NVX3+C0I/amsSXOtPfngONx1mnHc9yhe/Lex5/yi0uuZNaiFcxatJK9dxyFsgajFHGjufW+//HGzE9IpkdHLKniMCYc65MYt+MZH4eAuM7j1Q8WcO7vr2FtVR1GOTg24MM5C5j9yWKu+sM5lBdGws83leoZzoV1iBPh9oef4bpb76eyIR6mjxqfmR/Noam+hp/96FA8HeWRZ97kD9feS11TC462xFnDux9+ypql8/jTr36E0vDa+7N56o0PiWiLExgCC0ntAIqoMuwwahiTx4+R86ZDpedSp88BMG4OT734Jtfd+QRN1qFnSSE2nmDp6nVcfu1tDOuZx9Txg1qrFVubyV5rivtcccM9/O/paXiuQ4/uJdTUN/LBnIVcee1t3Ph/F1GaF0WrAN+EmUvPvfoG9z3xMtUtPgObkhgLDj71jc1UVtW17qVSWKWxVuFpSAYQGI2nnFRQG16T0onL3zbbJLC1tu1fa/qD3/jnm/NtTnH8vOPzecfms56f/dyv+jpboyNeU3wx8/NWkTw/oHuygKY1LVgXCrvnkhPzsBaaWxIsLVqLteEoxu+d+7OevYVCHJstzZca3UsPtqj0TzOLKHymTatKhl/FSbKLHc7RfP4yMqJ9pQvFhvNYNUnrctv9j/LPOx4nYRSRaIQN9VUse2IaNTU1XHnJmXTLcTa7rXjS8sb0OXzw8QISaEyqEIarLPn5MZJWkWjx+fM/bubZNz4iv8CjR6+erKlYy3+feo26mjr+duk5RHJ0eGpoj5XrKrj6hrv4ZOk6CvM8kjYsGCRdIFvr65xjC56nOPbI77DDkmUcf9gejO1fSI47lH/mutTVxWmJ+2jHxZpkeM+wYU3RuG957Z2PaEgaRg/py8nHHkiPWILyU45g98k7Ul6cS0nMEG+KgzG4SjN6UG/K3Tjj+ncnP+qxvjlOc5Aa71cOPprX3pnJvY88B5EIyvipYlImlc6azlj4/GuX+HpZrYhrTXWgue3RZ6ioqmH00P78+Ngjmb1kHY8+8ihvfTCH196dyeH7TkaHSaeZe49RLnMWrOCmex6jrjnBQbtsx/7778sLr7/DS6+8yX+ffJVDDtqHnIjHbQ89T2Vjkj0m78ARB+zM6299wGMvTefxadM57rC92W74AAb17cmkscOI2ABlIOFEWLmumnXrN9CrtJDh/frgGv/bGIN0KmFQm65IrGlMGJ555R2a/YDD9tqBS848gaqqek6++G8sX1fNy+/NYfLEUWBaJ7GElyHF3Pmf8Pwrb6G14tTjDuWEY4/gzfdm8oe/3sTqdZUsXVVB0YiBYMFoj4VLV3PtzQ/Q1JLAKhcTBERJkGuSHHHAVMaMGhVOt0GT1C6vvPEur709nTHDB7Pv3rtnrn+Z6bXf4nNpm43YWmvb9GZs/POwatjmA+Bvs/QxMSasrJb2RY+NMSbz2M2um5Xa/uaO/eY+r69T9rkgOs46avlh7l4caIajC3ySyiXQHho/rB2bC65JEKDwdSTT022Ug7IeWAdlLZoEjvLB+BgVwaBxrMHFTxUZcgEVppcqRaA0GJ8ICcAhsBqTWsYjDIDTV2yLtgatFEFgQUdTyaZJlIKlrOMJpnfkIfwWSxdECYtarKus5qnnXkPZgJ98dx+OPWxfnpj2Lv+69wlemT6P+YtXstvYgYBh4ztxU0sLy9asxTia3XaaSL/yElwToIxh9IAycp0Is5et5a2P5hCLWi771XF8Z/dJvPTeXM770z9546OFLFi5jknDepE0Dq98uIybbrqZD+YvIW5dfCzgbFr0Q3wJX2MqMpbC3Cg/OngXUDvTHA948u1PePCZN2msaWT80IHsNHoUJAJwNFZZUAms1iQSlqVLPkWZgIGDB/PB3KV8Ou9j8gqK2HXniQzsVUrE+hR2z2XKTuN49NnXuf3+x2monspbsxdSVd/MmCH9mDi0N65J0uhFWFTRwNX/egAdGI777l7c98jLJJQi6Tj4ysGxYVGh7Pl2omNYXCw5EE8wql8vgkmjOeGog9hz6q7sWhnn9WnTWL26gvUbKsOlnqwF5YE1KBsQoJj2zgzWVNVQXlrIH37xffoOHMr2o/szvFcB5aV55DgKP9HApO2G0aOkOxf8/DhGDC1mSP+evPTGhwTxBJW1cXA8Lj7jKIwJO0Fcq1haYzj1d3+ntq6SX516FDuOG4LeQuaK2JYUyoY1FwyKqOtz1kmH8Z2po5k4pB/9uhdg3Fy83ByUqiQnLw9jNVqFqwE4yoAJ8J1c3pi1hJaGOL3LCzni8L0oLcjlwMk7Me66Mtwchx5lpcT8OozyqGxx+b+bHmLR2lqKiwvZUF2Lh8XHwyjYbeIIdpo4hohNApoPP13PLXc+QLfiAn595g8Z1KsETRJrw1RkkwrRv622eSqyMYYgCFizZg0rVqygtraW4uJihgwZQllZGcBnBmLfRsYYVq1aRTwep7CwkLKysi90bKy11NbWsmHDBlzXpW/fvnjepnMhrbWsX7+empoaotEoffv2RWu9zY5/S0sLK1eGlQB79uxJfn7+NnldsWUOCgcNeBidR1JHqa+roak5Tl7Moyw/H6zBQYUFOjDowIQNS8JlL6x10SpCQzLB+toGtOvRo6QQrXwwAZ6jUDrAGEXSeGyoipNMBORHIpQURlBaoQlTDNOFHLCWQCsCHAIcrFa42HCJDx2m4ThKf4sv6Z1BePS1teR5mh8fdShLVqzhp8ceSv/yYmricMtDzxMESUyiZYufVeWGSqqrasiJRfnlz05g4vB+RFOzbSO2GdfEcQIfMLiew7Dhw8nPL2DI4MHEcqIk4mGnilLw/swPOfeSf5JsaqR79+40VdZhMKm0Lckd7ZyyFlpRipVrN/DrK29iTWUd3bqVcfrPfkTPXsU4QSMBGmXdVL+XIR5vpr6+AbRm+uz5vPbWe7Q0NqIdzaDeT3D5haex6/jh5OfG+OUpx/LJykqeeXsWr7/3IU2+pXuPcs7++cn07FaAskka4z433HwPS5au4odHHsyeu+/AA4+8FF7prI+Dn6mM7Fpf1kXuYNYqlFGURF0uOu0YmhJJ0C4rVlfw7CsfULmhktLCXCZtNwLXhqP9gXJSBXkgMJb5i5bgG0O/AQNpinbjxenzicRyOOWkH1KWp1FBHKNzuOTsn9KSdHCdgEXLVvLQs29SF08ydkAPBg3sh8aQo3yUozG4JI3mngfv4ZP5c/nO3rtw+AFT0dYPywDJedOBUiOehJXz0/OhtxvWl7HD+pBIujzw9Cs8Pm0GK1auYuSgPhw0dSIREvip+dIQjtj61rJw2WqSRMjr1p23PlrAP999mIjy2GvKeKbsOo4c16IVJGyE+x99mlffeJ9ddtieHuXdePR/z4Q1KnAw+GibxMMHa2hMKG64/X5Wravk5GMOZpfxw1oLj6nM2+DbPGS7TQNbYwxr1qzhb3/7G08++SRr1qzJjNANHjyYU089lRNOOIHc3NxN0pW/TPpyV5M9Orq59xuPxzn33HN5++23Of744/nDH/6w2RHuzW33qaee4uKLL6ZHjx7873//o1evXpntZr/GzTffzA033MD48eO57777MsFl9j5tzXv6IubNm8cxxxyD7/vccccdTJkyZbPPlY6ObceqsMKsr6JUNMLN9z/EK6+8RX1dLQUFBRywxy785JjDKCtwcEjgWEsksFidxHcsvo4RD/J44qk3uffJ51m1dh2u57H92BGcceIPGNmvO55tJiBgwaoq/n37E7w/azEtTS0U5hewz27jOOnHR9K9KIcIqcqV1mIU+ER47s0PueO/z9C7vITf/fInlOWAtTqrCL7oCOnjrwCXgLLCKD85cj+S1qG5qYnnXp/OHU+8SjyRYPJ2QxgztC8b56mHoyealavX09jYgpuXy/33P8ItGyrp3bOMAw/YjykThxBTLQzpXcLEMUN5ZfpcbnzgGQ7YYzIvvP4O1XVN7Lb9KAb1LUMrS3NLCx4Bhx68FyO234Hf/OX61OoKevNZ8qKTUFjtECiNHwTsvvMEFq9cz8y5C7nq+lsoL/wJu4wa2BoR2HC0NAgMvjEYa1m/oZphg/oyqH8fPpj1MYtWrefP193FXX+/mPxcw4MPPcaCRZ9SXlbCjmOHs3DZChYvW81Nt9/LqN+cRs/uJTzx3Gs8++JbbDdmBCf/5EcsXbkIjcVJdeOl9hTHBjhq8wXRxLajlEIZPwxarcH1YqyubeTsX1/Jx5+uwYtFOePU45kwehiubcQor829I/B9qqqqAKjYUM2Pz/0zq1ZXEHU144YP5Pe/PJ6dRvTGCSwxHaByEixYtIbTz7mSTyvrKenVnV/96lR69eyGNXU4GKx1AI/pC1bz8HNvUpqXw+nHHkpxFGzSYrWUvOlo6TVhgXBpHpsM57Nql+oWy60PPMvcRSuI5uVw5CH7M6hPOcrGQUVat2HDSvwNDQ1YN8riFeu59MqbCOIJrFU8/PLrnHL0dzj7xCMhWsjbsz/htvsep2dpARedfgyPPfdGeG+yrW1ebS0OPlZ7vPnhfF58+0N69+7BD79/MDkqCYTztb950dHW2aZ/SevXr+eMM87g2WefRSlF3759KSgoYNWqVcybN48LL7yQ5uZmzjrrrEzgtrl02Oz02uw0ZqVUm5Rda23msel/2QHTxmnQ2cFielvZr5Et/fv0dtOPS3+9ud9l73/2+8vednaAm50m3NzcTENDA/F4vM2+pfdlS1paWlizZg1a6zbP2VhDQwMVFRX07du3zeM2Pl7p19v4WG4pkM1+zsbHNn0MEokEFRUVJJNJfN/fJMjfmAS424IlAFoCzXW33MNdDz+HNYaY57C6qpZP7nqUDdW1XHb2j8lzw2IbvvKwCnyVpEW5PPrS2/zxmlvDaoCuIggCPl21liUr13DzFefRv8ijukHz2ytv540P5lFUkEe3slKWrV3HjQ88RU1jE78/56dE3bAwC0oT4LJoRSV/ueEePlm2mmED+uCjUcoPb0hybnSo7FtrarEMtGnB0y6fLFnMJX+6njUNLfTp34ezTj+FosIi7GZGuJSChUtX0WIhWdfIk8++ggf4Fp56bTp/POvHHL3PDhTm53L2mafy6aVX8+hTL/L0sy8TDwz9+/fhVz8/hZKCfKxNMHhAX67+0znsssN4Xp3xCcoGkEqFF51TuCRUWAklcByG9O/F/110EpUNcPYf/sEL78zkljufYPwffkEsYrAqSaB9lHFxIjG8aAyNZVB5ETf9+XwG9yrl6Tc/4pzf/R+Llq5m/uKVRKIe9z75Gq71+b/zT2C/XSewYE09J5//Z96cMYcHn3+L/fbYhetue4SmAEZvvz3vfjyXhUsWEyhNc2B4Y8ZcTDLO+BH9UVgCJQFKxwtTih1l0BgS1qe5uRkvJ5fuZaVsqKzmxWlvsPu4gYwZWIbdKCQw1hKPJ1DA8uUrKM6LMaR/H1ZVrOXtWQu45Jo7uO0vF9Ivz8MzjehYQEvNOspKSmi0msraGh578nm2G9KTAd2iqCAgsJCwDvc98RIbaur40UG7MWFoT0i2oFQEkzrXRcewG32jrcWxCh8HY1yiNsFRB+3OivW1PPTMq/zjxjtQiQZ+dsxBeBt1ZhljsNYQ+M0kmiw7jBnC7rvtxPszZ/Hm9Dnc98iL7D95R3r1689fb7iHmqY4vz37x4wdNoDHn3sdCwTKIcAFpcEGaAUNvuWBJ1+mvinOUd+bTP+yIhxTF07jkrZPxjabzGiM4aabbuL5558nJyeHiy66iJdffplXX32Vhx9+mAkTJpBMJvnXv/7F4sWLM4GdtZZkMsnatWtZuHAhq1evpqWlJZPSbIzB933q6+tpbGwEwiBtyZIlrF69OhMotbS0sGrVKlauXElzc3Ob4K2+vp6GhgaSySTNzc2sWLGCFStWkEgkMMZkXn/x4sXU19djjGkT9AZBQE1NDUuWLGHlypU0NDRk3nN6PxsaGjKvsX79elasWEFLS0smgEsHdwsXLmTNmjXE4/HM+49Go1x22WU88sgjnHbaaZkgNR3wrlmzhgULFmRSu5PJZObYbM7GAenGgaoxhqqqKj799FOqqqrwfb/N9tLvuba2lmXLlrF06VJqamoIgqBNMJ7+19LSwtq1a1mwYAEVFRUkEolMcJsdwKcFQYDv+zQ0NFBbW0tjY2ObbYuvn0ajlcOKlSt5+aXX8RSc8sPvcsf1l3PEYd8hwOWFV99h9apV4fmgPVocj4SOEhCjoTHJw48/R01TM7vvtgP/uf4KLvjVKURiOXw4fwlvvz8TVzks/KSCD+YsJZKby2WX/IIHb72cX53xA3ylePnND6hYtwFsGNT6yqUuobjm5vtYuGw1gQlHCAPCkVxpFHS8dGBrCXu5DWE1Y22S2CDBLpMnMXbkEKoq1nL1tTfyyfL1qKwOxXSnlp/0qaraQGF+HiOH9OfMU47i9FOOpm//PlQ2tHD9HQ+zuqaZ2hbDvQ88wqrly+nfo5T9d9+ZIX17sLZiLbfdeT/V9U0ADBnQmz13HkvMSeDho1SqX97KidNpKaitq+fF1z/gv0++Sm1dIzGVpLzQZejgASgbZdmydTQ2JsM5+xqSGgJliUQ8ykpLcIH+5UUMLvUoNtVMGFROYX4eLb6hqraRhUtWU9kQUF6Uz45DepCfrGVIeSEjhwzEB2YtXMKa9RuorKkn8C133vsg5118Odffcj8tSUtTwufKf97BnY+8QJwIvopglMyx7WjKWrSGQEVoUTF8HaO8rIwb/3Ypd1//ZyZNGM3bH8zm6pvuo7YlQKUqrqdprYh4YcdXYX4Of//dL3j0xsu47LzTiObkMHPBct6ft5Sk52F0BON7bD9mJPdcdyn/ufq3DCgr4flpb3P3A//DDxSBBVyPZWvW8urb04lGYxyy365ENVjtpArYSfumM7C0Vl8yysM6+cTJoSTX5ZSj9uein/+IHx11GA0tSW5/fBrLKptbC0el/mmtyc3NRePTvSCHy8//Ob86/mCu+PVpDOjZjfqGZt75eDEPPfkiMz5eQH5hIZ+u3MD1tz7AzI/mYIClq9dyw3/uZ9GKCgLlkMRl4cr1vPvhfAryYhy81y5EVRKlHQlqN7LNuhY3bNjAww8/jO/7HHrooZx33nnk5+djrWW33Xbj0ksv5U9/+hNDhw7NBD7WWhYsWMA//vEPXnzxRRobG8nJyWHXXXfl/PPPZ+zYsSil+PDDD7nwwgvJz8/nRz/6ETfddBMff/wxOTk5/OQnP+GII47gqquu4uWXX8YYw84778wVV1zBkCFDWL9+Paeffjr19fWceuqpPP7447z22msAHHDAAZx77rncddddPPjggzQ2NjJixAj+9Kc/scsuu6CUIh6P8/DDD3P99dezbNkyXNdl++2354ILLmDnnXdGKcX8+fM5++yziUQiHHroofzzn/+kvr6eiy66iFNPPZV58+bxt7/9jVdeeYWWlhZisRh77rknF154IUOGDCGRSHDbbbcxc+ZMDjvsMM4++2yUUsyaNYvLL7+c6dOnE4/HcRyH/v37c84553D44YdvVRGmeDzOv//9b+6//36qqqro1q0bp556Kscffzw5OTkYY2hqauKee+7hjjvuYOXKlVhr6devHz/72c/4wQ9+QF5eXma0/KOPPuK6667j9ddfp7Gxkby8PPbee2/OPvtshg0bhuM4my0o9tBDD3HjjTcCcPzxx/PjH//4q5+E4gszASityY9FOPZ7+1NdXcUZx+xDr9JCKqu357FnXsEPDEEyGT5eKZTy0daijSZfwaF77sLgfr046vAD2GFUfwZ0y+Wmux9mbVUd8UQSrXySQRO+tRTm57HDyEH0jil2HDaIiOcSDwyBCcJOEAuBE+G/Tz7H869/QDQaxba04KZK8wfKlcq2HUxZm1kL0ipF0jp4OizOpEyS7caO5qrxO7F6Qy2/Ov/3zJi9gJsfeIqrzvkRntN2OobrOvz8xO/zg+8eSG5ehJ6leaAcBvXvzfmX/ZOlazYwZ2kFvu/z5AuvU5gb5erfnslu44Yxc3EFJ194BS+8+h77Tt6eYw7cDZck1vi4WuOQTO2r+Oq+3qO4fF0t5//5Riqb41x6zgkcf8gUahrifPTJYqzyKSjMIycnh6YWw7J1dSStYWSPfPKjLtuNGsK092axcNUGPlldw3YDy1m2YgkNTQm0G6GstAidaMLTlsrGBMsqE/QqKyPe4rNh3Qa0hW75OXSPJhk/dCBNSYujAwIT0BAPWLKiAgcY0KcXPctLcTB4BGiTlL6STsBaRYNxWLm+lqqaOob160H3vAhlsVymThrH6+9/xAefLKWyMUlhTKNMEqvCu4jjuJSWlmKx9CrvzuTtR9E9Ztljp+3o0b2UZavXUblmBfWJISxb10hdTRPjh/WkML+F7QrKmTRmNIuXrWP6h/NpThjcqEvSwrsfzWJ9ZSWjBvdm7Igh+Ch8FcHF4Jiww010rExlfzS1TUnuf+Jxlqyt4ci9tmfHccNxlaZf7x5oBXV1ddQ31KPKuqcWZgjvgI7j0KdPH5SjyIlGKc3PJaZa6F7o0q2kkGWr1lMd92murSXwDRVrK7nlnsdwbZLAWgLlsHz1em66+1G2H9GHAf37gPJ456NPqKltYMzQAYzq2w0HQxwXLSUQ29hmge2nn37K8uXL0Vqz9957Z4LadFCzzz77MHXqVHJycnCcsMdz4cKFnHjiicyYMYOioiIGDx7M8uXLefDBB5k9ezZ33HEH48ePp7GxkXfffRff93n//fcpKCggPz+fxYsXc+WVV3LXXXdRX19PWVkZCxYs4NFHH6Vbt25ce+21xONxZs6cyZo1a5g3bx7RaJSioiIWLFjAnXfeyZtvvkllZSV9+vShsrKSN998k0suuYRHHnmEwsJC7rvvPs4991zi8TiDBg0imUzy7LPPsmDBAu69917GjRtHY2Mj7733Hslkkvfee4/q6moikQjl5eWsXLmSn/70p0yfPp3i4mIGDRrE0qVLueeee1ixYgX33nsvsViMOXPm8PbbbzNhwgSUUlRVVXH22Wfz1ltv0bNnTwYNGsSqVat4//33ueCCCxg9ejQjR4780p/TvHnzuOqqqxg4cCCe5zFv3jwuvvhiPM/j5JNPJplM8re//Y2//e1vBEHA4MGDAfjoo48466yzWLNmDeeeey6u6zJ37lxOOukk5syZQ2lpKf3792fZsmXcfvvtfPDBB9x9991t9jHdqJ02bRoXXXQRFRUVHH300VsdpIutEd5YHaUxxqFPeU/O/sn38I2hoaWF596cyd0PPo+fiLPjDuPo16sMRzskjQnXC0WhrCLPczjhyH3xAd/3mf7hTB5+9i2qq2sY1KucHceNBhswdGgPhgzsyfzFK7nrgUfZY+dxPPDka7QkfPbYcTy9y0qwxpDUMT6Y+ym33PMoRUUF7Dx5F5588ulwl1VYrCoc2e24IydU2LGRKvJlcFhT3cIHsz8h3tzIPlN2pDC3hT4luQweMpiZC5ez4NOlxH2D63nYdEaIUiT9gDkLFrNmfRWjB5YzuKQf4DK4d3einkMimaShJc7ipauobUkwpl9PthvWj6htYOTAHgzs15s166r4aO4Cjjt4Co5JEmBTKcgBVimMIqykKyMlX8HXWRUZ+g7oz9hxo3nurRlcddN/eeOdD1hb2cCHn6wgP2I5cK8diXgOH81bzk8vvIqksfznz2ey8/jhHLD3bjzw1DRWr6/h1IuuYuzwAXz8yRIa4z47jB3G4EED6FtWwMCyfBZW1HHxNfdw7KF789HsuXw8dyEFUY+pO45j0pjB3HfdpVidA7oZYy3vf7iEn57/R7xohL/+/mzGDe1FhCSO9duM/IkOoiw+lmXrqjjprMuorK7ld7/4Mccetg/GWFZUrMeoCI4XAc8haRwaEooAKIwoXNcyelh/npj2DlU19axbV0W3wX1paKwn2dxEjIDiwjymz53Hmb+5HmU8rr38PKbs1If6ukbWr9lAYDVeTg7W0RhtSRrNWx/MwQY+40YNIz8/D5suwGjDlQVExwlLCIadswrCeh5W8/hzr/HRwuVsWL+O7gNHEdiA5155CxdLj6ICuhXm0ZQIeGPGXJpb4owd2pcB/fPZeewQbvFc1tXU8fTr0zny8D2Zs2gFK1avxdGKgb264fQq5rADphLQOsVu1sIlLFyylvJuJewxaQQ9uheh0cSNwwezFpIwltHDB1GS66FNAl9HkXtYW9ssWkin17quS+/evVFKZYIVpRTRaJSCggIikUgm1famm25ixowZ9OvXj/vvv59nn32WRx55hOHDhzN37lz+/ve/Z1J2IRxt3GeffXjhhRd44IEH6N+/P83NzSSTSR544AGeffZZvvvd7wLw/vvv09TUlNm/ZDLJgAEDeOaZZ3j66aeZPHkyQRBQUVHBNddcw3PPPZcZKZ03bx6rV69mw4YNXH/99dTX1/O9732PZ599lqeeeorJkyezaNEibr311ky6bXr/ioqKuOKKK7jkkkvYZZdduO+++5gxYwY9e/bk7rvv5umnn+Y///kPAwYMYNWqVcycObPNXN308dqwYQMlJSXsueee/Pe//+Xpp5/m1ltvpaSkhIqKCpYtW/algsHsNN8LL7yQ5557jieffJLJkyfT0NDAf/7zH2pqapg9ezY33ngjyWSSM888k+eee47nn3+e0047jXg8zj//+U9mz55NMpnk+uuvZ968eQwePDhz/O+991769+/PrFmzuOGGG0gkEpn3pJTi448/5uyzz6aiooKDDz6Y//u//6OkpGSTYyC+bmF6MdaS4zcRw/DurBWceulNvPbhpwwbMoizTz+Rgrw8bKBwUz2GRimSjsbXGgiI2IB1G2o567KbuO2J18kvLOLc03/M4P498LVDebdSLjznTMp7lHHTfc9x/PlX89ArHzJ86GDOO/14CiIQAGtqmrnqX3dRU1PHz084gu1GDkqdswplU7Ml5fzoBHSmgrVSlrmfruKXv7+Wc/96By/NWAg2oLK6ho8XLydpFd2KCtCuR11jkkUrKlm0qormpKI5abni5v/yi8tv5po7nmRtU4QaW8hbHy4gnkhSkBOjX49u5EQ0aE1VfTNra5pJevlUN8eprK5BOZqC0m4E1qK0AuWC1ZkiY+E/aUx2ZvkeXPSzo5my3WAaGpp5+vWP+WDeMmIRh5OO3I9jDtkHTyuSFlr8gOZkkqQbxTguY4f05cKfHsuAbkWsXrWWp19+j1UVlYwdWM7FPzuKbsU5lPfpwcVn/ZAhvYr5eO4CLrryBu596lUiEY8Tv38A++w6CatcciJxcp168rSiQHsUqwQRrYg4ihzXEHNMajm0sLqu6GgWpQK6dS9lwMC+NDTH+fttj3LFLY9z8XX38Ojzb6GMZfKEoZSVxPh0TRVH/fwPHHLSRbw2fS7KJNln8nb0KM6nsrqW3/zl31x951Nc+vfbqa2qpk9pIUOHDWfAwIGUFedRV9PAZdfcyt/veoaLr7qN6bMXEHM1u+08nmgEDAENLUkWLFlFRGtGDhsIWuFaSzRIom2AryU86XitU1OUUuQX5nHQgXviRVyefW06R//s1/zgtIuY9uYMXK05fP/dKCsppLIuwSVX387pl17Hy9MXoo1lyuiB7DZhJL6f5Mp/385hJ/2G03/9d9ZV1zN6UA/2njiMow+cwj9/fzr//sOp/PvSk/jX73/KPruOI0LAdoP68NffnMYOo/vgGEOyOcmqVRWgHfr274+nLS7hIIRoa5uN2AZB6+Tqz6p0nC66VF1dzXPPPYe1liOOOII999wTpRQ77bQTRx99NH/84x957bXXWL16dea50WiUI488kl69epGfn09ZWRnLly9n8uTJ7LTTTjiOw8iRI9Fa09LSkpl/a63FcRwOOugghgwZgu/7DBkyhNdff51Bgwax//77U1xczIQJE3Ach0QiQTKZZOHChSxatIhIJMIRRxxBSUkJAIceeijvvPMOb731VmbeL4R59yeffDJnnXUWAIlEgjfffBPf99lxxx2ZOnUqkUiEvffem8cee4z8/HxKS0vbHKu0YcOGcffdd1NVVcXixYu57777eP7558NKbNa2Cdo/y8ZzXAcMGMBxxx1H9+7d6datG8cccwxvvfUWixYtYtWqVTz//PNUVlbSr18/TjvtNHr27AnA6aefzmOPPcbq1at5+eWXKS8vZ9q0aQAcc8wx7Lrrrmit2WOPPfj+97/P1VdfzfPPP8+FF16YeX+JRII///nPbNiwgZ49e/LHP/6R8vLyzLHb1uvqfqspiyIJBAQqDFKU38CeO4xkwdKVrFyxkr/fdA9Xnn8yvUvzUTa1HA9BOHIKhP1mGpuA7YaPILe0hvmLP+W62++nR88cdho1gMb6Zh569Alqq6oZ2LOMwQMHMmfRclYuX8WDD/2PoWccjetFuPOBh3j/w/kcuM9kvnfwfjz2/GthHUBrcJRF2dQC6XJ+dKggtYaeVRZrEowe1o+xQ/ry3vzl/PHqm3nhhSEsXrWBOYuWkxeLcNBeu5DnwrNvfcR5l99Ebk6M2/7+G0YNKGffqTsze8Eynn/rIzZcdBX5BQVM//BjjLHsOnECw/v2xQ0Cehbms25tFZf/4y7223cqr733AUuWr6YgJ8qOE8dhtEfSpkeRU3OgMotSyfnSWSlrcW2CCYPK+ddlZ/HmB/OYt+hTCvJy2WH8WCaOG0WeioMNGDJ4EBec83P+ccOtRCNeatmdBN8/ZC/GjR7JG+/OpKqqmgF9ythz1+3p2y0P7deBozlgyvaMHDCAd2fMZ9HS5RQWFbPj9qPZYfQgYm7QGm0oUtc2xZAhA7j+qt/gOKmRl9RyG2FVVdHRtIWIMXR34NwTjqJieQWLVqzl+tsfRZs4jnbYbdxQfnn894jZJH5gWFWxjvqmZhrjPkprRg7pz8+P/x7X/udh3py9mNdnLUJj6F6Qy6k/OoxhfUvQrs/ZpxzF5X+7m4WfLmHuDZ/iB5qoW8DBe4zlBwfvTYSwPkhTfR31dfV4jqZPz2442mKNlSV+OpnMn7sJcFWCYw/fj5rqGh59YhpVK1dglaV7QT5HfGcKpxx3OFFt0MqSG4sScRROanpUQX4ul5x1Ku4/bubdmfNZs3QJEc9h4ohBXPSLEyjvVoIyAZYAZU3qlQMKXEtJfg75UY02ibB2FJYg3ojyE5Tm59C3vBgUGJuawtNxh6tT2maBbVlZGZ7nZYodbRxQrVu3jjfeeIOJEyfSt29fampqqK2tRWvNkCFDMmmqWmuGDx+O67rU1dVlSrIDRCIRSktL0VrjOA6e56GUoqSkBNd1MyPD2UWLskcC0+voZj+3tLSUWCyGUirzs/TjN2zYkKnk++c//5l//vOfaK2pqKjIFGCqra3N7J/neYwaNSqTap1MJtmwYQPWWnr06JFZY9bzPEaMGJEpsNTS0rLJ8fR9n9tvv52bbrqJJUuWEI/HiUQi+L7/ldJ2S0pKKCgoAMJgcuDAgbiuS0tLC3V1daxYsQJjDN27d6e8vDwzut6tWzfKy8tZtWoVy5cvp6qqivXr12OtZcSIEbiumznew4cPB8h8xtAaYK9fvx6AyspK3nrrLUaNGtVmOSTxdUt1NinABlgFxo2R8A177DqRvXYZz9xlG/jpr6/ixTem88DIQfzihO/iYbDoVIl8A2gC7RDgMahPCf/8w+lUtDicc/k1vPLGe/zr1ofY7sqLeen1N3hx2lsUFxXyjz+dy3ZD+/H6B3M5/ff/4MGnX2X3ydvjRnO467GXcHJzGTNhe6Z/NJdPFi/HR9HQkuCN6R8zaURf+vXshvR5dxyr0rfm1BIFKqBbYQ4XnflDLv7rbSxYupr/vbieQGsK83L4yRH78b09d8C1CSyK+ngCX2sC7eEpw48P3ZPFi5fyzLR3eXvmHLCWqOMwedxwzjvjRxTGAsYNLef8037AX295mJff+YAX3pmOxlKUG+Onxx3MlHFD0CaJsRYHjVUaZSGqFFFU6lwVnZIKi5HZIE6v0jy+t/8uHHHAZJRJohX4JFPrNyo8R1O1fjXdCnLoVVYKQYCHxbVxxg7sznaDDwyXz7BJtE3ikABrCAKLox2G9illeJ/dCVTYLFXKoII42hqMSq9RaUGFax8XFuaw+8ThYQCNjzJJskd7RMcKcPCVi0ecnUf14pa/nM+Dz73BrAXLiLmKHcaP5rv77szg7hGMCSgtLeHYY3/Aff99DMf1UEoT1T4nHrk/Qwb043+vTGfturX0KO/OQXtNZo8dRxNVLWAN39lzF8q79eXxl15j6erl5OYVM3nSZA7ffSzdChRO0IxVmvyYx09/dATxpGHk4D4oAlQqOMmcOnL76gQUVqU71pKUxDzO/ekP+MGBezJ/wWLQDsOHDmJwv55ElY+2PqXFhVx12a857+I/UZIfAQIsMKJvKddedi5zPvmUNevWUVRYwHajR9CtMA8HP7WmT+t0GG0tpx33XY7+7veIeg4xR6OMi1VQUpjDjX8+l0ZyKC2MAQFGlqvbrG0W2A4ePJhevXqxePFipk2bxvHHH08sFsv8/rnnnuNXv/oVZWVl3HjjjQwePBjXddFaZ5a4AdqMRnqeRywWazM6mQ480yN8xphMUJt+/sbSj0sHxOnRZWNMprhR9vbS20hv13EchgwZkgmMx4wZw5577klRURE5OTltRqjTa/Smg/R06nVdXR2+72cCwHg8jtYa13Uzz8320ksv8dvf/pZ4PM4BBxzAQQcdREFBAWeffTZVVVVbHQQ2NzdnqkE7jkMymUwVc3GJxWLk5+ejlCKZTJJIJDLvLQiCzOcUi8WIRqNEo1Hq6+tpampqs/xRehQ7EongeV6biqjDhw9nzJgxPPHEE9xwww0ccMAB9O7dG601WmsJbrcRpRQOsHpDDR8vWkUi4bP7LuMp9ixDB/ajT98+LF1ZwcfzF+EHYbGfOBGiKok2PvUNzcxa9ClralqYOqGcnqUxekeL2GHkYF57/X2WL15HU7XP7HnLaY77jOvfi2HDyom6VWw/vjvlvcpYuGApHy1aTU5eHjWNzQTAX6+5ERdLi7UkrGb52irO/cO1/Obnx/GT7++LksrZHUpt9LWDYefxI/nP337HtHdmsGTpcgqKitllwmgmj+5HHo1gIowdO4Zf/PwU7r7/4bAD0Rp65lr+7/yTOGTfKbz/8SL8RJzxIwcxZdIYuhfnoGwTrutz9OG7MXr8SN6cPp81qyroXpTP1B1GMXHkAKKqCWVMar1aj0A5jBoxhH9deSGuVgzq32vjZXRFJ2EBo1ysExZyUcqCNShlUx9ZgMJglWLZ0sW8/sqr/PzEwykrKQASKGtQNhm2G4NEansORmuM9UCpVIaBxiUcMbE23J7BoBw3dW+yWTGHyRT4ca1pMzfSyr2p0/C1Q5OKEDPNREwzI/vHuOjUg2g2EQIVw3UsUdOE8ptxtEdRUS4TRg3iqYimd4/uWBPg2IAcDfvtNJq9dxyJbyzKcVIDBwFBakqDVoYdxg1k4nYDsUELLuBpJ+zqtT5h5pKitDCXE76/P6BRtgVlm8OVkJUsU9fppKrla0yqI00xbEB3hg0oJ5z+ZNE2gbYGaww2gHfeeA2dbGH00L4oDEYrvCBOSUwzefthGEaGE2BsgCYRBrXhi7XpzyjJjZKfH7b7HeOjrBtm0ClD7+4F+MoDbNghEnbXbtND0xVss8C2Z8+eHH744ZkKx9dddx0//OEPyc/P54MPPuAvf/kLDQ0N9OzZk8GDB1NcXMzAgQNZtWoV06ZN4yc/+QkFBQU0Njbyyiuv4Ps+AwYMoHfv3m1GbdvbZy0xM2DAAAoKCqipqeGQQw7h6KOPxlrLI488wty5cxk9ejSFhYWZx6eD4LRoNMqQIUN44403mDt3LtXV1ZSVlVFVVcXpp59OQ0MDZ5xxBvvtt98m6drvvPMO9fX1jB49mn/961+UlZXx3nvvtZmz+kVs/Ljly5fz8ccfs9dee+H7Pm+++SZBEFBeXk6PHj0YO3YsruuyYsUKZs2axdSpUwGYMWMGy5Ytw/M8dtppJ8rLyxkwYACVlZW8/PLLHH300cRiMZqbm5k2bRpBEDBs2DB69OiR+fw8z+O3v/0tEydO5KOPPmLu3Lnceuut/Pa3v/1S70l8denMmPdnfsK5f76ZWE6UG668kJ3HDWf5uhpWra5AKygtLQ6nDjQ0U9EIeSpJ75JcVlc2cO4frmVlTRO/+dUxnHjEvjQ3+cxfsBRjXYrzcsn3HCLRcO3b9VU11DQmyS8toLJ+Aw0NTSilyMvxKIi5DO3bC2MtngJjoaqxmbXVdUQ8l149y8iJRTv6kH3rheuOmtTSS+FNV9mwETCwLJ8TD98LH422hohNoII4SkdJGsjLiVC7roIBPbrRrSgfQ4CnLAURywG7jmPfKZOwxuCRxLEJsPFwdE1ptE0yfmB3xgzcB8cqHGUg8MP/2nBfNBZfhXMgS4pj7LnjUFwFxqR7zEXnozCE8/bD79JFXRzS4aZBobAMG9Kfa684n97dC3HxsTiQCYBTIyKKVPiqQDuZ32irMMolNZkhay3msMCYtqSe1Tqykj02a1OBSzr8lWTkjqcxOFis0gTaRdswNT1fBxgLvjVYFeA7OWA0a1Ys5cbrb+CQ3bdnxMDeKOWTzhHWNsCzCdAQWIUxKhwpU+EraQzQjELjqjB9XhufFp2TOnddlFVoG+DQkDo3fawyWOVkKunKedPx2l4rwrNIpQoiWuuHWSSWsEgmrdeShtpaPp41m7N+dgxDB/RCqTBzyVEB4ZrKhFkgNjw3tTWZzrLMVUcpsAplHSAIXygVYCvCzBHHkspw0qlMElKd+VY6R7Jss8DWdV1+8YtfMGPGDF599VX++Mc/cvvtt1NUVJRJXc3Pz+ess86ib9++aK358Y9/zPTp03nhhRc466yzOPDAA3nttdd49NFHiUQinHTSSW0Cxy35OgIiay2DBg1i6tSpPP7441x++eWZtNq//vWvVFRUcPbZZ/ODH/ygzWhxdoDqeR5HHHEEjz76KPPnz+f888/n8MMP58UXX+S5554jNzc3M8d247VnS0pKcByH5cuXc8stt9C7d29uvfVW6uvrgXDk9Yu+j2wNDQ1ceOGF/PznP2fNmjXccccdKKXYd999KS8vZ++992a77bbjww8/5JxzzuG0007DWsv1119PQ0MDu+++O3vssQdFRUUcd9xxzJ49m6eeeopzzjmH/fffnxdeeIHnn3+e/Px8TjrpJPLy8jKvrbWmd+/eDB48mJNOOolLL72UO+64gyOPPJJx48ZtxacktpY1oJTD2LHbUdazB0tWVnDxn65jx+1H8eGClSxfVUFBboy9p+yMdhyef+Utfv/PB+jfvYjbrv4NZb0HMHzMGBa8+j7/d8uzTJ+1koaaKl6d+QnKcdljj50pKNDsvPMo/vPYsyxbsZa/XHMP+++xO0889wrr11bSuziPyWOHMHrEIA7dexKuUmhlabEeDzz5KpdfcwsDe/fiP9f8kb6lkax5KqKj6NRNP8xL1qnVGTU6NZfItQpX+bg2IK48WvDwdJJZM2cw8913+cUZJ1CcF8GYZnwdxdpw1FcFzWilsCZMdFbWIe7kEKDwiBMJfKJBE9oJGxRJ5RFXEbRKNShtEqUNhgCtNG4QBxOgdARrNEoKcHRKCotjg6ywMWxwpmdJm1RgEYs49O5eRNS2gHLxiWQC1fTpCBZtg8z6xeF5ZDPLhYXbCsJAJXUtCX+7cTGo9FrNOhW4tLYvtAS2nYJrAvJMnEC5+CqSWsbHoq0hapJYbUhoF2ujeNqhvHsJl57zQ0YPG01UB6kOFA1Wg3JI6DzCMy9AEaAJwizSsOsFo8CoKAkVw1cuSiWyzh2FUhbH+miSqawAg0nVhZA5tp1L9lrsBt06JUKl/rZVONjaWqUhoLSkiKsuO5+cqItj4lhLKk14o6Uss0ZnVXgChR0bmaWCVNglo9JtmfS1JyBInY8uARaLQacebTCSctTGNgtsrbX06dOHG2+8kSuvvJJnnnmG5cuXY4whEokwcuRIzjzzTE444YRM+u3RRx/NsmXLuPHGG7n77ru57777CIKAoqIiTj31VI499thM0JhOGU4Hj+lUX8dxMinErWskupnUYiDzuOznZ4+upp/vOA5OKhXFWkssFuPiiy9m9erVTJ8+nXPOOSezrQMOOIAzzjgjs410Km122jPAvvvuy9lnn80111zDAw88wMMPP4wxhsLCQs4++2x23nnnTDpw9v4cdNBB3H333cyZM4c//vGPeJ7HpEmTGDVqFHPnzmXu3LmZlOrsfYbNB/rp/Z44cSKRSIQzzjiDIAjXEJ0yZQq//OUv8TyPvn37ctVVV3HBBRcwa9asTCEsrTVTpkzh6quvpqysDKUUJ5xwAsuXL+e2227j9ttv56677sIYQ0lJCb/85S8zFaqzj3cQBDiOw49+9CMefPBB5s6dy7/+9S+uvvpqcnJyZNmfbURpizVJBvbI5+KffZ8/XnMni1etZ96qDSige0EOpx17ELvvOB7QJI1DU1MzDY1RLJAbMZx18veorlrLu3NW8PDzr+FgyI1FOGzfHfnx9w9Aa8PUCaM547hDuPn+Z3j4+dd4+IXXwUCP4jx+dsIRjBwxCE8liMZAGYV1wrTBPM8SQRG1lryoxXP8VEDVwQfuWy7QqVGxzHBWeIM2yqZ6rcMUqiQOSodBJ0ozafxIbvq/8yjvUY628TBN1KaStEx4HbOEKXsBDmBxrY+2Cm3Dnymn9bXD0MekGp8WqxysUbhKh0P+uOE/K9XWOyOfgBYSZI9pZFiVaTD6qd9bE/43UApjA1Dxts/KxLhtt5Xqcsbi0xqgbvyaW+ow29z8bEtzaq9Ex7GozMh++jqQTin3lYMyGs8qlPWBgLxojEnjtgObHoBIZwmATRUDyu7QaD1zAMJyxhoLyic8n1w2HuUPyyuGKfAWB6wLaBR+aqcdkAClw1k2LU9tAZUaPU3PXAlPkbCYnAvkR8LzSSmNSXXIGtUaYunsrEt05h6Z/VLhdn1cE35nlAn7iJXGseEcf2PT53VqyqScM5vYZoFtOmgcOHAg1157LcuWLWPBggUkEglKSkoYNWoU5eXlmXmr1lpyc3P5zW9+wyGHHMLLL7/M8uXL6dmzJ3vttReTJk0iEokAMGLECG699dbM1xCm+f7hD3+gsrKSIUOGZIK6ww8/nKFDh5Kfn09+fj65ublce+21NDc3M3HixMwc2pNOOom99tors0/GGMaMGcPtt9+O4zj0798frTVjx47lgQce4IUXXmDmzJm4rsukSZPYb7/96NatG8YYhgwZkln6Z8yYMW1GSaPRKOeffz577bVXpuJw+j3uuOOOmSD/N7/5DZWVlQwePBitNUOHDuWee+7hiSeeYOXKlWy33XYccsghrF69msWLF9O7d2+MMeyxxx7cdddd5OTk0K1bty1+NkcddRQTJkygT58+DBw4kP/973/Mnj2bMWPG8N3vfpcePXpkGoBTp07lscce46WXXmLmzJkYY5g0aRL7778/3bt3zzyuqKiIyy67jO9973tMmzaNVatW0a9fP/bee28mTJhANBqmjw4dOpTbbrsNYwyjR48GoLy8nH//+98sW7aMvLw8KR7VAZQCF5/vTJ3EgAEDeOHtj1ixei09SovYc6cxTBzRn6huwVrN5B3H8aMfHs3b06bhuQ7a+owZ0pdr/3wBL781i7mfLCQaibDT9mOZMnE0xTkKJ2ihUGt+efz32G2nHXj9vVms37Ce8tJipu4yie1GDSKiE+Eoi1WgHKwBRyt223E7/nHFBeTlRCjOi6Gtn7nhiA6i0iNqoXA0IrtBmPq5ap21qFX4qeXkRMnNDQtiZB670YfZZiZSqlGhM6+7cchiIataZGsDNKtxqrIfLaFIZ1FELsvUei7jwa3bwJe5CHwNF4wkAVPsqPbfsPjCVqlqXmTO5n/Z9qLQym70+42//qq+wLYWsoZcIu34ouLLCT8kg+UdFrCUdV9lM1v3+887/zb+2Ub3sUrqv8AOfLMp+1mTSNtJepQy/XX20i3ZI6RApkBQ9nPS1YHTz03/LHsEMrs4UXYxouyRys0FR9nb3Hh76f3J/t3Gz00/Pv19ensbv7eNi1dljzxuvBRS9uM3fl72/qf3MT0CnH5uenQ5+71t/NyNj2H2sfF9f5Pjm73ucPo1sz+X9O/Tr73xPqa/zh553tx+Ze9P9u+zC3l9ewPcdCKLShXTS1C3ZBb+2kW4JMOAoh2OzZNMJ6o89rdjw/Re7eLrGAk8DAbXJvFMCx7JzJy3DU2K3//zIerWr+K6y84lzzMorUkSpqMqFebvaAzaJHEJwPi4jkPcugRODN8qXA0ESSwOWgcokuG8TRTWeijC8zpwwLphJKV9i0t6pAaWsJbHeY+zOHQrjzKZIFlj8IkQ6TmUgn7bYZwoWqlvxG3DWkvTmvnEl05v1+k5PgHnqzvIJ8YXOlKba1B2gNVUca49nFH03cotpJadUopAhfP6tEmS1FHcHkMpHrQDSn0zRmUMFmxAS9Vy6hfNIBo0oYAAHRY6+Qrbtm0S9romlZmF9xVZi4MhWTKIkhG7YFUk1RkUjtl0rStR2O1lMSRxca0hWbWMuoXv49hwjmp7/G0k8XmFOTQR/8rb6gg7MpTelH6lbYRHWhGxCbCKZEFvSkfthnXyUqm1qktNyUyfOdoGkEoI1xj8pkpqPn4N1zS169/Cp6xlNsvabXvbUjF5TGEUDluR3WhBWQ/jNKKsg+PHMF4zTTnd6THqABwv0iVuX9tsxHbjFNLsysCfNRqXft7GwdDmtvNFXgvaBk1bCvw2F3xtHGxtLtjMfi/ZQWn2YzZ+r9nB+ua2s7nnZQeI2e8rHfhtHIh+nuxtp0eJP0v255K9r+l92twxz0733vjYbKkD4LOOm/gapdL9FISFeGwzEeJhMZVwchq+dcKRMuXw0iuv8Mm8j/nNWScTjTg4WDCGiFJY/NR8ttTImAoDXu14BNZglAMmwFOAH+Bqi7VJCAyo9Dp/YYPZmnDWkrUJbBCmHyvrgvW6xAX328BBc7n9IUmCz38wqfSrcNJShxbAUCjykSJkHa3dgkLxreThsh/jO3o3RBc2mB4MpkdH74bYStsksN1SQLJxALjx77YUzH6R53/WPmxtgPRZgeYX/dnWPOfzvv8qAV97BIuf9/l+ka8/7/1+3rkg2lemgILSYeEWa3Ax+LipBFAPpcLpitYo9pi6G5N22ole3UtwTHpuXDhXxarU0gep+ShW6XCepCJV8Ck9lwmUcvCtwbU2VZwlPYdEhYWJlMGQqlRqdOveKlmPtLNQKHK/bIAocUwXJR+cEEKIzmObjdgKIbqOdIkEk5VaqKzFsQbH2rAaqAVHKZQ1dM/zKM330LYFRykwKqwamFoWQVmTqm5qUpUEw5IcYdn7cIZkeh6kJbXeJBCk5m06Nj2LMkiN4DooE0mN6AZY5YN1ZKRHiG2qa6cMCyGE+GaRwFYIsYn5rCKPnFQl2vBninCdUiBT3Se9XIZJBazWGjROanmFcHTWYtEqSM2MaQ2YrVWZqpHpEdvwOelQV6UKEYV1KB0MVqUr7Lqp+Ypg8bHhqnGAYg3VrUt9CCGEEEKIbwUJbIUQbezIUBpoYSnrwx9sXI/+s3zRan9f1OZee3PFhmzbLw9mh614MSGEEEII0VVJYCuEaKMHxRzDlI7eDSGEEEIIIb6wragHLYQQQgghhBBCdB4S2AohhBBiK0ixNiGEEJ2HBLZCCCGE2ApSpE0IIUTnIYGtEEIIIYQQQoguTQJbIYQQQmwFSUUWQgjReUhgK4QQQgghhBCiS5PAVgghhBBbQebYCiGE6DwksBVCCCGEEEII0aVJYCuEEEIIIYQQokuTwFYIIYQQW0GKRwkhhOg8JLAVQgghxFaQObZCCCE6DwlshRBCCCGEEEJ0aRLYCiGEEEIIIYTo0iSwFUIIIYQQQgjRpUlgK4QQQgghhBCiS5PAVgghhBBCCCFElyaBrRBCCCGEEEKILk0CWyGEEEIIIYQQXZoEtkIIIYQQQgghujQJbIUQQgghhBBCdGkS2AohhBBCCCGE6NIksBVCCCHEVlAdvQNCCCFEhgS2QgghhNgKtqN3QAghhMiQwFYIIYQQQgghRJcmga0QQgghhBBCiC5NAlshhBBCCCGEEF2aBLZCCCGEEEIIIbo0CWyFEEIIIYQQQnRpEtgKIYQQQgghhOjSJLAVQgghhBBCCNGlSWArhBBCCCGEEKJLk8BWCCGEEEIIIUSXJoGtEEIIIYQQQoguTQJbIYQQQgghhBBdmgS2QgghhBBCCCG6NAlshRBCCCGEEEJ0aRLYCiGEEEIIIYTo0iSwFUIIIcRWUB29A0IIIUSGBLZCCCGE2Aq2o3dACCGEyJDAVgghhBBCCCFElyaBrRBCCCGEEEKILs3t6B0QQogvauPER5nhJ0RHkr9A0fmk7xNd4ezMvqd1hf0VorOTwFYI0Za1OBaMCv/ZrLutstCRt19LuE8qtS/Ktn5tVIfumkh9FkHqc1AWtAWsDc+hTv3ZdOqd68S+xjm2WX/b0PoJpa9LytoO/dSMAkvqYpTaV53a1w6+TH6rpc9Io1rvD9D6dUfPCrfKtjmvbfo+CzgWlJw4HSPrOmNSH0Hr+WMzP+so6bZXdvsHWttncta0ksBWCJFhSd38lc3ccNNBimPD33dow0CFN/50w9FC606LDpVu2PsaAg2uAW3C34XBSEc3KbfASlOyM7Opv3PXhHOnLOA74fcdeTVSqUamUaAUOKY1sA3khOow6UPvpq49mXsaredSRzKpwNa14TljVeqaqUBuZB3LSQWyfmqSppvqnA07+G2HnTvhvTW83vg63E/PhPsVqPB70UoCWyFEG4GGZje8oLsGvCDdaLMkHQh0x11FvUDhBZB0wn/pG5BO3YAkROk46dF0x4IOws4QX4NRKvx8OrrLewtkdK1zChv8lqROBba2tbPEMwqjFKaDPrh0R5+XDp5SAVMydT3q9AkK32Spz8ZNNfx93drZZrFEgtYOiI6Q3hdfh/fV9D3WI3X+yInTYdK3qOzMi/DzUniB6tDzJuw0tuF1MIBIEJ5HmQ5+OXEyJLAVQmQowhttNJ6V+ofFd1TWKETHXd0TLrR4rXvgGPACi2sVSa3apE2Lbcumeo8jQZgm6mtFoMPzR6GwnfbDke7uzkhZm2rAhZ+P0WAIA1zPh4Sj6MhkZD81TKKNRacTFrNSGEXHsAoS6c5ZwoDAseD64e+TjsXvwEtRxAcVQMJJd9BatAHXqjap02Lbsiq8vljV2mHla4tBoU047t9x1xtLoFP/FDgajA0D20B33k7jjiKBrRBiE8qmGmnW4llFw7oa4nWNONh0InCHsAqs0uH+Ab6jiPYsw8Y8CU86UDpFPTM3iXTqsSInCUorfKfj9u+zWJMKRKRt0MmEcyDijS289NZsovkxxo8fwqo1GxhU1o2Xp89n5JC+NLckaGhqZpdxw3GcbbfQg1UKg8HoMIBSqVHCzHVIzqcOoWzY+RGxGxWRSs2JdmxrSqm1FmstWmuMMWilMNZiLV/bueSk9tEz6VRXBYFBWQgcJedNB7LpmiI2TD02hB210ZawI8t04JCtxaK0RWuLMgprIFCWQOnMFA05dUIS2AohMixhD2BjJPw6GkBRI0y/7TEa3vyInGSA+lLDEe1brsOxikgQJhzHHagqjfGdKy8g0q8EdCeNnL4tsuavBRqSjiIaQHJFFRsWLsFVpkN3b3OsoynZYTQU5kqjoJOxypLUBt8GvPrexyzbUM0BS1bx0oz57LP9KK55+AW6FxVQnBsj6roUHH8oE4b02yb7pgA3qVGOwuZHSETCTh1tFY6VObYdKT3ylnSy5tWmRvsVkJcMR9l9P+Dv9z7NwmUVHL7XDjz60vscNHV7Pl64goUrKvj7ecfTvbig3fev2Q2zn7zUKK2xBjwHY62M2HYC4WdgCXTYdgk21PPCdXeT0xhH246c099aOM+xYadMPKrpv8+u9N93p68hC6HrnonbJLC1X+FkUGrrD+5nvW57b3drt9ee29qa19qcr+v1xddMhb16X5VjIScZpkpZFFYpYs1JYvU+njUkv2CvZTp5Z3MXyDY96Wza27jx79N8pTBWkRMoHA21CR/jQH1M4fq2HYsoqM3v2DdUu5TFsGERnXBem8LXljxfs2LWAub/4w5Kkpt/jcxnnfXrLWUtf5Fs+DZVIlOfX/bDMz8HklGXsddfRKwwp126X9IVNL/J2QOZgm3AJgc385j2OQKegVXzllLywSzeqmnCrFxLoraBD+Yvo7y2jhWVNeRHI5R7Li9ddiP1udG2+0l63v3m9khl/a9N/W9rLnGm6mjW41RqOxbQgUNjzGXnX/6YkglDiHsqU605+/W/is+/9HxTLlDt+5djVHhe5vgQX1vDgmdfJSduiQSW9dpgsMSTPi3vzmKdMVwxfR6H9Czjnlv/x2ED+vDU3E9ZcOez1HjZTeT0ebDp55t9H9v4XdmNvtZotAVroclV9Jk6kYLR/Yh7iojfXsdAZf13c3+j35Tzhqxb9Vc/bpnK2Urhq9QUg4YkwUeL0TWNKPsFOmc36svfpGtfkck4+zL9/o7VaAWpjHqso4hHwB85IpVx9NWPgFJqkzjBtvmqa5w322zE1lrb5qClv07/N/11tvYKPo0xm7x2e20/ncbyVW3uuLSn7P1N/1cp1ea4pN/L1/H64uugAAesi1VJjDKb3m0/70q38WMUKKtwjCI3lVeadCwuFmOSGKVwNnNtt1isDnACl6hxSTiGFh2QY3wINIHWoAyusSjl0OxofAV5gSGuLMaBaDJV8ViliiLY8C6jLbiBwtcOSQccG4TpN0aTl3RwrEs0rklq03pz28z7+uLHImwKO0ajrINWDsrqb+bEOWUxymyaXv55x29z3xM2CAIdNvDdAKwKcByfnC11qql0lVCFG4RpekaF546jXAiC1DXKRVkPpXy0NVgbAd2CwkcbF3AwKsCzAU2OpsXxyE04RKyiRSUJHINrLcZaHOUQTVpQliYnwDgBVqVamlvYxy96LKw2GHSqmnj4Q6NtuP1vkOy7Q1i4LbwHajRG+YRJfGz1NShsP4Vz21bVNfBUUx3dPUtxYzXdlaGbnySRYxmuLIGNsygZ50A/gtvSiLIOSQ2+m0QbjRc4oCy+DsAqHAICBb6KoI1LTmCAJIFWBGgSbpjil+cH5CUtDa5HQ0RRHIecwFDvBSTdgEjSIWeDAy0JQBH1FYG2qVEV8xWvQa3f20wLOH3UTdaDtl3qdbtIv5c2vZgOWA+bfd6kHvalr0Gp7x2bumZj8Ktrqbz/eXJbfBxrwIZ/nwkNGwIfjWEgiqXVTayxPh+tWEexCZj30Eso5RIoh4Rr0MYl6kNOkADl0+Qpksoh6itiQXjfanHDjl+jwntzQcIn4RiMsuT4Do2ui1WWSBC+z4RWdOvXl/JhQ0kqg1XJzV+HvvSxUGjjoYwDhPex8Pc+Kpx5vNmPpyuy2C933mxO6jFhpXNFoBSO0VhtMS4oG1ZD3FyHa9hZAcpoAqXwHYOjfFzf4NooDj7NTgDWI+44KAwl8YBmVxF3IT9hQCkaHINnXXTgYJwkYFDGBVzi+CjXhFMdNCgTdrzlJjXJmMWk2z5f9jzZ5L0o0EmMclFolBPHkJpipONA5HMOZOewzQLbdHC5ue83F0htHAjD1gWi6aD56woW22Ob2YH31xlQpo+lMWazP1dKhfNM2iFQF9uCBQwokwpGnU1//UU2scn3NgwEAgVoTOp0sMoSaFI3xrYcY/ECS6NnabaWpHZIuC4tSZdcDRBgMQSOQhkbVlnWLo2uJlA+DgajDEkH4i4U+g7WauJaY6whZsEhIJo6VwOVupkpQ+AGuMriGqd1rbnNvq8vcywsqFTymoK24zrfHOF5o9nksvN5x29L31vQRoPWeMbiKBuOUJgw6N30ZVLXHht2oDSrcA6Ri8b4GlcpCBIo5eGrsEEaaIPBkHQDNJZowsExDr42YFy00UQBlE9CGZJOgNKaSMIJ5yQRnmPa2nAfAwfHfMY170scC2U0SmmMcnGsQluLY91UA/Ob01mY3W8fzkszmXnK2qY63NIP/CIb29z3qVGNF3eYS++fWnIDeAYfrGKVMgyw4KIwShMAj6tk6slBqhiPAQyBCrCpkdRwyYzwuqloCR+t06OzCm0VngU/da1zjMUqH6PCInWBhrijiAaaqtIkBz0C47QlcMIiVwEGq8LA6qtfg8LRQcXGPYlqo/92JW0iWiAIr7PWpjpHVNtfw1Z9r2x4nUi4BuMaYsaG9xgnde9BUVNsmD42oAnLdsrhQ5NktHL4EIODolJZplsfCMIsJZs6x7WPVQEWTXYske7LUqQDoIBoYGlyw+/zkj6+NsR1+JjtZjkUVlu0Dgj7hRTa6M1/qltxLIyyWBWuJ5RZb7krnjKfQ1sn/HtL+wp/dyrVpgoLSIV/eYHy0cqEmRgbxymkgj4LucbQ4lgSLjiBIopHretQGBggwLWKuNVYZUno8FoSCTQal6S1uITXjKTrokyASzhirExAREMyULjWxbc+RhsS2hLxww5kbRyczDDwZ7z3L9iAUYGHQqFNAvBwjPfFn9wJbLPANggC5syZQ0tLC9ZacnNzGTNmDI7joJTC933mz59PfX09ANFolLFjxxKNZqUWfcmUZmstxhgqKipYtmwZsViMMWPG4LoujuNssr3NDcNv6edBEGR+l72tzY1Kf9620oF3EAS4rttm1HRr0ri3FBwbY6ivr+eTTz7BWsvIkSMpKipi1apVrFy5ktzcXEaPHp15/S/7Ol9X6rfYknTDIImyJtV4/uqMtgQ6CBuoqS7KsOJt651x4+ZJeF9WJBxDXtIQ5Bcx4qc/Jje/jFW33k7LisUY5YSPTY2A5o8dw+BjjqB56VKW3H0vTqIFHUCzq6nOKaZ4hx0YsusknNwoFfPnsOHlV4itr8L1DUqFDT6rAowOwv0NdLtVBzTaEOgAZR0CLI4OGydB6r125bO57d9p2JhvjwFFq8IGo0aD1WGj3AYoq1BbyC3WVuGaMG057BXWJDDEHU08mkcsMOQ1mXCUVgfh/CIsuX4cYywJHSFBDAdFJLC0uIocH/L9gGbXknRc8px8EhZqXEPUGtwgSdI1GK3IMWF2gm6nBS7DNo4Kj0Mq8yHQim/iMlQ2nV2hwo4mpQwWcMyWP+8vy2hNQ1MDJ9/iUtocdq65gcYojWcgqTUJJzx/NAbHBhicMHPEDx/va9AYvEDhWE3cCYNbx4QBSsK1RIN0p1hAnm+xONR7DkmlyUlaPJvEJaA2Ci2uR7emCC/vnaAhP+ywSY/SBtoPz3fjtF+CR2b0P5MWkPW7rnxepTpm8VHKDzuF2qtyujKggjbHTRHez4LUn/r88YZJAxyGfxKmBk+x4f5MUhECPKwyaBJoErjWReGHI/3aQRuPnEARsZaEgibXEGiLa8JK/eHoXgDGwzFhG1b5SaIqgYvDoqEK4/hMfVljVUCgkxit8Pz2uxYbHd4bsSqVNQImDJW65njtZgeyw+PVXvd9leoMsKnRW43BEBB2nWV356Ueb8FN/T02uwkcFZCXcGjOKcSMG4mJQeOHc4i0+GgDUcK5302exbUa10SoKMgl7jmUtvh4LY1AEnBpVBGS3Qso6NeDqOPSsrYOW1FDLNmMtgnibqoDL6lSqe3t9bcTvk9lVaYN+Fn38PbUXlMzt1lgW1dXx89+9jMWLFiAtZY+ffrw9NNP079/fwCqqqo46aSTWLhwIUop+vbty7PPPkvv3r03m0acbUsjsumfPfroo/z2t79l8ODBPP3005SXl7cJHDdOx934ddIjnOmR1bVr13Lvvfey6667svPOO7d5vc3tV1r2NrNft6mpieeee466ujpOOOGEzKjp5vZp4/e5ue1vLsU7/fWcOXM4+uijAbj//vvZbbfduOuuu7jqqqsYN24cjz/+OMXFxVsMUrd0/D/rGGQ/55se4H6V+eRf+DWyvkpfa4wKCDaXI7yV2w//6UxD3SgNShMWv9/o4k4499XXbtgDaT36H34ow877BTaIse7JZ2hZ8SnWanKtRxNQ2bc7I37zC8oOP4T1016l5aFHyGmOEwsUKprL0AvPYdBJP8IrykOh6BM0UfPqO7xz7m/IW/gpShmUCQCTWqRchSml7dSrmLq0p74OA3pryVSK7jp9l5/NKkPS8b9kQbAtC5RCW016XqK2AYHrp9LkN21OpSvJNjuWiFHkJzQ1XozYQVMZe+IJ1E3/iNnXXENuUxyrAsKVSy0JT+H5LonyXnQ7+vtoz6H6vv9CRQWeVdTkRPH3msSwQw+jrNdgmltaWDrzXZY++iTln64h5sdpiEJSgXF8ko5Pe0S2CotBpxrPhiBI4jsO6HD7NpUR0dUZCP8erCLIDBSEAZ510o3Ar0qF54xVKBywYfAcVmxX+MoJl5Kylohv8SxEAoekcmju14v8PXcjWV1J1UuvUNAcYJUmrn3qogWYgQMoHT2A4lgeLSvqqfl4NtGaCpJuwNpcQ2HCwbh5+GNGkTtwFNFEIxtmTcesWUlhiyHQhqQyeMpNrafbes20yuA7yXZ4/6TWy9XpC8+mAzAdWMxm69g2/0GB0mADg99O9y+gTacsqdF40JlKt+kknOHzNTu9F3YIK2sJtEtztAhd1A1jk5jG9TiJRhyj0STDPAQ/QtLJJVEYwc2NYuqa8JoacUgSKANao4IwOyARzccUdEcZharbQH6iHm01XgDVRX5YhVmFHS2BIswuaae/HaM0NjUKblGpDIiwLai3ctCko2R16xBeR8PZ7taGnfBJt73+3hRGOalU8tTUAodwxF6l96Rt+8ez4ZzuRk+Rl1TEVIzcKVPZ/rrLsU31vH3ET7BLP0Wlsz6cMLPHsxGaevRi56t/T2z4INb941Yq7nmAvKCFmtxSeh7xfQb99CjyhvTG6hjJqjoqnniGuf+4gfLV64j6Jpz2o8F3fPx2nO6SXqLPmCTG0fiOHwb82G1++9qaTNZtOse2sbGR2tpalFIsX76cOXPmMGDAAKy1fPLJJyxatIiGhgYAmpqa2gR2nxUwZf8+CII2I55KKYIgoL6+nsbGxjbPTwtS87iynw9hIJsdGBpjWL58OSeccAJz5szh/vvvxxhDEAQ4jrPJdmHLgVz6cfF4nAsuuIB77rmHk046abPvOTtATZelT2/784LejdOOgyCgoaEh8zulFNFolPz8fHJycjYJ8rcUOGenK6cfl53GnH1M0z/7pge12b6+m4YJU6BQYQ83EZSNYZXF6vZqGCi0jaJTvbvGBuhUn+XmRp4spOZVOphoAXlHH86QS89DFXfH1LWQIBz9NU6EBlz8gQOYePEZdDv0O/hODLSLsZZ615BwPQon78DgU47Bz41Q+foMgupGeuw1ieJ99mX0T5ex8OJf4waWcPaQhsBFmRhWhxff9nj/yjpoE44sK+WlgjKNNZufZ9NVWcA66cUC2mF7WmGNTqXpGazWYeCjtjAimmrQBVrhG43v5GCHDmXsBedTtMN4Gi00RF1iLS1YG6AJ18NtcTWNXh4jfn46g3/1U/zmWl5+6zW8NSuJOx6Fh36Hsdf8kUhZb0yLIcdVlB++O30mT+CT039LrKKCJqNIeAqjNVa3V56eTQU3OqxyqsOGqyV9Teg6jcnPo4FwzqqLQyqzyjoYHQ9Hy9qBCtIp3OHctPQ8snQ6n2MN0SC9LxqrPVpyYgw/9RQG/vJkaqa/xzvvvIPTGKfZdWiKafod/X1GnPtLIgOKw/TXxhiV77/HrEsuIfLxxwQqQX1ePmNPPYOeZ55M0L0M1/dJLlnM3D/9lcbHnsLShE0Vl1HWQVsvNUpvwgag9j/7jX1RVoEfARtJNebTdQTS2Tld7XzK5HymRpg8bOBhTdjD1T7Xb8C4KOsCBqUirUFuqsGubGpgChtOktFQn1NA+X77MuLY71M8dBDaBNTMX8DCux6k4eV3yAlqscbQVFhKn+N+SK+j9iJWWkjj6g2suOtB1j3+NIWNLYCl2XPJm7oLo04+jtIRIwh8w/qZH7LohtsJ5szF2CQojQmHVnFsFG0BHW+nzlmFtjG0DXOMtHVTnUSprJIuFNRCunM5/CrzM5tqeyqFba/pc9bBEg07ALBYkhjrYpSLxd90Ko2CuA7bvlHfpcGL4UyYwM6/PY9k//44q9dgVQzQJJTFI1yzWOPQ4OUy5GenUHLYIWjXkujVjaQ2NDmQc/BejPvzJbglucSbmjC+Q3TQYAadeSKuY1n96yso8APqPfDd8P23Zx2HsHWlwqlepIqxbcOO2exYplOP2ELrzubk5NDc3Mzbb7/Nd77zHQDef/996uvrM7/LZowhkUiwatUqKioqiEQilJWV0bt3bzzPQylFIpGguroarTX5+fmsWLEC3/fp379/Jm04TSlFY2MjDQ0NGGPIz88nPz8/E6SuWLGC9evXk5+fT79+/cjLy8sEyMuWLWP+/Pn4vk9tbS1VVVWUlpZijKGxsZHVq1dTXV1NTk4OPXr0oKysLBPYpYPfNN/3Wbt2Le+//z5NTU00NTWxfv16SktL8X2furo6PM8jFouxbNkyXNelf//+RCIRfN9n1apVbNiwgSAIKCsro0+fPkSj0TajvU1NTaxYsYKmpib69u3bJlh1HAdjDEcddRS77bYbeXl55ObmYq2lurqaeDxOfn4+juOwfPlyGhoa6NGjB7169dqk8FRVVRWrVq1Ca03//v1xXZfa2lo8z6OkpATX/fasLFVbW5vpoGlvigCrHKx10L4PNQlUsyaqou2W7JhOO1ZGkSlU4hu88NXDz1y17btURhEd3J+hl5xH2SGHQG4BOqlR1uC7NjXK4lFyyH6MOO9MCsaOw/gurqtwfEtu0mAcIFD0HDEaU1VHw5vv8P4Zv0Y3xhlz/RX0O+Youo8Zw6LcKEGjD0ahfAeViJBs9HC120693eHIS4AKR+AU1FfW0+isJqkjqSZl12oYZMv+u9XVDUQaYu127igd9kZbpdFYTJDEbc7BNR5Yf5NOAaMUgTY4aOpyPMxOk9jx4osp2H5nfO0AUSKBQ8y3tLiGAEXUaBzfo/TQfRnw4x/iRwrQdXE84+BrRVBYzNifnIhb2oPqZ9/m42v+Sd6owYz/7YX02mcq6/faicb7/4djwx561RRBNea0y0cajihr0B4YH1dFCHBpVgEVbkWqgdD12XQQV18JcYtvwgDP4IaBwybzQrdOkEoLBIVSGmvTo8FhcSbHGDwDgXapi3g05+Uz+Ngj6Xfyj0nEirA6j8BYlIKkVkTGjGTMBWfj9OzB+vffZ+2C+QzdZ39K99mZsbW/YvZpZ5HfDPrQveh79mmogiLiyxdicwqIjhzKdpf+mtfnLSA2fzaO9cEYSBr8eDhXO3DCkWXHeu3y/gF8HBrr4zSvWoNxNdoawqKB7dchta2E00cMvorimgCnvhrTonGshxtX7Xb9DrMmHIxOEiQ04QQGP5PVrW1qXrVSBI4ioS19jjqCHS67DKcwh4QyaKXpOXIkJTtPYcYvLiT+/JP4Hgw4/USGnX8ebkxBQpE/1KF0whhmOdBy5/+wGHKn7MSEf1+H7d8dxyiiKAaMH03BmAm8fcqpGPVJKvfJg4RLslFjo254T2uXQ6DwlYey4UhmnCQVK9cQeBG0VputT9WZhdMeNK5NAookDpoAN14LzS7Kz2mX1wmLRLphhn9gsAQ4LR6RhIeyCdI9A5n4ToWFAa2naSospvt3D2Xs2WcQGzoCcPFtJJwXi6bFDXBSNeWaHZeC/fdgwEk/JOHlkBP4YdYZAUFuPoOOPAJbVkrNzA9449e/Rdcm2OHXl1By2P+3d57hcVRnw77PmZkt6pIlW3LBveOGK2BMNSSEBAhO6AmdQF5CCzWYgEMLEHoLLYQWagyBUBMg2FQX3Cuyjbsty7Kstrszc57vx+yuJVsmvF8Ett/MfV2yVzuzM7Mzj845Tz+A9kcezKp7HoFVq7B8hfIUNLTdHI4SFHZwL4zG0hrj2mxaU4trNfz7z/+H2LZNaWnpf+QI+861DaUUgwcPZubMmXz88cc0NTVh2zZTp05Fa83gwYOZNm1aC6/h6tWrufbaa3n77bdpbGwEID8/n2OOOYZrrrmGDh06sGDBAk4//XTy8vIYP348jz76KIlEguuvv36Ha9iyZQuXX345U6dOpbi4mDvvvJPhw4dTXV3NzTffzMsvv0xtbS2RSISRI0dy3XXXMWLECL744gvOP/986urqUEpx+eWXM2LECB577DGWLFnCtddey4wZM0gmk1iWRUVFBb/85S85/fTTiUQiO9yHuro6fvGLX7Bw4UIAJk+ezOeff87jjz/OkiVL+N3vfkfPnj3p3r07f/nLX4hEIvzpT39i77335vrrr+e1117Lel/z8vI44ogjuOGGG+jUqRMAixYt4je/+Q1Tp04lmUzSo0cPDjvssKyBIeOxnTx5Mg888AB9+vThmWeeQWvNr371K2bOnMlZZ53FnDlzeOutt0gkEpSWlnLJJZdw9tlnE4lEMMbw1ltvMWnSJJYsWYJSiv32249x48bx5JNP0qtXL55++ulsLvV/AxnPetuTUSWDsGBbaZZO+Zzqz6YSc93Ae9lGZ0naEiyglI9WHuqrVcQIqvcplcmNMoHFWVkYpYn17UHJ0Yfgbmlg3Ssf0W3CEQhBPqOdtqpW/OBg8gf3omrmfEwTlB6yD2ghagSVMlgYFj/xHMve+QeOlyK+pZr68nbEOuShvQR1y1eRcl0c46PFIpIUFjz9Oqn8PJRn2i7lTBQp26AwuKJof9CB9PjRXvhotGqu0u95ZKM8UGyY+yUbJ09uk2+TidQySqXzGoMCPtbK9YGnNV0xWJHOCUKCishWkLc24Kyz6X7hWdChA67nE1U2tq/JTQVhvYgGbeGjsXr3pd81F+G1LwGCc4l2MGLj5kexy4tQCr6c/CJ6yrt8Nb+EHsedTMH+FejOJTTYQU9kyxMWvfgubnFhG9yBILTbVwqRCFr5aPHwVJTi/cbS87huoPdcuWmOSJB/VrNqDQufepaonwI0iBMU52mjlbOxXLbsswpHqUDJJajCHPMFTwLvh6BJ6Qhq0N6M/OW5dDnyELziYnylsd3An5zUQShyzsBh2BXlNKzcwPRzr0J99SX1p81mzO23kDdsCF5ZGe5GQ+8JxyBl7Wj4cAYfn3060U49GPvEA0R7daPsB4dTvWQhDj6OUix7832aZs3F8gPDihKN7bdRVrUCV/k4A4Yw+IzTghkgU6C9Wc2DPQmlAv+71jb1q6uY8+dncQQcLygy1xYYHYSPivKIbq7FykSuZYxZaZ+cpwTEIlJYwoCTTkIXllL30RfMeOQxnMIChl9yPk73TnQ783i+mPJPIh070O3nJ+LmOax54S0Wv/oBQ84+kcKDB9Hn9NOZ9fpH1CdqGfjz44h07cqmWbOYfc+jtKvowpBfn0fxiOH0PuwQ5k1PK7bKYvW/Pmdl5SrqIzZRV9pEsRUUrqWwJRWkRVR0ZcQvzsOKRNNz+J4lN8HTyqRDpSO1xNBUU8vsx14mpzHRJuex0558T0tQt8Q2RGvriSc97HT4c1BRHRxRaKNQ+BilKP3h9xl1y28xdg71lWsp6NKZwKASVOfW+HhWYPq0u/dm6GUXI0U56KYktkRQvkPMCEWpKOarjdT+6yPWv/wiuVOmkuML6/72Bu2+dwDkxEjk2thpLbn24y+YXpVI10BpC4I1pqfBlhSWr0m178qIS/uinW8/OzvjNNtjPLYQLKoGDx7M8uXLWbx4MatXryYejzNv3jxyc3MZPnw406dPz3oWU6kUt912G8899xxlZWUcfPDBbN68mZkzZ/L4448zdOhQzjrrLJLJJMuXL8d1XebOnUsqlSIej9OrVy8WLFiQ9VI0NDRw55138uyzzxKPx7nyyisZNmwYrusyadIkHn30UfLy8th3331ZvXo1//znP1m3bh1//etf8X0fz/Oyx3JdF8/zqKmp4corr2TKlCn07duXvn37snr1ambPns21115Lr169GD9+fIv7kAlzdt3AopbxCGd+tm7dSmVlJStWrMgW12rfvj2dOnXigQce4E9/+hMFBQUccMABNDY2Mm3aNJ555hl69+7NVVddRW1tLb/+9a955513yM3NZfTo0dTV1fHwww/T1NRETk5O9rw1NTUsXbqUeDyeVXZXr17NkiVLuPXWWykoKGDUqFF88cUXfPXVV9xyyy0cfPDB9O/fn1mzZnHBBRewcuVKOnXqxKBBg1iyZAkfffQR9fX1OI6zx4W9/KcUFBRQUFDwLR3dAJok4LhNVC5bBq+8heW7reYw/n+hwFHBuZTy0SLYJqjYKBqM+NjKRynBaBtXCEKBEoZNb33KgsceJWrl0/2nh6GUExTQUWArhbd2HfPveYR5T7zM6F9dAIfsg28HFnXHwJZokrz6GvTSKpIqRo9Tz6TdhWdS2GMvNn8xl6UP/Ylog4dtBaGI4nl4736CVsl0Ll7bDO4xX3CjQXl923eId+tFWXkHFNE9slNCs5S29BuBcl67qQb/b29iNQ8VVtt98Bv+rgzEfUXSMqCDXNhMNWQrPQaYtJNJi4Dy8dLVJr1IjLxR++PEy1j8/EtEOnWj+0GHIFZgXGiKQsS1cD0Lr6AdAy/5H+L9+rB26kwqhg/Aj6bQosl3bTbUVVG/aAGxvv0pHzOMJVM+xOozkJyO7dG1dTQtWoJFINMpbTBTPt4W6vb/+d23/e6DVkTdCKI9jPKwJEqqfRntKzqAbpsCb7sHPvXTp2NNfg/HNIBIEPIYBDu2yRmUEqyOKaK+gzYa19Ik7MBLa5nAw+Jpi5QVo/upJ7HX8T8m8dVaalZvoHDIYLQKQjGTjibqeuRuaQS3EaQRLakgYtoHg4vUJVDJFKY4l3Z9B+MYmzWffYhavQZv4xbqFy2kpEsX2g3dh42RCEYSaN8gn80mmpaDb2NBFQEiCU2Hq0rByUl7w/dMpTY9CqBEMMpi02wh+uqbWK5gp0OH2wLNtmehIG1IC+QlCEUOwth9rYl5Cju/Ha52aFzzFWseuJuGN/+GkihrBnej19mnE68oJ2ZHyB06klhFF0ztRr784wN4H81khVXHqDH3YPcdAH16oBfMZdPcxejIa2z6y3P4b77D6vYV9DzxSOJFA4iWFGJZDkobfFxin8/FTJuNFQXttV2ZOaU0jnGDYml770PZNVdhlZSx58pNxpweKKBG+WzZtInkm+8R31rbNucxgawYO2iDZ4mQSOcmN2mbPN/CU4aU5QcpEAIpJUF7KSdOcuNm5j/1CLVNCQ763ZVBDQttEJ0ixzMklUWioIAhF/+K3AH9mD35ZUoGDSe3196gIwg+icZall99FSoTjaocklFNv/49sRxFYtU6pKoG2/ikHEEv+JLU4hXNwrX/UzSOr0hGPLQkyU1G8PsOoeDm3xAtLG6jc3y77JL40K5du7LXXnsxe/ZsZs2aRVFREevWraN79+707NmzhbfW8zwqKio45phjOOmkkzjssMOoqanhpJNO4rPPPmPevHkt8kg9z2PAgAFcfvnlJJNJRowYwYIFC7K5qY899hgPPPAAjuNw3XXXceKJJ2LbNrNnz+aFF17Asiyuvvpqzj77bNauXcvxxx/PggULeOmll7jgggt49NFHmTBhAslkkjvvvJMjjjiCtWvXsnDhQmKxGJdffjk/+tGPSCaT3HzzzWzevBnP2zHfRilFQUEBf/7znzn22GP54osvOOGEE5g0aRIFBQXMmTMn+32OOOIITj/9dBKJBBUVFRQVFXH00Udz7LHHcvTRR1NXV8cZZ5zB22+/zfz583Fdl88++4wpU6bgOA4TJ07krLPOIpFIcMkll/DCCy98o+ckIhQXF/PMM8/Qt29fXnvtNc4++2yqq6v58ssv6devH88//zwrV66koqKCJ598kuHDh7N06VJOPvlkFi9e3AbSsmfxrbZrQtLFIIJMW1GBHdOCbEGVtkAhOMagCVowaEkPmWJwfGGro0nqPHK9CPUaxDIUJ10aP53OR18sILdpC7lj9w8q2ArkepAQg59sZPZ9D5No9HB8jU6HhokKego6KKK+wvY1Sls05trkHTCEgu7lKKOo29JIyopi4+CrFE2OwVMGy2hyPNrUg2HSVZcdo4KQZAEwQQsQ1B5VjHQHFaOZoSkwWgjW9gra1x3ga35vsoOx2DYK2+htQanpoi2krd4oD42HIwpjHIpTKZLTP2bW66+y8p23GX7rrYH3RgL5iHpCzNNsjkfpctIPKT9uPFs++Yz5DzxPxz/eha9jaJIYq5H2tcK8O56id69RVJx8IhUHHYxfXIqyNbPve4otU+aT7ylQPinZpnT/p989/TWxRGEbguIt6cDctO05+H9PEp6dIOkCakoEOy1DIOh0DnpbZSunrMBDohDirmAZRV3UZmtUiHs++UkfWzy0Vmi3mup33uSLu5+g7KgjKB84gKZ0GIFRYOOz+fP3Wfvxvyg55DCG3/N76pauoOMhhyJ1hq+e/Cu5VTWk+pahSgsQX6jbsAnLCHg+jdWbKVGKgvIOKMfOet+t4BTfEpL2UEFr8aOKNrrZ3xHbis9I9h077Xm3RL7dP40guTRoW6fS5XEERPlsWb+Sd046kbz8PArWbgDLJRnJIaekBDwhWbkCkklKu+2FikZIVtWTXLeeQuORrFxBqqkRq9DB6dUBa/pnVN3zJJv0cyhLsPoNoOv3jyK/c1dk7SY2fPw5tuehjQFLI15QTTnqqyA9og2+aiAzwb31MvnEzcRnz/PYZiKN0hVGjEJbCkQR8yHHbZs/QF8HVYu1gO1bWOncGaPA0yCej2OEmBJs8fF0UEci4qeo//hDPv7sI6qWr6Ld8ceglI/je+R4Hlu1IiU2vsqj4pgf0+H4Q6mZ+Rmrb3+Qiof+gDhBBe6GiBBL+UQ9wXY9mmyHTfEcOhx5KBWn/BC3oY4FT07Gr02CREEgYWliXrodURug8XFEEUkaIhLM5YmM00C1Xmdld2OXKLZ5eXmMHDmSGTNmMGXKFEpKSkgmkwwZMoTCwpYhYRllccOGDcybN4/77ruPjz/+OKvQbp+Pq7Xm5z//ORMmTMjmmhpjMMawZs0a7rnnHhKJBOPHj+dnP/tZNvdz5syZbNmyhXbt2rHffvvR2NhIfn4+o0ePZsGCBXz66adccMEFLTxx+fn5FBYW0tjYSFlZGVVVVVxxxRU899xzjBo1iu9973sMHz6coqKiVu+DbdsUFRXhOE6QfB6NUlxc3KJAVDwe56KLLuKggw4Cgj/uCy+8kKqqKubPn89DDz3EJ598wowZM1BK4bouxhjmz59PU1MTnTt35sc//jF5eXkUFBRw3HHH8be//e0bP6vRo0czaNAgtNYMHTqUvLw8tm7dSiqVoqmpifnz5yMijBgxgpEjR+I4DgMGDODwww9n6dKl3/g8Id8ElQ3FiyjB8sFJWeSkHKKSwrWa/u0RvtFZRGH5EXzl4Kug6AHaRSkPzwc1cgjdJ5yI5eVRHFdYqXoannkRb9YMOjZ6OKTwtY8huEbtGYxlUGLI3VRDe+NQZ1mg/bRvR0jahjhCxLPS5xXykj5f3fUIC556hb1//nM6/eRQiu+ZyOennoVevYwC12D5QpNSRI2NqASmLWLZBCxxiLgRbF+RsBw8LETAI1gw7AmD+zdBY4gaD6sNvo+vhSbb4PgaS9L5rjoIW3dMoJSIdnCjMVK2ne7xqoNVQ6qK5fc/BK6HzgVf+yDBMVNaiKLxlE18xFAG/OocvM1JFl5/G4VJCyshaMvBNoZ6R8hzLXJzCsjVMWxlk8yJBIXVLKGwrCNbokUo2ZrO7bUCI05bhc4qQ8q2MFrjaR9fm3RucVtVCv7vQQERLzCOeZps38fCJpuEpUnaQr3tYYlHftJl9QOPsrS+iViNS+H4A9G4GB2EL9smUMLZtJkvH32VkUPH0f6A/Wl3yH5YJsKqzz5nwb8+pKPvkcy38eMO4hus2iZsUXieTyqRBCAaj6McC/NfFon0fwUlQsqygvrqErSUymlqxHHrydsQGNDqYjmUHTWe9gfsh59MsuK1dzDJBPGSEoyl8RMudmMSX3m4yQZ00sPJj5JTmE8TPkWej+03sKxrGYc+eBP5Q/elyU3xxa33senzGdgDgiBVg4unNZZnYfuqTQsA/V8iEwOiMmEyWWU9aPWVstuqcGZgpHOMBrHw0tOTFkPcA19pTLcu0LUC19dB2onfRGLuYvzFSynyXKJGYfuCaCfod6z8YB2ho5jhQ+n/64tI1SeYddPdxFdXY6X7bUdSGseNYhsXTxk8pWnSNt2//30G3/gb7JJcVj7yF2pfep2IuHhKiHoWSQtSlmmz/HSURyptf9K+ocExbLU9BH/HKKXdlF2i2GqtGTlyJI8++ihTp07NFmcaPXr0Dv1lRYTJkydz4403smLFClKpFLm5ubiui4i0KMiUyW3s1asXWusdKgWnUqns6+nTp/PFF1+w3377YVkWVVVV+L5PbW0tp512Wlbhra6uRkSoqqoilUq12oKnrKyMq6++mkmTJrF8+XLeeecd3n33XeLxOMOGDeP3v/89o0aNanEPmseQZ5TYTLXh5lWYc3Nz6dSpU4uCL2+++SbXX389S5cuJZVKtej1m9lv06ZNLQpjZc5VVlaWLRr1TSgsLMSyLCzLyuYJ+75Ppu9ubW0tIkJZWVm2B6/WmvLy8m90/JD/BRIotRgQS+FZFnkjB5Oo/xGW7xJto4VW0CnB4CsHEYuob9j0+SfYa1fiKY3Vowe9zzoFEykiYRmiTbXMmPsFdQs+pzDh4ePh6SCEGaPwtUVSCRY+joGYD/WOwrfTjXRMoMCgwBhFTW4UPxal0POpXzAH39gsbmxi9PdGUDCkN/ljhlD3wjLivuBFIuQfeShuPErcp+0GdzSWhpirsC2booEDwQMHg7L2wFjk7UlPUAZIWsEiqy3ITQkxP7Cr19tg8In6PkoZ3KhFTTTO4MsvJmfkPvg6gmU0qnIZ8679DdHNdek2KhpMUHzHpBvZN1maaLsyRl5yAdGu3Zl57zOsqt5EfO9+GCdobF/XsT2qsgMJrRj5u/8hZ++OrH36WWbedQeFHXsy6g830f2ko/FWfMW6O/6Ar3wsEyxe2qqBk23A8dKeS4I8dUuC90K99n+JpHMxBUQJroYGx6Jk9Ejye/cA16Eh5iMNW/Be+wC+qkI5glEaz/FIWgpfB52VHQM+GgYPY/TvrsEuLmDNs6+yYtEMek74Pl1GDiH+218z/YIL8W0ryP9Oj7Wa9FytVNprmllihw90jyIdUqoKCnGLCnFLk+Aq/HKLnPVriHqGBJqUU0jBD49k5PUTsQoLWfDkX1n7zvsUYjCOHcQZeYJlDEp8tDFB5XNloWwbbQQtQqPlEXEUqfVV1C1eRm6vruw94fvM/uIjFtZ/mA4oF/x0j1mVjWbZ1Tdq9yOjT2X/6kThpVOgBI0lbTfz20awjEXKsmmwDVo88v2gtc7mWIw+551G7zNPQ0kMZRTJzev46IRTsOYtwU2XtYolLTwcPEsHbYA8jVuYy4Bfn0WkRxfWfTKDeK++5PYeQLS0I/gW+cOGUfrjH1P17utEa5M0ODHKfno0wyZejiou5as/P8fyG2+jrKaGmkgKXwu5no1ke/i2VbSaImEFPWwdH5J20OYRr20q3X8X7BLFVkTYZ599yM/PZ+HChSilsvm1lZWV2f2UUqxYsYJrrrmGlStXcuihh3LiiSfSv39/rr76at57770dQiosy8oqytuf07IsTjzxRFavXs2//vUv7rzzToYNG0Z+fn621U08Hue4444jPz8fy7JwXRelFB07dtyhsm9GibQsiwkTJjB69GimTJnChx9+yMyZM1m2bBmffPIJN954I8899xy5ublfe09aCw9xHIdoNJrNwd24cSMTJ05k/vz5jBs3jpNPPplBgwZx++238/LLL2eV+8LCQpRSNDY2kkqlsserr6/Hdd0dKjS3RnPlu7XrtSwrm6tbVVWF53lZb/OGDRu+sfIc8r9EAoWkyXbofupP6HbKsRhlE2mzSpwGo5rwsLGxsBoSvHXuefD6anJ9gUUr+PKhP5N0YhhLEUslSC35MgjXIagyqSHIr9RC0rYQLCzjB149y6T7TwZ+T20EywStM0w8xpBLzyf3iHFsfW8KX9x+F7kJH8HH8m20RLGjOTjKolEbaorzGHvT1eR174ZDDm01uAehah4RP4iHNUpjtB0YF9rkDLsYHVi9TU4+ibKuQY7tf4yQxCfl27jKZqvjYSuXSG0t8YZ6UinBiVkU9O1NhwNG49kxlIDbLoZvWyRsC8RQ1ATxdC0i20DcE5JaEe/djaKRo/B0jH7HHUXfH+6PyYujCmP4KA74w+/Z9PLbLHvnDfKG9kHqG1n7xPMUL/mS5NK1rH73Q7r96kzKDj+AFQ/dR7ShHlAkS8oxdlv97XhB4SyJ4CoPrX2slENhQbv/EyHI35g2MrL5OlhoKQlCfhuiFn3OOJa9TjwWJI6vXMxXq/nk0wVElzcSM6kgfFkHHn7ExvGDNieNUYtuEyYQ7deNdTNmMnfitRRUVTFn+gxK//IE7Q7Zn5z9h9O0dDFWg8HkalR+BBeD0YpILAJKkWxsQlwv3eW77b5rq/wXicy3ScYU4doWnc85leGnncqW1L+I6jijt/Zm2v9cRHLuAtx4PkXH/ZhR11xJpKyIymdeYOkNt1NQV4soHz/lIoCDhWhD1LZB2fi2TUpZmKSglE2t9kjZcfLWbGbhGb+iIa8T/e+4hq4/PozBV17Ih3fMR3nV6VDXINxe9sy06e+EbbdFst7blFZYuXHyRozCqm+bar2+ZXCV4BuHhB30by2obyA1ax4xN0mOZ7DrUyRq6tB+AuVBqmELGA+FImXZiLaI6CCs3MPG1RZgYTsOJd07oxE6jxpGx/0G4vlCMpJLg1IUH38Yhft2Z+2MD/EaG+h87I/pf+NVePkR5v3xzyy58z7ab9lKo2Uw2sLyDEkl6C6dsDv2wLSR8Gi8wFiMxnY9rAi069ADS0X/7Wd3F3aZYtu5c2d69uzJtGnTUErRuXNnevXq1UKxBVixYgXr1q0jFotxySWXcNBBB7F+/Xo2b96cLcDUHKUUtm23WrCoY8eOXHPNNVRWVjJz5kzee+89/v73v3PCCScwYMAA4vE4IsKBBx7IYYcdRmNjIzfddBMbNmygZ8+eRKPRFv1qM22EZs6cyZ/+9CcaGxu57LLLOP7446mrq2PixIk88sgjrFq1Kutpbo2MAtna99FaZ73YlmWxbt06Vq5cSSQS4fzzz+fYY49l8+bNVFVVtejd279/fyKRCFVVVXz22WccffTRpFIp3nvvvWxhrW/ynHZW3VcpRSwWY/jw4bz33ntMnz6dGTNmMGLECBYtWsRbb731LVUG/u9FFCSBmALHDyoDWn4MTwvY0mbhlEosLL8AZStcBZatUXYMbSyMSuDNnsWqmXPQWEGurzYofPLEwjYWrh2EVeEbjA2eVkQ9i5hv0RjxabKCGdzygjWh8hWWBBbCJt/QENd0Hj6aotK9WLdkBVtWLqfXGWeQKimFTZvZumgFMR9StsZVDsrOwSIvqMvTJqFcCkvSvSM1NFlB70jHp2Uu6p5M+jb1OuaHdB0zuo0quAqiDNq3EaUwlodONrD8lTeovP0PFPqQ2+iz4qEnWPzmu0SMJuYr/NpN5GytRVIecSPUx4RE3A1CTz3I9xSeUiQcjTEgKZdYWQGYfMSysTwLL2KItOuEKSpBYrGg3Y528HSUJiuKiIOlLCKuxnccPK1o5wlbchwG3Xs7Jf36tcUdAOUiyqDEQZQXLHjcCMnysqDAmvq/EMSejlYiyOtPWRaWsgHBMnab+zGN8tIh7UJOSkguXMuaTxdCugGZWr0Ok3KpixgcPBwvguPZOGIhvsYxGqOFVERR0KUz2rg0rV1BQ9NGSkwS/6sq/C0eukcuTkU5/kezkKpa3IoKcjqVUWUpdMQht7QMRKhdvwGTdLNDjWdpjNbfjkdeSeBl1EHv8j2ZFqm1zTBodKZoVBvfw0x7MS2BV1RQqKIyYp26YNe1w9G5RPL3QukcdCSfjsceyeAbLsfKKWTJQ89QecftlG5aj0LToIXa6s1UGMGOxNE5UbZaPk5RPpbjYDUJam0dqWiE5N69iJV0hPlfEFmzHtWQYMWUKez1w/Hk9e6HrqjAXb0F5Qua4Np8LVjb5cL+/5JuO5o2Hutmh0yr+DtxpOy2bAuUABSig7SgvI4dOPSpR8Buq7Vm+kTGAq0QcalfVMkHx5xIXu06Yn6KynseZNafniDqG0SlcG2f4g0NRExQbKrWFhoiKbRJYvsKx7dJWArleWz+fB41W7wgGkUpjGVTPKgf8VgedcvX0jBrIXm1Pt6+I+g96XJMh3JWTv2E5R9/Sn6/XiRUD2LJFNb8RUSTSbbYhi4n/4S9L76sbWqsCChfMLYV1CVwXXzbR5k4bmHerlEY/z/4zvvYZpSdvLw8hg8fzowZM7KVkouKinbwErZr146cnBxqamr4/e9/z8yZM3n33XezlY4bGxuzobGtna/5/5FIhLy8PMaNG8eRRx7JSy+9xL333svBBx/MiBEjGDFiBFOmTOGiiy7ilFNOYfXq1Tz99NMopfje976H1pqcnBwikQj19fX85S9/YfXq1YwcOZJ//vOfVFZWsnTpUo499lgaGhp499130VozbNiwHRTJ5t7e/Px8AKZOncof/vAHjjnmmOx9yIQmZ75HQUFBNs/1rrvuYvny5UyZMoXPP/8825/X931GjRrF4MGDmT59OldeeSXz589n/fr1vPDCCy3KaTfva7v97xnv6/b7NP8OEyZM4Nlnn2X16tWceuqp9OvXj8rKStatW5f93H9bVeRvCwU4AFagv9kC2AqH7CzWZifylYBS2ICJBj1dPaUxVgTtK+x0iKBG4RudHlQNRqewfRuXCChBGQvbd/BF4xFF+5DQgmdbKM/FNy5GKeqdKDk6ScTAuqf+SvfDfkhuv/7se+/deMYnGonhN7kse+ZFvLnzSDmC8QXbT2H7QdsNlGrTe4AolIZIusWA0ntubu0OV52uOeOUtsMpK2mjsxgQg+CgTFBYwzIKa/pcIr7GGB9HktS/9wG+Bk+gCcHVHkUpRaOtSSqFp3PxlMbDp0lpaqIxCurqSc2awdQJP8azY8SMS9wXkoOGMvLWW9CeYtpFl8PHU2iwILVyE/HuJXT5xWlMr6+ic1kXOh16GIom1i2ciUq5RCWKUQq7+17EB7WRYiuSyYQPwrcQMBpH6z1dL2mJGDAu7YcMot8Dd2AbgzbBQtrobQpFG5yIGPfim0VAioifYvk9D9Dw0ENoUeniZ4ao62IrHyHIOcMIyoBngWcLMV/homlavwbP2LTrPYzcLn2pX7qEwn36YRfloRINJNevp66xlprKuZQM6kWnsYezpueLRDp2I7ffAIybYPO0aTiuG4TX21Ha/885xAYPxvIzVX0DD29bPHAFiNHEO3dBEUlbAvdQg3HzKFul0OKSVLCqqB0V9cl0dEzboNNV31PaQlSSsvoGmuygyn31g4+z/tXXmTd0E7kpm6I5BbDkK3IOPIBBN0zEKSli3vN/Y+GTf6HEjuFWdMS4Cdy6LWxeXoldn4DiDjj9BlKzZhXlg3qhcixk/Qa2fLUEv7yUg++5n1iv3sy98w6W3fUgMWXTu1c3lAiuB36TR1J5iLYRFcWL2DREIOJZbTaFaREsX5FyItTl5SL4iKRQyiFd8mzPQkFw3QptQQ4KOxqHWE6bFs7MdJ4AhY9BFedjtEFLsD6Obd2CU7clbdY3iAoii3yCOhJGoqBsIIHQhKvBQkPDZhZefBH1EQfPipCTgkRxEYc+9zQ5w0ew5C/PUnv7H5BIPkPOOQ1nr3I8y6Hn6LH0fGJMUCxUG8yaVUydcCr+ooXEfI0Xy8UuLETaYFzI3MWMHUEj6TQlvUdJzHeq2EYiESKRSDYXc8yYMTz11FOICPvvv382PzOzj4jQt29fTjnlFB555BHef/99PvzwQwYMGMCECRN4+eWX+fLLL6mtrUUpRTQaxff9Fj1ajTFYlkU0Gs3miGa8nf/617+YP38+L7/8Mueeey433XQTF154IXPnzuW6665DKUVhYSHnnXceRxxxBCJChw4dGDFiBO+88w4vvPAC06ZN4x//+Ae/+93vmDhxItOnT+ezzz7LnmfcuHH8+te/3qGPbfN7csghh/DJJ58wZ84cFi9eTI8ePRCRrIe4ueLepUsXzj77bP7whz/w2WefMW3aNHr37s2JJ57ICy+8wFdffcWWLVsoKyvj5ptv5sILL8z2xC0uLubEE0/k1VdfpbGxsYXSGY1GW7TmsW17Bw+1iOA4Tovvsvfee3PPPfdw3XXXUVlZyfTp0xk/fjz5+fk8/vjj2f61e5R1cDcm4zHM3s/MJNh2DVwDg4sY8EnXaTDEPYN2DZZKASaT8BJcE0EFWFfZCB5KLKjbwoZpn2G7EVT9RnyrHqXTocdaMKJJrlxK9aefk5i/iKjrosSgjcH9cjmfnHch/S78Be3GDEFyYtR+WcWqv/yN5U89RzyZxNcaW1TgIRILX+vg3ijddvpDEK2LnT3ininDOyq1arttbVWHUyEqKMgSmFoUom200tjGBDluKpgo7bTc+spgIyixcXVQpCNqNDkpQ8RPIKRotAzFIuTUbEGmzSahHTZHUrRPGFzbAUliPJ/k0nlEvlwM+QXMfewphl9+KZ1+fASl48egbY2dk0/D7Hls+ONfKGn0gpxLVLN/24Bmq1KVXgqItU2G9kwJagUV5LfldelE/xOP37YSSm9rqy8qYoh/+FeMLE4blXzibpKIFxgQVPPxL51D2egojOVjGReRVNDL1EAsmWLlq6/S9cijKe7ejTF/upv1lUvYa/S+mLJc6v71Md6UmRQ0JFjz/GTK9x+HGjGA0W+8hOPkoNsVkVy4lKq3/kEEH09DSinyDzmIboePR/kOaJ9gYWy13Z+Vr0HrIH0g7bHK/rsHCVQmhDSouwoKRcmgIRzy0IPk1jfiRRSmTUNiAgtLQ+USVl17E7aXDMLSV64kuX4Ffr5PdKuCL2JUVRRy2EXnEWnflaQNPX94FD0PPQyFwdNC4/yFzPjZ2chnn9KwYh6pwcPof+3VbDrwQDofeTi2ilEzbRap5UtJaMPGufPoNngYvX95HlaXbkRsm71+eATGcqh9byr5q1bh5vp4yqbz2afT7sBxJJwgPaetEGVwPIWYCKa0EFVQDOIE8rSnuN7SqKywb7s/NoBltd1wIzsOY6BAE6xNxMakt1oCpJMRtFH4SjDaoCRoi5jbJJh6D2kKDO8iwdyYk/KIukJKQ8QIduNWnLp6pD5BpDGJ9lKYPhUUDeqHcZPggREFTjDeifEQS5HQgh/ReMYm1wlSJHQbr7Ez3z/doS9UbFujoKCAxx9/nKamJnr06IFSiiOPPJK3334bIFvw6dBDD+Xtt98mGo1SVlZGNBrl2muv5ZBDDmHevHmUl5dz4IEHEo/HOeecc3Ach9zcXAYMGMCrr76KiDBgwICsUqu1ZsKECYwcOZJYLJatUDxs2DD+9re/0djYSFFREZ7nMXLkSF555RU++eQTli5dSk5ODvvuuy+DBg3CcYIcrPz8fO6//37effddqqur6d+/P6WlpRxzzDGMHDmSTz/9lBUrVmBZFgMHDmTUqFGtVkVuHgpy3nnn0bdvXxYtWkRZWRn77rsvSikGDhxIJBKhffv2WUXdtm0uvvhixowZw8yZM2nfvj0HHnggRUVFnHHGGdl8ZaUU48aN49VXX+W9996jrq6O/fbbj379+nHKKafg+z4DBgzAGMNpp53G+PHjyc3NJScnB601d955J3V1dS2KQFVUVPDSSy/heR69evXCGMOyZcsoLS3lvvvuyxar6tmzJ7feems2XDlUatuGVu9im9/adHSA1hgdLNGU76GUR8R4+JbC1S3DDTOXYIlLRAwxX6if/inTf/wT8rwotpsg6tuBlxeIGk3MN6y478+4Dz5FzEvR3k2iEBIWoC0SCz5h+v9Mp6C8HG3HaKquwmypIcdTRE0E4/tElIMojbEUCQ1x2j7/NZTctmKbN725VViLQhsbT9kYJdgY4l6S6n99THWiETV3PnmpJjxt8JSAERAhbjRNtiDV1VQ+8Re0Mpjq9aQci2giyarHnoIV6+h81FEU9elNQpJsmDOTdX98mpyFS0hahroI6aItbfw9/+07ezbB4k/jKgtt2fgi6IxBqa2rZkrQKs8lnZcPWEGZ0sBL00ooghaD2rqFxnVr8DZuwDEeRjzyfMGdNo1ZV/+WPpf+itx+nejbrwemIcL69z5m0W9/R8HGKhrtFJvee58lt9zFXheci9OhI5bxaZqzgLmTbsapXI4vPp7WiLZBWXjawtZWujWRzho12gKlJGtgVOhsmOmehqSjYEw69NagcSoq6NqhPVp8tLJQbeSNFgU+CtsIG6ZPY6FzF4Xp4jdGBw1ILYQ4Fr4YCvcZQMHQfnj4YBTRwnysvHzQQb52as1mbBWhePUqlvzhNnrdcgvRgQNo129vfCC5YAWL7vsjOXW1KFsx/8FHKemxNwWj92bvn50ShEAbn81TZjDvrntwcrdCrgARnKH70O6YH6KV3bL12H9IUhsiJkj1MVrjpvM+rdb+bPZAvqWlTzCEpTVcKwhEwxKI+K13ilUS9EnwLB/bCAVKqHn3ff5+3DJs3yO2dg1RMbi+QhsH21hEtIUoD0k08dmVV5GMtyO6dh0xHFi+iqlnXEB9PAdtLGwj+NrDKEhqIZpyKV6+GpJCg7KxPYs267HW8lbs9PfdHSXfQZxo85Dg7fM2myt4mdfb/59RUDNklLzsl2hWMXj791o7dvN9ml/f9u+1Fn67s/2aeyW/7lqah/tuXxU5s+/XFWzK3IvWimM1f505T+a+NX8Gza+jtfu0s+/cfHvGM/6HP/yBW2+9lVgsxjXXXMMPf/hDNm3axCWXXMKHH37I8ccfz+OPP5710odK7u6PmKA6lShwtSCmgXdOOxdefo24L9j+jos2IagKqcXH0x5JB5RRRDxNRt20hXSFU9K9TVXQgkMFXg6FQgyAjWsFLWhsX2GLxiB4lo9r+dn+tzHXobaoPftP/Tv5fXqhtPN/JIdxTyQI4RIMRmy08XG1YGFT+difWHn+hVi0EmqYbvkjEqEh4hMzSXJd2BSJkdI2eV6KqEnhWR4JS+ErmxzXotAz1NmQUg5RP4oWj6TdgPLtoIWQFZzfi+bixQpRaJzaWnJSKVzHY0vUoAVyVYx9/vEOpaNGfOd3bE9F0smSmRln+//b0GGLwefcD47jkB//k04NKQQLx7cxKugpvePFgWWEhnbFrCsuIMdNUbpuPXE3SdJWKFHUW3mk2negpHdXCnILSW5opPrLReRv2YRNE5tjPpZE0CaOtVdPCnr2xXEbqF40G696A45vcIzF+wen8BNxzrjiWfb6/uEEnbmD8L02jBtJ938WdHZsa772abPTfOtkJEYwQf9YMqNGEBxkodvsvikT/ICwcfrnfH7Ej8hLbAnOroLe1VMPMOQkLPrPjGL170O7MaPAtvEl8CYroxAURoFsrKLurTfIb2igLpqDM3o0XY86gnhFJ6q/WsvqV16BudPIc5sw2CR0Hn7n9nQ49geU7z0M3xfWz/2C9ZNfx6mqZtbQBraUeBz6dgHdHr6XrqedgO1pjA1t5+oPCjhmImvdbN/7tHdvTxKe74CMdPr4aNEoX4EybF6ykPcP/j6FNRt3tIIKQYQaFr720QQtCH1lk7Q1SoQoBnwPo8FXiohvYRkbz/ZxrSTKaGw/iq8UvuUT93xS6fxb2wNbDL4OWtKllEKUpn3SI2Fr6nSckt9ewcgrL0/n4YfAd+Sx3V4J3X5ba+81/7+5UpvJO/26c3zdeb/pfjvb9+uu899dy872/6ZFlpRSO61mvLPvur3iuv1+3+TaW9ueuY7DDjuMBx98kNWrV3PFFVdw1113UVtbS3V1NUVFRZxwwgnYth0qtHsIAqBUEP2WtlIaD3KSDrgxHBpQKrmDx8DXGqNstC/4lk/ECHkpwShosoIwHE+aeVQFLFHYAq4KmqIH3g6FEp+YF/zeFAn+dwxEfIi7CqMdkhoabJu6iIVn+fjKw8Ju0wVlyHeAAkNm4g5Cvnwl5PoeDj5oQ0opNDZxDywDCkODFVTKjYqPUo1B2J3R2MZBlCGlXNAejpsgntiCNjaCjWsHma+FyUCeTLR1K3zIzlGkUz3TY0B2aG9+I9sq1T0Tgqi2hbkLX5/DGxVFZNNW7NqtQQ9KI6S0la7EbhHzk+StWUls5VckERI2lPhBHr1rKQoSFp42aGkismQBTV/OJ4VLvvHZGoMGJ0JpoyJqFKl00TsrraE5mem5rdwF2ejjVgx2qu0d5N8+gkrnISsxKNFoNDZWkJvdRjdONKR00KdbtI+WIOLI0wqPCDFfsEVotAWjfXLmLMH7YjG+MngE85mng8KHYHBoQpRFTSQGBryPPmLpZx9itI32hJifQLRHwtJYvkW+mySxagmVjyxnlR/DFosmq4nSVArbzcPxHbQxWKLT98MDbROYRdrmHrgYRAuWBhsJ6nOk8yVRe1Jg6a7DNybrKdWisFqzzQIoQZt0BBKKiG/I8wNltNEOanNoT5G0g9ZEETHgB22For4QMSlS2qIBlTYICxEvhZZMlIpgi8FSGlfb+Jam3hGSEvZHb43vNNL+mypN/+lx2oJv+1q+S0Wvre57huZFofbee28ee+wxHnnkERYuXEgikaC0tJRRo0ZxxhlnMH78+P/k0kN2AQZIKIgSDBBGaSLdutIwbBAoF0Vr/cyECH7Q98wJpuqkB/VR0hWRVXYhBsFizCAkVZBtZQMxAVsETaDsghBv9hkBRIKWP8YK+lLa+UVY0QK0RELjyW6MiOxkwWbwtY+PhZ3uQ5y0DCI+2gSLS5RFxAfbBIth1zK4lkYbK/i8FYSrWn4EsVzAoI3GMhEskzaeaJUtHuP4aWVABE8ZpG1jkf87UOzgvch44drSZasQRENDnlCnBV8Jti+Ikp0qdfWiscTHkkCRadKBUcMSPwgJVS5KhIZ0br5r+UQ8g68tEE2Oq/AsIWX5WGllKGUrCpJB4ZpkxLAlkqI+18NOpeVHZSojCeATFHhqm5ugMzc0k7u+3Ti6pxAYRBSBmmUQZUAJSnQ6NxHaapEetM7JzFQKLTZIFJ/g/K42uNrHcwypHJe6qE+tFlzLxzKBZBmVLp5jIKkCX6eIICoReOYMWMogxqMBQ0o7uNpBS6CoiFJB3qWfCtR5x7ApBhHPw4sZNAZXm3SbFgvRQTG0NrkF6agoTwWxUC3Nd2oPNIh8+yi2u/UqiCQQ5dMUsdgazWs1B9pXgQHfSXv4g6WOCYzxBmpiEPE0OR7UOYGxJeYbPGWBRFCOpJ0FgigLQxBRgCV4OnhWtlEoPBK2hadsGlyP2pgHJkppaKTYgT0shTxkd0FrnQ1LPvjggxk7dixNTU00NjYSi8Wy1aP3uLLyIWggN1vQVdEUsRkz6TKUeyFBT50dhw1RQZEDmyDcRpsgwtjYpBcvmUCfbV4GhWqRGyLNfoJl4bbPZM4RxEH6QREiA/gWkhvHBHUHQ3YpiswyHJUpygSxnj3IOemnLZpObEMwShCsoOUTPp4yKKwgl5Kgj2lw9EARdZSQ6ytSOihr4YiPFoWrHIzyglBQ0YCFjyalFApDsQnC230gaQXnjVg2drt2aRdkOE59I7J/r7JNl2v2Pny9R/UbI6B8w6D8oUw+dxqOCfIjFCqoELqTLCqjFApBiyFYYmZGm5ZB04FcqbROuq0djJbm308QNL4OokYsIW0MgZSj2P+NPPyITaZiWqDY6xbn+U9QzRTalu/viX4alb1uURo/PSJottXFaov4CQUoI8SNAe1TZxRJIqSIkyKo3p1S0GG1zdtHuizqI5i0gVWLlX7m26YmJRlZMWhJZrf7KlNWR6OyM5aX/hZBdECQDu6jCAoMgYXCw1jCIe861FoaV8D2wbMUbVRMGwU4vgq8tLrlhjZOx/w/RyYgPmMcKazoyPceewQxqtXKw6IDo602wcMz6V2UBF5c11FYPlh+UKVdKUGZdHy4RIJxR7tBbQBJn0MIjHfpa1BGocSkU740lm/wbR9cKOzZPXyg2/Gd5NiG/N+kNdFpLd95++0huznS/KXsuIra2SOU1ja2sirb4TzNdvi34iGtvsx+PJSvXUjaJ9uq/robTzOZMM9Qdr4xrXnf21zZEvC9JMn6WhI1dekwQNVscW5alauMUr2tYnLrFybpMOesgpwN7VUtj5tWeLdXpMUPCljltishkp8PdqSlJ6ytxEkyKmGLt7LH36OktrlX/9vyO6e9noLBVx6N69az9KXXiaeSGO2jsTNW0m2fyVyCqO3EpeU1quZbsuOFtHwgLebMzAvVTCADH6qIosmy6TJuLCWD98a1HGK0UQeJbSK949t7otx8R2THtdbWFt/tpXxjshIazl9ZQsU2JCQkJCQkZLdCREgiuAiOERxRKBXk3AeesF2cHy0uIgbRFqI0NjY6HSccRCKHC81dgoCYdH0HBQ5CxAShz0kl2Di7tBaDjw/4gTfVgPEUYtkICtsKFZSQkP+UULENCQkJCQkJ2a2QIKkeSbeGVZCOW2Vbm6ZdtXpR4CqDp4JwZw046ctTogLNNlRQdg0S+N0MQa0Gx4BOESi8FhjHz/Yj/a5RqKCrgIDooKWsn06DUCJEvqYrRkhIyDcjVGxDQkJCQkJCdiuCpUnLomMZhWVbnv6uQmGlvbOSTsRULSoIhK3tdh2CSFB52aigYJWgMUHwelBJXbbt21KKWvsdWoQZf+3v3+CYOmhY56fftcSk8ysBK+wgERLynxIWjwoJCQkJCQnZbRARVqxYwZNP/ZlBe++Nb3xc16NPnz688+67fP/73+e9994j4jicdfaZRCKR7/T6FICxgpxMBUqrZjmXIbuSbSUHg6JygVJr0KKD37XVNsXN/j/RBHWh7WamEDBhUaeQkDYi9NiGhISEhISE7DaICJs3b+acc86BdEFC27bJiedg2zYd2rcnNy+Xf/7zH/ztb38jJyfnu7/G9P8qU+23hfNOhZHIuwhBMATtCC0yXvWg+jWGoDztrmrxJSDpePpshWhIh0YbbKzQYxsS8h8SdsgICQkJCQkJ2a1YuXIlEyZMYMb06RTk59OhfXvGjt2fLVtq2H/s/gwdOhRjhPXrNwT5rN/xj9ouHzLze0bRDdlVKDQq3QBu27NCKbAyW3fND0qjVKZ0VSApGoWNwlZW6LINCWkDwlDkkJCQkJCQkN2Kzyo/488v/5kJv5rAsmXL2JTcRPXiapY2LOWvn/6VJUuW0Hl4ZxIlCZYnlu/qywWg0CqkxC4JvW67kIzSuIOSqLZt3VUa5E6vLdRoQ0LajDAUOSQk5Gv5Jn2J22oY+Xd9kL/J50N2Pd/GtNLWsrb9cUN2Hxr8Bs5cdiYDowOxLAsRyT53Ywza0kFbnd2oiqwrLpu8Tdzd9W60CoPhdke+7eXufzpG7S6yHLIj34XstHaOb7omCmVnG6HHNiQkZKc0X1A2H2CNMWitW0zkmfdE5GsH2ebHyewrItnPNj9f8+swxqCUQmudfW/744bsXjSXheavjTHAtme2swVh5jNKqezzby4zSil8328hE5nXzY/X/POtEcrO7oXB0DHSkd90+Q3Izsebr1NsW3vm28vO9vtn9tl+fwiuIaNkt3bsRmnk2tXXts0NCPnW8H2/hdxk5KH5c29NNprLTobmMtjatu2Pt/0cuv37zWU8ZPdhe/loTmuysf1YktnW2jPPyE5mHmu+NmptLtvZuUO2ESq2ISEh/5bMoNrU1MS//vUvUqkUBx98MAUFBS0GbRGhtraWzz//nDlz5rB161Zyc3Pp3bs3BxxwAO3bt2+xUPR9H2MMX331FUuWLMGyLHr27EnXrl1xHKfFZLF582YWLFjA5s2b6d69O7179yYej7eYHEJ2L5rLxurVq1m0aBGJRIIuXbrQu3dvcnNzWywCfN+noaGBadOmMWvWLKqrq4nFYvTq1YsDDjiATp067bCQcF2XlStXUllZieu69OzZk549exKNRrPXYYxhy5YtLFy4kI0bN1JRUUH//v3Jy8vDsqxddXtCvgG+7yMirF27lsWLF9PQ0EC/fv3o1q0btm3vIA+NjY3MmjWLadOmUVVVRTQapXv37uy777507do1+7wzn3Fdl3Xr1rFo0SJSqRRdu3bNyo/WGmMMxhgSiQRLly5l5cqVdOjQgb59+1JcXAyEhpE9Cd/32bRpE57nUVZWRiwWy27LPOf58+czbdo01q1bh23bdOnShbFjx9KzZ08sy2qhDBtj2LBhA4sWLaKuro6uXbvSu3dvcnJyWox/iUSCyspKvvrqKwoKChgwYAAlJSVZGWuuxITsfmQMFfPmzePLL79k4MCB9O3bt4UBIzMfLVy4kKlTp1JVVYUxhk6dOrHvvvvSp08fIpFIC+MYBGubhQsXsnnzZjp16kTfvn3Jy8vbQbHN/DQ2NlJTU0MsFqO0tDScw7ZHQkJCQnaCMUY8zxPP8ySVSsnLL78s7dq1k4qKCpk/f74YY7I/ruvKhx9+KAceeKDk5uaKZVmitRattcRiMdlnn33kxRdflEQiIb7vi+/7sm7dOjnvvPOkQ4cOkpOTI7m5uVJeXi6XXnqpbNq0SXzfl1QqJe+9956MHj1a8vPzJRaLSbt27eTUU0+VFStWSCqVEtd1xRizq29XSBpjTPYZ19fXy2233Sbdu3eX3NxcycnJkXbt2smECRNkyZIlLfb97LPP5Hvf+57k5eWJZVmilBKllESjUenXr5888cQT0tDQkJXJ6upqueqqq6RTp06Sk5MjOTk5UlZWJuecc46sWbMmu9/nn38uhx12mBQUFEgsFpOioiI55phjZMGCBS1kOGT3YKu3VS5ecbF4vieNjY3y+OOPS9++fSU3N1disZh07NhRJk6cKDU1NVnZ8TxP5s2bJxMmTJCioiKxbVu01gKI4zjStWtXufvuu6W+vl5c1xXP86Surk5uvvlm6dq1q+Tk5Eg8HpfS0lI5/vjj5csvv5RUKiWpVEoWLlwoP/rRj6S4uFhisZgUFBTIoYceKjNnzhTP88T3fanz6uTiFReLb/xdfftCtqP53/iUKVOkf//+0qVLF/nHP/4hvu9n57lly5bJaaedJiUlJVn50VqL4zjSpUsXmTRpkmzevFlSqZT4vi9NTU1y3333Se/evSUvL09isZgUFxfLUUcdJXPmzJFUKiWe58ny5cvlhBNOkHbt2kk8Hpe8vDzZd9995YMPPsgeKxyDdj+2X9+sWrVKxo0bJ/F4XG644Ybs335mfbR27Vq56KKLpEOHDuI4jmitxbIscRxHysvL5ZJLLpH169dn56WmpiZ56qmnZPDgwdm1TVFRkRx00EHy6aefiud52fP7vi+u60p9fb38z//8j3To0EGOO+44qaurC+VmO0LFNiQkZKdkJvyMctmvXz/RWkv79u1bKAW+78tHH30kPXv2FNu2JS8vTw455BA599xz5cgjj5Ti4mLRWkt5ebm89tpr4nmeJJNJufLKK8W2bYlEItK9e3fp0qWL2LYt8XhcbrnlluxkMmzYMLEsS9q1aye9evWSWCwmtm3LL37xi6yiEw7uuw8ZmfA8T5577jkpKCgQx3Gkc+fO0rNnT8nJyRHbtuWEE06QhoYG8X1fFi5cKEOGDBGllOTm5soBBxwgZ511lhx99NHSvn170VpLcXGxPPnkk+K6rriuK7fddptEIhFxHEe6d+8uXbt2lWg0Ko7jyK9//WtJJpNSXV0thxxyiFiWJcXFxdlFqGVZMmHCBKmvrw+V292MjGLr+758/PHH0rFjR3EcRyoqKrLPODc3V+6///6skrp8+XI54IADxLIsiUajMnLkSDnrrLPkuOOOk44dO4pSSvLy8uT222+XZDIpiURCnnjiCSkoKBDbtqVLly7So0eP7Nhy6qmnSn19vdTW1sqECRPEsizJz8/Pyo/WWg477DCpqqoKFdvdmOZz1Lp16+Sggw4Sy7IkJydH3n777axhZP369XLUUUeJ4zgSiURk2LBhcsYZZ8hJJ50kXbt2zcrVVVddJfX19eJ5nrzxxhtSUlIilmVJx44ds2ObZVlyxBFHSHV1tSQSCTn//PMlHo9n5aeoqEi01jJs2DD56quvsgpSOP7sPjSXG9/3Ze3atXL66adLNBoVy7Lk+uuvz85xnufJli1b5JRTTsnOPwMGDJCf//zncuqpp0rv3r2z65xzzjlHtm7dKsYYmTp1qpSXl4tlWdK+fXvp3bt3djwaO3asbNiwocU1JJNJeeaZZ6SgoECUUnLooYeGim0rhIptSEjITjHGyJo1a+SGG26Qjh07itZalFJSVlaW9dj6vi91dXXy05/+VLTWUlpaKo8//rhs2bJFXNeV2tpaeeWVV6RLly5iWZaMHTtWqqqqZM2aNdK/f3+xLEvOPPNMWbVqlSxZskQOPPBAAWTcuHGydetW+etf/yoFBQXSuXNneeedd2TNmjVy7rnnilJKevfuLatXrw4V292MjIW7sbFRfvSjH4nWWsaMGSMLFiyQ1atXy/nnny+WZUmXLl1k8eLFkkwm5Re/+IVorSU/P19uu+02qa6ulmQyKQ0NDfLBBx9I3759RWstAwcOlK+++kqqq6tlzJgxYlmWHH300VJZWSmVlZVyzDHHZPfbuHGjvP/++1JaWiplZWXy8ssvy7p16+Q3v/mN2LYtnTt3lsWLF4eK7W5GRrFNuSmZOHGiRKNRGTVqlMybN08qKyvlwAMPFKWU/OhHP5LGxkZxXVcmTpwolmVJLBaTiRMnyoYNG8R1XWlqapJPPvlERowYIY7jSLdu3WTBggVSX18vRx11lCilZP/995fFixfLmjVr5Mwzz8wqusuWLZM5c+ZI586dpaCgQB577DFZv3693HXXXRKJRKS4uFg+/fTTULHdjckYZ5uamuSKK66QSCQilmVJPB6Xt956K6ucZJ5pNBqVCy64QNasWSOpVEoSiYTMmzdPDj74YNFaS1lZmUydOlWSyaScccYZorWWQYMGyRdffCFr166Vyy+/XGzblpKSEpk5c6YsW7ZM+vbtK3l5eXLLLbfI+vXr5c9//nM2euXvf/97VjkKx5/dh8wc1tTUJH/729/kgAMOEMdxxHGcrGKbeWae58nzzz8vubm54jiOnHDCCbJs2TJJJpPS1NQkixcvlqOPPjo7v7322muSTCblqquuEq219OjRQ6ZMmSIbNmyQ22+/XeLxuOTm5so///nPFlFzc+bMyc6DgBx66KFZw2zINsIc25CQkK/lH//4BzfccAOO4zBy5EhmzJiR3SbpnI/Kyko++OADAI477jhOPPFEbNtGa008HufII49k5syZ3HjjjcyePZtZs2YxYMAAjj76aNasWcNpp51Ghw4dABg1ahQffvghqVQKEWHMmDH85S9/YevWrYwbNw6tNeXl5SilyMnJwbbDYWx3RClFKpVi//33p6ioiIMOOoiePXuilOKAAw7g0UcfxfM8PM9j7dq1vPPOOwAcfvjhnHvuudkcNdu22W+//bjwwgu5+OKLWbZsGR999BGHH344RxxxBH369OGnP/0pe+21F8YYxowZw2uvvYbruniex957781TTz1FdXU1RxxxBNFolPLycrTWRCKRUH52Y5RSnHzyyQwcOJCSkhL69OlDY2NjNrc/Ly8PpRQ1NTW8+uqrGGMYOXIkF154Ifn5+Vn5GTFiBFdeeSU/+9nPWLNmDe+88w5nnHEG+++/PyUlJRx++OF069YNpRTjxo3jqaeewvM8fN9nr7324k9/+hPr16/nqKOOIi8vj/bt22flp3kud8juy1tvvcXDDz9MSUkJW7ZsAbbNXw0NDbzyyiu4rsugQYO44oor6NChA0opLMuiX79+XH311XzxxRdUV1fz97//nWHDhjF48GBOPfVURowYQf/+/bEsi4MOOoh7770XY0w2j/ePf/wjy5cv5/DDD6ddu3Z07tw5O+40z8UN2f3YtGkTV155JYsXL2bAgAFUVVVRVVWV3S4ipFIpXnrpJZqamujSpQu//e1v6dy5c7b2R48ePZg4cSKff/45GzZs4NVXX+Xggw+md+/enHbaafTu3Zvhw4dj2zZjx44lHo+TSCRwXTdbRKq2tpZJkyaxYsUK2rdvz/r163fhXdm9CWf0kJCQr8UYQ8+ePbnooouIx+OcfvrpOxS6WLJkCVu2bMFxHMaPH58tkABk9z300EO56667aGhoYO7cuRx88MHccMMN+L4PkF2gzpgxA6UUw4YNIxaLkZeXx+GHH45Sijlz5vDoo4/y8ssvk5+fz5lnnklJScl3e0NCvhFKKQoKCrj00kuzz9iyLDzP49NPP8X3fXr27ElFRQWzZs1i48aNKKUYP348OTk52WMA2Qm/uLiYTZs2MXfuXH76058yceLE7LG11iQSCaZPnw7AoEGDKCgoIBaLcdhhh6G1ZunSpfzxj3/kpZdewnEcTj/9dDp37txqJe6Q3YOePXvSu3dvPM/jzTff5LnnnuP999+nY8eOnH766TiOw9q1a1mzZg1KKQ455BAKCwtbFCWzLIvhw4dTUVHBihUrmD17NrFYjMsuuyxbtCxTmfSTTz7B8zz69OlDaWkpeXl5HHrooQCsXr2aW265hVdeeQWAn/70p/Tq1WtX3ZqQVmiuIEq6SM/y5cv57W9/C8Cll17KH/7wB2pra4Hgb37z5s0sX74cpRRjxoyhrKxshwq1gwcPpnv37syePZt58+YB8Mtf/jJbNNGyLIwxfPbZZ6RSKfr06UOXLl2IxWKMHTuWsWPHsnnzZm688UYmT55MU1MTP/nJTxg6dGj2OkJ2LzJVqnNycjj99NP5xS9+wWmnncbGjRtb7FdXV8fChQsREfbZZx+6devWooI6QJ8+fRgwYAAbNmxg9uzZeJ7Hz372M0455RR8388aOj7//HPq6+vp3LlzdmzxPI/HH3+c119/nQMPPJCePXvy4IMPtriG5nL/3y5LYRm2kJCQr2X8+PG8/vrrnHbaaVmFdftWBps2bcoOzhlLd2ZSyCi2paWlxONxjDFUV1dnP6u1RmtNU1MTt912G59++imdO3fmrLPOalHtT0R48803+eMf/0h1dTX77bdfVuH9bx/IdzeaPxOtNZZlYVkWruvy9NNP89RTT5Gbm8u5555LYWEhNTU1uK6LZVlZb9j2rS+KiorIy8vD8zw2bdrUohq2UopEIsH999/PW2+9RWlpKb/85S+Jx+NZr4uI8NFHH3Hfffexdu1ahg4dyo9+9KMWC9iQ3YuM7GQ8Wk8//TTPP/88ruty3HHHMXToUHzfp6amhlQqhdaaioqK7Ge01tkFY35+PkVFRdmquJkxTGuN4zgYY3jyySd5/vnnKSws5Pzzzyc/P7+FEW/OnDncc889LF26lH79+nH88ccTiUR2yb0J+Xoy81RdXR2TJk1i8eLFnHXWWRxxxBE7GGbr6upoamoCoGPHjlmZyYwtWmtyc3MpKytDRKiurs4aQzJjm4jw6quv8uCDDxKNRjn77LMpKytr0Qpo2bJl3HXXXcyfP58uXbpwwgknkJOTE7Zs2U0xxlBcXMxjjz3GPffcQ9euXVttDdXY2Eh9fT1aazp06IDjOADZeUxrTTQapaKiAhGhrq4O13Wz41tGHj/44APuuOMOAH7+85/TuXNnPM/j448/5o477qC8vJxJkyZRXFy8Q+sz3/ezRt7/dkLFNiQk5GspLy+nc+fOO7y/fS/ATPn65h5Y2GZJzFi2M4uBzLbMQH/99ddz//33k5OTw3XXXcegQYN28PoOGTKEW265hf33358PPviAc845hzVr1ny7NyDk/4vm8pEJ13rqqae44ooraGpq4pe//CXHHntsCxnKtFbZfvGQIfNeRnHJfDaVSnHXXXdx88034zgOV111Ffvvv3+LNjAiQo8ePbjxxhs5/PDDmTZtGqeffjpffvll2GpjN6b5c/7BD37AddddR8+ePXn44Ye56qqrSCaTLZSCjPy0RvPxpLnRLZVK8dhjj3HVVVeRSqW48MILOeqoo1rIJkBZWRmTJk3iuOOOY/HixZxxxhnZCJOQ3YvMgv+ZZ55h8uTJjBkzhosuuqhFNFFrfUAz7aUy2zPHyvw0N9o2/8xLL73EhRdeSG1tLT//+c85+eSTW1xPJoJl4sSJnHTSSWzYsIHzzz+ff/zjHy3mxpDdBxEhGo0ycODAbMpBa2NLRkHNyFzmB9hBAc1497dfH/3jH//Irmd+8pOfcN5552FZFlVVVVx33XVs2bKFK664Iuvhz8hgRi4zCnRIqNiGhIT8G1prPN4cEcnmDHmeR2VlZfb9ZDKJ53kopVizZg0NDQ1YltWiH+nWrVu56qqreOCBBygsLOTOO+/kxBNPbHG+zPm/973vcfHFF3PvvfdSXFzMJ598wmuvvfZd3IaQ/yXNlVPXdXnooYe47LLLSCaTXHbZZVx55ZXZRWZFRUXWa1ZZWZn9XDKZJJVKAbBhwwa2bNmCZVl07NgRCJSYpqYmbrjhBm666SYsy+L666/nnHPOyeZ4N7+O/fffn0suuYQHHniAHj16MHv2bJ599tkWEQghuxeZBaFt25x00klceeWV/O53v8OyLF566SVmzJhBhw4dyMnJwRjDl19+mc1NS6VSNDU1ZcNNM+HunTt3zi5Ek8kk9913H1dddRWu63L55Zdz8cUXt/DEZq5h+PDhXHTRRdxzzz0MHjyYFStW8MQTT4Sekt2QzJxz9913k0qlKCkp4cEHH+Tee++loaEBz/N4+umn+fOf/0xeXh75+fnZehGe5wHBuJVIJFBKUV9fz+rVqzHGtPDKZY5z0UUXUVtbyy9+8QtuvPFG8vLysteSGX/69OnDRRddxL333suBBx7IunXrePjhh/E8b6fGvJBdR3PDx9cZHTLRIMYYVqxYQSKRyPYnbmxsBKCpqYkVK1aglKKsrKyFovz6669z9tlns2bNGk4++WTuuOMOSkpKUErx7LPP8sknn1BQUEBlZSU33XQTU6ZMyZ7r5ptvZtGiRaHsNCPMsQ0JCflaMgVYdobWmr59+9K+fXvWrl3L3//+dyZMmEAkEuF3v/sdGzdu5NRTT+XVV18lkUhQWFjIsGHDso3Gr732Wp544gk6dOjA3XffzQ9+8IOs5VFEePvtt3n33XcpLy/nwgsvxLZt2rdvT2FhIevXr2fNmjUtclRCdj2ZvEUIFoePP/441113HUoprrvuOs477zxisRhAtkBP165dWbRoEW+99RannXYaxcXF3H///cyYMYPTTjuNqVOnsnXrVuLxOKNGjQICxfe2227j7rvvJi8vj1tvvZXjjz8ex3GyC8VPPvmEV155hby8PC699FJycnIoLi7O5mGuWbMGY0zY5H43JJlM8vRTTzN79mzGjh3Lcccdl1VMbdumsbGRjRs3MmTIEHr16kVVVRXvvPMOF1xwAR07duSZZ57hjTfe4LTTTqOyspKqqiqi0ShjxoxBKYXrujz44INZRfm6667j7LPPblEQaubMmTz//PMAXHbZZZSUlFBQUEBZWRmu67J27Vpc14UwInm3IjO/VFdXk0qlmDx5Mq+88koLY+mzzz7L2rVrOfrooxkwYADLly/n448/ZunSpQwYMIA33niDxx9/nJNPPplkMsnq1atxHIf99tsPy7LwfZ8XXniByy+/PGuwu/TSS8nNzc0qGkuXLuXJJ58kkUhwySWXUFFRQU5ODuXl5fi+z/r160kmk2FI+27IN50TcnJy2GeffbKFMefMmcPo0aOZOnUqd9xxB8cccwwlJSUsWrQIy7IYPXo00WgU3/d54403uOiii9i8eTPnnnsu119/PUVFRUBguF23bh2pVIr169dz5513AttyxysrK7n99tvZZ5996N+//7d1G/Y4wpVgSEjITmlupfw6i2DXrl35wQ9+wCOPPMI777zDDTfcwOmnn05TUxOTJ0/m5ZdfzlqljzjiCPr164cxhscff5wnnngCEeGAAw6gpqaGZ599FqUUxcXFHHbYYSxYsID777+f0tJS9tlnH4YNG8abb77JmjVrsG2b7t27hyE4uyEZb+mHH37IpEmTaGhoYNSoURQWFvLiiy9mcxvHjx9PWVkZxx57LLfccguffvop11xzDRdccAFbtmzh/fff54033sgqywcccAAjRoxARPjrX//KPffcg+u6jB49GhHhxRdfBCA3N5fx48ezbNky7r//fvLy8th77705+OCD+de//kVlZWW2YmUmDDpUbncvlFK8//77vPDCC3z22WfsvffelJWV8fLLL9PQ0EBeXh5dunQhPz+fk046iRkzZrB48WKuuOIKrrjiimwxurfffhvbtnFdl+HDh3PIIYcgIrz//vvccsstJBIJxowZQ25ublZ+otEohx9+OBs2bODBBx9EROjduzc//vGPmTt3Ll988QVaa7p27YrjOPiEXtvdhUzIZ35+Pj/5yU+oq6vLbquvr+fdd98llUpx0EEHMW7cOOLxOCeddBIffPABa9as4ZJLLskaZb/88kvOOussYrEY9fX19O3bNxumPmPGDK655hpqa2sZNGgQFRUVTJ48GQgK3h100EFs3bqVhx9+mPr6etq3b8+ZZ56ZVaAty6Jr165ZI1/I7sP2Htqvi1qzbZvjjz+eyZMns2XLFn79619z8803s3HjRlatWsWvfvUr4vE4tbW1dOzYkZ/85CdorVm8eDGXX345a9eupXfv3vTt25fXX389G1o8duxYhg4dyimnnNIiVH3evHnMnj2biooKDjnkEDp27BiGsjentR5AISEhIdtjjJEXX3xRbNuWsrIyWbBgQYv+n19++aWMHTtWbNvO9oEcMmSIFBQUiNZaLMuSnJwceeihh6Surk4qKyulT58+2d5wmf5wlmWJbduyzz77yKZNm2TRokXSv39/sW1b2rdvL4MHD5aioiKxLEtGjBghK1asCJvb72Zk+htv3bpVjjzyyOzztyxLHMcRrXW2J+TMmTPF931ZvXq1fO9738vKT8eOHWX48OFSXFyc/Ww0GpWbbrpJampqZP369TJy5MgWsqO1Ftu2s70BV6xYIStXrpRRo0aJ4zhSWloqgwYNknbt2olt29K3b1+ZM2dOtpdlKEO7B5k+tp7nyVtvvSWlpaViWZbstddeMnDgwGy/yBNPPFFqa2vFdV2prq6Wk046SSKRSHasGDp0qJSVlYllWaKUEsuy5NJLL5Xq6mqpqamRI444Ivt+RnYyrzt06CDz5s2TTZs2yeGHHy6WZUlBQYEMGjRIOnToIEop6dKli3zyySdhH9vdjEzvT9/3xXXdbB9Qz/Nk4cKFUl5eLvF4XN58803xPE9c15WtW7fKL3/5S4nH49l+7EOHDpXy8vLsnGTbtvzsZz+TDRs2SH19vZxyyilZ+cnITWasy8/PlylTpsjWrVvlpJNOEtu2JScnRwYOHCidO3cW27altLQ028c27KO9+5J5NlVVVTJw4EBRSrXoY5vp2f7b3/5W8vLyxLIsKSkpkSFDhshee+0lWmtRSolt2/L9739fVq9eLYlEQi688MIWa57M3KW1llgsJpMnT87KZ+b/VColV199tWit5bDDDpO6ujpxXTf7E8pQ2Mc2JCTkf4HjOLRr1y7bI7I53bt354knnuD222/ntddeY/PmzWzYsAHLsmjXrh3xeJx169ZxxRVXMHfuXMaNG8fWrVspLCxs1RucyXnq3r07d999N7/5zW9YsGABCxcuJCcnhwMPPJCbbrqJjh07ht623ZRVq1ZRWVlJcXFx9r3mOdsFBQVZz25FRQWPPvood9xxBy+++CI1NTVUV1ejtaawsJC8vDzWrl3LTTfdxLx58zjllFNYv359tqdpcxmStLdGKUV5eTl33XUXV1xxBbNmzWLJkiXZnsyTJk1iwIABoaV7d0XBuHHjuPnmm7nllltYu3YtGzduJDc3l+OOO47rr78+W/m6qKiIO++8kz59+vD000+zbt065s+fj23bFBQUUFhYyNq1a3nooYdYunRptidypl2YbOfxyMhmQUEBt956K1dddRUff/wxixYtIhKJMGTIECZOnMiwYcN21d0J+RoyUTzbzwuZZ5rZlsmfzMnJ4cYbb6Rbt248/vjjrFq1ivnz56O1Ji8vj3bt2rF27VpeeOEFVq1axXXXXcfcuXNbVKhtTm5uLrZtk5OTw6RJk/B9n3feeYelS5dmI42uvvrqbCsyCNu07M4YY7IFwDLrGWlWuCkajXL55ZdTUVHBww8/TGVlJYsXL0ZEyM3NpV27dmzcuJF//vOfHHfccdx0003MnDmT4uLiFkUOMziOkw1P3z4iLRaLUVxcTG5uLvDNQ6b/W1DS2ooyJCQkZDtEhPr6ejZs2IDWmo4dOxKNRltU5hMRPM9j1apVLF26lOrqanJzc+nbty9KKe6++25eeOEFzjnnHC677DJqamp2er5IJEJ5eXm2yEtVVRWzZs2iqqqK7t27M3DgwKxSA+xQqTJk15GRhUQiwbp163Yaxq61pry8PJvTqJQilUqxbt06li5dyoYNG8jJyaFXr17k5uby8MMP86c//Ymjjz6aW265hZqamp0+c9u2KS8vzxZ5qa6uZt68eaxdu5YOHTowZMgQSkpKWlSoDNk9qPPr+O3q33Jb59uAYFG5atUq5s6dSyKRoFevXvTp0yfbKqV5Tn4mL23JkiWsW7eOaDRKz549KS0t5amnnuLBBx9kxIgRPPLII9TV1e20+nZmjMssLrdu3cqCBQtYvnw5paWlDB48mPbt22cVo0Zp5NrV13L7XrejVZgasTuy/ZjUoUOHrHKQUVx836eqqoqlS5fy1VdfEYlE6N69O+Xl5fz1r3/l7rvvpkuXLjz33HMkk8mvLTyXmSMlne87f/58KisrKSoqYu+996ZLly7hvLUHkBlXjDGsXbs2W4yssLAw+/wy6yDP86ipqWHp0qWsWrUK3/fp2rUre+21F//85z/5/e9/TywWy/bCzhQqa05GHtq3b088Hm+h2IoINTU1bNmyhVgsll0jhTK0jVCxDQkJ+UY0V14zg/j2Jee3J5O7mPm867rMmjWLLl260KFDhxYFn7b/fPM+k82P33wSaU64QNh9yDyvzGLx657L9p7WjHxlnmfmGMYYPM9jzpw5tGvXLttT8Ous1b7v72Dtzsht5jxhH+Tdj4xie2vnW1FsG18yRq7m1Uq3H48ycgctx4qM0WTx4sVYlkW/fv1arXq6s7HGGJM9fqbiaQbLsmgwDaFiu5sj6Tz95nMX0GIOa00eMmOQiLB06VJSqRQDBgz42hYrvu9n5TVznO0VlHD82TNoPiZsvy7JvG4+TjT/XPNtnuexcuVKqqur2WeffVp9/s3lrrU83+3ny+aKdUhAGIocEhLyv6K5h7S1bdsPyM0XnbFYLFvkZ3vFdPtCVc0nhOY9J5t/rrX3QnY928vI102628vM9h6Q5iGFWmtGjBjR6rlaI2PJzhw/o5yEC4Hdn3q/nqXJpSiaPScXUICk/yf9OoNqtiBsZUgQESK9IygUS5NLQW2Tn8x5BMH4Bm3pbeeR4P3t92t+bU3SREpSbfHVQ75FdjYmNVdytzd4NN83E33U2jGaY9t2i3GtNQUmnLf2HJo/x+0No63tl3nd/HO2bdOjRw969OjR6v47Ow6w0/OF7EjosQ0JCflGfJ0iurPt33R42V6p/aZsf45w0N99+N88l6975q3J0Td57v/umCG7L554PFn1JJu9zbv6Ur4xgtAv3o+jio4K5Ws35n+75P1389jOnvXOIpha2xbKy+7PzmTgm65dvk6OWjvGzmRlZ58L2Uao2IaEhISEhISEhISEhITs0YSJICEhISEhISEhISEhISF7NKFiGxISEhISEhISEhISErJHEyq2ISEhISEhISEhISEhIXs0oWIbEhISEhISEhISEhISskcTKrYhISEhISEhISEhISEhezShYhsSEhISEhISEhISEhKyRxMqtiEhISEhISEhISEhISF7NKFiGxISEhISEhISEhISErJHEyq2ISEhISEhISEhISEhIXs0oWIbEhISEhISEhISEhISskcTKrYhISEhISEhISEhISEhezShYhsSEhISEhISEhISEhKyRxMqtiEhISEhISEhISEhISF7NKFiGxISEhISEhISEhISErJHEyq2ISEhISEhISEhISEhIXs0oWIbEhISEhISEhISEhISskcTKrYhISEhISEhISEhISEhezShYhsSEhISEhISEhISEhKyRxMqtiEhISEhISEhISEhISF7NKFiGxISEhISEhISEhISErJH8/8A8X9lq8CLnvQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- One cell: run EasyOCR on your chart image (simplified) ---\n",
    "# Works in a notebook. If you just installed packages, restart the kernel once if imports fail.\n",
    "\n",
    "# --- (A) Installs ---\n",
    "# Tip: if SSL cert errors happen on macOS, uncomment the certifi block below first.\n",
    "# import certifi, os\n",
    "# os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "# os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
    "\n",
    "%pip -q install easyocr opencv-python-headless pillow matplotlib pandas numpy certifi\n",
    "\n",
    "# --- (B) Config ---\n",
    "IMG_PATH = \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/_page_4_Figure_1.jpeg\"\n",
    "\n",
    "# --- (C) Imports & utils ---\n",
    "import re, math, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display as _show\n",
    "\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(p)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(\"cv2.imread() returned None\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    # Upscale + denoise + local contrast + threshold\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct: s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r[\"text\"]).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def overlay(img_bgr, df, title=\"Detections\"):\n",
    "    vis = img_bgr.copy()\n",
    "    for _, r in (df if isinstance(df, pd.DataFrame) else pd.DataFrame()).iterrows():\n",
    "        x1,y1,x2,y2 = int(r.x1),int(r.y1),int(r.x2),int(r.y2)\n",
    "        color = (255,0,0) if bool(r.get(\"is_pct\", False)) else (0,200,0)\n",
    "        cv2.rectangle(vis, (x1,y1), (x2,y2), color, 2)\n",
    "        cv2.putText(vis, str(r.raw), (x1, max(12,y1-4)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\"); plt.title(title); plt.show()\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3): break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "# --- (D) Backend wrappers ---\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "# --- (E) Extraction logic specific to your slide layout ---\n",
    "def extract_series_from_df(df, img_up, backend_name):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    # Heuristic bands for right panel\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    # Fallback to detect decimal NIM labels even when '%' is missed\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    # Split two NIM lines (Commercial vs Group) by vertical clustering (y)\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]:\"Commercial NIM (%)\", order[1]:\"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        qlabels = [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"]\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\")\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                if i < len(qlabels):\n",
    "                    rows.append({\"Quarter\": qlabels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # Net interest income bars (top-right values above beige bars)\n",
    "    nii_df = pd.DataFrame()\n",
    "    if not nums.empty:\n",
    "        band = nums[(nums.value > 500) & (nums.value < 20000) & (nums.cy.between(top_band_min, top_band_max))]\n",
    "        if band.shape[0] < 5:\n",
    "            band = nums[(nums.value > 500) & (nums.value < 20000)]\n",
    "        if not band.empty:\n",
    "            pick = band.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            nii_df = pd.DataFrame({\n",
    "                \"Quarter\": [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"][:len(pick)],\n",
    "                \"Net interest income ($m)\": pick[\"value\"].tolist()\n",
    "            })\n",
    "\n",
    "    # Sort quarters chronologically\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns: return df_in\n",
    "        order = pd.Categorical(df_in[\"Quarter\"], [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"], ordered=True)\n",
    "        return df_in.assign(Quarter=order).sort_values(\"Quarter\").reset_index(drop=True)\n",
    "\n",
    "    nim_df = _sort_q(nim_df)\n",
    "    nii_df = _sort_q(nii_df)\n",
    "\n",
    "    # Show per-backend results\n",
    "    print(f\"\\n=== Backend: {backend_name} ===\")\n",
    "    if not nim_df.empty:\n",
    "        print(\"Extracted NIM (Commercial vs Group):\")\n",
    "        _show(nim_df)\n",
    "    else:\n",
    "        print(\"No NIM table detected.\")\n",
    "\n",
    "    if not nii_df.empty:\n",
    "        print(\"Extracted Net interest income ($m):\")\n",
    "        _show(nii_df)\n",
    "    else:\n",
    "        print(\"No Net interest income table detected.\")\n",
    "\n",
    "    # Overlay\n",
    "    overlay(img_up, df, title=f\"{backend_name}: detected tokens — red≈percent  green=number\")\n",
    "\n",
    "    return nim_df, nii_df\n",
    "\n",
    "# --- (F) Run EasyOCR only ---\n",
    "img_bgr = load_image(IMG_PATH)\n",
    "img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "try:\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    df = extract_numbers(ocr)\n",
    "    if df.empty:\n",
    "        print(f\"\\n=== Backend: easyocr ===\\nNo numeric tokens detected.\")\n",
    "    else:\n",
    "        nim_df, nii_df = extract_series_from_df(df, img_up, \"easyocr\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n=== Backend: easyocr ===\\nERROR → {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a72e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: Demo PDF Merge.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "Running CLI command for JSON output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:01:24,315 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:13<00:00,  6.58s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:01:39,218 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 13:01:39,218 [INFO] marker: Total time: 13.468534708023071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:01:49,331 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:12<00:00,  6.16s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:02:02,926 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 13:02:02,926 [INFO] marker: Total time: 12.607863187789917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_2.jpeg → relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — running OCR… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/_page_0_Figure_2.jsonl\n",
      "   • _page_1_Figure_3.jpeg → relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant (No graphs/plots)\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/.marker_md5\n",
      "--- Finished processing: Demo PDF Merge.pdf ---\n",
      "\n",
      "--- Processing file: Demo PDF.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "Running CLI command for JSON output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:02:36,793 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.96s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:02:45,148 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 13:02:45,148 [INFO] marker: Total time: 7.150288105010986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:02:54,695 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.43s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:03:02,074 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 13:03:02,075 [INFO] marker: Total time: 6.619595050811768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_3.jpeg → relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant (No graphs/plots)\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF/.marker_md5\n",
      "--- Finished processing: Demo PDF.pdf ---\n",
      "\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers (standalone in Untitled-1) ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "RELEVANT_KEYWORDS = [\"net interest margin\", \"net interest income\", \"nim\", \"nii\"]\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "def extract_series_from_df(df, img_up):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]:\"Commercial NIM (%)\", order[1]:\"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        qlabels = [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"]\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\")\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                if i < len(qlabels):\n",
    "                    rows.append({\"Quarter\": qlabels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    nii_df = pd.DataFrame()\n",
    "    if not nums.empty:\n",
    "        band = nums[(nums.value > 500) & (nums.value < 20000) & (nums.cy.between(top_band_min, top_band_max))]\n",
    "        if band.shape[0] < 5:\n",
    "            band = nums[(nums.value > 500) & (nums.value < 20000)]\n",
    "        if not band.empty:\n",
    "            pick = band.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            nii_df = pd.DataFrame({\n",
    "                \"Quarter\": [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"][:len(pick)],\n",
    "                \"Net interest income ($m)\": pick[\"value\"].tolist()\n",
    "            })\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        order = pd.Categorical(df_in[\"Quarter\"], [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"], ordered=True)\n",
    "        return df_in.assign(Quarter=order).sort_values(\"Quarter\").reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def is_relevant_image(img_path):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in RELEVANT_KEYWORDS)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def process_image_to_jsonl(img_path: Path):\n",
    "    \"\"\"Run EasyOCR → parse series → save nim_df JSONL beside the image (image_stem.jsonl).\"\"\"\n",
    "    img_bgr = load_image(img_path)\n",
    "    img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "    img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    df = extract_numbers(ocr)\n",
    "    if df.empty:\n",
    "        return False, \"No numeric tokens detected\"\n",
    "    nim_df, nii_df = extract_series_from_df(df, img_up)\n",
    "    if nim_df is None or nim_df.empty:\n",
    "        return False, \"No NIM table detected\"\n",
    "    out_path = img_path.with_suffix(\".jsonl\")\n",
    "    nim_df.to_json(out_path, orient=\"records\", lines=True)\n",
    "    return True, str(out_path)\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name} → relevance check…\", end=\" \")\n",
    "            if not is_relevant_image(img_path):\n",
    "                print(\"⏭️  Not relevant (No graphs/plots)\")\n",
    "                continue\n",
    "            print(\"✅ Relevant — running OCR…\", end=\" \")\n",
    "            ok, msg = process_image_to_jsonl(img_path)\n",
    "            if ok:\n",
    "                print(f\"💾 Saved → {msg}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Skipped ({msg})\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2bd4c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: Demo PDF Merge.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "Running CLI command for JSON output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:33:19,993 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:11<00:00,  5.91s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:33:33,492 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 13:33:33,492 [INFO] marker: Total time: 12.08766508102417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:33:41,222 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:10<00:00,  5.29s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:33:52,694 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 13:33:52,694 [INFO] marker: Total time: 10.853907823562622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_2.jpeg → relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — running OCR… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/_page_0_Figure_2.jsonl\n",
      "   • _page_1_Figure_3.jpeg → relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant (No graphs/plots)\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/.marker_md5\n",
      "--- Finished processing: Demo PDF Merge.pdf ---\n",
      "\n",
      "--- Processing file: Demo PDF.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "Running CLI command for JSON output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:34:28,476 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.67s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:34:36,482 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 13:34:36,482 [INFO] marker: Total time: 6.870627164840698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:34:46,670 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.47s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:34:54,147 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 13:34:54,147 [INFO] marker: Total time: 6.66786003112793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_3.jpeg → relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant (No graphs/plots)\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF/.marker_md5\n",
      "--- Finished processing: Demo PDF.pdf ---\n",
      "\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers (standalone in Untitled-1) ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "RELEVANT_KEYWORDS = [\"net interest margin\", \"net interest income\", \"nim\", \"nii\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4])Q(\\d{2}|\\d{4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.70)  # bottom 30%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: for ordering we only need x\n",
    "        qtokens = []\n",
    "        for r in ocr or []:\n",
    "            txt = str(r.get(\"text\",\"\")).strip()\n",
    "            m = QUARTER_PAT.search(txt)\n",
    "            if not m:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            # Convert x from upsampled-crop space back to original global space\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.0)  # undo scale\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            qtokens.append((cx_global, q))\n",
    "        qtokens.sort(key=lambda x: x[0])\n",
    "        # Dedup by proximity and text\n",
    "        ordered = []\n",
    "        last_x = -9999\n",
    "        last_q = None\n",
    "        for x, q in qtokens:\n",
    "            if last_q == q and abs(x - last_x) < 30:\n",
    "                continue\n",
    "            ordered.append(q)\n",
    "            last_x, last_q = x, q\n",
    "        return ordered\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]:\"Commercial NIM (%)\", order[1]:\"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        # --- Dynamic quarter labels ---\n",
    "        detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "        detected_q_bot = detect_qlabels_bottom(img_up)\n",
    "        # Prefer the source with more tokens, but merge to keep any uniques\n",
    "        if len(detected_q_bot) > len(detected_q_ocr):\n",
    "            detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "        else:\n",
    "            detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\")\n",
    "            n = len(pick)\n",
    "            labels = []\n",
    "            # 1) Prefer OCR-detected quarters (left→right)\n",
    "            if detected_q:\n",
    "                # Use the rightmost n (latest) detected quarters to align with right-panel values\n",
    "                labels = detected_q[-n:] if len(detected_q) >= n else detected_q\n",
    "            # 2) If insufficient, try markdown-derived hint tokens (document order)\n",
    "            if (not labels or len(labels) != n) and qlabels_hint:\n",
    "                labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            # 3) Final fallback: infer a sequence from any anchor like 2Q24\n",
    "            if not labels or len(labels) != n:\n",
    "                # Try to infer an anchor quarter from OCR or markdown and expand\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            # 4) If still nothing, use neutral placeholders\n",
    "            if not labels or len(labels) != n:\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    nii_df = pd.DataFrame()\n",
    "    if not nums.empty:\n",
    "        band = nums[(nums.value > 500) & (nums.value < 20000) & (nums.cy.between(top_band_min, top_band_max))]\n",
    "        if band.shape[0] < 5:\n",
    "            band = nums[(nums.value > 500) & (nums.value < 20000)]\n",
    "        if not band.empty:\n",
    "            pick = band.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            nii_df = pd.DataFrame({\n",
    "                \"Quarter\": [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"][:len(pick)],\n",
    "                \"Net interest income ($m)\": pick[\"value\"].tolist()\n",
    "            })\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in RELEVANT_KEYWORDS)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def process_image_to_jsonl(img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "    \"\"\"\n",
    "    Run EasyOCR → parse series → save:\n",
    "      1) First line: {\"_context\": {...}} figure-level summary record\n",
    "      2) Following lines: row records from nim_df\n",
    "    Output file is placed BESIDE the image: <image_stem>.jsonl\n",
    "    \"\"\"\n",
    "    img_bgr = load_image(img_path)\n",
    "    img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "    img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    df = extract_numbers(ocr)\n",
    "    if df.empty:\n",
    "        return False, \"No numeric tokens detected\"\n",
    "    md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "    nim_df, nii_df = extract_series_from_df(df, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "    if nim_df is None or nim_df.empty:\n",
    "        return False, \"No NIM table detected\"\n",
    "\n",
    "    out_path = img_path.with_suffix(\".jsonl\")\n",
    "\n",
    "    # Build context record\n",
    "    image_name = img_path.name\n",
    "    ctx = {\n",
    "        \"source_pdf\": pdf_name,\n",
    "        \"image\": image_name,\n",
    "        \"units\": \"percent\",\n",
    "        \"entity\": \"DBS\",\n",
    "        \"topic\": \"Net Interest Margin\",\n",
    "    }\n",
    "    # Merge page/figure indices if parsable\n",
    "    ctx.update(_parse_page_and_figure_from_name(image_name))\n",
    "    # Merge markdown-derived headings/paragraph\n",
    "    md_ctx = _extract_md_context(dest_dir, image_name)\n",
    "    if md_ctx:\n",
    "        ctx.update(md_ctx)\n",
    "    # One-line natural language summary (very short, based on available columns)\n",
    "    try:\n",
    "        cols = [c for c in nim_df.columns if c != \"Quarter\"]\n",
    "        # Build a short trend note using first and last row if possible\n",
    "        if len(nim_df) >= 2 and cols:\n",
    "            # Prefer detected labels if they look like quarters, else use the first/last present\n",
    "            def _pick_q(s):\n",
    "                return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "            _fq = str(nim_df.iloc[0][\"Quarter\"])\n",
    "            _lq = str(nim_df.iloc[-1][\"Quarter\"])\n",
    "            first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "            last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "            pieces = []\n",
    "            for col in cols[:2]:\n",
    "                a = nim_df.iloc[0][col]\n",
    "                b = nim_df.iloc[-1][col]\n",
    "                if pd.notna(a) and pd.notna(b):\n",
    "                    pieces.append(f\"{col}: {a:.2f}% → {b:.2f}%\")\n",
    "            if pieces:\n",
    "                ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Write context and rows\n",
    "    import json\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "        for rec in nim_df.to_dict(orient=\"records\"):\n",
    "            # Add light provenance to each row (kept minimal)\n",
    "            rec_out = dict(rec)\n",
    "            rec_out[\"_meta\"] = {\"source_pdf\": pdf_name, \"image\": image_name}\n",
    "            f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    return True, str(out_path)\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name} → relevance check…\", end=\" \")\n",
    "            if not is_relevant_image(img_path):\n",
    "                print(\"⏭️  Not relevant (No graphs/plots)\")\n",
    "                continue\n",
    "            print(\"✅ Relevant — running OCR…\", end=\" \")\n",
    "            ok, msg = process_image_to_jsonl(img_path, dest_dir, pdf_path.name)\n",
    "            if ok:\n",
    "                print(f\"💾 Saved → {msg}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Skipped ({msg})\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e52e5e",
   "metadata": {},
   "source": [
    "## Latest Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11ccb020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: Demo PDF Merge.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "Running CLI command for JSON output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:40:26,141 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:12<00:00,  6.01s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:40:40,152 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 13:40:40,152 [INFO] marker: Total time: 12.379868030548096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:40:50,384 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:12<00:00,  6.03s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:41:03,625 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 13:41:03,625 [INFO] marker: Total time: 12.42951488494873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/_page_0_Figure_2.nim.jsonl\n",
      "   • _page_1_Figure_3.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/.marker_md5\n",
      "--- Finished processing: Demo PDF Merge.pdf ---\n",
      "\n",
      "--- Processing file: Demo PDF.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "Running CLI command for JSON output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:41:49,606 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.75s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:41:57,708 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 13:41:57,709 [INFO] marker: Total time: 6.958008766174316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 13:42:07,284 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:07<00:00,  7.01s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 13:42:15,252 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 13:42:15,253 [INFO] marker: Total time: 7.2077717781066895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_3.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF/.marker_md5\n",
      "--- Finished processing: Demo PDF.pdf ---\n",
      "\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers (standalone in Untitled-1) ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"net interest income\", \"nim\", \"nii\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4])Q(\\d{2}|\\d{4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.70)  # bottom 30%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: for ordering we only need x\n",
    "        qtokens = []\n",
    "        for r in ocr or []:\n",
    "            txt = str(r.get(\"text\",\"\")).strip()\n",
    "            m = QUARTER_PAT.search(txt)\n",
    "            if not m:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            # Convert x from upsampled-crop space back to original global space\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.0)  # undo scale\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            qtokens.append((cx_global, q))\n",
    "        qtokens.sort(key=lambda x: x[0])\n",
    "        # Dedup by proximity and text\n",
    "        ordered = []\n",
    "        last_x = -9999\n",
    "        last_q = None\n",
    "        for x, q in qtokens:\n",
    "            if last_q == q and abs(x - last_x) < 30:\n",
    "                continue\n",
    "            ordered.append(q)\n",
    "            last_x, last_q = x, q\n",
    "        return ordered\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]:\"Commercial NIM (%)\", order[1]:\"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        # --- Dynamic quarter labels ---\n",
    "        detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "        detected_q_bot = detect_qlabels_bottom(img_up)\n",
    "        # Prefer the source with more tokens, but merge to keep any uniques\n",
    "        if len(detected_q_bot) > len(detected_q_ocr):\n",
    "            detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "        else:\n",
    "            detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\")\n",
    "            n = len(pick)\n",
    "            labels = []\n",
    "            # 1) Prefer OCR-detected quarters (left→right)\n",
    "            if detected_q:\n",
    "                # Use the rightmost n (latest) detected quarters to align with right-panel values\n",
    "                labels = detected_q[-n:] if len(detected_q) >= n else detected_q\n",
    "            # 2) If insufficient, try markdown-derived hint tokens (document order)\n",
    "            if (not labels or len(labels) != n) and qlabels_hint:\n",
    "                labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            # 3) Final fallback: infer a sequence from any anchor like 2Q24\n",
    "            if not labels or len(labels) != n:\n",
    "                # Try to infer an anchor quarter from OCR or markdown and expand\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            # 4) If still nothing, use neutral placeholders\n",
    "            if not labels or len(labels) != n:\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    nii_df = pd.DataFrame()\n",
    "    if not nums.empty:\n",
    "        band = nums[(nums.value > 500) & (nums.value < 20000) & (nums.cy.between(top_band_min, top_band_max))]\n",
    "        if band.shape[0] < 5:\n",
    "            band = nums[(nums.value > 500) & (nums.value < 20000)]\n",
    "        if not band.empty:\n",
    "            pick = band.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            nii_df = pd.DataFrame({\n",
    "                \"Quarter\": [\"2Q24\",\"3Q24\",\"4Q24\",\"1Q25\",\"2Q25\"][:len(pick)],\n",
    "                \"Net interest income ($m)\": pick[\"value\"].tolist()\n",
    "            })\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text against given keywords.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in keywords)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        if not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a33bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️  process_existing_only=True → Skipping Marker. Scanning existing extracted folders…\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation (as 1Q24_CEO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 1Q24_CEO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation (as 1Q24_CFO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/_page_2_Figure_1.nim.jsonl\n",
      "   • _page_3_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "   • _page_4_Picture_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 1Q24_CFO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update (as 1Q24_trading_update.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update/.marker_md5\n",
      "--- Finished extracted folder: 1Q24_trading_update ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation (as 1Q25_CEO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 1Q25_CEO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation (as 1Q25_CFO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/_page_2_Figure_1.nim.jsonl\n",
      "   • _page_3_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/_page_3_Figure_1.nim.jsonl\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_8_Picture_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 1Q25_CFO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update (as 1Q25_trading_update.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update/.marker_md5\n",
      "--- Finished extracted folder: 1Q25_trading_update ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation (as 2Q24_CEO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 2Q24_CEO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation (as 2Q24_CFO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_14_Figure_1.nim.jsonl\n",
      "   • _page_14_Picture_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_25_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_26_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_27_Picture_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_27_Picture_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_28_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_28_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_29_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_2_Figure_1.nim.jsonl\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_5_Figure_1.nim.jsonl\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 2Q24_CFO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary (as 2Q24_performance_summary.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary/.marker_md5\n",
      "--- Finished extracted folder: 2Q24_performance_summary ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement (as 2Q24_press_statement.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement/.marker_md5\n",
      "--- Finished extracted folder: 2Q24_press_statement ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation (as 2Q25_CEO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_28.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 2Q25_CEO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation (as 2Q25_CFO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_25_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_26_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_27_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_28_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/_page_5_Figure_1.nim.jsonl\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 2Q25_CFO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary (as 2Q25_performance_summary.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary/.marker_md5\n",
      "--- Finished extracted folder: 2Q25_performance_summary ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement (as 2Q25_press_statement.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement/.marker_md5\n",
      "--- Finished extracted folder: 2Q25_press_statement ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation (as 3Q24_CEO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 3Q24_CEO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation (as 3Q24_CFO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Figure_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_5_Figure_1.nim.jsonl\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_6_Figure_1.nim.jsonl\n",
      "   • _page_7_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_7_Figure_1.nim.jsonl\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 3Q24_CFO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update (as 3Q24_trading_update.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update/.marker_md5\n",
      "--- Finished extracted folder: 3Q24_trading_update ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation (as 4Q24_CEO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 4Q24_CEO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation (as 4Q24_CFO_presentation.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_25_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_25_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_26_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_27_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_28_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_28_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_29_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/_page_2_Figure_1.nim.jsonl\n",
      "   • _page_3_Figure_6.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/_page_3_Figure_6.nim.jsonl\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/_page_5_Figure_1.nim.jsonl\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/.marker_md5\n",
      "--- Finished extracted folder: 4Q24_CFO_presentation ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary (as 4Q24_performance_summary.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_38_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary/.marker_md5\n",
      "--- Finished extracted folder: 4Q24_performance_summary ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement (as 4Q24_press_statement.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement/.marker_md5\n",
      "--- Finished extracted folder: 4Q24_press_statement ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022 (as dbs-annual-report-2022.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_103_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_104_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_111_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_27.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_13_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_10.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022/_page_14_Figure_10.nim.jsonl\n",
      "   • _page_14_Figure_11.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_44.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_51.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_54.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_41.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_48.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_50.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_33.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Figure_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_26_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_31_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_35_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_35_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_65.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_67.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_69.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_71.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_73.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_75.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_77.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_79.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_39_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_39_Figure_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_39_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_57.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_44_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_44_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_46_Figure_49.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_48_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_53_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Figure_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_18.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_51.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_58.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Figure_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Figure_30.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Figure_44.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_32.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_23.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_31.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_33.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_35.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_37.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_41.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_43.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_37.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/var/folders/xg/dmt_t8md5hq2stkfs082xh5c0000gn/T/ipykernel_12814/2269583266.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    624\u001b[39m                     print(\u001b[33m\"⏭️  Not relevant\"\u001b[39m)\n\u001b[32m    625\u001b[39m                     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    626\u001b[39m                 any_hit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    627\u001b[39m                 print(\u001b[33m\"✅ Relevant — extracting…\"\u001b[39m, end=\u001b[33m\" \"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m                 ok, msg = ex.handle_image(img_path, dest_dir, pdf_name_guess)\n\u001b[32m    629\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[32m    630\u001b[39m                     print(\u001b[33mf\"💾 Saved → {msg}\"\u001b[39m)\n\u001b[32m    631\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m/var/folders/xg/dmt_t8md5hq2stkfs082xh5c0000gn/T/ipykernel_12814/2269583266.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, img_path, dest_dir, pdf_name)\u001b[39m\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str):\n\u001b[32m    524\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m self.is_relevant(img_path):\n\u001b[32m    525\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"Not relevant\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m         df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n\u001b[32m    527\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mor\u001b[39;00m df.empty:\n\u001b[32m    528\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, ctx_extra \u001b[38;5;28;01mif\u001b[39;00m isinstance(ctx_extra, str) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"No data\"\u001b[39m\n\u001b[32m    529\u001b[39m         \u001b[38;5;66;03m# Build context and summary if possible\u001b[39;00m\n",
      "\u001b[32m/var/folders/xg/dmt_t8md5hq2stkfs082xh5c0000gn/T/ipykernel_12814/2269583266.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, img_path, dest_dir, pdf_name)\u001b[39m\n\u001b[32m    564\u001b[39m         img_bgr = load_image(img_path)\n\u001b[32m    565\u001b[39m         img_up, gray, thr, scale = preprocess(img_bgr)\n\u001b[32m    566\u001b[39m         img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n\u001b[32m    567\u001b[39m         ocr = run_easyocr(img_rgb)\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m         df_tokens = extract_numbers(ocr)\n\u001b[32m    569\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m df_tokens.empty:\n\u001b[32m    570\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"No numeric tokens detected\"\u001b[39m\n\u001b[32m    571\u001b[39m         md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
      "\u001b[32m/var/folders/xg/dmt_t8md5hq2stkfs082xh5c0000gn/T/ipykernel_12814/2269583266.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(ocr_results)\u001b[39m\n\u001b[32m    126\u001b[39m                 \u001b[33m\"raw\"\u001b[39m: txt, \u001b[33m\"value\"\u001b[39m: val, \u001b[33m\"is_pct\"\u001b[39m: is_pct, \u001b[33m\"conf\"\u001b[39m: r.get(\u001b[33m\"conf\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    127\u001b[39m                 \u001b[33m\"x1\"\u001b[39m: int(x1), \u001b[33m\"y1\"\u001b[39m: int(y1), \u001b[33m\"x2\"\u001b[39m: int(x2), \u001b[33m\"y2\"\u001b[39m: int(y2),\n\u001b[32m    128\u001b[39m                 \u001b[33m\"cx\"\u001b[39m: int((x1+x2)/\u001b[32m2\u001b[39m), \u001b[33m\"cy\"\u001b[39m: int((y1+y2)/\u001b[32m2\u001b[39m)\n\u001b[32m    129\u001b[39m             })\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     df = pd.DataFrame(rows).sort_values([\u001b[33m\"cy\"\u001b[39m,\u001b[33m\"cx\"\u001b[39m]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"is_pct\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m df.columns \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m df.empty:\n\u001b[32m    132\u001b[39m         df[\u001b[33m\"is_pct\"\u001b[39m] = df[\u001b[33m\"raw\"\u001b[39m].astype(str).str.endswith(\u001b[33m\"%\"\u001b[39m)\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7190\u001b[39m                 \u001b[33mf\"Length of ascending ({len(ascending)})\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   7191\u001b[39m                 \u001b[33mf\" != length of by ({len(by)})\"\u001b[39m\n\u001b[32m   7192\u001b[39m             )\n\u001b[32m   7193\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7194\u001b[39m             keys = [self._get_label_or_level_values(x, axis=axis) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n\u001b[32m   7195\u001b[39m \n\u001b[32m   7196\u001b[39m             \u001b[38;5;66;03m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[32m   7197\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m7194\u001b[39m         ...     key=\u001b[38;5;28;01mlambda\u001b[39;00m x: np.argsort(index_natsorted(df[\u001b[33m\"time\"\u001b[39m]))\n",
      "\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'cy'"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def md5_of_folder_inputs(dest_dir: Path) -> str:\n",
    "    \"\"\"\n",
    "    Compute an md5 hash over the extracted inputs in dest_dir.\n",
    "    Includes only source artifacts likely produced by Marker (md/json/images),\n",
    "    excludes derived *.jsonl outputs and .marker_md5.\n",
    "    \"\"\"\n",
    "    h = hashlib.md5()\n",
    "    include_exts = {\".md\", \".json\", \".png\", \".jpg\", \".jpeg\"}\n",
    "    paths = []\n",
    "    for p in dest_dir.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            if p.name == \".marker_md5\":\n",
    "                continue\n",
    "            if p.suffix.lower() in include_exts:\n",
    "                paths.append(p)\n",
    "    # Stable order for deterministic hash\n",
    "    for p in sorted(paths, key=lambda x: str(x.relative_to(dest_dir))):\n",
    "        rel = str(p.relative_to(dest_dir)).encode(\"utf-8\")\n",
    "        try:\n",
    "            with open(p, \"rb\") as f:\n",
    "                data = f.read()\n",
    "        except Exception:\n",
    "            data = b\"\"\n",
    "        h.update(rel + b\"\\x00\" + hashlib.md5(data).hexdigest().encode(\"utf-8\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers (standalone in Untitled-1) ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"net interest income\", \"nim\", \"nii\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4])Q(\\d{2}|\\d{4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.70)  # bottom 30%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: for ordering we only need x\n",
    "        qtokens = []\n",
    "        for r in ocr or []:\n",
    "            txt = str(r.get(\"text\",\"\")).strip()\n",
    "            m = QUARTER_PAT.search(txt)\n",
    "            if not m:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            # Convert x from upsampled-crop space back to original global space\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.0)  # undo scale\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            qtokens.append((cx_global, q))\n",
    "        qtokens.sort(key=lambda x: x[0])\n",
    "        # Dedup by proximity and text\n",
    "        ordered = []\n",
    "        last_x = -9999\n",
    "        last_q = None\n",
    "        for x, q in qtokens:\n",
    "            if last_q == q and abs(x - last_x) < 30:\n",
    "                continue\n",
    "            ordered.append(q)\n",
    "            last_x, last_q = x, q\n",
    "        return ordered\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "            \n",
    "    # --- Detect quarter labels once (OCR full + bottom crop), reusable below ---\n",
    "    detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "    detected_q_bot = detect_qlabels_bottom(img_up)\n",
    "    # Prefer the source with more tokens, but merge to keep any uniques\n",
    "    if len(detected_q_bot) > len(detected_q_ocr):\n",
    "        detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "    else:\n",
    "        detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            n = len(pick)\n",
    "            # Choose quarter labels: detected OCR → markdown hint → anchor expansion → placeholders\n",
    "            labels = []\n",
    "            if detected_q:\n",
    "                labels = detected_q[-n:] if len(detected_q) >= n else detected_q\n",
    "            if (not labels or len(labels) != n) and qlabels_hint:\n",
    "                labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if not labels or len(labels) != n:\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if not labels or len(labels) != n:\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "\n",
    "        if rows:\n",
    "            nim_df = pd.DataFrame(rows)\n",
    "            nim_df = nim_df.pivot_table(index=\"Quarter\", columns=\"series\", values=\"value\", aggfunc=\"first\").reset_index()\n",
    "            # Make column order stable: Quarter first, then sorted series names\n",
    "            cols = [\"Quarter\"] + sorted([c for c in nim_df.columns if c != \"Quarter\"])\n",
    "            nim_df = nim_df[cols]\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text against given keywords.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in keywords)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        if not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "process_existing_only = True\n",
    "\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available (only when running Marker)\n",
    "if not process_existing_only:\n",
    "    if not shutil.which(\"marker_single\"):\n",
    "        print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "        print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH, or set process_existing_only=True.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "if process_existing_only:\n",
    "    print(\"🛠️  process_existing_only=True → Skipping Marker. Scanning existing extracted folders…\")\n",
    "    # Iterate subfolders under pdf_directory (each should be a per-PDF extraction folder)\n",
    "    for dest_dir in sorted([p for p in pdf_directory.iterdir() if p.is_dir()]):\n",
    "        pdf_name_guess = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"--- Processing extracted folder: {dest_dir} (as {pdf_name_guess}) ---\")\n",
    "        checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "        # Scan images and run all registered extractors\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_name_guess)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes for this folder, write/update checksum sidecar based on folder inputs\n",
    "        try:\n",
    "            checksum = md5_of_folder_inputs(dest_dir)\n",
    "            checksum_file.write_text(checksum)\n",
    "            print(f\"🧾 Recorded folder checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "        print(f\"--- Finished extracted folder: {dest_dir.name} ---\\n\")\n",
    "\n",
    "    print(\"🎉 All extracted folders in the directory have been processed.\")\n",
    "    sys.exit(0)\n",
    "    \n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1011e",
   "metadata": {},
   "source": [
    "Skipping MD5 generated folders (Marker Disabled, Continuing On)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c8089ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️  process_existing_only=True → Skipping Marker. Scanning existing extracted folders…\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation (as 1Q24_CEO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 1Q24_CEO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation (as 1Q24_CFO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 1Q24_CFO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update (as 1Q24_trading_update.pdf) ---\n",
      "⏭️  Skipping (already processed): 1Q24_trading_update [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation (as 1Q25_CEO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 1Q25_CEO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation (as 1Q25_CFO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 1Q25_CFO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update (as 1Q25_trading_update.pdf) ---\n",
      "⏭️  Skipping (already processed): 1Q25_trading_update [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation (as 2Q24_CEO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q24_CEO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation (as 2Q24_CFO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q24_CFO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary (as 2Q24_performance_summary.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q24_performance_summary [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement (as 2Q24_press_statement.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q24_press_statement [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation (as 2Q25_CEO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q25_CEO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation (as 2Q25_CFO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q25_CFO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary (as 2Q25_performance_summary.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q25_performance_summary [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement (as 2Q25_press_statement.pdf) ---\n",
      "⏭️  Skipping (already processed): 2Q25_press_statement [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation (as 3Q24_CEO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 3Q24_CEO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation (as 3Q24_CFO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 3Q24_CFO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update (as 3Q24_trading_update.pdf) ---\n",
      "⏭️  Skipping (already processed): 3Q24_trading_update [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation (as 4Q24_CEO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 4Q24_CEO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation (as 4Q24_CFO_presentation.pdf) ---\n",
      "⏭️  Skipping (already processed): 4Q24_CFO_presentation [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary (as 4Q24_performance_summary.pdf) ---\n",
      "⏭️  Skipping (already processed): 4Q24_performance_summary [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement (as 4Q24_press_statement.pdf) ---\n",
      "⏭️  Skipping (already processed): 4Q24_press_statement [has .marker_md5]\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022 (as dbs-annual-report-2022.pdf) ---\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_103_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_104_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_111_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_27.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No NIM table detected)\n",
      "   • _page_13_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_10.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_44.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_51.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_54.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_41.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_0.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_48.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_50.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_33.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Figure_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_26_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_31_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_35_Figure_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_35_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_65.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_67.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_69.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_71.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_73.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_75.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_77.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Picture_79.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_39_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_39_Figure_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_39_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_57.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_44_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_44_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_46_Figure_49.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_48_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_53_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Figure_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_18.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_51.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_58.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Figure_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Figure_30.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Figure_44.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_32.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_55_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_23.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_31.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_33.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_35.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_37.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_41.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_43.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_37.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… ⚠️ Skipped (No numeric tokens detected)\n",
      "   • _page_8_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_6.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_106.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_62.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_82.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_98_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_98_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_98_Picture_36.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_98_Picture_51.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_98_Picture_75.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_99_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_99_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022/.marker_md5\n",
      "--- Finished extracted folder: dbs-annual-report-2022 ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023 (as dbs-annual-report-2023.pdf) ---\n",
      "   • _page_0_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_0_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_102_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_103_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_103_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_111_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_114_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_7.jpeg\n",
      "      · [nim] relevance check… ✅ Relevant — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023/_page_14_Figure_7.nim.jsonl\n",
      "   • _page_14_Figure_8.jpeg\n",
      "      · [nim] relevance check… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Figure_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_43.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_43.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_28.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_33.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_31.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Figure_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_27_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_38.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_31_Figure_54.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_35_Figure_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_23.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_87.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_89.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_91.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_93.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_37_Picture_95.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_40_Figure_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_40_Picture_43.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_40_Picture_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_43_Figure_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_43_Figure_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_45_Figure_49.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_45_Figure_50.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_46_Figure_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_46_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_46_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_48_Figure_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_48_Figure_28.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_48_Figure_32.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_52_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_53_Figure_35.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_53_Picture_32.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_18.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_54_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_18.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_26.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_28.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_30.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_32.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_34.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_36.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_38.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_40.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_42.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_44.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_46.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_48.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_50.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_52.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_36.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_96_Picture_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_96_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_96_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_96_Picture_60.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_96_Picture_63.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_96_Picture_66.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_35.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_51.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_97_Picture_53.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_98_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023/.marker_md5\n",
      "--- Finished extracted folder: dbs-annual-report-2023 ---\n",
      "\n",
      "--- Processing extracted folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024 (as dbs-annual-report-2024.pdf) ---\n",
      "   • _page_0_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_100_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_108_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_1.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_110_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_110_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_110_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_110_Picture_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_110_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Figure_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Figure_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_46.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_48.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_50.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_52.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_54.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_56.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_58.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_60.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_32.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Figure_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_49.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_55.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_57.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Figure_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Figure_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Figure_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_36.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_38.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_53.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_48.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_54.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_21_Picture_57.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_22_Picture_49.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_23.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_28.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_36.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_23_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_24_Picture_30.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_25_Figure_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_28_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_51.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_32_Picture_53.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_36_Figure_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_38_Picture_66.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_38_Picture_68.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_38_Picture_70.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_38_Picture_72.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_38_Picture_74.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_38_Picture_76.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_18.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_41_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_41_Picture_35.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_41_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_41_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_41_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_42_Figure_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_42_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_42_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_42_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_42_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_42_Picture_23.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_44_Figure_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_44_Figure_8.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_46_Figure_49.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_12.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_47_Figure_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_49_Figure_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_10.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_16.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_22.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_6.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_53_Figure_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_14.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_20.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_11.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_13.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_15.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_17.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_19.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_23.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_27.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_29.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_31.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_33.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_35.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_37.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_39.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_41.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_43.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_45.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_47.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_7.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_9.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_93_Picture_24.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_93_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_93_Picture_5.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_93_Picture_52.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_93_Picture_79.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_93_Picture_92.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_94_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_94_Picture_36.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_94_Picture_4.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_94_Picture_62.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_95_Picture_25.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_95_Picture_3.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_99_Picture_2.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_99_Picture_23.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_99_Picture_54.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_21.jpeg\n",
      "      · [nim] relevance check… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded folder checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024/.marker_md5\n",
      "--- Finished extracted folder: dbs-annual-report-2024 ---\n",
      "\n",
      "🎉 All extracted folders in the directory have been processed.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def md5_of_folder_inputs(dest_dir: Path) -> str:\n",
    "    \"\"\"\n",
    "    Compute an md5 hash over the extracted inputs in dest_dir.\n",
    "    Includes only source artifacts likely produced by Marker (md/json/images),\n",
    "    excludes derived *.jsonl outputs and .marker_md5.\n",
    "    \"\"\"\n",
    "    h = hashlib.md5()\n",
    "    include_exts = {\".md\", \".json\", \".png\", \".jpg\", \".jpeg\"}\n",
    "    paths = []\n",
    "    for p in dest_dir.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            if p.name == \".marker_md5\":\n",
    "                continue\n",
    "            if p.suffix.lower() in include_exts:\n",
    "                paths.append(p)\n",
    "    # Stable order for deterministic hash\n",
    "    for p in sorted(paths, key=lambda x: str(x.relative_to(dest_dir))):\n",
    "        rel = str(p.relative_to(dest_dir)).encode(\"utf-8\")\n",
    "        try:\n",
    "            with open(p, \"rb\") as f:\n",
    "                data = f.read()\n",
    "        except Exception:\n",
    "            data = b\"\"\n",
    "        h.update(rel + b\"\\x00\" + hashlib.md5(data).hexdigest().encode(\"utf-8\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers (standalone in Untitled-1) ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "# Strictly NIM-only keywords (exclude income/\"nii\" to avoid earnings slides)\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4])Q(\\d{2}|\\d{4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    \n",
    "    # 1. Create the DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # 2. Check if it's empty BEFORE sorting\n",
    "    if df.empty:\n",
    "        return df  # Return the empty DataFrame immediately\n",
    "\n",
    "    # 3. If not empty, proceed with sorting and processing\n",
    "    df = df.sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "\n",
    "    if \"is_pct\" not in df.columns: # The 'and not df.empty' check is no longer needed\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.70)  # bottom 30%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: for ordering we only need x\n",
    "        qtokens = []\n",
    "        for r in ocr or []:\n",
    "            txt = str(r.get(\"text\",\"\")).strip()\n",
    "            m = QUARTER_PAT.search(txt)\n",
    "            if not m:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            # Convert x from upsampled-crop space back to original global space\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.0)  # undo scale\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            qtokens.append((cx_global, q))\n",
    "        qtokens.sort(key=lambda x: x[0])\n",
    "        # Dedup by proximity and text\n",
    "        ordered = []\n",
    "        last_x = -9999\n",
    "        last_q = None\n",
    "        for x, q in qtokens:\n",
    "            if last_q == q and abs(x - last_x) < 30:\n",
    "                continue\n",
    "            ordered.append(q)\n",
    "            last_x, last_q = x, q\n",
    "        return ordered\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "            \n",
    "    # --- Detect quarter labels once (OCR full + bottom crop), reusable below ---\n",
    "    detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "    detected_q_bot = detect_qlabels_bottom(img_up)\n",
    "    # Prefer the source with more tokens, but merge to keep any uniques\n",
    "    if len(detected_q_bot) > len(detected_q_ocr):\n",
    "        detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "    else:\n",
    "        detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            n = len(pick)\n",
    "            # Choose quarter labels: detected OCR → markdown hint → anchor expansion → placeholders\n",
    "            labels = []\n",
    "            if detected_q:\n",
    "                labels = detected_q[-n:] if len(detected_q) >= n else detected_q\n",
    "            if (not labels or len(labels) != n) and qlabels_hint:\n",
    "                labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if not labels or len(labels) != n:\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if not labels or len(labels) != n:\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "\n",
    "        if rows:\n",
    "            nim_df = pd.DataFrame(rows)\n",
    "            nim_df = nim_df.pivot_table(index=\"Quarter\", columns=\"series\", values=\"value\", aggfunc=\"first\").reset_index()\n",
    "            # Make column order stable: Quarter first, then sorted series names\n",
    "            cols = [\"Quarter\"] + sorted([c for c in nim_df.columns if c != \"Quarter\"])\n",
    "            nim_df = nim_df[cols]\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text against given keywords.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in keywords)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        if not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "\n",
    "process_existing_only = True\n",
    "# In process_existing_only mode, skip folders that already have a .marker_md5 (resume-friendly)\n",
    "resume_existing_only_skip_md5 = True\n",
    "\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available (only when running Marker)\n",
    "if not process_existing_only:\n",
    "    if not shutil.which(\"marker_single\"):\n",
    "        print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "        print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH, or set process_existing_only=True.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "if process_existing_only:\n",
    "    print(\"🛠️  process_existing_only=True → Skipping Marker. Scanning existing extracted folders…\")\n",
    "    # Iterate subfolders under pdf_directory (each should be a per-PDF extraction folder)\n",
    "    for dest_dir in sorted([p for p in pdf_directory.iterdir() if p.is_dir()]):\n",
    "        pdf_name_guess = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"--- Processing extracted folder: {dest_dir} (as {pdf_name_guess}) ---\")\n",
    "        checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "        # Resume mode: if this folder already has a checksum, skip it\n",
    "        if resume_existing_only_skip_md5 and checksum_file.exists():\n",
    "            print(f\"⏭️  Skipping (already processed): {dest_dir.name} [has .marker_md5]\")\n",
    "            continue\n",
    "\n",
    "        # Scan images and run all registered extractors\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_name_guess)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes for this folder, write/update checksum sidecar based on folder inputs\n",
    "        try:\n",
    "            checksum = md5_of_folder_inputs(dest_dir)\n",
    "            checksum_file.write_text(checksum)\n",
    "            print(f\"🧾 Recorded folder checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "        print(f\"--- Finished extracted folder: {dest_dir.name} ---\\n\")\n",
    "\n",
    "    print(\"🎉 All extracted folders in the directory have been processed.\")\n",
    "    sys.exit(0)\n",
    "    \n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8a3a3",
   "metadata": {},
   "source": [
    "Revalidating jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf53935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def md5_of_folder_inputs(dest_dir: Path) -> str:\n",
    "    \"\"\"\n",
    "    Compute an md5 hash over the extracted inputs in dest_dir.\n",
    "    Includes only source artifacts likely produced by Marker (md/json/images),\n",
    "    excludes derived *.jsonl outputs and .marker_md5.\n",
    "    \"\"\"\n",
    "    h = hashlib.md5()\n",
    "    include_exts = {\".md\", \".json\", \".png\", \".jpg\", \".jpeg\"}\n",
    "    paths = []\n",
    "    for p in dest_dir.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            if p.name == \".marker_md5\":\n",
    "                continue\n",
    "            if p.suffix.lower() in include_exts:\n",
    "                paths.append(p)\n",
    "    # Stable order for deterministic hash\n",
    "    for p in sorted(paths, key=lambda x: str(x.relative_to(dest_dir))):\n",
    "        rel = str(p.relative_to(dest_dir)).encode(\"utf-8\")\n",
    "        try:\n",
    "            with open(p, \"rb\") as f:\n",
    "                data = f.read()\n",
    "        except Exception:\n",
    "            data = b\"\"\n",
    "        h.update(rel + b\"\\x00\" + hashlib.md5(data).hexdigest().encode(\"utf-8\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers (standalone in Untitled-1) ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "# NIM value band (pct) and geometry heuristics for verification\n",
    "NIM_MIN, NIM_MAX = 1.3, 3.2\n",
    "TOP_FRACTION = 0.45     # upper portion of image for NIM labels\n",
    "RIGHT_HALF_ONLY = True  # NIM values appear on right panel in these decks\n",
    "def is_strict_nim_image(img_path: Path) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Heuristic re-check:\n",
    "      1) Title/text contains NIM keywords (coarse gate)\n",
    "      2) Percent tokens mostly within NIM_MIN..NIM_MAX\n",
    "      3) Tokens located in the top region (and right half, if enabled)\n",
    "    Returns (ok, reason)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_bgr = load_image(img_path)\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        # 1) quick-text gate\n",
    "        if not is_relevant_image(img_path, NIM_KEYWORDS):\n",
    "            return (False, \"irrelevant_non_nim\")\n",
    "        # 2) numeric gate on enhanced image\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df = extract_numbers(ocr)\n",
    "        if df.empty:\n",
    "            return (False, \"no_numbers\")\n",
    "        # geometry filters (apply before value checks)\n",
    "        top_cut = int(img_up.shape[0] * TOP_FRACTION)\n",
    "        cond_geom = (df[\"cy\"] < top_cut)\n",
    "        if RIGHT_HALF_ONLY:\n",
    "            cond_geom &= (df[\"cx\"] > (img_up.shape[1] // 2))\n",
    "\n",
    "        # 2a) Preferred path: explicit percentage tokens\n",
    "        df_pct = df[(df[\"is_pct\"] == True) & cond_geom].copy()\n",
    "        if not df_pct.empty:\n",
    "            in_band = df_pct[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_pct))\n",
    "            if ratio >= 0.6:\n",
    "                return (True, \"ok\")\n",
    "            else:\n",
    "                return (False, f\"non_nim_values_out_of_band({ratio:.2f})\")\n",
    "\n",
    "        # 2b) Fallback: some decks omit the % sign near the series values.\n",
    "        # If the slide mentions units (e.g., \"Net interest margin (%)\"), accept\n",
    "        # plain numbers in the NIM range within the geometry region.\n",
    "        # Build a quick lowercased concatenation of OCR texts to detect \"(%)\".\n",
    "        title_text = \" \".join(str(r.get(\"text\", \"\")).lower() for r in ocr or [])\n",
    "        has_units_pct = \"(%)\" in title_text or \"margin (%)\" in title_text\n",
    "        df_nums = df[(df[\"is_pct\"] == False) & cond_geom].copy()\n",
    "        if has_units_pct and not df_nums.empty:\n",
    "            in_band = df_nums[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_nums))\n",
    "            if ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_no_percent_signs\")\n",
    "            # fall through if not convincing\n",
    "\n",
    "        return (False, \"no_percentages_or_units\")\n",
    "    except Exception as e:\n",
    "        return (False, f\"exception:{e}\")\n",
    "\n",
    "def reverify_nim_jsonl_in_folder(dest_dir: Path):\n",
    "    \"\"\"\n",
    "    For each *.nim.jsonl, trace back to its source image and verify with strict rules.\n",
    "    If invalid, suffix the file with '.rejected' (non-destructive).\n",
    "    \"\"\"\n",
    "    jsonl_files = sorted(dest_dir.rglob(\"*.nim.jsonl\"))\n",
    "    if not jsonl_files:\n",
    "        return\n",
    "    for jf in jsonl_files:\n",
    "        try:\n",
    "            # Read first line (_context) to find image path if present\n",
    "            ctx = None\n",
    "            with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "                first = f.readline().strip()\n",
    "            if first.startswith(\"{\"):\n",
    "                import json\n",
    "                obj = json.loads(first)\n",
    "                ctx = obj.get(\"_context\", {})\n",
    "            image_name = None\n",
    "            if ctx and isinstance(ctx, dict):\n",
    "                image_name = ctx.get(\"image\", None)\n",
    "            # Fallback: derive from filename\n",
    "            if not image_name:\n",
    "                image_name = jf.with_suffix(\"\").name  # <image>.<name>.jsonl → <image>.<name>\n",
    "                # Try removing extractor suffix\n",
    "                if image_name.endswith(\".nim\"):\n",
    "                    image_name = image_name[:-4]\n",
    "                # Re-add common image extension guesses\n",
    "            # Locate image next to jsonl\n",
    "            img_path = None\n",
    "            for ext in (\".png\", \".jpg\", \".jpeg\"):\n",
    "                cand = jf.with_suffix(\"\").with_suffix(ext)\n",
    "                # If name has .nim in the stem, swap: <stem>.nim.jsonl → <stem>.jpeg\n",
    "                if cand.exists():\n",
    "                    img_path = cand\n",
    "                    break\n",
    "                if image_name:\n",
    "                    alt = (jf.parent / image_name).with_suffix(ext)\n",
    "                    if alt.exists():\n",
    "                        img_path = alt\n",
    "                        break\n",
    "            if img_path is None:\n",
    "                print(f\"   ⚠️  {jf.name}: cannot find source image; skipping reverification.\")\n",
    "                continue\n",
    "            ok, reason = is_strict_nim_image(img_path)\n",
    "            if not ok:\n",
    "                flag = jf.with_suffix(jf.suffix + \".flag\")\n",
    "                try:\n",
    "                    with open(flag, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(str(reason))\n",
    "                    print(f\"   ⚑ Flagged {jf.name} (reason: {reason}) → {flag.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️  Could not write flag for {jf.name}: {e}\")\n",
    "            else:\n",
    "                # If a previous flag exists but this file now validates, remove the stale flag\n",
    "                flag = jf.with_suffix(jf.suffix + \".flag\")\n",
    "                if flag.exists():\n",
    "                    try:\n",
    "                        flag.unlink()\n",
    "                        print(f\"   🧹 Cleared flag for {jf.name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️  Could not clear flag for {jf.name}: {e}\")\n",
    "                print(f\"   ✅ Verified {jf.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Error checking {jf.name}: {e}\")\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4])Q(\\d{2}|\\d{4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.70)  # bottom 30%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: for ordering we only need x\n",
    "        qtokens = []\n",
    "        for r in ocr or []:\n",
    "            txt = str(r.get(\"text\",\"\")).strip()\n",
    "            m = QUARTER_PAT.search(txt)\n",
    "            if not m:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            # Convert x from upsampled-crop space back to original global space\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.0)  # undo scale\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            qtokens.append((cx_global, q))\n",
    "        qtokens.sort(key=lambda x: x[0])\n",
    "        # Dedup by proximity and text\n",
    "        ordered = []\n",
    "        last_x = -9999\n",
    "        last_q = None\n",
    "        for x, q in qtokens:\n",
    "            if last_q == q and abs(x - last_x) < 30:\n",
    "                continue\n",
    "            ordered.append(q)\n",
    "            last_x, last_q = x, q\n",
    "        return ordered\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "            \n",
    "    # --- Detect quarter labels once (OCR full + bottom crop), reusable below ---\n",
    "    detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "    detected_q_bot = detect_qlabels_bottom(img_up)\n",
    "    # Prefer the source with more tokens, but merge to keep any uniques\n",
    "    if len(detected_q_bot) > len(detected_q_ocr):\n",
    "        detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "    else:\n",
    "        detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            n = len(pick)\n",
    "            # Choose quarter labels: detected OCR → markdown hint → anchor expansion → placeholders\n",
    "            labels = []\n",
    "            if detected_q:\n",
    "                labels = detected_q[-n:] if len(detected_q) >= n else detected_q\n",
    "            if (not labels or len(labels) != n) and qlabels_hint:\n",
    "                labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if not labels or len(labels) != n:\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if not labels or len(labels) != n:\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "\n",
    "        if rows:\n",
    "            nim_df = pd.DataFrame(rows)\n",
    "            nim_df = nim_df.pivot_table(index=\"Quarter\", columns=\"series\", values=\"value\", aggfunc=\"first\").reset_index()\n",
    "            # Make column order stable: Quarter first, then sorted series names\n",
    "            cols = [\"Quarter\"] + sorted([c for c in nim_df.columns if c != \"Quarter\"])\n",
    "            nim_df = nim_df[cols]\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text against given keywords.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in keywords)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        if not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "process_existing_only = True\n",
    "\n",
    "# If True → ONLY scan existing *.nim.jsonl files, re-OCR their images, and DELETE irrelevant jsonl files\n",
    "reverify_only = True\n",
    "\n",
    "# If True → during reverify/flag pass, re-run OCR and (re)write the JSONL for each item\n",
    "reverify_rebuild_jsonl = True\n",
    "\n",
    "# Helper: regenerate a JSONL from a single image using the NIM extractor, bypassing the relevance gate\n",
    "def _regenerate_nim_jsonl(img_path: Path, dest_dir: Path, pdf_name_guess: str) -> tuple[bool, str]:\n",
    "    \"\"\"Re-run OCR and write <image>.nim.jsonl. Returns (ok, message).\"\"\"\n",
    "    try:\n",
    "        ex = NIMExtractor()\n",
    "        nim_df, ctx_extra = ex.extract_table(img_path, dest_dir, pdf_name_guess)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return False, \"No NIM table detected\"\n",
    "        ctx = ex._build_context(pdf_name_guess, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        out_path = img_path.with_suffix(f\".{ex.name}.jsonl\")\n",
    "        ex._write_jsonl(out_path, ctx, nim_df)\n",
    "        # Clear stale flag if any\n",
    "        flag = out_path.with_suffix(out_path.suffix + \".flag\")\n",
    "        if flag.exists():\n",
    "            try:\n",
    "                flag.unlink()\n",
    "            except Exception:\n",
    "                pass\n",
    "        return True, str(out_path)\n",
    "    except Exception as e:\n",
    "        return False, f\"exception:{e}\"\n",
    "\n",
    "\n",
    "def purge_irrelevant_jsonl_in_folder(dest_dir: Path, dry_run: bool = False, flag_only: bool = True):\n",
    "    \"\"\"\n",
    "    For each *.nim.jsonl in dest_dir, trace back to its source image and run strict NIM verification.\n",
    "    If invalid, flag the jsonl file with a .flag file (non-destructive by default).\n",
    "    Set dry_run=True to only log actions.\n",
    "    Optionally, rebuild JSONLs for all encountered items when reverify_rebuild_jsonl is True.\n",
    "    \"\"\"\n",
    "    jsonl_files = sorted(dest_dir.rglob(\"*.nim.jsonl\"))\n",
    "    if not jsonl_files:\n",
    "        return\n",
    "    for jf in jsonl_files:\n",
    "        try:\n",
    "            # Read first line to get _context.image if present\n",
    "            ctx = None\n",
    "            with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "                first = f.readline().strip()\n",
    "            if first.startswith(\"{\"):\n",
    "                import json\n",
    "                obj = json.loads(first)\n",
    "                ctx = obj.get(\"_context\", {})\n",
    "            image_name = ctx.get(\"image\") if isinstance(ctx, dict) else None\n",
    "\n",
    "            # Fallback: derive from stem\n",
    "            if not image_name:\n",
    "                image_name = jf.with_suffix(\"\").name\n",
    "                if image_name.endswith(\".nim\"):\n",
    "                    image_name = image_name[:-4]\n",
    "\n",
    "            # Locate image alongside jsonl\n",
    "            img_path = None\n",
    "            for ext in (\".png\", \".jpg\", \".jpeg\"):\n",
    "                cand = jf.with_suffix(\"\").with_suffix(ext)\n",
    "                if cand.exists():\n",
    "                    img_path = cand\n",
    "                    break\n",
    "                if image_name:\n",
    "                    alt = (jf.parent / image_name).with_suffix(ext)\n",
    "                    if alt.exists():\n",
    "                        img_path = alt\n",
    "                        break\n",
    "            if img_path is None:\n",
    "                print(f\"   ⚠️  {jf.name}: cannot find source image; skipping purge.\")\n",
    "                continue\n",
    "\n",
    "            pdf_name_guess = f\"{dest_dir.name}.pdf\"\n",
    "\n",
    "            ok, reason = is_strict_nim_image(img_path)\n",
    "            if not ok:\n",
    "                flag = jf.with_suffix(jf.suffix + \".flag\")\n",
    "                if dry_run:\n",
    "                    print(f\"   ⚑ Would flag {jf.name} (reason: {reason}) → {flag.name}\")\n",
    "                else:\n",
    "                    try:\n",
    "                        with open(flag, \"w\", encoding=\"utf-8\") as f:\n",
    "                            f.write(str(reason))\n",
    "                        print(f\"   ⚑ Flagged {jf.name} (reason: {reason}) → {flag.name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️  Could not write flag for {jf.name}: {e}\")\n",
    "                if reverify_rebuild_jsonl and not dry_run:\n",
    "                    ok2, msg2 = _regenerate_nim_jsonl(img_path, dest_dir, pdf_name_guess)\n",
    "                    if ok2:\n",
    "                        print(f\"   🔁 Rebuilt JSONL → {msg2}\")\n",
    "                    else:\n",
    "                        print(f\"   ⚠️  Rebuild skipped: {msg2}\")\n",
    "            else:\n",
    "                # If previously flagged, clear the flag when valid\n",
    "                flag = jf.with_suffix(jf.suffix + '.flag')\n",
    "                if flag.exists():\n",
    "                    try:\n",
    "                        flag.unlink()\n",
    "                        print(f\"   🧹 Cleared flag for {jf.name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️  Could not clear flag for {jf.name}: {e}\")\n",
    "                if reverify_rebuild_jsonl and not dry_run:\n",
    "                    ok2, msg2 = _regenerate_nim_jsonl(img_path, dest_dir, pdf_name_guess)\n",
    "                    if ok2:\n",
    "                        print(f\"   🔁 Rebuilt JSONL → {msg2}\")\n",
    "                    else:\n",
    "                        print(f\"   ⚠️  Rebuild skipped: {msg2}\")\n",
    "                print(f\"   ✅ Kept {jf.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Error checking {jf.name}: {e}\")\n",
    "\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available (only when running Marker)\n",
    "if not process_existing_only:\n",
    "    if not shutil.which(\"marker_single\"):\n",
    "        print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "        print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH, or set process_existing_only=True.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "# Purge-only mode: walk subfolders, delete irrelevant jsonl, then exit\n",
    "if 'reverify_only' in globals() and reverify_only:\n",
    "    print(\"🔍 reverify_only=True → Scanning JSONLs, flagging irrelevant ones, and rebuilding outputs…\")\n",
    "    for dest_dir in sorted([p for p in pdf_directory.iterdir() if p.is_dir()]):\n",
    "        print(f\"--- Purge pass in: {dest_dir} ---\")\n",
    "        purge_irrelevant_jsonl_in_folder(dest_dir, dry_run=False, flag_only=True)\n",
    "        print(f\"--- Done: {dest_dir.name} ---\\n\")\n",
    "    print(\"✅ Reverify-only purge complete.\")\n",
    "    if \"ipykernel\" not in sys.modules:\n",
    "        sys.exit(0)\n",
    "\n",
    "if process_existing_only:\n",
    "    print(\"🛠️  process_existing_only=True → Skipping Marker. Scanning existing extracted folders…\")\n",
    "    # Iterate subfolders under pdf_directory (each should be a per-PDF extraction folder)\n",
    "    for dest_dir in sorted([p for p in pdf_directory.iterdir() if p.is_dir()]):\n",
    "        pdf_name_guess = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"--- Processing extracted folder: {dest_dir} (as {pdf_name_guess}) ---\")\n",
    "        checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "        # Scan images and run all registered extractors\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_name_guess)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # Post-pass: reverify all generated *.nim.jsonl against source images\n",
    "        reverify_nim_jsonl_in_folder(dest_dir)\n",
    "        # After OCR completes for this folder, write/update checksum sidecar based on folder inputs\n",
    "        try:\n",
    "            checksum = md5_of_folder_inputs(dest_dir)\n",
    "            checksum_file.write_text(checksum)\n",
    "            print(f\"🧾 Recorded folder checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "        print(f\"--- Finished extracted folder: {dest_dir.name} ---\\n\")\n",
    "\n",
    "    print(\"🎉 All extracted folders in the directory have been processed.\")\n",
    "    if \"ipykernel\" not in sys.modules:\n",
    "        sys.exit(0)\n",
    "    \n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # Post-pass: reverify all generated *.nim.jsonl against source images\n",
    "        reverify_nim_jsonl_in_folder(dest_dir)\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06efae1",
   "metadata": {},
   "source": [
    "Enhanced jsonl check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25e832a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rebuilt JSONL → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation/_page_7_Figure_1.nim.jsonl\n",
      "🔍 reverify_only=True → Scanning JSONLs and flagging irrelevant ones (no rebuilds). Will stop after this pass…\n",
      "--- Purge pass in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation ---\n",
      "--- Done: 1Q24_CEO_presentation ---\n",
      "\n",
      "--- Purge pass in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Kept _page_4_Figure_1.nim.jsonl\n",
      "--- Done: 1Q24_CFO_presentation ---\n",
      "\n",
      "--- Purge pass in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update ---\n",
      "--- Done: 1Q24_trading_update ---\n",
      "\n",
      "--- Purge pass in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation ---\n",
      "--- Done: 1Q25_CEO_presentation ---\n",
      "\n",
      "--- Purge pass in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 873\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dest_dir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pdf_directory.iterdir() \u001b[38;5;28;01mif\u001b[39;00m p.is_dir()]):\n\u001b[32m    872\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Purge pass in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     \u001b[43mpurge_irrelevant_jsonl_in_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Done: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest_dir.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    875\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Reverify-only purge complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 808\u001b[39m, in \u001b[36mpurge_irrelevant_jsonl_in_folder\u001b[39m\u001b[34m(dest_dir, dry_run, flag_only)\u001b[39m\n\u001b[32m    804\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    806\u001b[39m pdf_name_guess = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest_dir.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m ok, reason = \u001b[43mis_strict_nim_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[32m    810\u001b[39m     flag = jf.with_suffix(jf.suffix + \u001b[33m\"\u001b[39m\u001b[33m.flag\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mis_strict_nim_image\u001b[39m\u001b[34m(img_path)\u001b[39m\n\u001b[32m     68\u001b[39m H, W = img_bgr.shape[:\u001b[32m2\u001b[39m]\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# 1) quick-text gate (soft): don't return yet; allow numeric signature to validate\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m kw_ok = \u001b[43mis_relevant_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNIM_KEYWORDS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# 2) numeric gate on enhanced image\u001b[39;00m\n\u001b[32m     72\u001b[39m img_up, gray, thr, scale = preprocess(img_bgr)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 609\u001b[39m, in \u001b[36mis_relevant_image\u001b[39m\u001b[34m(img_path, keywords)\u001b[39m\n\u001b[32m    607\u001b[39m \u001b[38;5;66;03m# Upscale a bit to help EasyOCR read thin underlined headings\u001b[39;00m\n\u001b[32m    608\u001b[39m scaled = cv2.resize(img, \u001b[38;5;28;01mNone\u001b[39;00m, fx=\u001b[32m1.2\u001b[39m, fy=\u001b[32m1.2\u001b[39m, interpolation=cv2.INTER_CUBIC)\n\u001b[32m--> \u001b[39m\u001b[32m609\u001b[39m results = \u001b[43mrdr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join([t.lower() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(k \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keywords)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/easyocr/easyocr.py:456\u001b[39m, in \u001b[36mReader.readtext\u001b[39m\u001b[34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    451\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[33;03mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    454\u001b[39m img, img_cv_grey = reformat_input(image)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m horizontal_list, free_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreformat\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[32m    467\u001b[39m horizontal_list, free_list = horizontal_list[\u001b[32m0\u001b[39m], free_list[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/easyocr/easyocr.py:321\u001b[39m, in \u001b[36mReader.detect\u001b[39m\u001b[34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[32m    319\u001b[39m     img, img_cv_grey = reformat_input(img)\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m text_box_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m                            \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m horizontal_list_agg, free_list_agg = [], []\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/easyocr/detection.py:95\u001b[39m, in \u001b[36mget_textbox\u001b[39m\u001b[34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m result = []\n\u001b[32m     94\u001b[39m estimate_num_chars = optimal_num_chars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m bboxes_list, polys_list = \u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimate_num_chars:\n\u001b[32m    100\u001b[39m     polys_list = [[p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(polys, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(optimal_num_chars - x[\u001b[32m1\u001b[39m]))]\n\u001b[32m    101\u001b[39m                   \u001b[38;5;28;01mfor\u001b[39;00m polys \u001b[38;5;129;01min\u001b[39;00m polys_list]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/easyocr/detection.py:46\u001b[39m, in \u001b[36mtest_net\u001b[39m\u001b[34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     y, feature = \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m boxes_list, polys_list = [], []\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# make score and link map\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/easyocr/craft.py:64\u001b[39m, in \u001b[36mCRAFT.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" U network \"\"\"\u001b[39;00m\n\u001b[32m     63\u001b[39m y = torch.cat([sources[\u001b[32m0\u001b[39m], sources[\u001b[32m1\u001b[39m]], dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m y = F.interpolate(y, size=sources[\u001b[32m2\u001b[39m].size()[\u001b[32m2\u001b[39m:], mode=\u001b[33m'\u001b[39m\u001b[33mbilinear\u001b[39m\u001b[33m'\u001b[39m, align_corners=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     67\u001b[39m y = torch.cat([y, sources[\u001b[32m2\u001b[39m]], dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/easyocr/craft.py:26\u001b[39m, in \u001b[36mdouble_conv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def md5_of_folder_inputs(dest_dir: Path) -> str:\n",
    "    \"\"\"\n",
    "    Compute an md5 hash over the extracted inputs in dest_dir.\n",
    "    Includes only source artifacts likely produced by Marker (md/json/images),\n",
    "    excludes derived *.jsonl outputs and .marker_md5.\n",
    "    \"\"\"\n",
    "    h = hashlib.md5()\n",
    "    include_exts = {\".md\", \".json\", \".png\", \".jpg\", \".jpeg\"}\n",
    "    paths = []\n",
    "    for p in dest_dir.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            if p.name == \".marker_md5\":\n",
    "                continue\n",
    "            if p.suffix.lower() in include_exts:\n",
    "                paths.append(p)\n",
    "    # Stable order for deterministic hash\n",
    "    for p in sorted(paths, key=lambda x: str(x.relative_to(dest_dir))):\n",
    "        rel = str(p.relative_to(dest_dir)).encode(\"utf-8\")\n",
    "        try:\n",
    "            with open(p, \"rb\") as f:\n",
    "                data = f.read()\n",
    "        except Exception:\n",
    "            data = b\"\"\n",
    "        h.update(rel + b\"\\x00\" + hashlib.md5(data).hexdigest().encode(\"utf-8\"))\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers (standalone in Untitled-1) ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "# NIM value band (pct) and geometry heuristics for verification\n",
    "NIM_MIN, NIM_MAX = 1.3, 3.2\n",
    "TOP_FRACTION = 0.45     # upper portion of image for NIM labels\n",
    "RIGHT_HALF_ONLY = True  # NIM values appear on right panel in these decks\n",
    "def is_strict_nim_image(img_path: Path) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Heuristic re-check:\n",
    "      1) Title/text contains NIM keywords (coarse gate)\n",
    "      2) Percent tokens mostly within NIM_MIN..NIM_MAX\n",
    "      3) Tokens located in the top region (and right half, if enabled)\n",
    "    Returns (ok, reason)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_bgr = load_image(img_path)\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        # 1) quick-text gate (soft): don't return yet; allow numeric signature to validate\n",
    "        kw_ok = is_relevant_image(img_path, NIM_KEYWORDS)\n",
    "        # 2) numeric gate on enhanced image\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # --- Semantic gate: accept classic NIM slides based on stable labels ---\n",
    "        text_lower = \" \".join(str(r.get(\"text\", \"\")).lower() for r in ocr or [])\n",
    "        has_nim = \"net interest margin\" in text_lower\n",
    "        has_cb  = \"commercial book\" in text_lower\n",
    "        has_grp = \"group\" in text_lower\n",
    "        if has_nim and (has_cb or has_grp):\n",
    "            which = [w for w, ok in ((\"nim\", has_nim), (\"cb\", has_cb), (\"grp\", has_grp)) if ok]\n",
    "            return (True, f\"ok_semantic({'+' .join(which)})\")\n",
    "        df = extract_numbers(ocr)\n",
    "        if df.empty:\n",
    "            return (False, \"no_numbers\")\n",
    "        # geometry filters (apply before value checks)\n",
    "        top_cut = int(img_up.shape[0] * TOP_FRACTION)\n",
    "        cond_geom = (df[\"cy\"] < top_cut)\n",
    "        if RIGHT_HALF_ONLY:\n",
    "            cond_geom &= (df[\"cx\"] > (img_up.shape[1] // 2))\n",
    "\n",
    "        # 2a) Preferred path: explicit percentage tokens\n",
    "        df_pct = df[(df[\"is_pct\"] == True) & cond_geom].copy()\n",
    "        if not df_pct.empty:\n",
    "            in_band = df_pct[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_pct))\n",
    "            if ratio >= 0.6:\n",
    "                return (True, \"ok\")\n",
    "            else:\n",
    "                return (False, f\"non_nim_values_out_of_band({ratio:.2f})\")\n",
    "\n",
    "        # 2b) Fallback: some decks omit the % sign near the series values.\n",
    "        # Accept plain numbers in the NIM range if units are explicit or implied, or if numeric signature is strong.\n",
    "        title_text = text_lower  # already computed above\n",
    "        has_units_pct = \"(%)\" in title_text or \"margin (%)\" in title_text or \"net interest margin\" in title_text\n",
    "        df_nums = df[(df[\"is_pct\"] == False) & cond_geom].copy()\n",
    "        if not df_nums.empty:\n",
    "            in_band = df_nums[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_nums))\n",
    "            # Case A: explicit or implied units in title → accept when enough in-band hits\n",
    "            if has_units_pct and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_no_percent_signs\")\n",
    "            # Case B: title OCR may have missed units; if the quick keyword gate succeeded, accept with a stricter ratio\n",
    "            if kw_ok and ratio >= 0.7 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_numeric_signature\")\n",
    "\n",
    "        # Final decision: if numeric signature still failed, report clearer reason\n",
    "        if not kw_ok:\n",
    "            return (False, \"irrelevant_non_nim\")\n",
    "        else:\n",
    "            return (False, \"no_percentages_or_units\")\n",
    "    except Exception as e:\n",
    "        return (False, f\"exception:{e}\")\n",
    "\n",
    "def reverify_nim_jsonl_in_folder(dest_dir: Path):\n",
    "    \"\"\"\n",
    "    For each *.nim.jsonl, trace back to its source image and verify with strict rules.\n",
    "    If invalid, suffix the file with '.rejected' (non-destructive).\n",
    "    \"\"\"\n",
    "    jsonl_files = sorted(dest_dir.rglob(\"*.nim.jsonl\"))\n",
    "    if not jsonl_files:\n",
    "        return\n",
    "    for jf in jsonl_files:\n",
    "        try:\n",
    "            # Read first line (_context) to find image path if present\n",
    "            ctx = None\n",
    "            with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "                first = f.readline().strip()\n",
    "            if first.startswith(\"{\"):\n",
    "                import json\n",
    "                obj = json.loads(first)\n",
    "                ctx = obj.get(\"_context\", {})\n",
    "            image_name = None\n",
    "            if ctx and isinstance(ctx, dict):\n",
    "                image_name = ctx.get(\"image\", None)\n",
    "            # Fallback: derive from filename\n",
    "            if not image_name:\n",
    "                image_name = jf.with_suffix(\"\").name  # <image>.<name>.jsonl → <image>.<name>\n",
    "                # Try removing extractor suffix\n",
    "                if image_name.endswith(\".nim\"):\n",
    "                    image_name = image_name[:-4]\n",
    "                # Re-add common image extension guesses\n",
    "            # Locate image next to jsonl\n",
    "            img_path = None\n",
    "            for ext in (\".png\", \".jpg\", \".jpeg\"):\n",
    "                cand = jf.with_suffix(\"\").with_suffix(ext)\n",
    "                # If name has .nim in the stem, swap: <stem>.nim.jsonl → <stem>.jpeg\n",
    "                if cand.exists():\n",
    "                    img_path = cand\n",
    "                    break\n",
    "                if image_name:\n",
    "                    alt = (jf.parent / image_name).with_suffix(ext)\n",
    "                    if alt.exists():\n",
    "                        img_path = alt\n",
    "                        break\n",
    "            if img_path is None:\n",
    "                print(f\"   ⚠️  {jf.name}: cannot find source image; skipping reverification.\")\n",
    "                continue\n",
    "            ok, reason = is_strict_nim_image(img_path)\n",
    "            if not ok:\n",
    "                flag = jf.with_suffix(jf.suffix + \".flag\")\n",
    "                try:\n",
    "                    with open(flag, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(str(reason))\n",
    "                    print(f\"   ⚑ Flagged {jf.name} (reason: {reason}) → {flag.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ⚠️  Could not write flag for {jf.name}: {e}\")\n",
    "            else:\n",
    "                # If a previous flag exists but this file now validates, remove the stale flag\n",
    "                flag = jf.with_suffix(jf.suffix + \".flag\")\n",
    "                if flag.exists():\n",
    "                    try:\n",
    "                        flag.unlink()\n",
    "                        print(f\"   🧹 Cleared flag for {jf.name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️  Could not clear flag for {jf.name}: {e}\")\n",
    "                print(f\"   ✅ Verified {jf.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Error checking {jf.name}: {e}\")\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4])Q(\\d{2}|\\d{4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.70)  # bottom 30%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: for ordering we only need x\n",
    "        qtokens = []\n",
    "        for r in ocr or []:\n",
    "            txt = str(r.get(\"text\",\"\")).strip()\n",
    "            m = QUARTER_PAT.search(txt)\n",
    "            if not m:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            # Convert x from upsampled-crop space back to original global space\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.0)  # undo scale\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            qtokens.append((cx_global, q))\n",
    "        qtokens.sort(key=lambda x: x[0])\n",
    "        # Dedup by proximity and text\n",
    "        ordered = []\n",
    "        last_x = -9999\n",
    "        last_q = None\n",
    "        for x, q in qtokens:\n",
    "            if last_q == q and abs(x - last_x) < 30:\n",
    "                continue\n",
    "            ordered.append(q)\n",
    "            last_x, last_q = x, q\n",
    "        return ordered\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "            \n",
    "    # --- Detect quarter labels once (OCR full + bottom crop), reusable below ---\n",
    "    detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "    detected_q_bot = detect_qlabels_bottom(img_up)\n",
    "    # Prefer the source with more tokens, but merge to keep any uniques\n",
    "    if len(detected_q_bot) > len(detected_q_ocr):\n",
    "        detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "    else:\n",
    "        detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\").reset_index(drop=True)\n",
    "            n = len(pick)\n",
    "            # Choose quarter labels: detected OCR → markdown hint → anchor expansion → placeholders\n",
    "            labels = []\n",
    "            if detected_q:\n",
    "                labels = detected_q[-n:] if len(detected_q) >= n else detected_q\n",
    "            if (not labels or len(labels) != n) and qlabels_hint:\n",
    "                labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if not labels or len(labels) != n:\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if not labels or len(labels) != n:\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "\n",
    "        if rows:\n",
    "            nim_df = pd.DataFrame(rows)\n",
    "            nim_df = nim_df.pivot_table(index=\"Quarter\", columns=\"series\", values=\"value\", aggfunc=\"first\").reset_index()\n",
    "            # Make column order stable: Quarter first, then sorted series names\n",
    "            cols = [\"Quarter\"] + sorted([c for c in nim_df.columns if c != \"Quarter\"])\n",
    "            nim_df = nim_df[cols]\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text against given keywords.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        # Upscale a bit to help EasyOCR read thin underlined headings\n",
    "        scaled = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "        results = rdr.readtext(scaled, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in keywords)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        if not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "process_existing_only = True\n",
    "\n",
    "# If True → ONLY scan existing *.nim.jsonl files, re-OCR their images, and DELETE irrelevant jsonl files\n",
    "reverify_only = True\n",
    "\n",
    "# Disable auto-rebuilds during reverify; rebuild only via single-image mode\n",
    "reverify_rebuild_jsonl = False\n",
    "reverify_rebuild_on_keep = False\n",
    "reverify_rebuild_on_flag = False\n",
    "\n",
    "# Single-image regeneration mode: set to True and provide an absolute image path\n",
    "single_image_mode = True\n",
    "single_image_path = \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation/_page_7_Figure_1.jpeg\"  # e.g., \"/Users/.../All/1Q24_CFO_presentation/_page_4_Figure_1.jpeg\"\n",
    "\n",
    "\n",
    "# Helper: regenerate a JSONL from a single image using the NIM extractor, bypassing the relevance gate\n",
    "def _regenerate_nim_jsonl(img_path: Path, dest_dir: Path, pdf_name_guess: str) -> tuple[bool, str]:\n",
    "    \"\"\"Re-run OCR and write <image>.nim.jsonl. Returns (ok, message).\"\"\"\n",
    "    try:\n",
    "        ex = NIMExtractor()\n",
    "        nim_df, ctx_extra = ex.extract_table(img_path, dest_dir, pdf_name_guess)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return False, \"No NIM table detected\"\n",
    "        ctx = ex._build_context(pdf_name_guess, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        out_path = img_path.with_suffix(f\".{ex.name}.jsonl\")\n",
    "        ex._write_jsonl(out_path, ctx, nim_df)\n",
    "        # Clear stale flag if any\n",
    "        flag = out_path.with_suffix(out_path.suffix + \".flag\")\n",
    "        if flag.exists():\n",
    "            try:\n",
    "                flag.unlink()\n",
    "            except Exception:\n",
    "                pass\n",
    "        return True, str(out_path)\n",
    "    except Exception as e:\n",
    "        return False, f\"exception:{e}\"\n",
    "\n",
    "\n",
    "def purge_irrelevant_jsonl_in_folder(dest_dir: Path, dry_run: bool = False, flag_only: bool = True):\n",
    "    \"\"\"\n",
    "    For each *.nim.jsonl in dest_dir, trace back to its source image and run strict NIM verification.\n",
    "    If invalid, flag the jsonl file with a .flag file (non-destructive by default).\n",
    "    Set dry_run=True to only log actions.\n",
    "    \"\"\"\n",
    "    jsonl_files = sorted(dest_dir.rglob(\"*.nim.jsonl\"))\n",
    "    if not jsonl_files:\n",
    "        return\n",
    "    for jf in jsonl_files:\n",
    "        try:\n",
    "            # Read first line to get _context.image if present\n",
    "            ctx = None\n",
    "            with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "                first = f.readline().strip()\n",
    "            if first.startswith(\"{\"):\n",
    "                import json\n",
    "                obj = json.loads(first)\n",
    "                ctx = obj.get(\"_context\", {})\n",
    "            image_name = ctx.get(\"image\") if isinstance(ctx, dict) else None\n",
    "\n",
    "            # Fallback: derive from stem\n",
    "            if not image_name:\n",
    "                image_name = jf.with_suffix(\"\").name\n",
    "                if image_name.endswith(\".nim\"):\n",
    "                    image_name = image_name[:-4]\n",
    "\n",
    "            # Locate image alongside jsonl\n",
    "            img_path = None\n",
    "            for ext in (\".png\", \".jpg\", \".jpeg\"):\n",
    "                cand = jf.with_suffix(\"\").with_suffix(ext)\n",
    "                if cand.exists():\n",
    "                    img_path = cand\n",
    "                    break\n",
    "                if image_name:\n",
    "                    alt = (jf.parent / image_name).with_suffix(ext)\n",
    "                    if alt.exists():\n",
    "                        img_path = alt\n",
    "                        break\n",
    "            if img_path is None:\n",
    "                print(f\"   ⚠️  {jf.name}: cannot find source image; skipping purge.\")\n",
    "                continue\n",
    "\n",
    "            pdf_name_guess = f\"{dest_dir.name}.pdf\"\n",
    "\n",
    "            ok, reason = is_strict_nim_image(img_path)\n",
    "            if not ok:\n",
    "                flag = jf.with_suffix(jf.suffix + \".flag\")\n",
    "                if dry_run:\n",
    "                    print(f\"   ⚑ Would flag {jf.name} (reason: {reason}) → {flag.name}\")\n",
    "                else:\n",
    "                    try:\n",
    "                        with open(flag, \"w\", encoding=\"utf-8\") as f:\n",
    "                            f.write(str(reason))\n",
    "                        print(f\"   ⚑ Flagged {jf.name} (reason: {reason}) → {flag.name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️  Could not write flag for {jf.name}: {e}\")\n",
    "            else:\n",
    "                # If previously flagged, clear the flag when valid\n",
    "                flag = jf.with_suffix(jf.suffix + '.flag')\n",
    "                if flag.exists():\n",
    "                    try:\n",
    "                        flag.unlink()\n",
    "                        print(f\"   🧹 Cleared flag for {jf.name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️  Could not clear flag for {jf.name}: {e}\")\n",
    "                print(f\"   ✅ Kept {jf.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️  Error checking {jf.name}: {e}\")\n",
    "\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available (only when running Marker)\n",
    "if not process_existing_only:\n",
    "    if not shutil.which(\"marker_single\"):\n",
    "        print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "        print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH, or set process_existing_only=True.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "# --- Single-image regeneration entrypoint ---\n",
    "if 'single_image_mode' in globals() and single_image_mode:\n",
    "    p = Path(single_image_path)\n",
    "    if not p.is_file():\n",
    "        print(f\"❌ single_image_mode: image not found: {p}\")\n",
    "        if \"ipykernel\" not in sys.modules:\n",
    "            sys.exit(2)\n",
    "    dest_dir = p.parent\n",
    "    pdf_name_guess = f\"{dest_dir.name}.pdf\"\n",
    "    ok, msg = _regenerate_nim_jsonl(p, dest_dir, pdf_name_guess)\n",
    "    if ok:\n",
    "        print(f\"✅ Rebuilt JSONL → {msg}\")\n",
    "    else:\n",
    "        print(f\"⚠️  Rebuild failed/skipped: {msg}\")\n",
    "    # Exit after single-image action to avoid scanning folders\n",
    "    if \"ipykernel\" not in sys.modules:\n",
    "        sys.exit(0)\n",
    "             \n",
    "# Purge-only mode: walk subfolders, delete irrelevant jsonl, then exit\n",
    "if 'reverify_only' in globals() and reverify_only:\n",
    "    print(\"🔍 reverify_only=True → Scanning JSONLs and flagging irrelevant ones (no rebuilds). Will stop after this pass…\")\n",
    "    for dest_dir in sorted([p for p in pdf_directory.iterdir() if p.is_dir()]):\n",
    "        print(f\"--- Purge pass in: {dest_dir} ---\")\n",
    "        purge_irrelevant_jsonl_in_folder(dest_dir, dry_run=False, flag_only=True)\n",
    "        print(f\"--- Done: {dest_dir.name} ---\\n\")\n",
    "    print(\"✅ Reverify-only purge complete.\")\n",
    "    # Prevent further processing in this run\n",
    "    globals()[\"_STOP_AFTER_REVERIFY\"] = True\n",
    "    if \"ipykernel\" not in sys.modules:\n",
    "        sys.exit(0)\n",
    "\n",
    "if not globals().get(\"_STOP_AFTER_REVERIFY\", False) and process_existing_only:\n",
    "    print(\"🛠️  process_existing_only=True → Skipping Marker. Scanning existing extracted folders…\")\n",
    "    # Iterate subfolders under pdf_directory (each should be a per-PDF extraction folder)\n",
    "    for dest_dir in sorted([p for p in pdf_directory.iterdir() if p.is_dir()]):\n",
    "        pdf_name_guess = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"--- Processing extracted folder: {dest_dir} (as {pdf_name_guess}) ---\")\n",
    "        checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "        # Scan images and run all registered extractors\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                any_hit = True\n",
    "                print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_name_guess)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # Post-pass: reverify all generated *.nim.jsonl against source images\n",
    "        reverify_nim_jsonl_in_folder(dest_dir)\n",
    "        # After OCR completes for this folder, write/update checksum sidecar based on folder inputs\n",
    "        try:\n",
    "            checksum = md5_of_folder_inputs(dest_dir)\n",
    "            checksum_file.write_text(checksum)\n",
    "            print(f\"🧾 Recorded folder checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "        print(f\"--- Finished extracted folder: {dest_dir.name} ---\\n\")\n",
    "\n",
    "    print(\"🎉 All extracted folders in the directory have been processed.\")\n",
    "    if \"ipykernel\" not in sys.modules:\n",
    "        sys.exit(0)\n",
    "    \n",
    "# Loop through PDFs only when not in reverify-only mode and not in process-existing-only mode\n",
    "if not globals().get(\"_STOP_AFTER_REVERIFY\", False) and not process_existing_only:\n",
    "    for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "        print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "        # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "        # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "        output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "        # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "        dest_dir = output_parent / pdf_path.stem\n",
    "        checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "        # Compute the current md5 of the source PDF\n",
    "        current_md5 = md5sum(pdf_path)\n",
    "\n",
    "        # Define the expected main outputs (Marker uses the same stem)\n",
    "        expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "        expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "        outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "        # md5 two-mode logic\n",
    "        if md5_check:\n",
    "            # Normal: skip if checksum matches and key outputs exist\n",
    "            if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "                try:\n",
    "                    saved_md5 = checksum_file.read_text().strip()\n",
    "                except Exception:\n",
    "                    saved_md5 = \"\"\n",
    "                if saved_md5 == current_md5:\n",
    "                    print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                    print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                    try:\n",
    "                        shutil.rmtree(dest_dir)\n",
    "                    except Exception as _e:\n",
    "                        print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "            else:\n",
    "                print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "        else:\n",
    "            # Force reprocess regardless of checksum\n",
    "            print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "            if dest_dir.exists():\n",
    "                print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "        try:\n",
    "            # ======================================================================\n",
    "            # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "            # ======================================================================\n",
    "            print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "            json_command = [\n",
    "                \"marker_single\",\n",
    "                str(pdf_path),\n",
    "                \"--output_format\", \"json\",\n",
    "                \"--output_dir\", str(output_parent)\n",
    "            ]\n",
    "            # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "            result_json = subprocess.run(json_command, check=True)\n",
    "            print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "            # ======================================================================\n",
    "            # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "            # ======================================================================\n",
    "            print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "            md_command = [\n",
    "                \"marker_single\",\n",
    "                str(pdf_path),\n",
    "                # Default format is markdown, so we don't need to specify it\n",
    "                \"--output_dir\", str(output_parent)\n",
    "            ]\n",
    "            result_md = subprocess.run(md_command, check=True)\n",
    "            print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "            print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "            print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "            # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "            print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "            img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "            img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "            if not img_files:\n",
    "                print(\"   🖼️  No images found in extracted folder.\")\n",
    "            for img_path in sorted(img_files):\n",
    "                print(f\"   • {img_path.name}\")\n",
    "                any_hit = False\n",
    "                for ex in EXTRACTORS:\n",
    "                    print(f\"      · [{ex.name}] relevance check…\", end=\" \")\n",
    "                    if not ex.is_relevant(img_path):\n",
    "                        print(\"⏭️  Not relevant\")\n",
    "                        continue\n",
    "                    any_hit = True\n",
    "                    print(\"✅ Relevant — extracting…\", end=\" \")\n",
    "                    ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name)\n",
    "                    if ok:\n",
    "                        print(f\"💾 Saved → {msg}\")\n",
    "                    else:\n",
    "                        print(f\"⚠️ Skipped ({msg})\")\n",
    "                if not any_hit:\n",
    "                    print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "            # Post-pass: reverify all generated *.nim.jsonl against source images\n",
    "            reverify_nim_jsonl_in_folder(dest_dir)\n",
    "            # After OCR completes, write/update checksum sidecar\n",
    "            try:\n",
    "                dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "                checksum_file.write_text(current_md5)\n",
    "                print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "            except Exception as _e:\n",
    "                print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "            print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "            print(f\"Return Code: {e.returncode}\")\n",
    "            print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "        \n",
    "        print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "    print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeebf59",
   "metadata": {},
   "source": [
    "Beta Test Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7c76697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: Demo PDF Merge.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "Running CLI command for JSON output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 20:01:57,234 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:12<00:00,  6.30s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 20:02:11,332 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 20:02:11,332 [INFO] marker: Total time: 12.91714096069336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF Merge.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 20:02:19,045 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 2/2 [00:09<00:00,  4.99s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 26.01it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 20:02:29,866 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge\n",
      "2025-10-30 20:02:29,866 [INFO] marker: Total time: 10.215930223464966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_2.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ok; strict gate… ✅ Strict OK — extracting… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/_page_0_Figure_2.nim.jsonl\n",
      "   • _page_1_Figure_3.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF Merge/.marker_md5\n",
      "--- Finished processing: Demo PDF Merge.pdf ---\n",
      "\n",
      "--- Processing file: Demo PDF.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "    Cleaning existing folder: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "Running CLI command for JSON output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 20:03:18,603 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.67s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 20:03:26,622 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 20:03:26,623 [INFO] marker: Total time: 6.868319034576416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on Demo PDF.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 20:03:36,573 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 1/1 [00:06<00:00,  6.53s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 20:03:44,317 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF\n",
      "2025-10-30 20:03:44,317 [INFO] marker: Total time: 6.72737717628479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Figure_3.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/Demo PDF/.marker_md5\n",
      "--- Finished processing: Demo PDF.pdf ---\n",
      "\n",
      "--- Processing file: 3Q24_CFO_presentation.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "Running CLI command for JSON output on 3Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 20:03:58,454 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 21/21 [01:53<00:00,  5.38s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 6/6 [00:01<00:00,  5.42it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Recognizing Text: 100%|██████████| 13/13 [00:33<00:00,  2.61s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:04<00:00,  4.93s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "Recognizing Text: 100%|██████████| 42/42 [00:11<00:00,  3.82it/s]\n",
      "2025-10-30 20:06:56,216 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation\n",
      "2025-10-30 20:06:56,216 [INFO] marker: Total time: 176.57989597320557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 3Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 20:07:07,233 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 21/21 [01:53<00:00,  5.39s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 6/6 [00:00<00:00, 15.03it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Recognizing Text: 100%|██████████| 13/13 [00:33<00:00,  2.60s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "Recognizing Text: 100%|██████████| 42/42 [00:10<00:00,  3.88it/s]\n",
      "2025-10-30 20:10:02,935 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation\n",
      "2025-10-30 20:10:02,935 [INFO] marker: Total time: 174.69536089897156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_3.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_3.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_5.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_16.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_0.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_11.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Figure_4.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_8.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ⏭️  Failed strict (no_percentages_or_units)\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ⏭️  Failed strict (no_percentages_or_units)\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation/_page_7_Figure_1.nim.jsonl\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_6.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation/.marker_md5\n",
      "--- Finished processing: 3Q24_CFO_presentation.pdf ---\n",
      "\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4])Q(\\d{2}|\\d{4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = rdr.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "# NIM value band (pct) and geometry heuristics for verification\n",
    "NIM_MIN, NIM_MAX = 1.3, 3.2\n",
    "TOP_FRACTION = 0.45     # upper portion of image for NIM labels\n",
    "RIGHT_HALF_ONLY = True  # NIM values appear on right panel in these deck\n",
    "\n",
    "def is_strict_nim_image(img_path: Path) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Heuristic re-check:\n",
    "      1) Title/text contains NIM keywords (coarse gate)\n",
    "      2) Percent tokens mostly within NIM_MIN..NIM_MAX\n",
    "      3) Tokens located in the top region (and right half, if enabled)\n",
    "    Returns (ok, reason)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_bgr = load_image(img_path)\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        # 1) quick-text gate (soft): don't return yet; allow numeric signature to validate\n",
    "        kw_ok = is_relevant_image(img_path, NIM_KEYWORDS)\n",
    "        # 2) numeric gate on enhanced image\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # --- Semantic gate: accept classic NIM slides based on stable labels ---\n",
    "        text_lower = \" \".join(str(r.get(\"text\", \"\")).lower() for r in ocr or [])\n",
    "        has_nim = \"net interest margin\" in text_lower\n",
    "        has_cb  = \"commercial book\" in text_lower\n",
    "        has_grp = \"group\" in text_lower\n",
    "        if has_nim and (has_cb or has_grp):\n",
    "            which = [w for w, ok in ((\"nim\", has_nim), (\"cb\", has_cb), (\"grp\", has_grp)) if ok]\n",
    "            return (True, f\"ok_semantic({'+' .join(which)})\")\n",
    "        df = extract_numbers(ocr)\n",
    "        if df.empty:\n",
    "            return (False, \"no_numbers\")\n",
    "        # geometry filters (apply before value checks)\n",
    "        top_cut = int(img_up.shape[0] * TOP_FRACTION)\n",
    "        cond_geom = (df[\"cy\"] < top_cut)\n",
    "        if RIGHT_HALF_ONLY:\n",
    "            cond_geom &= (df[\"cx\"] > (img_up.shape[1] // 2))\n",
    "\n",
    "        # 2a) Preferred path: explicit percentage tokens\n",
    "        df_pct = df[(df[\"is_pct\"] == True) & cond_geom].copy()\n",
    "        if not df_pct.empty:\n",
    "            in_band = df_pct[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_pct))\n",
    "            if ratio >= 0.6:\n",
    "                return (True, \"ok\")\n",
    "            else:\n",
    "                return (False, f\"non_nim_values_out_of_band({ratio:.2f})\")\n",
    "\n",
    "        # 2b) Fallback: some decks omit the % sign near the series values.\n",
    "        # Accept plain numbers in the NIM range if units are explicit or implied, or if numeric signature is strong.\n",
    "        title_text = text_lower  # already computed above\n",
    "        has_units_pct = \"(%)\" in title_text or \"margin (%)\" in title_text or \"net interest margin\" in title_text\n",
    "        df_nums = df[(df[\"is_pct\"] == False) & cond_geom].copy()\n",
    "        if not df_nums.empty:\n",
    "            in_band = df_nums[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_nums))\n",
    "            # Case A: explicit or implied units in title → accept when enough in-band hits\n",
    "            if has_units_pct and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_no_percent_signs\")\n",
    "            # Case B: title OCR may have missed units; if the quick keyword gate succeeded, accept with a stricter ratio\n",
    "            if kw_ok and ratio >= 0.7 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_numeric_signature\")\n",
    "\n",
    "        # Final decision: if numeric signature still failed, report clearer reason\n",
    "        if not kw_ok:\n",
    "            return (False, \"irrelevant_non_nim\")\n",
    "        else:\n",
    "            return (False, \"no_percentages_or_units\")\n",
    "    except Exception as e:\n",
    "        return (False, f\"exception:{e}\")\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.70)  # bottom 30%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: for ordering we only need x\n",
    "        qtokens = []\n",
    "        for r in ocr or []:\n",
    "            txt = str(r.get(\"text\",\"\")).strip()\n",
    "            m = QUARTER_PAT.search(txt)\n",
    "            if not m:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            # Convert x from upsampled-crop space back to original global space\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.0)  # undo scale\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            qtokens.append((cx_global, q))\n",
    "        qtokens.sort(key=lambda x: x[0])\n",
    "        # Dedup by proximity and text\n",
    "        ordered = []\n",
    "        last_x = -9999\n",
    "        last_q = None\n",
    "        for x, q in qtokens:\n",
    "            if last_q == q and abs(x - last_x) < 30:\n",
    "                continue\n",
    "            ordered.append(q)\n",
    "            last_x, last_q = x, q\n",
    "        return ordered\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "    nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        approx_top = int(H * 0.35)\n",
    "        cand_pct = df[(df.cx > mid_x) & (df.value.between(1.3, 3.2)) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        if pct.shape[0] >= 8:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)\n",
    "            remap = {order[0]:\"Commercial NIM (%)\", order[1]:\"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        # --- Dynamic quarter labels ---\n",
    "        detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "        detected_q_bot = detect_qlabels_bottom(img_up)\n",
    "        # Prefer the source with more tokens, but merge to keep any uniques\n",
    "        if len(detected_q_bot) > len(detected_q_ocr):\n",
    "            detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "        else:\n",
    "            detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            pick = sub.sort_values(\"cx\").tail(5).sort_values(\"cx\")\n",
    "            n = len(pick)\n",
    "            labels = []\n",
    "            # 1) Prefer OCR-detected quarters (left→right)\n",
    "            if detected_q:\n",
    "                # Use the rightmost n (latest) detected quarters to align with right-panel values\n",
    "                labels = detected_q[-n:] if len(detected_q) >= n else detected_q\n",
    "            # 2) If insufficient, try markdown-derived hint tokens (document order)\n",
    "            if (not labels or len(labels) != n) and qlabels_hint:\n",
    "                labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            # 3) Final fallback: infer a sequence from any anchor like 2Q24\n",
    "            if not labels or len(labels) != n:\n",
    "                # Try to infer an anchor quarter from OCR or markdown and expand\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            # 4) If still nothing, use neutral placeholders\n",
    "            if not labels or len(labels) != n:\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "            for i, r in enumerate(pick.itertuples(index=False)):\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text against given keywords.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in keywords)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str, *, bypass_relevance: bool = False):\n",
    "        if not bypass_relevance and not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                # Stage 1: quick keyword/title skim\n",
    "                print(f\"      · [{ex.name}] quick gate…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                print(\"✅ ok; strict gate…\", end=\" \")\n",
    "\n",
    "                # Stage 2: strict verifier (geometry + numeric band + semantic anchors)\n",
    "                ok_strict, reason = is_strict_nim_image(img_path)\n",
    "                if not ok_strict:\n",
    "                    print(f\"⏭️  Failed strict ({reason})\")\n",
    "                    continue\n",
    "\n",
    "                any_hit = True\n",
    "                print(\"✅ Strict OK — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name, bypass_relevance=True)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb1044",
   "metadata": {},
   "source": [
    "Working Quarter Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64f22e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================\n",
      "Image: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/_page_4_Figure_1.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Raw tokens from bottom axis:\n",
      "  - Raw: 'Commercial book'  ->  Normalized: 'C0mmercia1b00k'\n",
      "  - Raw: '3,384'  ->  Normalized: '3,334'\n",
      "  - Raw: '3,581'  ->  Normalized: '3,531'\n",
      "  - Raw: '3,684'  ->  Normalized: '3,634'\n",
      "  - Raw: '3,637'  ->  Normalized: '3,637'\n",
      "  - Raw: '3,647'  ->  Normalized: '3,647'\n",
      "  - Raw: 'Markets trading'  ->  Normalized: 'Market5trading'\n",
      "  - Raw: ''113'  ->  Normalized: ''113'\n",
      "  - Raw: ''148'  ->  Normalized: ''143'\n",
      "  - Raw: ''180'  ->  Normalized: ''130'\n",
      "  - Raw: '2203'  ->  Normalized: '2203'\n",
      "  - Raw: '142'  ->  Normalized: '142'\n",
      "  - Raw: '1023'  ->  Normalized: '1023'\n",
      "  - Raw: '2023'  ->  Normalized: '2023'\n",
      "  - Raw: '3023'  ->  Normalized: '3023'\n",
      "  - Raw: '4023'  ->  Normalized: '4023'\n",
      "  - Raw: '1Q24'  ->  Normalized: '1Q24'\n",
      "Detected quarters (EasyOCR, bottom axis): 1Q23, 2Q23, 3Q23, 4Q23, 1Q24\n",
      "x-pos: [683, 1040, 1396, 1753, 2111]\n",
      "\n",
      "========================================================================================\n",
      "Image: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_5_Figure_1.jpeg\n",
      "\n",
      "[DEBUG] Raw tokens from bottom axis:\n",
      "  - Raw: '3,581'  ->  Normalized: '3,531'\n",
      "  - Raw: '3,684'  ->  Normalized: '3,634'\n",
      "  - Raw: '3,637'  ->  Normalized: '3,637'\n",
      "  - Raw: '3,647'  ->  Normalized: '3,647'\n",
      "  - Raw: 'O,05'  ->  Normalized: '0,05'\n",
      "  - Raw: 'Commercial book'  ->  Normalized: 'C0mmercia1b00k'\n",
      "  - Raw: '6,965'  ->  Normalized: '6,965'\n",
      "  - Raw: '7,416'  ->  Normalized: '7,416'\n",
      "  - Raw: 'Markets trading'  ->  Normalized: 'Market5trading'\n",
      "  - Raw: '2261'  ->  Normalized: '2261'\n",
      "  - Raw: ''317'  ->  Normalized: ''317'\n",
      "  - Raw: '2148'  ->  Normalized: '2143'\n",
      "  - Raw: '2180'  ->  Normalized: '2130'\n",
      "  - Raw: '2203'  ->  Normalized: '2203'\n",
      "  - Raw: '2142'  ->  Normalized: '2142'\n",
      "  - Raw: '7175'  ->  Normalized: '7175'\n",
      "  - Raw: '1H23'  ->  Normalized: '1H23'\n",
      "  - Raw: '1H24'  ->  Normalized: '1H24'\n",
      "  - Raw: '2023'  ->  Normalized: '2023'\n",
      "  - Raw: '3023'  ->  Normalized: '3023'\n",
      "  - Raw: '4Q23'  ->  Normalized: '4Q23'\n",
      "  - Raw: '1Q24'  ->  Normalized: '1Q24'\n",
      "  - Raw: '2024'  ->  Normalized: '2024'\n",
      "  - Raw: 'DBS'  ->  Normalized: '035'\n",
      "Detected quarters (EasyOCR, bottom axis): 2Q23, 3Q23, 4Q23, 1Q24, 2Q24\n",
      "x-pos: [1231, 1475, 1717, 1962, 2204]\n",
      "\n",
      "========================================================================================\n",
      "Image: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_7_Figure_1.jpeg\n",
      "\n",
      "[DEBUG] Raw tokens from bottom axis:\n",
      "  - Raw: '0,04 ['  ->  Normalized: '0,04['\n",
      "  - Raw: 'Y /'  ->  Normalized: 'Y/'\n",
      "  - Raw: 'Cdd e'  ->  Normalized: 'Cdde'\n",
      "  - Raw: 'Commercial book'  ->  Normalized: 'C0mmercia1b00k'\n",
      "  - Raw: '10,649'  ->  Normalized: '10,649'\n",
      "  - Raw: '11,212'  ->  Normalized: '11,212'\n",
      "  - Raw: 'Markets trading'  ->  Normalized: 'Market5trading'\n",
      "  - Raw: 'P441'  ->  Normalized: 'P441'\n",
      "  - Raw: '2516'  ->  Normalized: '2516'\n",
      "  - Raw: '142'  ->  Normalized: '142'\n",
      "  - Raw: '3175'  ->  Normalized: '3175'\n",
      "  - Raw: '7199='  ->  Normalized: '7199='\n",
      "  - Raw: '9M23'  ->  Normalized: '9M23'\n",
      "  - Raw: '9M24'  ->  Normalized: '9M24'\n",
      "  - Raw: '1Q24'  ->  Normalized: '1Q24'\n",
      "  - Raw: '2024'  ->  Normalized: '2024'\n",
      "  - Raw: '3024'  ->  Normalized: '3024'\n",
      "  - Raw: 'DBS'  ->  Normalized: '035'\n",
      "Detected quarters (EasyOCR, bottom axis): 1Q24, 2Q24, 3Q24\n",
      "x-pos: [1420, 1722, 2024]\n",
      "\n",
      "========================================================================================\n",
      "Image: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/_page_5_Figure_1.jpeg\n",
      "\n",
      "[DEBUG] Raw tokens from bottom axis:\n",
      "  - Raw: '3,647'  ->  Normalized: '3,647'\n",
      "  - Raw: 'D,r03'  ->  Normalized: '0,r03'\n",
      "  - Raw: '0,/90'  ->  Normalized: '0,/90'\n",
      "  - Raw: 'P,o0 ['  ->  Normalized: 'P,00['\n",
      "  - Raw: 'Commercial book'  ->  Normalized: 'C0mmercia1b00k'\n",
      "  - Raw: '14,286'  ->  Normalized: '14,236'\n",
      "  - Raw: '15,043'  ->  Normalized: '15,043'\n",
      "  - Raw: 'Markets trading'  ->  Normalized: 'Market5trading'\n",
      "  - Raw: ''644'  ->  Normalized: ''644'\n",
      "  - Raw: ''619'  ->  Normalized: ''619'\n",
      "  - Raw: '2142'  ->  Normalized: '2142'\n",
      "  - Raw: '71757'  ->  Normalized: '71757'\n",
      "  - Raw: '2199'  ->  Normalized: '2199'\n",
      "  - Raw: '103'  ->  Normalized: '103'\n",
      "  - Raw: 'FY23'  ->  Normalized: 'FY23'\n",
      "  - Raw: 'FY24'  ->  Normalized: 'FY24'\n",
      "  - Raw: '1Q24'  ->  Normalized: '1Q24'\n",
      "  - Raw: '2Q24'  ->  Normalized: '2Q24'\n",
      "  - Raw: '3024'  ->  Normalized: '3024'\n",
      "  - Raw: '4Q24'  ->  Normalized: '4Q24'\n",
      "  - Raw: 'XDBS'  ->  Normalized: 'X035'\n",
      "Detected quarters (EasyOCR, bottom axis): 1Q24, 2Q24, 3Q24, 4Q24\n",
      "x-pos: [1378, 1640, 1903, 2167]\n",
      "\n",
      "========================================================================================\n",
      "Image: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/_page_4_Figure_1.jpeg\n",
      "\n",
      "[DEBUG] Raw tokens from bottom axis:\n",
      "  - Raw: '5,04('  ->  Normalized: '5,04('\n",
      "  - Raw: 'Vi0d'  ->  Normalized: 'Vi0d'\n",
      "  - Raw: 'Yy O'  ->  Normalized: 'Yy0'\n",
      "  - Raw: 'y #'  ->  Normalized: 'y#'\n",
      "  - Raw: '9,7 T0'  ->  Normalized: '9,7T0'\n",
      "  - Raw: 'Commercial book'  ->  Normalized: 'C0mmercia1b00k'\n",
      "  - Raw: ''142'  ->  Normalized: ''142'\n",
      "  - Raw: '{175 '  ->  Normalized: '{175'\n",
      "  - Raw: '2199'  ->  Normalized: '2199'\n",
      "  - Raw: ''103'  ->  Normalized: ''103'\n",
      "  - Raw: ''38'  ->  Normalized: ''33'\n",
      "  - Raw: 'Markets trading'  ->  Normalized: 'Market5trading'\n",
      "  - Raw: '1Q24'  ->  Normalized: '1Q24'\n",
      "  - Raw: '2024'  ->  Normalized: '2024'\n",
      "  - Raw: '3024'  ->  Normalized: '3024'\n",
      "  - Raw: '4Q24'  ->  Normalized: '4Q24'\n",
      "  - Raw: '1Q25'  ->  Normalized: '1Q25'\n",
      "  - Raw: 'DBS'  ->  Normalized: '035'\n",
      "Detected quarters (EasyOCR, bottom axis): 1Q24, 2Q24, 3Q24, 4Q24, 1Q25\n",
      "x-pos: [775, 1100, 1427, 1754, 2080]\n",
      "\n",
      "========================================================================================\n",
      "Image: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/_page_5_Figure_1.jpeg\n",
      "\n",
      "[DEBUG] Raw tokens from bottom axis:\n",
      "  - Raw: 'Vi0o'  ->  Normalized: 'Vi00'\n",
      "  - Raw: 'YJi Y'  ->  Normalized: 'YJiY'\n",
      "  - Raw: 'L9 #'  ->  Normalized: 'L9#'\n",
      "  - Raw: 'V,/ T0'  ->  Normalized: 'V,/T0'\n",
      "  - Raw: 'J,ozo'  ->  Normalized: 'J,020'\n",
      "  - Raw: 'Markets trading'  ->  Normalized: 'Market5trading'\n",
      "  - Raw: '5317'  ->  Normalized: '5317'\n",
      "  - Raw: 'P151'  ->  Normalized: 'P151'\n",
      "  - Raw: '2175'  ->  Normalized: '2175'\n",
      "  - Raw: '2199'  ->  Normalized: '2199'\n",
      "  - Raw: '2103'  ->  Normalized: '2103'\n",
      "  - Raw: 'P387'  ->  Normalized: 'P337'\n",
      "  - Raw: '1H24'  ->  Normalized: '1H24'\n",
      "  - Raw: '1H25'  ->  Normalized: '1H25'\n",
      "  - Raw: '2Q24'  ->  Normalized: '2Q24'\n",
      "  - Raw: '3024'  ->  Normalized: '3024'\n",
      "  - Raw: '4Q24'  ->  Normalized: '4Q24'\n",
      "  - Raw: '1Q25'  ->  Normalized: '1Q25'\n",
      "  - Raw: '2025'  ->  Normalized: '2025'\n",
      "  - Raw: 'DBS'  ->  Normalized: '035'\n",
      "Detected quarters (EasyOCR, bottom axis): 2Q24, 3Q24, 4Q24, 1Q25, 2Q25\n",
      "x-pos: [1285, 1507, 1730, 1953, 2173]\n"
     ]
    }
   ],
   "source": [
    "# --- One cell: run EasyOCR on your chart image (simplified) ---\n",
    "# Works in a notebook. If you just installed packages, restart the kernel once if imports fail.\n",
    "\n",
    "# --- (A) Installs ---\n",
    "# Tip: if SSL cert errors happen on macOS, uncomment the certifi block below first.\n",
    "# import certifi, os\n",
    "# os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "# os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
    "\n",
    "# %pip -q install easyocr opencv-python-headless pillow matplotlib pandas numpy certifi\n",
    "\n",
    "# --- (B) Config ---\n",
    "IMG_PATHS = [\n",
    "    \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/_page_4_Figure_1.jpeg\",\n",
    "    \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_5_Figure_1.jpeg\",\n",
    "    \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_7_Figure_1.jpeg\",\n",
    "    \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/_page_5_Figure_1.jpeg\",\n",
    "    \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/_page_4_Figure_1.jpeg\",\n",
    "    \"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/_page_5_Figure_1.jpeg\",\n",
    "]\n",
    "\n",
    "# --- (C) Imports & utils ---\n",
    "import re, math, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display as _show\n",
    "\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "# This is the FIX\n",
    "QUARTER_PAT = re.compile(r\"([1-4Iil|])\\s*[QO0]\\s*([0-9O]{2,4})\", re.I)\n",
    "\n",
    "_CHAR_FIX = str.maketrans({\n",
    "    \"O\":\"0\",\"o\":\"0\",\n",
    "    \"S\":\"5\",\"s\":\"5\",\n",
    "    \"I\":\"1\",\"l\":\"1\",\"|\":\"1\",\"!\":\"1\",\n",
    "    \"D\":\"0\",\n",
    "    \"B\":\"3\", \"8\":\"3\",  # Force B and 8 to become 3\n",
    "    \"Z\":\"2\", \"z\":\"2\"   # Force Z to become 2\n",
    "})\n",
    "\n",
    "def normalize_token(t: str) -> str:\n",
    "    t = (t or \"\").strip()\n",
    "    return t.translate(_CHAR_FIX).replace(\" \", \"\")\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(p)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(\"cv2.imread() returned None\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    # Upscale + denoise + local contrast + threshold\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct: s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r[\"text\"]).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def _is_half_token(t: str) -> bool:\n",
    "    t = (t or \"\").lower().replace(\" \", \"\")\n",
    "    return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t)\n",
    "\n",
    "def overlay(img_bgr, df, title=\"Detections\"):\n",
    "    vis = img_bgr.copy()\n",
    "    for _, r in (df if isinstance(df, pd.DataFrame) else pd.DataFrame()).iterrows():\n",
    "        x1,y1,x2,y2 = int(r.x1),int(r.y1),int(r.x2),int(r.y2)\n",
    "        color = (255,0,0) if bool(r.get(\"is_pct\", False)) else (0,200,0)\n",
    "        cv2.rectangle(vis, (x1,y1), (x2,y2), color, 2)\n",
    "        cv2.putText(vis, str(r.raw), (x1, max(12,y1-4)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\"); plt.title(title); plt.show()\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3): break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "# --- (D) Backend wrappers ---\n",
    "_EASY_OCR_READER = None\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    global _EASY_OCR_READER\n",
    "    if _EASY_OCR_READER is None:\n",
    "        _EASY_OCR_READER = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = _EASY_OCR_READER.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "def detect_quarters_easyocr(img_bgr):\n",
    "    \"\"\"\n",
    "    Use EasyOCR to read quarter labels along the bottom axis.\n",
    "    Returns a list of (x_global, 'nQyy') sorted left→right, with half-year tokens removed.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    y0 = int(H * 0.66)  # bottom 34% to include labels (changed from 0.60)\n",
    "    crop = img_bgr[y0:H, 0:W]\n",
    "    # preprocess: gray -> bilateral -> CLAHE -> adaptive thr -> morph close -> upsample\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    # kernel = np.ones((3,3), np.uint8)\n",
    "    # thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    up = cv2.resize(thr, None, fx=3.0, fy=3.0, interpolation=cv2.INTER_CUBIC)  # changed from 2.5\n",
    "    img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    print(\"\\n[DEBUG] Raw tokens from bottom axis:\")\n",
    "    for r in ocr or []:\n",
    "        print(f\"  - Raw: '{r.get('text','')}'  ->  Normalized: '{normalize_token(r.get('text',''))}'\")\n",
    "    # PASS 1 — direct regex on normalized tokens\n",
    "    tokens = []\n",
    "    for r in ocr or []:\n",
    "        raw = str(r.get(\"text\",\"\")).strip()\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx_local = (x1 + x2) // 2\n",
    "        cx_global = int(cx_local / 3.0)  # undo scaling\n",
    "        tokens.append({\"x\": cx_global, \"raw\": raw, \"norm\": normalize_token(raw)})\n",
    "\n",
    "    quarters = []\n",
    "    for t in tokens:\n",
    "        if _is_half_token(t[\"norm\"]):\n",
    "            continue\n",
    "        m = QUARTER_PAT.search(t[\"norm\"])\n",
    "        if m:\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            q = normalize_token(q)\n",
    "            quarters.append((t[\"x\"], q))\n",
    "\n",
    "    # PASS 2 — stitch split tokens if too few quarters were found\n",
    "    if len(quarters) < 4 and tokens:\n",
    "        # classify simple pieces\n",
    "        pieces = sorted(tokens, key=lambda d: d[\"x\"])\n",
    "        digits_1to4 = [p for p in pieces if p[\"norm\"] in (\"1\",\"2\",\"3\",\"4\")]\n",
    "        q_only      = [p for p in pieces if p[\"norm\"].upper() == \"Q\"]\n",
    "        q_with_year = [p for p in pieces if re.fullmatch(r\"Q[0-9O]{2,4}\", p[\"norm\"], flags=re.I)]\n",
    "        years_2d    = [p for p in pieces if re.fullmatch(r\"[0-9O]{2,4}\", p[\"norm\"])]\n",
    "\n",
    "        used = set()\n",
    "        def near(a, b, tol=70):  # pixels in global coords\n",
    "            return abs(a[\"x\"] - b[\"x\"]) <= tol\n",
    "\n",
    "        # patterns: [digit][Q][year] or [digit][Qyy] or [digitQ][yy] or [digit][Qyy] (with OCR confusions)\n",
    "        for d in digits_1to4:\n",
    "            # digit + Qyy\n",
    "            candidates = [q for q in q_with_year if near(d, q)]\n",
    "            if candidates:\n",
    "                qtok = min(candidates, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                qyy = normalize_token(qtok[\"norm\"])[1:]\n",
    "                quarters.append(( (d[\"x\"]+qtok[\"x\"])//2, f\"{d['norm']}Q{qyy[-2:]}\" ))\n",
    "                used.add(id(d)); used.add(id(qtok)); continue\n",
    "            # digit + Q + yy\n",
    "            qs = [q for q in q_only if near(d, q)]\n",
    "            ys = [y for y in years_2d if near(d, y, tol=120)]\n",
    "            if qs and ys:\n",
    "                qtok = min(qs, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                ytok = min(ys, key=lambda y: abs(y[\"x\"]-qtok[\"x\"]))\n",
    "                yy = normalize_token(ytok[\"norm\"])\n",
    "                quarters.append(( (d[\"x\"]+ytok[\"x\"])//2, f\"{d['norm']}Q{yy[-2:]}\" ))\n",
    "                used.add(id(d)); used.add(id(qtok)); used.add(id(ytok)); continue\n",
    "\n",
    "    # PASS 3 — clean and dedupe results\n",
    "    if not quarters:\n",
    "        return []\n",
    "    quarters.sort(key=lambda t: t[0])\n",
    "    deduped = []\n",
    "    last_x = -10**9\n",
    "    for x,q in quarters:\n",
    "        if abs(x - last_x) <= 22:\n",
    "            continue\n",
    "        deduped.append((x,q))\n",
    "        last_x = x\n",
    "    quarters = deduped\n",
    "\n",
    "    return quarters\n",
    "\n",
    "# --- (E) Extraction logic specific to your slide layout ---\n",
    "# Removed entire extract_series_from_df function as per instructions\n",
    "\n",
    "# --- (F) Run EasyOCR only ---\n",
    "for path in IMG_PATHS:\n",
    "    print(\"\\n\" + \"=\"*88)\n",
    "    print(f\"Image: {path}\")\n",
    "    try:\n",
    "        img_bgr = load_image(path)\n",
    "        q_xy = detect_quarters_easyocr(img_bgr)\n",
    "        if q_xy:\n",
    "            quarters = [q for _, q in q_xy]\n",
    "            xpos     = [int(x) for x, _ in q_xy]\n",
    "            print(\"Detected quarters (EasyOCR, bottom axis):\", \", \".join(quarters))\n",
    "            print(\"x-pos:\", xpos)\n",
    "        else:\n",
    "            print(\"Detected quarters (EasyOCR, bottom axis): <none>\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR → {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75434f2a",
   "metadata": {},
   "source": [
    "Working Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba85e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Multi-image mode ---\n",
      "\n",
      "🖼️  Image: _page_4_Figure_1.jpeg  |  PDF: 1Q24_CFO_presentation.pdf\n",
      "   📎 Quarters (EasyOCR): 1Q23, 2Q23, 3Q23, 4Q23, 1Q24\n",
      "   · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting…\n",
      "   💾 Saved JSONL → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "\n",
      "   📊 Extracted table:\n",
      "Quarter  Commercial NIM (%)  Group NIM (%)\n",
      "   1Q23                2.69           2.12\n",
      "   2Q23                2.81           2.16\n",
      "   3Q23                2.82           2.19\n",
      "   4Q23                2.75           2.13\n",
      "   1Q24                2.77           2.14\n",
      "\n",
      "🖼️  Image: _page_5_Figure_1.jpeg  |  PDF: 2Q24_CFO_presentation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   📎 Quarters (EasyOCR): 2Q23, 3Q23, 4Q23, 1Q24, 2Q24\n",
      "   · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting…\n",
      "   💾 Saved JSONL → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_5_Figure_1.nim.jsonl\n",
      "\n",
      "   📊 Extracted table:\n",
      "Quarter  Commercial NIM (%)  Group NIM (%)\n",
      "   2Q23                2.81           2.16\n",
      "   3Q23                2.82           2.19\n",
      "   4Q23                2.75           2.13\n",
      "   1Q24                2.77           2.14\n",
      "   2Q24                2.83           2.14\n",
      "\n",
      "🖼️  Image: _page_7_Figure_1.jpeg  |  PDF: 3Q24_CFO_presentation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   📎 Quarters (EasyOCR): 1Q24, 2Q24, 3Q24\n",
      "   · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting…\n",
      "   💾 Saved JSONL → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_7_Figure_1.nim.jsonl\n",
      "\n",
      "   📊 Extracted table:\n",
      "Quarter  Commercial NIM (%)  Group NIM (%)\n",
      "   1Q24                2.77           2.14\n",
      "   2Q24                2.83           2.14\n",
      "   3Q24                2.83           2.11\n",
      "\n",
      "🖼️  Image: _page_5_Figure_1.jpeg  |  PDF: 4Q24_CFO_presentation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   📎 Quarters (EasyOCR): 1Q24, 2Q24, 3Q24, 4Q24\n",
      "   · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting…\n",
      "   💾 Saved JSONL → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/_page_5_Figure_1.nim.jsonl\n",
      "\n",
      "   📊 Extracted table:\n",
      "Quarter  Commercial NIM (%)  Group NIM (%)\n",
      "   1Q24                2.77           2.14\n",
      "   2Q24                2.83           2.14\n",
      "   3Q24                2.83           2.11\n",
      "   4Q24                2.77           2.15\n",
      "\n",
      "✅ Done. Extracted from 4 image(s).\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4Iil|])\\s*[QO0]\\s*([0-9O]{2,4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- OCR character normalization for quarter tokens (common OCR mistakes) ---\n",
    "_CHAR_FIX = str.maketrans({\n",
    "    \"O\":\"0\",\"o\":\"0\",\n",
    "    \"S\":\"5\",\"s\":\"5\",\n",
    "    \"I\":\"1\",\"l\":\"1\",\"|\":\"1\",\"!\":\"1\",\n",
    "    \"D\":\"0\",\n",
    "    \"B\":\"3\",\"8\":\"3\",\n",
    "    \"Z\":\"2\",\"z\":\"2\"\n",
    "})\n",
    "def normalize_token(t: str) -> str:\n",
    "    t = (t or \"\").strip()\n",
    "    return t.translate(_CHAR_FIX).replace(\" \", \"\")\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    global _EASY_OCR_READER\n",
    "    try:\n",
    "        _EASY_OCR_READER\n",
    "    except NameError:\n",
    "        _EASY_OCR_READER = None\n",
    "    if _EASY_OCR_READER is None:\n",
    "        _EASY_OCR_READER = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = _EASY_OCR_READER.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "# --- Focused bottom-axis quarter detection using EasyOCR (robust to OCR confusions) ---\n",
    "def detect_quarters_easyocr(img_bgr):\n",
    "    \"\"\"\n",
    "    Use EasyOCR to read quarter labels along the bottom axis.\n",
    "    Returns a list of (x_global, 'nQyy') sorted left→right, with half-year tokens removed.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    y0 = int(H * 0.66)  # bottom ~34%\n",
    "    crop = img_bgr[y0:H, 0:W]\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    # kernel = np.ones((3,3), np.uint8)\n",
    "    # thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    up = cv2.resize(thr, None, fx=3.0, fy=3.0, interpolation=cv2.INTER_CUBIC)\n",
    "    img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    # PASS 1 — direct regex on normalized tokens\n",
    "    tokens = []\n",
    "    for r in ocr or []:\n",
    "        raw = str(r.get(\"text\",\"\")).strip()\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx_local = (x1 + x2) // 2\n",
    "        cx_global = int(cx_local / 3.0)  # undo scaling\n",
    "        tokens.append({\"x\": cx_global, \"raw\": raw, \"norm\": normalize_token(raw)})\n",
    "    def _is_half_token(t: str) -> bool:\n",
    "        t = (t or \"\").lower().replace(\" \", \"\")\n",
    "        return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t)\n",
    "    quarters = []\n",
    "    for t in tokens:\n",
    "        if _is_half_token(t[\"norm\"]):\n",
    "            continue\n",
    "        m = QUARTER_PAT.search(t[\"norm\"])\n",
    "        if m:\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            q = normalize_token(q)\n",
    "            quarters.append((t[\"x\"], q))\n",
    "    # PASS 2 — stitch split tokens if too few quarters were found\n",
    "    if len(quarters) < 4 and tokens:\n",
    "        pieces = sorted(tokens, key=lambda d: d[\"x\"])\n",
    "        digits_1to4 = [p for p in pieces if p[\"norm\"] in (\"1\",\"2\",\"3\",\"4\")]\n",
    "        q_only      = [p for p in pieces if p[\"norm\"].upper() == \"Q\"]\n",
    "        q_with_year = [p for p in pieces if re.fullmatch(r\"Q[0-9O]{2,4}\", p[\"norm\"], flags=re.I)]\n",
    "        years_2d    = [p for p in pieces if re.fullmatch(r\"[0-9O]{2,4}\", p[\"norm\"])]\n",
    "        def near(a, b, tol=70):\n",
    "            return abs(a[\"x\"] - b[\"x\"]) <= tol\n",
    "        for d in digits_1to4:\n",
    "            # digit + Qyy\n",
    "            candidates = [q for q in q_with_year if near(d, q)]\n",
    "            if candidates:\n",
    "                qtok = min(candidates, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                qyy = normalize_token(qtok[\"norm\"])[1:]\n",
    "                quarters.append(((d[\"x\"]+qtok[\"x\"])//2, f\"{d['norm']}Q{qyy[-2:]}\"))\n",
    "                continue\n",
    "            # digit + Q + yy\n",
    "            qs = [q for q in q_only if near(d, q)]\n",
    "            ys = [y for y in years_2d if near(d, y, tol=120)]\n",
    "            if qs and ys:\n",
    "                qtok = min(qs, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                ytok = min(ys, key=lambda y: abs(y[\"x\"]-qtok[\"x\"]))\n",
    "                yy = normalize_token(ytok[\"norm\"])\n",
    "                quarters.append(((d[\"x\"]+ytok[\"x\"])//2, f\"{d['norm']}Q{yy[-2:]}\"))\n",
    "                continue\n",
    "    if not quarters:\n",
    "        return []\n",
    "    quarters.sort(key=lambda t: t[0])\n",
    "    deduped, last_x = [], -10**9\n",
    "    for x,q in quarters:\n",
    "        if abs(x - last_x) <= 22:\n",
    "            continue\n",
    "        deduped.append((x,q))\n",
    "        last_x = x\n",
    "    return deduped\n",
    "\n",
    "# NIM value band (pct) and geometry heuristics for verification\n",
    "NIM_MIN, NIM_MAX = 1.3, 3.2\n",
    "TOP_FRACTION = 0.65     # widen band: NIM labels often sit higher than 45%\n",
    "RIGHT_HALF_ONLY = True  # NIM values appear on right panel in these deck\n",
    "\n",
    "def is_strict_nim_image(img_path: Path) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Heuristic re-check:\n",
    "      1) Title/text contains NIM keywords (coarse gate)\n",
    "      2) Percent tokens mostly within NIM_MIN..NIM_MAX\n",
    "      3) Tokens located in the top region (and right half, if enabled)\n",
    "    Returns (ok, reason)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_bgr = load_image(img_path)\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        # 1) quick-text gate (soft): don't return yet; allow numeric signature to validate\n",
    "        kw_ok = is_relevant_image(img_path, NIM_KEYWORDS)\n",
    "        # 2) numeric gate on enhanced image\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # --- Semantic gate: accept classic NIM slides based on stable labels ---\n",
    "        text_lower = \" \".join(str(r.get(\"text\", \"\")).lower() for r in ocr or [])\n",
    "        has_nim = \"net interest margin\" in text_lower\n",
    "        has_cb  = \"commercial book\" in text_lower\n",
    "        has_grp = \"group\" in text_lower\n",
    "        if has_nim and (has_cb or has_grp):\n",
    "            which = [w for w, ok in ((\"nim\", has_nim), (\"cb\", has_cb), (\"grp\", has_grp)) if ok]\n",
    "            return (True, f\"ok_semantic({'+' .join(which)})\")\n",
    "        df = extract_numbers(ocr)\n",
    "        if df.empty:\n",
    "            return (False, \"no_numbers\")\n",
    "        # geometry filters (apply before value checks)\n",
    "        top_cut = int(img_up.shape[0] * TOP_FRACTION)\n",
    "        cond_geom = (df[\"cy\"] < top_cut)\n",
    "        if RIGHT_HALF_ONLY:\n",
    "            cond_geom &= (df[\"cx\"] > (img_up.shape[1] // 2))\n",
    "\n",
    "        # 2a) Preferred path: explicit percentage tokens\n",
    "        df_pct = df[(df[\"is_pct\"] == True) & cond_geom].copy()\n",
    "        if not df_pct.empty:\n",
    "            in_band = df_pct[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_pct))\n",
    "            if ratio >= 0.6:\n",
    "                return (True, \"ok\")\n",
    "            else:\n",
    "                return (False, f\"non_nim_values_out_of_band({ratio:.2f})\")\n",
    "\n",
    "        # 2b) Fallback: some decks omit the % sign near the series values.\n",
    "        # Accept plain numbers in the NIM range if units are explicit or implied, or if numeric signature is strong.\n",
    "        title_text = text_lower  # already computed above\n",
    "        has_units_pct = \"(%)\" in title_text or \"margin (%)\" in title_text or \"net interest margin\" in title_text\n",
    "        df_nums = df[(df[\"is_pct\"] == False) & cond_geom].copy()\n",
    "        if not df_nums.empty:\n",
    "            in_band = df_nums[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_nums))\n",
    "            # Case A: explicit or implied units in title → accept when enough in-band hits\n",
    "            if has_units_pct and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_no_percent_signs\")\n",
    "            # Case B: title OCR may have missed units; if the quick keyword gate succeeded, accept with a stricter ratio\n",
    "            if kw_ok and ratio >= 0.7 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_numeric_signature\")\n",
    "\n",
    "        # Final decision: if numeric signature still failed, report clearer reason\n",
    "        if not kw_ok:\n",
    "            return (False, \"irrelevant_non_nim\")\n",
    "        else:\n",
    "            return (False, \"no_percentages_or_units\")\n",
    "    except Exception as e:\n",
    "        return (False, f\"exception:{e}\")\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)  # bottom 40%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Morphological close to strengthen thin glyphs\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: decide single-panel vs split-panel\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text, right_tokens_text = [], []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)  # undo scale\n",
    "\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            else:\n",
    "                right_tokens_text.append(raw.lower())\n",
    "\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        # Panel selection logic: prefer both halves unless left clearly half-year and right has ≥3 quarters\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        # Sort and dedupe close neighbors (≤18 px)\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "\n",
    "        return [q for _, q in deduped]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Same as detect_qlabels_bottom, but returns (x, label) for alignment ---\n",
    "def detect_qlabels_bottom_with_xy(img_bgr) -> list[tuple[int, str]]:\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text = []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "        return deduped\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    # Detect bottom quarter labels (with x) early to infer layout\n",
    "    detected_q_bot_xy = detect_quarters_easyocr(img_up)\n",
    "    left_count  = sum(1 for x, _ in detected_q_bot_xy if x <= mid_x)\n",
    "    right_count = sum(1 for x, _ in detected_q_bot_xy if x >  mid_x)\n",
    "    # Heuristic: if we see ≥4 quarter tokens spanning both halves, it's a single-panel timeline\n",
    "    single_panel = (len(detected_q_bot_xy) >= 4 and left_count >= 1 and right_count >= 1)\n",
    "\n",
    "    # Filter tokens: keep right-half only for split panels; keep all for single panels\n",
    "    if single_panel:\n",
    "        pct = df[(df.is_pct==True)].copy()\n",
    "        nums = df[(df.is_pct==False)].copy()\n",
    "    else:\n",
    "        pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "        nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        # Fallback for charts that omit the '%' sign on the value dots.\n",
    "        # Use a wider top band and avoid forcing right-half on single-panel timelines.\n",
    "        approx_top = int(H * 0.60)\n",
    "        if single_panel:\n",
    "            cx_mask = (df.cx > 0)  # keep all x for single panel\n",
    "        else:\n",
    "            cx_mask = (df.cx > mid_x)\n",
    "        cand_pct = df[cx_mask & df.value.between(NIM_MIN, NIM_MAX) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        # Try to split into two horizontal series by Y even when we have only 3 quarters (→ 6 points)\n",
    "        # Deduplicate by proximity on Y to stabilize clustering\n",
    "        y_sorted = pct.sort_values(\"cy\")[\"cy\"].to_numpy()\n",
    "        uniq_y = []\n",
    "        last_y = -10**9\n",
    "        for yy in y_sorted:\n",
    "            if abs(yy - last_y) >= 6:  # 6px tolerance for duplicates\n",
    "                uniq_y.append(yy)\n",
    "                last_y = yy\n",
    "        # Attempt k-means when we have at least 4 points total (≈ 2 series × 2 quarters)\n",
    "        if pct.shape[0] >= 4 and len(uniq_y) >= 2:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)  # top (commercial) should have smaller y\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "            # Sanity: ensure both series have data; else collapse to one\n",
    "            counts = pct[\"series_name\"].value_counts()\n",
    "            if any(counts.get(name, 0) == 0 for name in [\"Commercial NIM (%)\", \"Group NIM (%)\"]):\n",
    "                pct[\"series_name\"] = \"NIM (%)\"\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        # Reuse bottom-quarter labels captured above\n",
    "        detected_q_bot = [q for _, q in detected_q_bot_xy]\n",
    "        detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "        if len(detected_q_bot) > len(detected_q_ocr):\n",
    "            detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "        else:\n",
    "            detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            # Sort left→right and collapse near-duplicates (same x within 12px)\n",
    "            sub_sorted = sub.sort_values(\"cx\")\n",
    "            uniq_rows = []\n",
    "            last_x = -10**9\n",
    "            for r in sub_sorted.itertuples(index=False):\n",
    "                if abs(r.cx - last_x) < 12:\n",
    "                    continue\n",
    "                uniq_rows.append(r)\n",
    "                last_x = r.cx\n",
    "            # Keep only the right-panel portion (already ensured by cx>mid_x earlier)\n",
    "            pick = list(uniq_rows)[-5:]  # cap to 5 most recent positions, but may be <5\n",
    "            n = len(pick)\n",
    "            if n == 0:\n",
    "                continue\n",
    "            labels = []\n",
    "            # Robust mapping: map each value x to its nearest bottom quarter label x (right panel).\n",
    "            # Filter any accidental half-year tokens (1H/2H/H1/H2/9M) just in case OCR returns them.\n",
    "            def _is_half_token(t: str) -> bool:\n",
    "                t = (t or \"\").lower().replace(\" \", \"\")\n",
    "                return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t) or (\"h24\" in t) or (\"h23\" in t)\n",
    "\n",
    "            # detected_q_bot_xy already respects split vs single panel. Keep right-panel positions only here.\n",
    "            q_xy = []\n",
    "            for x, q in detected_q_bot_xy:\n",
    "                if x <= mid_x:\n",
    "                    continue\n",
    "                if _is_half_token(q):\n",
    "                    continue\n",
    "                q_xy.append((x, q))\n",
    "\n",
    "            if len(q_xy) < n:\n",
    "                # Borrow from left panel if they look like quarters (and not half-year)\n",
    "                for x, q in detected_q_bot_xy:\n",
    "                    if x > mid_x:\n",
    "                        continue\n",
    "                    if _is_half_token(q):\n",
    "                        continue\n",
    "                    q_xy.append((x, q))\n",
    "\n",
    "            if q_xy:\n",
    "                q_xy.sort(key=lambda t: t[0])  # left→right\n",
    "                # Map each picked value to nearest quarter label by x-position\n",
    "                vx = [rr.cx for rr in pick]\n",
    "                qx = [x for x, _ in q_xy]\n",
    "                ql = [q for _, q in q_xy]\n",
    "                mapped = []\n",
    "                for x in vx:\n",
    "                    j = int(np.argmin([abs(x - xx) for xx in qx])) if qx else -1\n",
    "                    mapped.append(ql[j] if j >= 0 else None)\n",
    "                labels = mapped\n",
    "            else:\n",
    "                detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "                if detected_q_ocr:\n",
    "                    labels = detected_q_ocr[-n:] if len(detected_q_ocr) >= n else detected_q_ocr\n",
    "\n",
    "            # If still short, use markdown tokens; else expand from an anchor like 2Q24\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                if qlabels_hint:\n",
    "                    labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "            # Ensure left→right order for consistent mapping to labels\n",
    "            pick = sorted(pick, key=lambda r: r.cx)\n",
    "            labels = list(labels)[:n]\n",
    "            for i, r in enumerate(pick):\n",
    "                if i >= len(labels):\n",
    "                    break\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            # Guard: drop rows with missing labels\n",
    "            nim_table = nim_table.dropna(subset=[\"Quarter\", \"series\"])  \n",
    "            # If multiple detections map to the same (Quarter, series), average them\n",
    "            if not nim_table.empty:\n",
    "                dupe_mask = nim_table.duplicated(subset=[\"Quarter\", \"series\"], keep=False)\n",
    "                if dupe_mask.any():\n",
    "                    # Aggregate duplicates by mean (stable for minor OCR jitter)\n",
    "                    nim_table = nim_table.groupby([\"Quarter\", \"series\"], as_index=False)[\"value\"].mean()\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Quick OCR pass to check if an image is relevant by title text against given keywords.\"\"\"\n",
    "    try:\n",
    "        import easyocr\n",
    "        rdr = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "        small = cv2.resize(img, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)\n",
    "        results = rdr.readtext(small, detail=0, paragraph=True)\n",
    "        text = \" \".join([t.lower() for t in results])\n",
    "        return any(k in text for k in keywords)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str, *, bypass_relevance: bool = False):\n",
    "        if not bypass_relevance and not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# === Single-image rebuild/verify mode (optional) ===\n",
    "# Set single_image_mode=True and point single_image_path to a specific extracted image\n",
    "# to run the two-stage gate + extraction just for that file, then exit.\n",
    "single_image_mode = True\n",
    "single_image_paths: list[Path] = [\n",
    "    Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation/_page_4_Figure_1.jpeg\"),\n",
    "    Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation/_page_5_Figure_1.jpeg\"),\n",
    "    Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation/_page_7_Figure_1.jpeg\"),\n",
    "    Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation/_page_5_Figure_1.jpeg\"), \n",
    "    \n",
    "]\n",
    "# Optional singular fallback path (legacy): set to a string/Path if you want a single-image override\n",
    "single_image_path = None\n",
    "\n",
    "# Legacy fallback (ignored i\n",
    " # Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# === Fast path: single image only ===\n",
    "# === Fast path: single/multi-image only ===\n",
    "if single_image_mode:\n",
    "    paths: list[Path] = []\n",
    "    if single_image_paths:\n",
    "        paths = [Path(p) for p in single_image_paths if p is not None]\n",
    "    elif single_image_path:\n",
    "        paths = [Path(single_image_path)]\n",
    "\n",
    "    if not paths:\n",
    "        print(\"❌ single_image_mode=True but no paths were provided.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"--- Multi-image mode ---\")\n",
    "    successes = 0\n",
    "    for img_path in paths:\n",
    "        if not img_path.exists():\n",
    "            print(f\"❌ Missing: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        dest_dir = img_path.parent\n",
    "        pdf_name = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"\\n🖼️  Image: {img_path.name}  |  PDF: {pdf_name}\")\n",
    "\n",
    "        # Quick quarter readout (EasyOCR-only, bottom axis)\n",
    "        try:\n",
    "            img_bgr_quarters = load_image(img_path)\n",
    "            q_xy = detect_quarters_easyocr(img_bgr_quarters)\n",
    "            if q_xy:\n",
    "                print(\"   📎 Quarters (EasyOCR):\", \", \".join([q for _,q in q_xy]))\n",
    "            else:\n",
    "                print(\"   📎 Quarters (EasyOCR): <none>\")\n",
    "        except Exception as _qe:\n",
    "            print(f\"   📎 Quarters (EasyOCR): error → {_qe}\")\n",
    "\n",
    "        any_hit = False\n",
    "\n",
    "        for ex in EXTRACTORS:\n",
    "            print(f\"   · [{ex.name}] quick gate…\", end=\" \")\n",
    "            if not ex.is_relevant(img_path):\n",
    "                print(\"⏭️  Not relevant\")\n",
    "                continue\n",
    "            print(\"✅ ok; strict gate…\", end=\" \")\n",
    "            ok_strict, reason = is_strict_nim_image(img_path)\n",
    "            if not ok_strict:\n",
    "                print(f\"⏭️  Failed strict ({reason})\")\n",
    "                continue\n",
    "            print(\"✅ Strict OK — extracting…\")\n",
    "\n",
    "            # Extract directly so we can print the table; still write JSONL\n",
    "            df, ctx_extra = ex.extract_table(img_path, dest_dir, pdf_name)\n",
    "            if df is None or df.empty:\n",
    "                print(\"   ⚠️ No data extracted.\")\n",
    "                continue\n",
    "\n",
    "            any_hit = True\n",
    "            successes += 1\n",
    "\n",
    "            # Build context + summary and write JSONL\n",
    "            ctx = ex._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "            try:\n",
    "                cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "                if len(df) >= 2 and cols:\n",
    "                    def _pick_q(s):\n",
    "                        return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                    _fq = str(df.iloc[0][\"Quarter\"]); _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                    first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                    last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                    pieces = []\n",
    "                    for col in cols[:2]:\n",
    "                        a = df.iloc[0][col]; b = df.iloc[-1][col]\n",
    "                        if pd.notna(a) and pd.notna(b):\n",
    "                            suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                            pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                    if pieces:\n",
    "                        ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            out_path = img_path.with_suffix(f\".{ex.name}.jsonl\")\n",
    "            ex._write_jsonl(out_path, ctx, df)\n",
    "            print(f\"   💾 Saved JSONL → {out_path}\")\n",
    "\n",
    "            # Pretty-print the extracted table directly\n",
    "            try:\n",
    "                print(\"\\n   📊 Extracted table:\")\n",
    "                print(df.to_string(index=False))\n",
    "            except Exception:\n",
    "                print(df)\n",
    "\n",
    "        if not any_hit:\n",
    "            print(\"   ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "    print(f\"\\n✅ Done. Extracted from {successes} image(s).\")\n",
    "    # Prevent the pipeline (marker/md5) from running if notebook catches SystemExit\n",
    "    globals()[\"_STOP_AFTER_SINGLE\"] = True\n",
    "    sys.exit(0)\n",
    "    \n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                # Stage 1: quick keyword/title skim\n",
    "                print(f\"      · [{ex.name}] quick gate…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                print(\"✅ ok; strict gate…\", end=\" \")\n",
    "\n",
    "                # Stage 2: strict verifier (geometry + numeric band + semantic anchors)\n",
    "                ok_strict, reason = is_strict_nim_image(img_path)\n",
    "                if not ok_strict:\n",
    "                    print(f\"⏭️  Failed strict ({reason})\")\n",
    "                    continue\n",
    "\n",
    "                any_hit = True\n",
    "                print(\"✅ Strict OK — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name, bypass_relevance=True)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567392d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Multi-image mode ---\n",
      "\n",
      "🖼️  Image: _page_4_Figure_1.jpeg  |  PDF: 1Q25_CFO_presentation.pdf\n",
      "   📎 Quarters (EasyOCR): 1Q24, 2Q24, 3Q24, 4Q24, 1Q25\n",
      "   · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting…\n",
      "   💾 Saved JSONL → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "\n",
      "   📊 Extracted table:\n",
      "Quarter  Commercial NIM (%)  Group NIM (%)\n",
      "   1Q24                2.77           2.14\n",
      "   2Q24                2.83           2.14\n",
      "   3Q24                2.83           2.11\n",
      "   4Q24                2.77           2.15\n",
      "   1Q25                2.68           2.12\n",
      "\n",
      "🖼️  Image: _page_5_Figure_1.jpeg  |  PDF: 2Q25_CFO_presentation.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   📎 Quarters (EasyOCR): 2Q24, 3Q24, 4Q24, 1Q25, 2Q25\n",
      "   · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting…\n",
      "   💾 Saved JSONL → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/_page_5_Figure_1.nim.jsonl\n",
      "\n",
      "   📊 Extracted table:\n",
      "Quarter  Commercial NIM (%)  Group NIM (%)\n",
      "   2Q24                2.83           2.14\n",
      "   3Q24                2.83           2.11\n",
      "   4Q24                2.77           2.15\n",
      "   1Q25                2.68           2.12\n",
      "   2Q25                2.55           2.05\n",
      "\n",
      "✅ Done. Extracted from 2 image(s).\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4Iil|])\\s*[QO0]\\s*([0-9O]{2,4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- OCR character normalization for quarter tokens (common OCR mistakes) ---\n",
    "_CHAR_FIX = str.maketrans({\n",
    "    \"O\":\"0\",\"o\":\"0\",\n",
    "    \"S\":\"5\",\"s\":\"5\",\n",
    "    \"I\":\"1\",\"l\":\"1\",\"|\":\"1\",\"!\":\"1\",\n",
    "    \"D\":\"0\",\n",
    "    \"B\":\"3\",\"8\":\"3\",\n",
    "    \"Z\":\"2\",\"z\":\"2\"\n",
    "})\n",
    "def normalize_token(t: str) -> str:\n",
    "    t = (t or \"\").strip()\n",
    "    return t.translate(_CHAR_FIX).replace(\" \", \"\")\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    global _EASY_OCR_READER\n",
    "    try:\n",
    "        _EASY_OCR_READER\n",
    "    except NameError:\n",
    "        _EASY_OCR_READER = None\n",
    "    if _EASY_OCR_READER is None:\n",
    "        _EASY_OCR_READER = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = _EASY_OCR_READER.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "# --- Focused bottom-axis quarter detection using EasyOCR (robust to OCR confusions) ---\n",
    "def detect_quarters_easyocr(img_bgr):\n",
    "    \"\"\"\n",
    "    Use EasyOCR to read quarter labels along the bottom axis.\n",
    "    Returns a list of (x_global, 'nQyy') sorted left→right, with half-year tokens removed.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    y0 = int(H * 0.66)  # bottom ~34%\n",
    "    crop = img_bgr[y0:H, 0:W]\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    # kernel = np.ones((3,3), np.uint8)\n",
    "    # thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    up = cv2.resize(thr, None, fx=3.0, fy=3.0, interpolation=cv2.INTER_CUBIC)\n",
    "    img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    # PASS 1 — direct regex on normalized tokens\n",
    "    tokens = []\n",
    "    for r in ocr or []:\n",
    "        raw = str(r.get(\"text\",\"\")).strip()\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx_local = (x1 + x2) // 2\n",
    "        cx_global = int(cx_local / 3.0)  # undo scaling\n",
    "        tokens.append({\"x\": cx_global, \"raw\": raw, \"norm\": normalize_token(raw)})\n",
    "    def _is_half_token(t: str) -> bool:\n",
    "        t = (t or \"\").lower().replace(\" \", \"\")\n",
    "        return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t)\n",
    "    quarters = []\n",
    "    for t in tokens:\n",
    "        if _is_half_token(t[\"norm\"]):\n",
    "            continue\n",
    "        m = QUARTER_PAT.search(t[\"norm\"])\n",
    "        if m:\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            q = normalize_token(q)\n",
    "            quarters.append((t[\"x\"], q))\n",
    "    # PASS 2 — stitch split tokens if too few quarters were found\n",
    "    if len(quarters) < 4 and tokens:\n",
    "        pieces = sorted(tokens, key=lambda d: d[\"x\"])\n",
    "        digits_1to4 = [p for p in pieces if p[\"norm\"] in (\"1\",\"2\",\"3\",\"4\")]\n",
    "        q_only      = [p for p in pieces if p[\"norm\"].upper() == \"Q\"]\n",
    "        q_with_year = [p for p in pieces if re.fullmatch(r\"Q[0-9O]{2,4}\", p[\"norm\"], flags=re.I)]\n",
    "        years_2d    = [p for p in pieces if re.fullmatch(r\"[0-9O]{2,4}\", p[\"norm\"])]\n",
    "        def near(a, b, tol=70):\n",
    "            return abs(a[\"x\"] - b[\"x\"]) <= tol\n",
    "        for d in digits_1to4:\n",
    "            # digit + Qyy\n",
    "            candidates = [q for q in q_with_year if near(d, q)]\n",
    "            if candidates:\n",
    "                qtok = min(candidates, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                qyy = normalize_token(qtok[\"norm\"])[1:]\n",
    "                quarters.append(((d[\"x\"]+qtok[\"x\"])//2, f\"{d['norm']}Q{qyy[-2:]}\"))\n",
    "                continue\n",
    "            # digit + Q + yy\n",
    "            qs = [q for q in q_only if near(d, q)]\n",
    "            ys = [y for y in years_2d if near(d, y, tol=120)]\n",
    "            if qs and ys:\n",
    "                qtok = min(qs, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                ytok = min(ys, key=lambda y: abs(y[\"x\"]-qtok[\"x\"]))\n",
    "                yy = normalize_token(ytok[\"norm\"])\n",
    "                quarters.append(((d[\"x\"]+ytok[\"x\"])//2, f\"{d['norm']}Q{yy[-2:]}\"))\n",
    "                continue\n",
    "    if not quarters:\n",
    "        return []\n",
    "    quarters.sort(key=lambda t: t[0])\n",
    "    deduped, last_x = [], -10**9\n",
    "    for x,q in quarters:\n",
    "        if abs(x - last_x) <= 22:\n",
    "            continue\n",
    "        deduped.append((x,q))\n",
    "        last_x = x\n",
    "    return deduped\n",
    "\n",
    "# NIM value band (pct) and geometry heuristics for verification\n",
    "NIM_MIN, NIM_MAX = 1.3, 3.2\n",
    "TOP_FRACTION = 0.65     # widen band: NIM labels often sit higher than 45%\n",
    "RIGHT_HALF_ONLY = True  # NIM values appear on right panel in these deck\n",
    "\n",
    "def is_strict_nim_image(img_path: Path) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Heuristic re-check:\n",
    "      1) Title/text contains NIM keywords (coarse gate)\n",
    "      2) Percent tokens mostly within NIM_MIN..NIM_MAX\n",
    "      3) Tokens located in the top region (and right half, if enabled)\n",
    "    Returns (ok, reason)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_bgr = load_image(img_path)\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        # 1) quick-text gate (soft): don't return yet; allow numeric signature to validate\n",
    "        kw_ok = is_relevant_image(img_path, NIM_KEYWORDS)\n",
    "        # 2) numeric gate on enhanced image\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # --- Semantic gate: accept classic NIM slides based on stable labels ---\n",
    "        text_lower = \" \".join(str(r.get(\"text\", \"\")).lower() for r in ocr or [])\n",
    "        has_nim = \"net interest margin\" in text_lower\n",
    "        has_cb  = \"commercial book\" in text_lower\n",
    "        has_grp = \"group\" in text_lower\n",
    "        if has_nim and (has_cb or has_grp):\n",
    "            which = [w for w, ok in ((\"nim\", has_nim), (\"cb\", has_cb), (\"grp\", has_grp)) if ok]\n",
    "            return (True, f\"ok_semantic({'+' .join(which)})\")\n",
    "        df = extract_numbers(ocr)\n",
    "        if df.empty:\n",
    "            return (False, \"no_numbers\")\n",
    "        # geometry filters (apply before value checks)\n",
    "        top_cut = int(img_up.shape[0] * 0.62)\n",
    "        cond_geom = (df[\"cy\"] < top_cut)\n",
    "        if RIGHT_HALF_ONLY:\n",
    "            cond_geom &= (df[\"cx\"] > (img_up.shape[1] // 2))\n",
    "\n",
    "        # 2a) Preferred path: explicit percentage tokens\n",
    "        df_pct = df[(df[\"is_pct\"] == True) & cond_geom].copy()\n",
    "        if not df_pct.empty:\n",
    "            in_band = df_pct[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_pct))\n",
    "            if ratio >= 0.6:\n",
    "                return (True, \"ok\")\n",
    "            else:\n",
    "                return (False, f\"non_nim_values_out_of_band({ratio:.2f})\")\n",
    "\n",
    "        # 2b) Fallback: some decks omit the % sign near the series values.\n",
    "        # Accept plain numbers in the NIM range if units are explicit or implied, or if numeric signature is strong.\n",
    "        title_text = text_lower  # already computed above\n",
    "        has_units_pct = \"(%)\" in title_text or \"margin (%)\" in title_text or has_nim\n",
    "        df_nums = df[(df[\"is_pct\"] == False) & cond_geom].copy()\n",
    "        if not df_nums.empty:\n",
    "            in_band = df_nums[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_nums))\n",
    "            # Case A: explicit or implied units in title → accept when enough in-band hits\n",
    "            if has_units_pct and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_no_percent_signs\")\n",
    "            # Case B: title OCR may have missed units; if the quick keyword gate succeeded, accept with a stricter ratio\n",
    "            if kw_ok and ratio >= 0.7 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_numeric_signature\")\n",
    "            # Case C: strong structural evidence (quarters on bottom) + numeric signature in band\n",
    "            q_xy_fallback = detect_quarters_easyocr(img_bgr)\n",
    "            if len(q_xy_fallback) >= 4 and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_structural_numeric_signature\")\n",
    "\n",
    "        # Final decision: if numeric signature still failed, report clearer reason\n",
    "        if not kw_ok:\n",
    "            return (False, \"irrelevant_non_nim\")\n",
    "        else:\n",
    "            return (False, \"no_percentages_or_units\")\n",
    "    except Exception as e:\n",
    "        return (False, f\"exception:{e}\")\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)  # bottom 40%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Morphological close to strengthen thin glyphs\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: decide single-panel vs split-panel\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text, right_tokens_text = [], []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)  # undo scale\n",
    "\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            else:\n",
    "                right_tokens_text.append(raw.lower())\n",
    "\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        # Panel selection logic: prefer both halves unless left clearly half-year and right has ≥3 quarters\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        # Sort and dedupe close neighbors (≤18 px)\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "\n",
    "        return [q for _, q in deduped]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Same as detect_qlabels_bottom, but returns (x, label) for alignment ---\n",
    "def detect_qlabels_bottom_with_xy(img_bgr) -> list[tuple[int, str]]:\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text = []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "        return deduped\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    # Detect bottom quarter labels (with x) early to infer layout\n",
    "    detected_q_bot_xy = detect_quarters_easyocr(img_up)\n",
    "    left_count  = sum(1 for x, _ in detected_q_bot_xy if x <= mid_x)\n",
    "    right_count = sum(1 for x, _ in detected_q_bot_xy if x >  mid_x)\n",
    "    # Heuristic: if we see ≥4 quarter tokens spanning both halves, it's a single-panel timeline\n",
    "    single_panel = (len(detected_q_bot_xy) >= 4 and left_count >= 1 and right_count >= 1)\n",
    "\n",
    "    # Filter tokens: keep right-half only for split panels; keep all for single panels\n",
    "    if single_panel:\n",
    "        pct = df[(df.is_pct==True)].copy()\n",
    "        nums = df[(df.is_pct==False)].copy()\n",
    "    else:\n",
    "        pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "        nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        # Fallback for charts that omit the '%' sign on the value dots.\n",
    "        # Use a wider top band and avoid forcing right-half on single-panel timelines.\n",
    "        approx_top = int(H * 0.60)\n",
    "        if single_panel:\n",
    "            cx_mask = (df.cx > 0)  # keep all x for single panel\n",
    "        else:\n",
    "            cx_mask = (df.cx > mid_x)\n",
    "        cand_pct = df[cx_mask & df.value.between(NIM_MIN, NIM_MAX) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        # Try to split into two horizontal series by Y even when we have only 3 quarters (→ 6 points)\n",
    "        # Deduplicate by proximity on Y to stabilize clustering\n",
    "        y_sorted = pct.sort_values(\"cy\")[\"cy\"].to_numpy()\n",
    "        uniq_y = []\n",
    "        last_y = -10**9\n",
    "        for yy in y_sorted:\n",
    "            if abs(yy - last_y) >= 6:  # 6px tolerance for duplicates\n",
    "                uniq_y.append(yy)\n",
    "                last_y = yy\n",
    "        # Attempt k-means when we have at least 4 points total (≈ 2 series × 2 quarters)\n",
    "        if pct.shape[0] >= 4 and len(uniq_y) >= 2:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)  # top (commercial) should have smaller y\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "            # Sanity: ensure both series have data; else collapse to one\n",
    "            counts = pct[\"series_name\"].value_counts()\n",
    "            if any(counts.get(name, 0) == 0 for name in [\"Commercial NIM (%)\", \"Group NIM (%)\"]):\n",
    "                pct[\"series_name\"] = \"NIM (%)\"\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        # Reuse bottom-quarter labels captured above\n",
    "        detected_q_bot = [q for _, q in detected_q_bot_xy]\n",
    "        detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "        if len(detected_q_bot) > len(detected_q_ocr):\n",
    "            detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "        else:\n",
    "            detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            # Sort left→right and collapse near-duplicates (same x within 12px)\n",
    "            sub_sorted = sub.sort_values(\"cx\")\n",
    "            uniq_rows = []\n",
    "            last_x = -10**9\n",
    "            for r in sub_sorted.itertuples(index=False):\n",
    "                if abs(r.cx - last_x) < 12:\n",
    "                    continue\n",
    "                uniq_rows.append(r)\n",
    "                last_x = r.cx\n",
    "            # Keep only the right-panel portion (already ensured by cx>mid_x earlier)\n",
    "            pick = list(uniq_rows)[-5:]  # cap to 5 most recent positions, but may be <5\n",
    "            n = len(pick)\n",
    "            if n == 0:\n",
    "                continue\n",
    "            labels = []\n",
    "            # Robust mapping: map each value x to its nearest bottom quarter label x (right panel).\n",
    "            # Filter any accidental half-year tokens (1H/2H/H1/H2/9M) just in case OCR returns them.\n",
    "            def _is_half_token(t: str) -> bool:\n",
    "                t = (t or \"\").lower().replace(\" \", \"\")\n",
    "                return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t) or (\"h24\" in t) or (\"h23\" in t)\n",
    "\n",
    "            # detected_q_bot_xy already respects split vs single panel. Keep right-panel positions only here.\n",
    "            q_xy = []\n",
    "            for x, q in detected_q_bot_xy:\n",
    "                if x <= mid_x:\n",
    "                    continue\n",
    "                if _is_half_token(q):\n",
    "                    continue\n",
    "                q_xy.append((x, q))\n",
    "\n",
    "            if len(q_xy) < n:\n",
    "                # Borrow from left panel if they look like quarters (and not half-year)\n",
    "                for x, q in detected_q_bot_xy:\n",
    "                    if x > mid_x:\n",
    "                        continue\n",
    "                    if _is_half_token(q):\n",
    "                        continue\n",
    "                    q_xy.append((x, q))\n",
    "\n",
    "            if q_xy:\n",
    "                q_xy.sort(key=lambda t: t[0])  # left→right\n",
    "                # Map each picked value to nearest quarter label by x-position\n",
    "                vx = [rr.cx for rr in pick]\n",
    "                qx = [x for x, _ in q_xy]\n",
    "                ql = [q for _, q in q_xy]\n",
    "                mapped = []\n",
    "                for x in vx:\n",
    "                    j = int(np.argmin([abs(x - xx) for xx in qx])) if qx else -1\n",
    "                    mapped.append(ql[j] if j >= 0 else None)\n",
    "                labels = mapped\n",
    "            else:\n",
    "                detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "                if detected_q_ocr:\n",
    "                    labels = detected_q_ocr[-n:] if len(detected_q_ocr) >= n else detected_q_ocr\n",
    "\n",
    "            # If still short, use markdown tokens; else expand from an anchor like 2Q24\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                if qlabels_hint:\n",
    "                    labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "            # Ensure left→right order for consistent mapping to labels\n",
    "            pick = sorted(pick, key=lambda r: r.cx)\n",
    "            labels = list(labels)[:n]\n",
    "            for i, r in enumerate(pick):\n",
    "                if i >= len(labels):\n",
    "                    break\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            # Guard: drop rows with missing labels\n",
    "            nim_table = nim_table.dropna(subset=[\"Quarter\", \"series\"])  \n",
    "            # If multiple detections map to the same (Quarter, series), average them\n",
    "            if not nim_table.empty:\n",
    "                dupe_mask = nim_table.duplicated(subset=[\"Quarter\", \"series\"], keep=False)\n",
    "                if dupe_mask.any():\n",
    "                    # Aggregate duplicates by mean (stable for minor OCR jitter)\n",
    "                    nim_table = nim_table.groupby([\"Quarter\", \"series\"], as_index=False)[\"value\"].mean()\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Robust relevance check for NIM slides.\n",
    "    - Reuse the singleton EasyOCR reader (run_easyocr)\n",
    "    - Accept split tokens like \"Net\" / \"interest\" / \"margin\" (not only the exact phrase)\n",
    "    - Fallback: if we see ≥4 quarter labels on the bottom AND ≥3 top-band percent-like values in NIM range, treat as relevant.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "\n",
    "        # Pass A: OCR on lightly upscaled original\n",
    "        view_a = cv2.resize(img, None, fx=1.3, fy=1.3, interpolation=cv2.INTER_CUBIC)\n",
    "        ocr_a = run_easyocr(cv2.cvtColor(view_a, cv2.COLOR_BGR2RGB))\n",
    "        tokens_a = [str(r.get(\"text\",\"\")).lower() for r in (ocr_a or [])]\n",
    "        text_a = \" \".join(tokens_a)\n",
    "\n",
    "        # Quick phrase match (exact keywords like \"net interest margin\")\n",
    "        if any(k in text_a for k in keywords):\n",
    "            return True\n",
    "\n",
    "        # Pass B: OCR on preprocessed thresholded view (more stable for thin fonts)\n",
    "        _, _, thr, _ = preprocess(img)\n",
    "        ocr_b = run_easyocr(cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB))\n",
    "        tokens_b = [str(r.get(\"text\",\"\")).lower() for r in (ocr_b or [])]\n",
    "        text_b = \" \".join(tokens_b)\n",
    "        if any(k in text_b for k in keywords):\n",
    "            return True\n",
    "\n",
    "        # Token-level split-word check\n",
    "        tokens = tokens_a + tokens_b\n",
    "        has_net      = any(\"net\" in t for t in tokens)\n",
    "        has_interest = any(\"interest\" in t for t in tokens)\n",
    "        has_margin   = any(\"margin\" in t for t in tokens or [])\n",
    "        has_nim_abbr = any(re.search(r\"\\bnim\\b\", t) for t in tokens)\n",
    "        has_cb       = any(\"commercial book\" in t for t in tokens)\n",
    "        has_grp      = any(re.search(r\"\\bgroup\\b\", t) for t in tokens)\n",
    "        if (has_net and has_interest and has_margin) or has_nim_abbr:\n",
    "            # Strengthen with context words if available\n",
    "            if has_cb or has_grp:\n",
    "                return True\n",
    "\n",
    "        # Structural fallback: quarters + percent values in the NIM band\n",
    "        q_xy = detect_quarters_easyocr(img)\n",
    "        if len(q_xy) >= 4:\n",
    "            # Look for ≥3 percent-ish values in the top band within NIM_MIN..NIM_MAX\n",
    "            df = extract_numbers(ocr_b)\n",
    "            if not df.empty:\n",
    "                H, W = view_a.shape[:2]\n",
    "                top_cut = int(H * 0.55)\n",
    "                in_top = df[\"cy\"] < top_cut\n",
    "                in_band = df[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "                pctish = in_band  # allow numbers without % (the series sometimes omit it)\n",
    "                if int((in_top & pctish).sum()) >= 3:\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str, *, bypass_relevance: bool = False):\n",
    "        if not bypass_relevance and not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# === Single-image rebuild/verify mode (optional) ===\n",
    "# Set single_image_mode=True and point single_image_path to a specific extracted image\n",
    "# to run the two-stage gate + extraction just for that file, then exit.\n",
    "single_image_mode = True\n",
    "single_image_paths: list[Path] = [\n",
    "    Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation/_page_4_Figure_1.jpeg\"),\n",
    "    Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation/_page_5_Figure_1.jpeg\")  \n",
    "]\n",
    "# Optional singular fallback path (legacy): set to a string/Path if you want a single-image override\n",
    "single_image_path = None\n",
    "\n",
    "# Legacy fallback (ignored i\n",
    " # Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# === Fast path: single image only ===\n",
    "# === Fast path: single/multi-image only ===\n",
    "if single_image_mode:\n",
    "    paths: list[Path] = []\n",
    "    if single_image_paths:\n",
    "        paths = [Path(p) for p in single_image_paths if p is not None]\n",
    "    elif single_image_path:\n",
    "        paths = [Path(single_image_path)]\n",
    "\n",
    "    if not paths:\n",
    "        print(\"❌ single_image_mode=True but no paths were provided.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"--- Multi-image mode ---\")\n",
    "    successes = 0\n",
    "    for img_path in paths:\n",
    "        if not img_path.exists():\n",
    "            print(f\"❌ Missing: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        dest_dir = img_path.parent\n",
    "        pdf_name = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"\\n🖼️  Image: {img_path.name}  |  PDF: {pdf_name}\")\n",
    "\n",
    "        # Quick quarter readout (EasyOCR-only, bottom axis)\n",
    "        try:\n",
    "            img_bgr_quarters = load_image(img_path)\n",
    "            q_xy = detect_quarters_easyocr(img_bgr_quarters)\n",
    "            if q_xy:\n",
    "                print(\"   📎 Quarters (EasyOCR):\", \", \".join([q for _,q in q_xy]))\n",
    "            else:\n",
    "                print(\"   📎 Quarters (EasyOCR): <none>\")\n",
    "        except Exception as _qe:\n",
    "            print(f\"   📎 Quarters (EasyOCR): error → {_qe}\")\n",
    "\n",
    "        any_hit = False\n",
    "\n",
    "        for ex in EXTRACTORS:\n",
    "            print(f\"   · [{ex.name}] quick gate…\", end=\" \")\n",
    "            if not ex.is_relevant(img_path):\n",
    "                print(\"⏭️  Not relevant\")\n",
    "                continue\n",
    "            print(\"✅ ok; strict gate…\", end=\" \")\n",
    "            ok_strict, reason = is_strict_nim_image(img_path)\n",
    "            if not ok_strict:\n",
    "                print(f\"⏭️  Failed strict ({reason})\")\n",
    "                continue\n",
    "            print(\"✅ Strict OK — extracting…\")\n",
    "\n",
    "            # Extract directly so we can print the table; still write JSONL\n",
    "            df, ctx_extra = ex.extract_table(img_path, dest_dir, pdf_name)\n",
    "            if df is None or df.empty:\n",
    "                print(\"   ⚠️ No data extracted.\")\n",
    "                continue\n",
    "\n",
    "            any_hit = True\n",
    "            successes += 1\n",
    "\n",
    "            # Build context + summary and write JSONL\n",
    "            ctx = ex._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "            try:\n",
    "                cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "                if len(df) >= 2 and cols:\n",
    "                    def _pick_q(s):\n",
    "                        return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                    _fq = str(df.iloc[0][\"Quarter\"]); _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                    first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                    last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                    pieces = []\n",
    "                    for col in cols[:2]:\n",
    "                        a = df.iloc[0][col]; b = df.iloc[-1][col]\n",
    "                        if pd.notna(a) and pd.notna(b):\n",
    "                            suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                            pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                    if pieces:\n",
    "                        ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            out_path = img_path.with_suffix(f\".{ex.name}.jsonl\")\n",
    "            ex._write_jsonl(out_path, ctx, df)\n",
    "            print(f\"   💾 Saved JSONL → {out_path}\")\n",
    "\n",
    "            # Pretty-print the extracted table directly\n",
    "            try:\n",
    "                print(\"\\n   📊 Extracted table:\")\n",
    "                print(df.to_string(index=False))\n",
    "            except Exception:\n",
    "                print(df)\n",
    "\n",
    "        if not any_hit:\n",
    "            print(\"   ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "    print(f\"\\n✅ Done. Extracted from {successes} image(s).\")\n",
    "    # Prevent the pipeline (marker/md5) from running if notebook catches SystemExit\n",
    "    globals()[\"_STOP_AFTER_SINGLE\"] = True\n",
    "    sys.exit(0)\n",
    "    \n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                # Stage 1: quick keyword/title skim\n",
    "                print(f\"      · [{ex.name}] quick gate…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                print(\"✅ ok; strict gate…\", end=\" \")\n",
    "\n",
    "                # Stage 2: strict verifier (geometry + numeric band + semantic anchors)\n",
    "                ok_strict, reason = is_strict_nim_image(img_path)\n",
    "                if not ok_strict:\n",
    "                    print(f\"⏭️  Failed strict ({reason})\")\n",
    "                    continue\n",
    "\n",
    "                any_hit = True\n",
    "                print(\"✅ Strict OK — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name, bypass_relevance=True)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f491152",
   "metadata": {},
   "source": [
    "Stage 1 Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd73c88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: 3Q24_CFO_presentation.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "Running CLI command for JSON output on 3Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 22:24:28,387 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 21/21 [01:50<00:00,  5.26s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 6/6 [00:00<00:00, 13.39it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Recognizing Text: 100%|██████████| 13/13 [00:33<00:00,  2.55s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:04<00:00,  4.71s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n",
      "Recognizing Text: 100%|██████████| 42/42 [00:11<00:00,  3.81it/s]\n",
      "2025-10-30 22:27:21,618 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation\n",
      "2025-10-30 22:27:21,618 [INFO] marker: Total time: 171.5794539451599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 3Q24_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 22:27:32,588 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 21/21 [01:56<00:00,  5.53s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 6/6 [00:00<00:00, 13.58it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Recognizing Text: 100%|██████████| 13/13 [00:30<00:00,  2.37s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "Recognizing Text: 100%|██████████| 42/42 [00:08<00:00,  4.86it/s]\n",
      "2025-10-30 22:30:23,850 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation\n",
      "2025-10-30 22:30:23,850 [INFO] marker: Total time: 170.33986520767212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_3.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_18_Picture_3.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_19_Picture_5.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_16.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_20_Picture_0.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Picture_11.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Figure_4.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Picture_8.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ⏭️  Failed strict (non_nim_values_out_of_band(0.00))\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ⏭️  Failed strict (non_nim_values_out_of_band(0.00))\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation/_page_7_Figure_1.nim.jsonl\n",
      "   • _page_8_Figure_1.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_6.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/3Q24_CFO_presentation/.marker_md5\n",
      "--- Finished processing: 3Q24_CFO_presentation.pdf ---\n",
      "\n",
      "--- Processing file: 1Q25_CFO_presentation.pdf ---\n",
      "⚙️  md5_check=False → forcing reprocess (marker + OCR).\n",
      "Running CLI command for JSON output on 1Q25_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 22:36:41,830 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 18/18 [01:36<00:00,  5.38s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 5/5 [00:00<00:00,  6.68it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:08<00:00,  4.02s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 22:38:37,411 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/1Q25_CFO_presentation\n",
      "2025-10-30 22:38:37,411 [INFO] marker: Total time: 114.31595182418823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON file generated successfully by CLI.\n",
      "\n",
      "Running CLI command for Markdown and Image output on 1Q25_CFO_presentation.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 22:38:48,102 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 18/18 [01:33<00:00,  5.18s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 5/5 [00:00<00:00, 13.04it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:07<00:00,  4.00s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:05<00:00,  5.73s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "2025-10-30 22:40:38,991 [INFO] marker: Saved markdown to /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/1Q25_CFO_presentation\n",
      "2025-10-30 22:40:38,991 [INFO] marker: Total time: 110.01462292671204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Markdown file and images generated successfully by CLI.\n",
      "\n",
      "✨ Files saved under '/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/1Q25_CFO_presentation'.\n",
      "Note: Marker creates a subfolder named after the PDF automatically.\n",
      "🔎 Scanning extracted images for relevant charts/plots…\n",
      "   • _page_0_Picture_0.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_10_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_11_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_12_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_13_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_14_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_15_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_16_Picture_5.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_17_Picture_0.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_1_Picture_14.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_2_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_3_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ⏭️  Failed strict (non_nim_values_out_of_band(0.00))\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_4_Figure_1.jpeg\n",
      "      · [nim] quick gate… ✅ ok; strict gate… ✅ Strict OK — extracting… 💾 Saved → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/1Q25_CFO_presentation/_page_4_Figure_1.nim.jsonl\n",
      "   • _page_5_Figure_1.jpeg\n",
      "      · [nim] quick gate… "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_5_Picture_3.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Figure_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_6_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_7_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_8_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_1.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "   • _page_9_Picture_2.jpeg\n",
      "      · [nim] quick gate… ⏭️  Not relevant\n",
      "      ⏭️  No matching extractors for this image.\n",
      "🧾 Recorded checksum in: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/1Q25_CFO_presentation/.marker_md5\n",
      "--- Finished processing: 1Q25_CFO_presentation.pdf ---\n",
      "\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4Iil|])\\s*[QO0]\\s*([0-9O]{2,4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- OCR character normalization for quarter tokens (common OCR mistakes) ---\n",
    "_CHAR_FIX = str.maketrans({\n",
    "    \"O\":\"0\",\"o\":\"0\",\n",
    "    \"S\":\"5\",\"s\":\"5\",\n",
    "    \"I\":\"1\",\"l\":\"1\",\"|\":\"1\",\"!\":\"1\",\n",
    "    \"D\":\"0\",\n",
    "    \"B\":\"3\",\"8\":\"3\",\n",
    "    \"Z\":\"2\",\"z\":\"2\"\n",
    "})\n",
    "def normalize_token(t: str) -> str:\n",
    "    t = (t or \"\").strip()\n",
    "    return t.translate(_CHAR_FIX).replace(\" \", \"\")\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    global _EASY_OCR_READER\n",
    "    try:\n",
    "        _EASY_OCR_READER\n",
    "    except NameError:\n",
    "        _EASY_OCR_READER = None\n",
    "    if _EASY_OCR_READER is None:\n",
    "        _EASY_OCR_READER = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = _EASY_OCR_READER.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "# --- Focused bottom-axis quarter detection using EasyOCR (robust to OCR confusions) ---\n",
    "def detect_quarters_easyocr(img_bgr):\n",
    "    \"\"\"\n",
    "    Use EasyOCR to read quarter labels along the bottom axis.\n",
    "    Returns a list of (x_global, 'nQyy') sorted left→right, with half-year tokens removed.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    y0 = int(H * 0.66)  # bottom ~34%\n",
    "    crop = img_bgr[y0:H, 0:W]\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    # kernel = np.ones((3,3), np.uint8)\n",
    "    # thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    up = cv2.resize(thr, None, fx=3.0, fy=3.0, interpolation=cv2.INTER_CUBIC)\n",
    "    img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    # PASS 1 — direct regex on normalized tokens\n",
    "    tokens = []\n",
    "    for r in ocr or []:\n",
    "        raw = str(r.get(\"text\",\"\")).strip()\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx_local = (x1 + x2) // 2\n",
    "        cx_global = int(cx_local / 3.0)  # undo scaling\n",
    "        tokens.append({\"x\": cx_global, \"raw\": raw, \"norm\": normalize_token(raw)})\n",
    "    def _is_half_token(t: str) -> bool:\n",
    "        t = (t or \"\").lower().replace(\" \", \"\")\n",
    "        return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t)\n",
    "    quarters = []\n",
    "    for t in tokens:\n",
    "        if _is_half_token(t[\"norm\"]):\n",
    "            continue\n",
    "        m = QUARTER_PAT.search(t[\"norm\"])\n",
    "        if m:\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            q = normalize_token(q)\n",
    "            quarters.append((t[\"x\"], q))\n",
    "    # PASS 2 — stitch split tokens if too few quarters were found\n",
    "    if len(quarters) < 4 and tokens:\n",
    "        pieces = sorted(tokens, key=lambda d: d[\"x\"])\n",
    "        digits_1to4 = [p for p in pieces if p[\"norm\"] in (\"1\",\"2\",\"3\",\"4\")]\n",
    "        q_only      = [p for p in pieces if p[\"norm\"].upper() == \"Q\"]\n",
    "        q_with_year = [p for p in pieces if re.fullmatch(r\"Q[0-9O]{2,4}\", p[\"norm\"], flags=re.I)]\n",
    "        years_2d    = [p for p in pieces if re.fullmatch(r\"[0-9O]{2,4}\", p[\"norm\"])]\n",
    "        def near(a, b, tol=70):\n",
    "            return abs(a[\"x\"] - b[\"x\"]) <= tol\n",
    "        for d in digits_1to4:\n",
    "            # digit + Qyy\n",
    "            candidates = [q for q in q_with_year if near(d, q)]\n",
    "            if candidates:\n",
    "                qtok = min(candidates, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                qyy = normalize_token(qtok[\"norm\"])[1:]\n",
    "                quarters.append(((d[\"x\"]+qtok[\"x\"])//2, f\"{d['norm']}Q{qyy[-2:]}\"))\n",
    "                continue\n",
    "            # digit + Q + yy\n",
    "            qs = [q for q in q_only if near(d, q)]\n",
    "            ys = [y for y in years_2d if near(d, y, tol=120)]\n",
    "            if qs and ys:\n",
    "                qtok = min(qs, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                ytok = min(ys, key=lambda y: abs(y[\"x\"]-qtok[\"x\"]))\n",
    "                yy = normalize_token(ytok[\"norm\"])\n",
    "                quarters.append(((d[\"x\"]+ytok[\"x\"])//2, f\"{d['norm']}Q{yy[-2:]}\"))\n",
    "                continue\n",
    "    if not quarters:\n",
    "        return []\n",
    "    quarters.sort(key=lambda t: t[0])\n",
    "    deduped, last_x = [], -10**9\n",
    "    for x,q in quarters:\n",
    "        if abs(x - last_x) <= 22:\n",
    "            continue\n",
    "        deduped.append((x,q))\n",
    "        last_x = x\n",
    "    return deduped\n",
    "\n",
    "# NIM value band (pct) and geometry heuristics for verification\n",
    "NIM_MIN, NIM_MAX = 1.3, 3.2\n",
    "TOP_FRACTION = 0.65     # widen band: NIM labels often sit higher than 45%\n",
    "RIGHT_HALF_ONLY = True  # NIM values appear on right panel in these deck\n",
    "\n",
    "def is_strict_nim_image(img_path: Path) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Heuristic re-check:\n",
    "      1) Title/text contains NIM keywords (coarse gate)\n",
    "      2) Percent tokens mostly within NIM_MIN..NIM_MAX\n",
    "      3) Tokens located in the top region (and right half, if enabled)\n",
    "    Returns (ok, reason)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_bgr = load_image(img_path)\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        # 1) quick-text gate (soft): don't return yet; allow numeric signature to validate\n",
    "        kw_ok = is_relevant_image(img_path, NIM_KEYWORDS)\n",
    "        # 2) numeric gate on enhanced image\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # --- Semantic gate: accept classic NIM slides based on stable labels ---\n",
    "        text_lower = \" \".join(str(r.get(\"text\", \"\")).lower() for r in ocr or [])\n",
    "        has_nim = \"net interest margin\" in text_lower\n",
    "        has_cb  = \"commercial book\" in text_lower\n",
    "        has_grp = \"group\" in text_lower\n",
    "        if has_nim and (has_cb or has_grp):\n",
    "            which = [w for w, ok in ((\"nim\", has_nim), (\"cb\", has_cb), (\"grp\", has_grp)) if ok]\n",
    "            return (True, f\"ok_semantic({'+' .join(which)})\")\n",
    "        df = extract_numbers(ocr)\n",
    "        if df.empty:\n",
    "            return (False, \"no_numbers\")\n",
    "        # geometry filters (apply before value checks)\n",
    "        top_cut = int(img_up.shape[0] * 0.62)\n",
    "        cond_geom = (df[\"cy\"] < top_cut)\n",
    "        if RIGHT_HALF_ONLY:\n",
    "            cond_geom &= (df[\"cx\"] > (img_up.shape[1] // 2))\n",
    "\n",
    "        # 2a) Preferred path: explicit percentage tokens\n",
    "        df_pct = df[(df[\"is_pct\"] == True) & cond_geom].copy()\n",
    "        if not df_pct.empty:\n",
    "            in_band = df_pct[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_pct))\n",
    "            if ratio >= 0.6:\n",
    "                return (True, \"ok\")\n",
    "            else:\n",
    "                return (False, f\"non_nim_values_out_of_band({ratio:.2f})\")\n",
    "\n",
    "        # 2b) Fallback: some decks omit the % sign near the series values.\n",
    "        # Accept plain numbers in the NIM range if units are explicit or implied, or if numeric signature is strong.\n",
    "        title_text = text_lower  # already computed above\n",
    "        has_units_pct = \"(%)\" in title_text or \"margin (%)\" in title_text or has_nim\n",
    "        df_nums = df[(df[\"is_pct\"] == False) & cond_geom].copy()\n",
    "        if not df_nums.empty:\n",
    "            in_band = df_nums[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_nums))\n",
    "            # Case A: explicit or implied units in title → accept when enough in-band hits\n",
    "            if has_units_pct and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_no_percent_signs\")\n",
    "            # Case B: title OCR may have missed units; if the quick keyword gate succeeded, accept with a stricter ratio\n",
    "            if kw_ok and ratio >= 0.7 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_numeric_signature\")\n",
    "            # Case C: strong structural evidence (quarters on bottom) + numeric signature in band\n",
    "            q_xy_fallback = detect_quarters_easyocr(img_bgr)\n",
    "            if len(q_xy_fallback) >= 4 and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_structural_numeric_signature\")\n",
    "\n",
    "        # Final decision: if numeric signature still failed, report clearer reason\n",
    "        if not kw_ok:\n",
    "            return (False, \"irrelevant_non_nim\")\n",
    "        else:\n",
    "            return (False, \"no_percentages_or_units\")\n",
    "    except Exception as e:\n",
    "        return (False, f\"exception:{e}\")\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)  # bottom 40%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Morphological close to strengthen thin glyphs\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: decide single-panel vs split-panel\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text, right_tokens_text = [], []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)  # undo scale\n",
    "\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            else:\n",
    "                right_tokens_text.append(raw.lower())\n",
    "\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        # Panel selection logic: prefer both halves unless left clearly half-year and right has ≥3 quarters\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        # Sort and dedupe close neighbors (≤18 px)\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "\n",
    "        return [q for _, q in deduped]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Same as detect_qlabels_bottom, but returns (x, label) for alignment ---\n",
    "def detect_qlabels_bottom_with_xy(img_bgr) -> list[tuple[int, str]]:\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text = []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "        return deduped\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    # Detect bottom quarter labels (with x) early to infer layout\n",
    "    detected_q_bot_xy = detect_quarters_easyocr(img_up)\n",
    "    left_count  = sum(1 for x, _ in detected_q_bot_xy if x <= mid_x)\n",
    "    right_count = sum(1 for x, _ in detected_q_bot_xy if x >  mid_x)\n",
    "    # Heuristic: if we see ≥4 quarter tokens spanning both halves, it's a single-panel timeline\n",
    "    single_panel = (len(detected_q_bot_xy) >= 4 and left_count >= 1 and right_count >= 1)\n",
    "\n",
    "    # Filter tokens: keep right-half only for split panels; keep all for single panels\n",
    "    if single_panel:\n",
    "        pct = df[(df.is_pct==True)].copy()\n",
    "        nums = df[(df.is_pct==False)].copy()\n",
    "    else:\n",
    "        pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "        nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        # Fallback for charts that omit the '%' sign on the value dots.\n",
    "        # Use a wider top band and avoid forcing right-half on single-panel timelines.\n",
    "        approx_top = int(H * 0.60)\n",
    "        if single_panel:\n",
    "            cx_mask = (df.cx > 0)  # keep all x for single panel\n",
    "        else:\n",
    "            cx_mask = (df.cx > mid_x)\n",
    "        cand_pct = df[cx_mask & df.value.between(NIM_MIN, NIM_MAX) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        # Try to split into two horizontal series by Y even when we have only 3 quarters (→ 6 points)\n",
    "        # Deduplicate by proximity on Y to stabilize clustering\n",
    "        y_sorted = pct.sort_values(\"cy\")[\"cy\"].to_numpy()\n",
    "        uniq_y = []\n",
    "        last_y = -10**9\n",
    "        for yy in y_sorted:\n",
    "            if abs(yy - last_y) >= 6:  # 6px tolerance for duplicates\n",
    "                uniq_y.append(yy)\n",
    "                last_y = yy\n",
    "        # Attempt k-means when we have at least 4 points total (≈ 2 series × 2 quarters)\n",
    "        if pct.shape[0] >= 4 and len(uniq_y) >= 2:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)  # top (commercial) should have smaller y\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "            # Sanity: ensure both series have data; else collapse to one\n",
    "            counts = pct[\"series_name\"].value_counts()\n",
    "            if any(counts.get(name, 0) == 0 for name in [\"Commercial NIM (%)\", \"Group NIM (%)\"]):\n",
    "                pct[\"series_name\"] = \"NIM (%)\"\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        # Reuse bottom-quarter labels captured above\n",
    "        detected_q_bot = [q for _, q in detected_q_bot_xy]\n",
    "        detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "        if len(detected_q_bot) > len(detected_q_ocr):\n",
    "            detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "        else:\n",
    "            detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            # Sort left→right and collapse near-duplicates (same x within 12px)\n",
    "            sub_sorted = sub.sort_values(\"cx\")\n",
    "            uniq_rows = []\n",
    "            last_x = -10**9\n",
    "            for r in sub_sorted.itertuples(index=False):\n",
    "                if abs(r.cx - last_x) < 12:\n",
    "                    continue\n",
    "                uniq_rows.append(r)\n",
    "                last_x = r.cx\n",
    "            # Keep only the right-panel portion (already ensured by cx>mid_x earlier)\n",
    "            pick = list(uniq_rows)[-5:]  # cap to 5 most recent positions, but may be <5\n",
    "            n = len(pick)\n",
    "            if n == 0:\n",
    "                continue\n",
    "            labels = []\n",
    "            # Robust mapping: map each value x to its nearest bottom quarter label x (right panel).\n",
    "            # Filter any accidental half-year tokens (1H/2H/H1/H2/9M) just in case OCR returns them.\n",
    "            def _is_half_token(t: str) -> bool:\n",
    "                t = (t or \"\").lower().replace(\" \", \"\")\n",
    "                return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t) or (\"h24\" in t) or (\"h23\" in t)\n",
    "\n",
    "            # detected_q_bot_xy already respects split vs single panel. Keep right-panel positions only here.\n",
    "            q_xy = []\n",
    "            for x, q in detected_q_bot_xy:\n",
    "                if x <= mid_x:\n",
    "                    continue\n",
    "                if _is_half_token(q):\n",
    "                    continue\n",
    "                q_xy.append((x, q))\n",
    "\n",
    "            if len(q_xy) < n:\n",
    "                # Borrow from left panel if they look like quarters (and not half-year)\n",
    "                for x, q in detected_q_bot_xy:\n",
    "                    if x > mid_x:\n",
    "                        continue\n",
    "                    if _is_half_token(q):\n",
    "                        continue\n",
    "                    q_xy.append((x, q))\n",
    "\n",
    "            if q_xy:\n",
    "                q_xy.sort(key=lambda t: t[0])  # left→right\n",
    "                # Map each picked value to nearest quarter label by x-position\n",
    "                vx = [rr.cx for rr in pick]\n",
    "                qx = [x for x, _ in q_xy]\n",
    "                ql = [q for _, q in q_xy]\n",
    "                mapped = []\n",
    "                for x in vx:\n",
    "                    j = int(np.argmin([abs(x - xx) for xx in qx])) if qx else -1\n",
    "                    mapped.append(ql[j] if j >= 0 else None)\n",
    "                labels = mapped\n",
    "            else:\n",
    "                detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "                if detected_q_ocr:\n",
    "                    labels = detected_q_ocr[-n:] if len(detected_q_ocr) >= n else detected_q_ocr\n",
    "\n",
    "            # If still short, use markdown tokens; else expand from an anchor like 2Q24\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                if qlabels_hint:\n",
    "                    labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "            # Ensure left→right order for consistent mapping to labels\n",
    "            pick = sorted(pick, key=lambda r: r.cx)\n",
    "            labels = list(labels)[:n]\n",
    "            for i, r in enumerate(pick):\n",
    "                if i >= len(labels):\n",
    "                    break\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            # Guard: drop rows with missing labels\n",
    "            nim_table = nim_table.dropna(subset=[\"Quarter\", \"series\"])  \n",
    "            # If multiple detections map to the same (Quarter, series), average them\n",
    "            if not nim_table.empty:\n",
    "                dupe_mask = nim_table.duplicated(subset=[\"Quarter\", \"series\"], keep=False)\n",
    "                if dupe_mask.any():\n",
    "                    # Aggregate duplicates by mean (stable for minor OCR jitter)\n",
    "                    nim_table = nim_table.groupby([\"Quarter\", \"series\"], as_index=False)[\"value\"].mean()\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Robust relevance check for NIM slides.\n",
    "    - Reuse the singleton EasyOCR reader (run_easyocr)\n",
    "    - Accept split tokens like \"Net\" / \"interest\" / \"margin\" (not only the exact phrase)\n",
    "    - Fallback: if we see ≥4 quarter labels on the bottom AND ≥3 top-band percent-like values in NIM range, treat as relevant.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "\n",
    "        # Pass A: OCR on lightly upscaled original\n",
    "        view_a = cv2.resize(img, None, fx=1.3, fy=1.3, interpolation=cv2.INTER_CUBIC)\n",
    "        ocr_a = run_easyocr(cv2.cvtColor(view_a, cv2.COLOR_BGR2RGB))\n",
    "        tokens_a = [str(r.get(\"text\",\"\")).lower() for r in (ocr_a or [])]\n",
    "        text_a = \" \".join(tokens_a)\n",
    "\n",
    "        # Quick phrase match (exact keywords like \"net interest margin\")\n",
    "        if any(k in text_a for k in keywords):\n",
    "            return True\n",
    "\n",
    "        # Pass B: OCR on preprocessed thresholded view (more stable for thin fonts)\n",
    "        _, _, thr, _ = preprocess(img)\n",
    "        ocr_b = run_easyocr(cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB))\n",
    "        tokens_b = [str(r.get(\"text\",\"\")).lower() for r in (ocr_b or [])]\n",
    "        text_b = \" \".join(tokens_b)\n",
    "        if any(k in text_b for k in keywords):\n",
    "            return True\n",
    "\n",
    "        # Token-level split-word check\n",
    "        tokens = tokens_a + tokens_b\n",
    "        has_net      = any(\"net\" in t for t in tokens)\n",
    "        has_interest = any(\"interest\" in t for t in tokens)\n",
    "        has_margin   = any(\"margin\" in t for t in tokens or [])\n",
    "        has_nim_abbr = any(re.search(r\"\\bnim\\b\", t) for t in tokens)\n",
    "        has_cb       = any(\"commercial book\" in t for t in tokens)\n",
    "        has_grp      = any(re.search(r\"\\bgroup\\b\", t) for t in tokens)\n",
    "        if (has_net and has_interest and has_margin) or has_nim_abbr:\n",
    "            # Strengthen with context words if available\n",
    "            if has_cb or has_grp:\n",
    "                return True\n",
    "\n",
    "        # Structural fallback: quarters + percent values in the NIM band\n",
    "        q_xy = detect_quarters_easyocr(img)\n",
    "        if len(q_xy) >= 4:\n",
    "            # Look for ≥3 percent-ish values in the top band within NIM_MIN..NIM_MAX\n",
    "            df = extract_numbers(ocr_b)\n",
    "            if not df.empty:\n",
    "                H, W = view_a.shape[:2]\n",
    "                top_cut = int(H * 0.55)\n",
    "                in_top = df[\"cy\"] < top_cut\n",
    "                in_band = df[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "                pctish = in_band  # allow numbers without % (the series sometimes omit it)\n",
    "                if int((in_top & pctish).sum()) >= 3:\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str, *, bypass_relevance: bool = False):\n",
    "        if not bypass_relevance and not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# === Single-image rebuild/verify mode (optional) ===\n",
    "# Set single_image_mode=True and point single_image_path to a specific extracted image\n",
    "# to run the two-stage gate + extraction just for that file, then exit.\n",
    "single_image_mode = False\n",
    "single_image_paths: list[Path] = [\n",
    "   \n",
    "]\n",
    "# Optional singular fallback path (legacy): set to a string/Path if you want a single-image override\n",
    "single_image_path = None\n",
    "\n",
    "# Legacy fallback (ignored i\n",
    " # Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = False\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/Demo/\")\n",
    "\n",
    "# === Fast path: single image only ===\n",
    "# === Fast path: single/multi-image only ===\n",
    "if single_image_mode:\n",
    "    paths: list[Path] = []\n",
    "    if single_image_paths:\n",
    "        paths = [Path(p) for p in single_image_paths if p is not None]\n",
    "    elif single_image_path:\n",
    "        paths = [Path(single_image_path)]\n",
    "\n",
    "    if not paths:\n",
    "        print(\"❌ single_image_mode=True but no paths were provided.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"--- Multi-image mode ---\")\n",
    "    successes = 0\n",
    "    for img_path in paths:\n",
    "        if not img_path.exists():\n",
    "            print(f\"❌ Missing: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        dest_dir = img_path.parent\n",
    "        pdf_name = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"\\n🖼️  Image: {img_path.name}  |  PDF: {pdf_name}\")\n",
    "\n",
    "        # Quick quarter readout (EasyOCR-only, bottom axis)\n",
    "        try:\n",
    "            img_bgr_quarters = load_image(img_path)\n",
    "            q_xy = detect_quarters_easyocr(img_bgr_quarters)\n",
    "            if q_xy:\n",
    "                print(\"   📎 Quarters (EasyOCR):\", \", \".join([q for _,q in q_xy]))\n",
    "            else:\n",
    "                print(\"   📎 Quarters (EasyOCR): <none>\")\n",
    "        except Exception as _qe:\n",
    "            print(f\"   📎 Quarters (EasyOCR): error → {_qe}\")\n",
    "\n",
    "        any_hit = False\n",
    "\n",
    "        for ex in EXTRACTORS:\n",
    "            print(f\"   · [{ex.name}] quick gate…\", end=\" \")\n",
    "            if not ex.is_relevant(img_path):\n",
    "                print(\"⏭️  Not relevant\")\n",
    "                continue\n",
    "            print(\"✅ ok; strict gate…\", end=\" \")\n",
    "            ok_strict, reason = is_strict_nim_image(img_path)\n",
    "            if not ok_strict:\n",
    "                print(f\"⏭️  Failed strict ({reason})\")\n",
    "                continue\n",
    "            print(\"✅ Strict OK — extracting…\")\n",
    "\n",
    "            # Extract directly so we can print the table; still write JSONL\n",
    "            df, ctx_extra = ex.extract_table(img_path, dest_dir, pdf_name)\n",
    "            if df is None or df.empty:\n",
    "                print(\"   ⚠️ No data extracted.\")\n",
    "                continue\n",
    "\n",
    "            any_hit = True\n",
    "            successes += 1\n",
    "\n",
    "            # Build context + summary and write JSONL\n",
    "            ctx = ex._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "            try:\n",
    "                cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "                if len(df) >= 2 and cols:\n",
    "                    def _pick_q(s):\n",
    "                        return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                    _fq = str(df.iloc[0][\"Quarter\"]); _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                    first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                    last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                    pieces = []\n",
    "                    for col in cols[:2]:\n",
    "                        a = df.iloc[0][col]; b = df.iloc[-1][col]\n",
    "                        if pd.notna(a) and pd.notna(b):\n",
    "                            suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                            pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                    if pieces:\n",
    "                        ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            out_path = img_path.with_suffix(f\".{ex.name}.jsonl\")\n",
    "            ex._write_jsonl(out_path, ctx, df)\n",
    "            print(f\"   💾 Saved JSONL → {out_path}\")\n",
    "\n",
    "            # Pretty-print the extracted table directly\n",
    "            try:\n",
    "                print(\"\\n   📊 Extracted table:\")\n",
    "                print(df.to_string(index=False))\n",
    "            except Exception:\n",
    "                print(df)\n",
    "\n",
    "        if not any_hit:\n",
    "            print(\"   ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "    print(f\"\\n✅ Done. Extracted from {successes} image(s).\")\n",
    "    # Prevent the pipeline (marker/md5) from running if notebook catches SystemExit\n",
    "    globals()[\"_STOP_AFTER_SINGLE\"] = True\n",
    "    sys.exit(0)\n",
    "    \n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                # Stage 1: quick keyword/title skim\n",
    "                print(f\"      · [{ex.name}] quick gate…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                print(\"✅ ok; strict gate…\", end=\" \")\n",
    "\n",
    "                # Stage 2: strict verifier (geometry + numeric band + semantic anchors)\n",
    "                ok_strict, reason = is_strict_nim_image(img_path)\n",
    "                if not ok_strict:\n",
    "                    print(f\"⏭️  Failed strict ({reason})\")\n",
    "                    continue\n",
    "\n",
    "                any_hit = True\n",
    "                print(\"✅ Strict OK — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name, bypass_relevance=True)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee01a1",
   "metadata": {},
   "source": [
    "## Approved V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76589084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing file: 2Q24_performance_summary.pdf ---\n",
      "⏭️  Skipping 2Q24_performance_summary.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_performance_summary\n",
      "--- Processing file: 3Q24_CEO_presentation.pdf ---\n",
      "⏭️  Skipping 3Q24_CEO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CEO_presentation\n",
      "--- Processing file: 4Q24_CFO_presentation.pdf ---\n",
      "⏭️  Skipping 4Q24_CFO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CFO_presentation\n",
      "--- Processing file: 4Q24_performance_summary.pdf ---\n",
      "⏭️  Skipping 4Q24_performance_summary.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_performance_summary\n",
      "--- Processing file: 4Q24_CEO_presentation.pdf ---\n",
      "⏭️  Skipping 4Q24_CEO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_CEO_presentation\n",
      "--- Processing file: 3Q24_trading_update.pdf ---\n",
      "⏭️  Skipping 3Q24_trading_update.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_trading_update\n",
      "--- Processing file: 3Q24_CFO_presentation.pdf ---\n",
      "⏭️  Skipping 3Q24_CFO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/3Q24_CFO_presentation\n",
      "--- Processing file: 1Q24_trading_update.pdf ---\n",
      "⏭️  Skipping 1Q24_trading_update.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_trading_update\n",
      "--- Processing file: 2Q25_CFO_presentation.pdf ---\n",
      "⏭️  Skipping 2Q25_CFO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CFO_presentation\n",
      "--- Processing file: 4Q24_press_statement.pdf ---\n",
      "⏭️  Skipping 4Q24_press_statement.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/4Q24_press_statement\n",
      "--- Processing file: 1Q25_CEO_presentation.pdf ---\n",
      "⏭️  Skipping 1Q25_CEO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CEO_presentation\n",
      "--- Processing file: 1Q25_trading_update.pdf ---\n",
      "⏭️  Skipping 1Q25_trading_update.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_trading_update\n",
      "--- Processing file: dbs-annual-report-2024.pdf ---\n",
      "⏭️  Skipping dbs-annual-report-2024.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2024\n",
      "--- Processing file: 1Q24_CFO_presentation.pdf ---\n",
      "⏭️  Skipping 1Q24_CFO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CFO_presentation\n",
      "--- Processing file: dbs-annual-report-2023.pdf ---\n",
      "⏭️  Skipping dbs-annual-report-2023.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2023\n",
      "--- Processing file: 2Q24_CEO_presentation.pdf ---\n",
      "⏭️  Skipping 2Q24_CEO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CEO_presentation\n",
      "--- Processing file: 2Q25_performance_summary.pdf ---\n",
      "⏭️  Skipping 2Q25_performance_summary.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_performance_summary\n",
      "--- Processing file: dbs-annual-report-2022.pdf ---\n",
      "⏭️  Skipping dbs-annual-report-2022.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/dbs-annual-report-2022\n",
      "--- Processing file: 1Q24_CEO_presentation.pdf ---\n",
      "⏭️  Skipping 1Q24_CEO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q24_CEO_presentation\n",
      "--- Processing file: 2Q24_CFO_presentation.pdf ---\n",
      "⏭️  Skipping 2Q24_CFO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_CFO_presentation\n",
      "--- Processing file: 2Q25_CEO_presentation.pdf ---\n",
      "⏭️  Skipping 2Q25_CEO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_CEO_presentation\n",
      "--- Processing file: 1Q25_CFO_presentation.pdf ---\n",
      "⏭️  Skipping 1Q25_CFO_presentation.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/1Q25_CFO_presentation\n",
      "--- Processing file: 2Q25_press_statement.pdf ---\n",
      "⏭️  Skipping 2Q25_press_statement.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q25_press_statement\n",
      "--- Processing file: 2Q24_press_statement.pdf ---\n",
      "⏭️  Skipping 2Q24_press_statement.pdf: up-to-date (md5 match). → /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/2Q24_press_statement\n",
      "🎉 All PDF files in the directory have been processed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the marker library\n",
    "# This command should be run in your terminal or a Colab cell:\n",
    "# !pip install marker-pdf -q\n",
    "\n",
    "# 2. Import necessary components\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import hashlib\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    \"\"\"Return the hex md5 of a file.\"\"\"\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === OCR & extraction helpers ===\n",
    "NUM_PAT = re.compile(r\"^[+-]?\\d{1,4}(?:[.,]\\d+)?%?$\")\n",
    "NIM_KEYWORDS = [\"net interest margin\", \"nim\"]\n",
    "\n",
    "QUARTER_PAT = re.compile(r\"\\b([1-4Iil|])\\s*[QO0]\\s*([0-9O]{2,4})\\b\", re.IGNORECASE)\n",
    "# Simpler decade-only pattern for quarters, e.g., 2Q24, 1Q25\n",
    "QUARTER_SIMPLE_PAT = re.compile(r\"\\b([1-4])Q(2\\d)\\b\", re.IGNORECASE)  # e.g., 2Q24, 1Q25\n",
    "\n",
    "# --- OCR character normalization for quarter tokens (common OCR mistakes) ---\n",
    "_CHAR_FIX = str.maketrans({\n",
    "    \"O\":\"0\",\"o\":\"0\",\n",
    "    \"S\":\"5\",\"s\":\"5\",\n",
    "    \"I\":\"1\",\"l\":\"1\",\"|\":\"1\",\"!\":\"1\",\n",
    "    \"D\":\"0\",\n",
    "    \"B\":\"3\",\"8\":\"3\",\n",
    "    \"Z\":\"2\",\"z\":\"2\"\n",
    "})\n",
    "def normalize_token(t: str) -> str:\n",
    "    t = (t or \"\").strip()\n",
    "    return t.translate(_CHAR_FIX).replace(\" \", \"\")\n",
    "\n",
    "# --- Helper: detect quarter tokens from nearby Markdown file ---\n",
    "def detect_qlabels_from_md(dest_dir: Path, image_name: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Scan the figure's markdown file for quarter tokens (e.g., 2Q24, 1Q2025).\n",
    "    Returns tokens in document order (deduped).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cand = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cand:\n",
    "                return []\n",
    "            md_file = cand[0]\n",
    "        text = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return []\n",
    "    # Collect all quarter tokens across the document\n",
    "    tokens = []\n",
    "    for m in QUARTER_PAT.finditer(text):\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "        tokens.append(q)\n",
    "    # Deduplicate preserving order\n",
    "    seen = set()\n",
    "    ordered = []\n",
    "    for q in tokens:\n",
    "        if q not in seen:\n",
    "            seen.add(q)\n",
    "            ordered.append(q)\n",
    "    return ordered\n",
    "\n",
    "def load_image(path):\n",
    "    p = Path(path)\n",
    "    im = cv2.imread(str(p))\n",
    "    if im is None:\n",
    "        raise RuntimeError(f\"cv2.imread() failed: {p}\")\n",
    "    return im\n",
    "\n",
    "def preprocess(img_bgr):\n",
    "    scale = 2.0\n",
    "    img = cv2.resize(img_bgr, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    return img, gray, thr, scale\n",
    "\n",
    "def norm_num(s):\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    pct = s.endswith(\"%\")\n",
    "    if pct:\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return float(s), pct\n",
    "    except:\n",
    "        return None, pct\n",
    "\n",
    "def extract_numbers(ocr_results):\n",
    "    rows = []\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        if NUM_PAT.match(txt):\n",
    "            val, is_pct = norm_num(txt)\n",
    "            if val is None:\n",
    "                continue\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            rows.append({\n",
    "                \"raw\": txt, \"value\": val, \"is_pct\": is_pct, \"conf\": r.get(\"conf\", None),\n",
    "                \"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2),\n",
    "                \"cx\": int((x1+x2)/2), \"cy\": int((y1+y2)/2)\n",
    "            })\n",
    "    df = pd.DataFrame(rows).sort_values([\"cy\",\"cx\"]).reset_index(drop=True)\n",
    "    if \"is_pct\" not in df.columns and not df.empty:\n",
    "        df[\"is_pct\"] = df[\"raw\"].astype(str).str.endswith(\"%\")\n",
    "    return df\n",
    "\n",
    "def kmeans_1d(values, k=2, iters=20):\n",
    "    values = np.asarray(values, dtype=float).reshape(-1,1)\n",
    "    centers = np.array([values.min(), values.max()]).reshape(k,1)\n",
    "    for _ in range(iters):\n",
    "        d = ((values - centers.T)**2)\n",
    "        labels = d.argmin(axis=1)\n",
    "        new_centers = np.array([values[labels==i].mean() if np.any(labels==i) else centers[i] for i in range(k)]).reshape(k,1)\n",
    "        if np.allclose(new_centers, centers, atol=1e-3):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    return labels, centers.flatten()\n",
    "\n",
    "def run_easyocr(img_rgb):\n",
    "    import easyocr\n",
    "    global _EASY_OCR_READER\n",
    "    try:\n",
    "        _EASY_OCR_READER\n",
    "    except NameError:\n",
    "        _EASY_OCR_READER = None\n",
    "    if _EASY_OCR_READER is None:\n",
    "        _EASY_OCR_READER = easyocr.Reader(['en'], gpu=False, verbose=False)\n",
    "    results = _EASY_OCR_READER.readtext(img_rgb, detail=1, paragraph=False)\n",
    "    out = []\n",
    "    for quad, text, conf in results:\n",
    "        (x1,y1),(x2,y2),(x3,y3),(x4,y4) = quad\n",
    "        out.append({\"bbox\": (int(x1),int(y1),int(x3),int(y3)), \"text\": str(text), \"conf\": float(conf)})\n",
    "    return out\n",
    "\n",
    "# --- Focused bottom-axis quarter detection using EasyOCR (robust to OCR confusions) ---\n",
    "def detect_quarters_easyocr(img_bgr):\n",
    "    \"\"\"\n",
    "    Use EasyOCR to read quarter labels along the bottom axis.\n",
    "    Returns a list of (x_global, 'nQyy') sorted left→right, with half-year tokens removed.\n",
    "    \"\"\"\n",
    "    H, W = img_bgr.shape[:2]\n",
    "    y0 = int(H * 0.66)  # bottom ~34%\n",
    "    crop = img_bgr[y0:H, 0:W]\n",
    "    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 8)\n",
    "    # kernel = np.ones((3,3), np.uint8)\n",
    "    # thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    up = cv2.resize(thr, None, fx=3.0, fy=3.0, interpolation=cv2.INTER_CUBIC)\n",
    "    img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "    ocr = run_easyocr(img_rgb)\n",
    "    # PASS 1 — direct regex on normalized tokens\n",
    "    tokens = []\n",
    "    for r in ocr or []:\n",
    "        raw = str(r.get(\"text\",\"\")).strip()\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx_local = (x1 + x2) // 2\n",
    "        cx_global = int(cx_local / 3.0)  # undo scaling\n",
    "        tokens.append({\"x\": cx_global, \"raw\": raw, \"norm\": normalize_token(raw)})\n",
    "    def _is_half_token(t: str) -> bool:\n",
    "        t = (t or \"\").lower().replace(\" \", \"\")\n",
    "        return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t)\n",
    "    quarters = []\n",
    "    for t in tokens:\n",
    "        if _is_half_token(t[\"norm\"]):\n",
    "            continue\n",
    "        m = QUARTER_PAT.search(t[\"norm\"])\n",
    "        if m:\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            q = normalize_token(q)\n",
    "            quarters.append((t[\"x\"], q))\n",
    "    # PASS 2 — stitch split tokens if too few quarters were found\n",
    "    if len(quarters) < 4 and tokens:\n",
    "        pieces = sorted(tokens, key=lambda d: d[\"x\"])\n",
    "        digits_1to4 = [p for p in pieces if p[\"norm\"] in (\"1\",\"2\",\"3\",\"4\")]\n",
    "        q_only      = [p for p in pieces if p[\"norm\"].upper() == \"Q\"]\n",
    "        q_with_year = [p for p in pieces if re.fullmatch(r\"Q[0-9O]{2,4}\", p[\"norm\"], flags=re.I)]\n",
    "        years_2d    = [p for p in pieces if re.fullmatch(r\"[0-9O]{2,4}\", p[\"norm\"])]\n",
    "        def near(a, b, tol=70):\n",
    "            return abs(a[\"x\"] - b[\"x\"]) <= tol\n",
    "        for d in digits_1to4:\n",
    "            # digit + Qyy\n",
    "            candidates = [q for q in q_with_year if near(d, q)]\n",
    "            if candidates:\n",
    "                qtok = min(candidates, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                qyy = normalize_token(qtok[\"norm\"])[1:]\n",
    "                quarters.append(((d[\"x\"]+qtok[\"x\"])//2, f\"{d['norm']}Q{qyy[-2:]}\"))\n",
    "                continue\n",
    "            # digit + Q + yy\n",
    "            qs = [q for q in q_only if near(d, q)]\n",
    "            ys = [y for y in years_2d if near(d, y, tol=120)]\n",
    "            if qs and ys:\n",
    "                qtok = min(qs, key=lambda q: abs(q[\"x\"]-d[\"x\"]))\n",
    "                ytok = min(ys, key=lambda y: abs(y[\"x\"]-qtok[\"x\"]))\n",
    "                yy = normalize_token(ytok[\"norm\"])\n",
    "                quarters.append(((d[\"x\"]+ytok[\"x\"])//2, f\"{d['norm']}Q{yy[-2:]}\"))\n",
    "                continue\n",
    "    if not quarters:\n",
    "        return []\n",
    "    quarters.sort(key=lambda t: t[0])\n",
    "    deduped, last_x = [], -10**9\n",
    "    for x,q in quarters:\n",
    "        if abs(x - last_x) <= 22:\n",
    "            continue\n",
    "        deduped.append((x,q))\n",
    "        last_x = x\n",
    "    return deduped\n",
    "\n",
    "# NIM value band (pct) and geometry heuristics for verification\n",
    "NIM_MIN, NIM_MAX = 1.3, 3.2\n",
    "TOP_FRACTION = 0.65     # widen band: NIM labels often sit higher than 45%\n",
    "RIGHT_HALF_ONLY = True  # NIM values appear on right panel in these deck\n",
    "\n",
    "def is_strict_nim_image(img_path: Path) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Heuristic re-check:\n",
    "      1) Title/text contains NIM keywords (coarse gate)\n",
    "      2) Percent tokens mostly within NIM_MIN..NIM_MAX\n",
    "      3) Tokens located in the top region (and right half, if enabled)\n",
    "    Returns (ok, reason)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img_bgr = load_image(img_path)\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        # 1) quick-text gate (soft): don't return yet; allow numeric signature to validate\n",
    "        kw_ok = is_relevant_image(img_path, NIM_KEYWORDS)\n",
    "        # 2) numeric gate on enhanced image\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # --- Semantic gate: accept classic NIM slides based on stable labels ---\n",
    "        text_lower = \" \".join(str(r.get(\"text\", \"\")).lower() for r in ocr or [])\n",
    "        has_nim = \"net interest margin\" in text_lower\n",
    "        has_cb  = \"commercial book\" in text_lower\n",
    "        has_grp = \"group\" in text_lower\n",
    "        if has_nim and (has_cb or has_grp):\n",
    "            which = [w for w, ok in ((\"nim\", has_nim), (\"cb\", has_cb), (\"grp\", has_grp)) if ok]\n",
    "            return (True, f\"ok_semantic({'+' .join(which)})\")\n",
    "        df = extract_numbers(ocr)\n",
    "        if df.empty:\n",
    "            return (False, \"no_numbers\")\n",
    "        # geometry filters (apply before value checks)\n",
    "        top_cut = int(img_up.shape[0] * 0.62)\n",
    "        cond_geom = (df[\"cy\"] < top_cut)\n",
    "        if RIGHT_HALF_ONLY:\n",
    "            cond_geom &= (df[\"cx\"] > (img_up.shape[1] // 2))\n",
    "\n",
    "        # 2a) Preferred path: explicit percentage tokens\n",
    "        df_pct = df[(df[\"is_pct\"] == True) & cond_geom].copy()\n",
    "        if not df_pct.empty:\n",
    "            in_band = df_pct[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_pct))\n",
    "            if ratio >= 0.6:\n",
    "                return (True, \"ok\")\n",
    "            else:\n",
    "                return (False, f\"non_nim_values_out_of_band({ratio:.2f})\")\n",
    "\n",
    "        # 2b) Fallback: some decks omit the % sign near the series values.\n",
    "        # Accept plain numbers in the NIM range if units are explicit or implied, or if numeric signature is strong.\n",
    "        title_text = text_lower  # already computed above\n",
    "        has_units_pct = \"(%)\" in title_text or \"margin (%)\" in title_text or has_nim\n",
    "        df_nums = df[(df[\"is_pct\"] == False) & cond_geom].copy()\n",
    "        if not df_nums.empty:\n",
    "            in_band = df_nums[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "            ratio = float(in_band.sum()) / float(len(df_nums))\n",
    "            # Case A: explicit or implied units in title → accept when enough in-band hits\n",
    "            if has_units_pct and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_no_percent_signs\")\n",
    "            # Case B: title OCR may have missed units; if the quick keyword gate succeeded, accept with a stricter ratio\n",
    "            if kw_ok and ratio >= 0.7 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_numeric_signature\")\n",
    "            # Case C: strong structural evidence (quarters on bottom) + numeric signature in band\n",
    "            q_xy_fallback = detect_quarters_easyocr(img_bgr)\n",
    "            if len(q_xy_fallback) >= 4 and ratio >= 0.6 and in_band.sum() >= 3:\n",
    "                return (True, \"ok_structural_numeric_signature\")\n",
    "\n",
    "        # Final decision: if numeric signature still failed, report clearer reason\n",
    "        if not kw_ok:\n",
    "            return (False, \"irrelevant_non_nim\")\n",
    "        else:\n",
    "            return (False, \"no_percentages_or_units\")\n",
    "    except Exception as e:\n",
    "        return (False, f\"exception:{e}\")\n",
    "\n",
    "\n",
    "# --- Helper: detect and order quarter labels from OCR ---\n",
    "def detect_qlabels(ocr_results, img_width: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract quarter tokens like 1Q25, 2Q2025 from OCR and return them left→right.\n",
    "    We keep only tokens on the right half (where the series values live in your layout).\n",
    "    \"\"\"\n",
    "    qtokens = []\n",
    "    mid_x = img_width // 2\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_PAT.search(txt)\n",
    "        if not m:\n",
    "            continue\n",
    "        x1,y1,x2,y2 = r[\"bbox\"]\n",
    "        cx = (x1 + x2) // 2\n",
    "        if cx <= mid_x:\n",
    "            continue  # ignore left panel quarters/titles\n",
    "        q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"  # normalize to 1Q25 style\n",
    "        qtokens.append((cx, q))\n",
    "    # sort by visual x-position and deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    qtokens.sort(key=lambda x: x[0])\n",
    "    # Deduplicate by both text and proximity (ignore near-duplicates)\n",
    "    ordered = []\n",
    "    last_x = -9999\n",
    "    last_q = None\n",
    "    for x, q in qtokens:\n",
    "        if last_q == q and abs(x - last_x) < 30:\n",
    "            continue\n",
    "        ordered.append(q)\n",
    "        last_x, last_q = x, q\n",
    "    return ordered\n",
    "\n",
    "# === Focused bottom-of-chart scan for small quarter labels ===\n",
    "def detect_qlabels_bottom(img_bgr) -> list[str]:\n",
    "    \"\"\"\n",
    "    Focused pass: crop the bottom ~30% (where quarter labels usually sit),\n",
    "    enhance contrast, OCR, and extract quarter tokens left→right.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)  # bottom 40%\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        # Enhance: grayscale -> bilateral -> CLAHE -> adaptive threshold\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        # Morphological close to strengthen thin glyphs\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        # Upscale for small text\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        # Map bboxes back to global coords: decide single-panel vs split-panel\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text, right_tokens_text = [], []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)  # undo scale\n",
    "\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            else:\n",
    "                right_tokens_text.append(raw.lower())\n",
    "\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        # Panel selection logic: prefer both halves unless left clearly half-year and right has ≥3 quarters\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        # Sort and dedupe close neighbors (≤18 px)\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "\n",
    "        return [q for _, q in deduped]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Same as detect_qlabels_bottom, but returns (x, label) for alignment ---\n",
    "def detect_qlabels_bottom_with_xy(img_bgr) -> list[tuple[int, str]]:\n",
    "    try:\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        y0 = int(H * 0.60)\n",
    "        crop = img_bgr[y0:H, 0:W]\n",
    "        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.bilateralFilter(gray, d=7, sigmaColor=50, sigmaSpace=50)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        thr = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY, 31, 8)\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        up = cv2.resize(thr, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_CUBIC)\n",
    "        img_rgb = cv2.cvtColor(up, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "\n",
    "        mid_x = W // 2\n",
    "        left_quarters, right_quarters = [], []\n",
    "        left_tokens_text = []\n",
    "        for r in ocr or []:\n",
    "            raw = str(r.get(\"text\", \"\")).strip()\n",
    "            x1,y1,x2,y2 = r[\"bbox\"]\n",
    "            cx_local = (x1 + x2) // 2\n",
    "            cx_global = int(cx_local / 2.5)\n",
    "            if cx_global <= mid_x:\n",
    "                left_tokens_text.append(raw.lower())\n",
    "            m = QUARTER_PAT.search(raw)\n",
    "            if not m:\n",
    "                continue\n",
    "            q = f\"{m.group(1)}Q{m.group(2)[-2:]}\"\n",
    "            if cx_global <= mid_x:\n",
    "                left_quarters.append((cx_global, q))\n",
    "            else:\n",
    "                right_quarters.append((cx_global, q))\n",
    "\n",
    "        def has_halfyear_or_9m(tokens: list[str]) -> bool:\n",
    "            s = \" \".join(tokens)\n",
    "            return (\"9m\" in s) or (\"1h\" in s) or (\"h1\" in s) or (\"h2\" in s) or (\"2h\" in s)\n",
    "\n",
    "        left_has_h = has_halfyear_or_9m(left_tokens_text)\n",
    "        if (not left_has_h) and (len(left_quarters) + len(right_quarters) >= 2):\n",
    "            # Likely single panel or weak OCR on one side → use both halves\n",
    "            qtokens = left_quarters + right_quarters\n",
    "        elif len(right_quarters) >= 3:\n",
    "            # Strong right panel signal → use right only\n",
    "            qtokens = right_quarters\n",
    "        else:\n",
    "            # Fallback: use everything we found\n",
    "            qtokens = left_quarters + right_quarters\n",
    "\n",
    "        qtokens.sort(key=lambda t: t[0])\n",
    "        deduped = []\n",
    "        last_x = -10**9\n",
    "        for x, q in qtokens:\n",
    "            if abs(x - last_x) <= 18:\n",
    "                continue\n",
    "            deduped.append((x, q))\n",
    "            last_x = x\n",
    "        return deduped\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# --- Merge two ordered quarter lists ---\n",
    "def _merge_ordered(primary: list[str], secondary: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Merge two left→right sequences, keeping 'primary' order and filling with\n",
    "    any unseen items from 'secondary' in their order.\n",
    "    \"\"\"\n",
    "    out = list(primary)\n",
    "    seen = set(primary)\n",
    "    for q in secondary:\n",
    "        if q not in seen:\n",
    "            out.append(q)\n",
    "            seen.add(q)\n",
    "    return out\n",
    "\n",
    "# --- Expand a quarter label like '2Q24' forward n quarters ---\n",
    "def _expand_quarters(start_q: str, n: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Given a label like '2Q24', produce a forward sequence of n quarters:\n",
    "    2Q24, 3Q24, 4Q24, 1Q25, 2Q25, ...\n",
    "    \"\"\"\n",
    "    m = QUARTER_PAT.match(start_q) or QUARTER_SIMPLE_PAT.match(start_q)\n",
    "    if not m:\n",
    "        return []\n",
    "    q = int(m.group(1))\n",
    "    yy = int(m.group(2)[-2:])\n",
    "    seq = []\n",
    "    for _ in range(n):\n",
    "        seq.append(f\"{q}Q{yy:02d}\")\n",
    "        q += 1\n",
    "        if q == 5:\n",
    "            q = 1\n",
    "            yy = (yy + 1) % 100\n",
    "    return seq\n",
    "\n",
    "# --- Find a plausible anchor quarter like 2Q24 from OCR or markdown tokens ---\n",
    "def _anchor_quarter_from_texts(ocr_results, md_tokens: list[str]) -> str | None:\n",
    "    \"\"\"\n",
    "    Find any token like 1Q2x..4Q2x from OCR texts or markdown tokens.\n",
    "    Returns the first plausible anchor (normalized to e.g. 2Q24) or None.\n",
    "    \"\"\"\n",
    "    # prefer bottom/ocr-derived tokens first (already parsed in detect_qlabels_bottom)\n",
    "    # fallback: scan all OCR texts with simple pattern\n",
    "    for r in ocr_results or []:\n",
    "        txt = str(r.get(\"text\",\"\")).strip()\n",
    "        m = QUARTER_SIMPLE_PAT.search(txt)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    # fallback to any markdown token that matches the decade pattern\n",
    "    for t in md_tokens or []:\n",
    "        m = QUARTER_SIMPLE_PAT.match(t)\n",
    "        if m:\n",
    "            return f\"{m.group(1)}Q{m.group(2)}\"\n",
    "    return None\n",
    "\n",
    "def extract_series_from_df(df, img_up, ocr_results=None, qlabels_hint=None):\n",
    "    H, W = img_up.shape[:2]\n",
    "    mid_x = W//2\n",
    "    top_band_min = int(H * 0.38)\n",
    "    top_band_max = int(H * 0.58)\n",
    "\n",
    "    # Detect bottom quarter labels (with x) early to infer layout\n",
    "    detected_q_bot_xy = detect_quarters_easyocr(img_up)\n",
    "    left_count  = sum(1 for x, _ in detected_q_bot_xy if x <= mid_x)\n",
    "    right_count = sum(1 for x, _ in detected_q_bot_xy if x >  mid_x)\n",
    "    # Heuristic: if we see ≥4 quarter tokens spanning both halves, it's a single-panel timeline\n",
    "    single_panel = (len(detected_q_bot_xy) >= 4 and left_count >= 1 and right_count >= 1)\n",
    "\n",
    "    # Filter tokens: keep right-half only for split panels; keep all for single panels\n",
    "    if single_panel:\n",
    "        pct = df[(df.is_pct==True)].copy()\n",
    "        nums = df[(df.is_pct==False)].copy()\n",
    "    else:\n",
    "        pct = df[(df.is_pct==True) & (df.cx > mid_x)].copy()\n",
    "        nums = df[(df.is_pct==False) & (df.cx > mid_x)].copy()\n",
    "\n",
    "    if pct.empty:\n",
    "        # Fallback for charts that omit the '%' sign on the value dots.\n",
    "        # Use a wider top band and avoid forcing right-half on single-panel timelines.\n",
    "        approx_top = int(H * 0.60)\n",
    "        if single_panel:\n",
    "            cx_mask = (df.cx > 0)  # keep all x for single panel\n",
    "        else:\n",
    "            cx_mask = (df.cx > mid_x)\n",
    "        cand_pct = df[cx_mask & df.value.between(NIM_MIN, NIM_MAX) & (df.cy < approx_top)].copy()\n",
    "        if not cand_pct.empty:\n",
    "            cand_pct[\"is_pct\"] = True\n",
    "            pct = cand_pct\n",
    "\n",
    "    nim_df = pd.DataFrame()\n",
    "    if not pct.empty:\n",
    "        # Try to split into two horizontal series by Y even when we have only 3 quarters (→ 6 points)\n",
    "        # Deduplicate by proximity on Y to stabilize clustering\n",
    "        y_sorted = pct.sort_values(\"cy\")[\"cy\"].to_numpy()\n",
    "        uniq_y = []\n",
    "        last_y = -10**9\n",
    "        for yy in y_sorted:\n",
    "            if abs(yy - last_y) >= 6:  # 6px tolerance for duplicates\n",
    "                uniq_y.append(yy)\n",
    "                last_y = yy\n",
    "        # Attempt k-means when we have at least 4 points total (≈ 2 series × 2 quarters)\n",
    "        if pct.shape[0] >= 4 and len(uniq_y) >= 2:\n",
    "            labels, centers = kmeans_1d(pct[\"cy\"].values, k=2)\n",
    "            pct[\"series\"] = labels\n",
    "            order = np.argsort(centers)  # top (commercial) should have smaller y\n",
    "            remap = {order[0]: \"Commercial NIM (%)\", order[1]: \"Group NIM (%)\"}\n",
    "            pct[\"series_name\"] = pct[\"series\"].map(remap)\n",
    "            # Sanity: ensure both series have data; else collapse to one\n",
    "            counts = pct[\"series_name\"].value_counts()\n",
    "            if any(counts.get(name, 0) == 0 for name in [\"Commercial NIM (%)\", \"Group NIM (%)\"]):\n",
    "                pct[\"series_name\"] = \"NIM (%)\"\n",
    "        else:\n",
    "            pct[\"series_name\"] = \"NIM (%)\"\n",
    "\n",
    "        # Reuse bottom-quarter labels captured above\n",
    "        detected_q_bot = [q for _, q in detected_q_bot_xy]\n",
    "        detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "        if len(detected_q_bot) > len(detected_q_ocr):\n",
    "            detected_q = _merge_ordered(detected_q_bot, detected_q_ocr)\n",
    "        else:\n",
    "            detected_q = _merge_ordered(detected_q_ocr, detected_q_bot)\n",
    "        rows = []\n",
    "        for name, sub in pct.groupby(\"series_name\"):\n",
    "            # Sort left→right and collapse near-duplicates (same x within 12px)\n",
    "            sub_sorted = sub.sort_values(\"cx\")\n",
    "            uniq_rows = []\n",
    "            last_x = -10**9\n",
    "            for r in sub_sorted.itertuples(index=False):\n",
    "                if abs(r.cx - last_x) < 12:\n",
    "                    continue\n",
    "                uniq_rows.append(r)\n",
    "                last_x = r.cx\n",
    "            # Keep only the right-panel portion (already ensured by cx>mid_x earlier)\n",
    "            pick = list(uniq_rows)[-5:]  # cap to 5 most recent positions, but may be <5\n",
    "            n = len(pick)\n",
    "            if n == 0:\n",
    "                continue\n",
    "            labels = []\n",
    "            # Robust mapping: map each value x to its nearest bottom quarter label x (right panel).\n",
    "            # Filter any accidental half-year tokens (1H/2H/H1/H2/9M) just in case OCR returns them.\n",
    "            def _is_half_token(t: str) -> bool:\n",
    "                t = (t or \"\").lower().replace(\" \", \"\")\n",
    "                return (\"9m\" in t) or (\"1h\" in t) or (\"h1\" in t) or (\"h2\" in t) or (\"2h\" in t) or (\"h24\" in t) or (\"h23\" in t)\n",
    "\n",
    "            # detected_q_bot_xy already respects split vs single panel. Keep right-panel positions only here.\n",
    "            q_xy = []\n",
    "            for x, q in detected_q_bot_xy:\n",
    "                if x <= mid_x:\n",
    "                    continue\n",
    "                if _is_half_token(q):\n",
    "                    continue\n",
    "                q_xy.append((x, q))\n",
    "\n",
    "            if len(q_xy) < n:\n",
    "                # Borrow from left panel if they look like quarters (and not half-year)\n",
    "                for x, q in detected_q_bot_xy:\n",
    "                    if x > mid_x:\n",
    "                        continue\n",
    "                    if _is_half_token(q):\n",
    "                        continue\n",
    "                    q_xy.append((x, q))\n",
    "\n",
    "            if q_xy:\n",
    "                q_xy.sort(key=lambda t: t[0])  # left→right\n",
    "                # Map each picked value to nearest quarter label by x-position\n",
    "                vx = [rr.cx for rr in pick]\n",
    "                qx = [x for x, _ in q_xy]\n",
    "                ql = [q for _, q in q_xy]\n",
    "                mapped = []\n",
    "                for x in vx:\n",
    "                    j = int(np.argmin([abs(x - xx) for xx in qx])) if qx else -1\n",
    "                    mapped.append(ql[j] if j >= 0 else None)\n",
    "                labels = mapped\n",
    "            else:\n",
    "                detected_q_ocr = detect_qlabels(ocr_results or [], W) if ocr_results is not None else []\n",
    "                if detected_q_ocr:\n",
    "                    labels = detected_q_ocr[-n:] if len(detected_q_ocr) >= n else detected_q_ocr\n",
    "\n",
    "            # If still short, use markdown tokens; else expand from an anchor like 2Q24\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                if qlabels_hint:\n",
    "                    labels = qlabels_hint[-n:] if len(qlabels_hint) >= n else qlabels_hint\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                anchor = _anchor_quarter_from_texts(ocr_results, qlabels_hint)\n",
    "                if anchor:\n",
    "                    labels = _expand_quarters(anchor, n)\n",
    "            if (not labels) or (len(labels) != n):\n",
    "                labels = [f\"{i+1}Q??\" for i in range(n)]\n",
    "            # Ensure left→right order for consistent mapping to labels\n",
    "            pick = sorted(pick, key=lambda r: r.cx)\n",
    "            labels = list(labels)[:n]\n",
    "            for i, r in enumerate(pick):\n",
    "                if i >= len(labels):\n",
    "                    break\n",
    "                rows.append({\"Quarter\": labels[i], \"series\": name, \"value\": r.value})\n",
    "        if rows:\n",
    "            nim_table = pd.DataFrame(rows)\n",
    "            # Guard: drop rows with missing labels\n",
    "            nim_table = nim_table.dropna(subset=[\"Quarter\", \"series\"])  \n",
    "            # If multiple detections map to the same (Quarter, series), average them\n",
    "            if not nim_table.empty:\n",
    "                dupe_mask = nim_table.duplicated(subset=[\"Quarter\", \"series\"], keep=False)\n",
    "                if dupe_mask.any():\n",
    "                    # Aggregate duplicates by mean (stable for minor OCR jitter)\n",
    "                    nim_table = nim_table.groupby([\"Quarter\", \"series\"], as_index=False)[\"value\"].mean()\n",
    "            nim_df = nim_table.pivot(index=\"Quarter\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # NIM-only mode: skip NII extraction entirely\n",
    "    nii_df = pd.DataFrame()\n",
    "\n",
    "    def _sort_q(df_in):\n",
    "        if df_in is None or df_in.empty or \"Quarter\" not in df_in.columns:\n",
    "            return df_in\n",
    "        # Try to sort by numeric (Q#, year) if labels are like 2Q24; else keep input order\n",
    "        def _key(q):\n",
    "            m = QUARTER_PAT.match(str(q))\n",
    "            if not m:\n",
    "                return (999, 999)\n",
    "            qn = int(m.group(1))\n",
    "            yr = int(m.group(2)[-2:])  # last two digits\n",
    "            return (yr, qn)\n",
    "        try:\n",
    "            return df_in.assign(_k=df_in[\"Quarter\"].map(_key)).sort_values(\"_k\").drop(columns=[\"_k\"]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            return df_in.reset_index(drop=True)\n",
    "\n",
    "    return _sort_q(nim_df), _sort_q(nii_df)\n",
    "\n",
    "def _extract_md_context(dest_dir: Path, image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Best-effort: read the <pdf_stem>.md in dest_dir, find the <image_name> reference,\n",
    "    capture nearby headings and a neighbor paragraph to build context.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prefer \"<pdf_stem>.md\", else any .md\n",
    "        md_file = dest_dir / f\"{dest_dir.name}.md\"\n",
    "        if not md_file.exists():\n",
    "            cands = list(dest_dir.glob(\"*.md\"))\n",
    "            if not cands:\n",
    "                return {}\n",
    "            md_file = cands[0]\n",
    "        lines = md_file.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    # Find the image line\n",
    "    idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_name in line:\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        return {}\n",
    "\n",
    "    # Walk upward to find up to two headings and a neighbor paragraph\n",
    "    figure_title = None\n",
    "    section_title = None\n",
    "    neighbor_text = None\n",
    "\n",
    "    # Find the closest preceding heading(s)\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # markdown heading levels\n",
    "        if s.startswith(\"#\"):\n",
    "            # Remove leading #'s and whitespace\n",
    "            heading = s.lstrip(\"#\").strip()\n",
    "            if figure_title is None:\n",
    "                figure_title = heading\n",
    "            elif section_title is None:\n",
    "                section_title = heading\n",
    "                break\n",
    "\n",
    "    # Find a non-empty paragraph between the image and last heading\n",
    "    for j in range(idx - 1, -1, -1):\n",
    "        s = lines[j].strip()\n",
    "        if s and not s.startswith(\"#\") and not s.startswith(\"![](\"):\n",
    "            neighbor_text = s\n",
    "            break\n",
    "\n",
    "    out = {}\n",
    "    if figure_title: out[\"figure_title\"] = figure_title\n",
    "    if section_title: out[\"section_title\"] = section_title\n",
    "    if neighbor_text: out[\"neighbor_text\"] = neighbor_text\n",
    "    return out\n",
    "\n",
    "def _parse_page_and_figure_from_name(image_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract page/figure indices from names like '_page_0_Figure_2.jpeg'.\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    try:\n",
    "        # Very loose parse\n",
    "        if \"_page_\" in image_name:\n",
    "            after = image_name.split(\"_page_\", 1)[1]\n",
    "            num = after.split(\"_\", 1)[0]\n",
    "            info[\"page\"] = int(num) + 1  # 1-based for human readability\n",
    "        if \"Figure_\" in image_name:\n",
    "            after = image_name.split(\"Figure_\", 1)[1]\n",
    "            num = \"\"\n",
    "            for ch in after:\n",
    "                if ch.isdigit():\n",
    "                    num += ch\n",
    "                else:\n",
    "                    break\n",
    "            if num:\n",
    "                info[\"figure_index\"] = int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def is_relevant_image(img_path, keywords):\n",
    "    \"\"\"Robust relevance check for NIM slides.\n",
    "    - Reuse the singleton EasyOCR reader (run_easyocr)\n",
    "    - Accept split tokens like \"Net\" / \"interest\" / \"margin\" (not only the exact phrase)\n",
    "    - Fallback: if we see ≥4 quarter labels on the bottom AND ≥3 top-band percent-like values in NIM range, treat as relevant.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            return False\n",
    "\n",
    "        # Pass A: OCR on lightly upscaled original\n",
    "        view_a = cv2.resize(img, None, fx=1.3, fy=1.3, interpolation=cv2.INTER_CUBIC)\n",
    "        ocr_a = run_easyocr(cv2.cvtColor(view_a, cv2.COLOR_BGR2RGB))\n",
    "        tokens_a = [str(r.get(\"text\",\"\")).lower() for r in (ocr_a or [])]\n",
    "        text_a = \" \".join(tokens_a)\n",
    "\n",
    "        # Quick phrase match (exact keywords like \"net interest margin\")\n",
    "        if any(k in text_a for k in keywords):\n",
    "            return True\n",
    "\n",
    "        # Pass B: OCR on preprocessed thresholded view (more stable for thin fonts)\n",
    "        _, _, thr, _ = preprocess(img)\n",
    "        ocr_b = run_easyocr(cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB))\n",
    "        tokens_b = [str(r.get(\"text\",\"\")).lower() for r in (ocr_b or [])]\n",
    "        text_b = \" \".join(tokens_b)\n",
    "        if any(k in text_b for k in keywords):\n",
    "            return True\n",
    "\n",
    "        # Token-level split-word check\n",
    "        tokens = tokens_a + tokens_b\n",
    "        has_net      = any(\"net\" in t for t in tokens)\n",
    "        has_interest = any(\"interest\" in t for t in tokens)\n",
    "        has_margin   = any(\"margin\" in t for t in tokens or [])\n",
    "        has_nim_abbr = any(re.search(r\"\\bnim\\b\", t) for t in tokens)\n",
    "        has_cb       = any(\"commercial book\" in t for t in tokens)\n",
    "        has_grp      = any(re.search(r\"\\bgroup\\b\", t) for t in tokens)\n",
    "        if (has_net and has_interest and has_margin) or has_nim_abbr:\n",
    "            # Strengthen with context words if available\n",
    "            if has_cb or has_grp:\n",
    "                return True\n",
    "\n",
    "        # Structural fallback: quarters + percent values in the NIM band\n",
    "        q_xy = detect_quarters_easyocr(img)\n",
    "        if len(q_xy) >= 4:\n",
    "            # Look for ≥3 percent-ish values in the top band within NIM_MIN..NIM_MAX\n",
    "            df = extract_numbers(ocr_b)\n",
    "            if not df.empty:\n",
    "                H, W = view_a.shape[:2]\n",
    "                top_cut = int(H * 0.55)\n",
    "                in_top = df[\"cy\"] < top_cut\n",
    "                in_band = df[\"value\"].between(NIM_MIN, NIM_MAX)\n",
    "                pctish = in_band  # allow numbers without % (the series sometimes omit it)\n",
    "                if int((in_top & pctish).sum()) >= 3:\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============== Pluggable OCR Extractor Framework ===============\n",
    "class BaseChartExtractor:\n",
    "    \"\"\"\n",
    "    Minimal interface for pluggable chart extractors.\n",
    "    Implement `is_relevant` and `extract_table`, then call `handle_image(...)`.\n",
    "    \"\"\"\n",
    "    name = \"base\"\n",
    "    topic = \"Generic Chart\"\n",
    "    units = None\n",
    "    entity = None\n",
    "    keywords = []\n",
    "\n",
    "    def is_relevant(self, img_path: Path) -> bool:\n",
    "        return is_relevant_image(img_path, self.keywords)\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        \"\"\"\n",
    "        Return (df, context_dict) or (None, reason) on failure.\n",
    "        context_dict will be merged into the _context object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_context(self, pdf_name: str, img_path: Path, dest_dir: Path, extra: dict | None = None) -> dict:\n",
    "        ctx = {\n",
    "            \"source_pdf\": pdf_name,\n",
    "            \"image\": img_path.name,\n",
    "            \"topic\": self.topic,\n",
    "        }\n",
    "        if self.units:  ctx[\"units\"]  = self.units\n",
    "        if self.entity: ctx[\"entity\"] = self.entity\n",
    "        ctx.update(_parse_page_and_figure_from_name(img_path.name))\n",
    "        md_ctx = _extract_md_context(dest_dir, img_path.name)\n",
    "        if md_ctx: ctx.update(md_ctx)\n",
    "        if extra:  ctx.update(extra)\n",
    "        return ctx\n",
    "\n",
    "    def _write_jsonl(self, out_path: Path, ctx: dict, df: pd.DataFrame):\n",
    "        import json\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\"_context\": ctx}, ensure_ascii=False) + \"\\n\")\n",
    "            for rec in df.to_dict(orient=\"records\"):\n",
    "                rec_out = dict(rec)\n",
    "                rec_out[\"_meta\"] = {\"source_pdf\": ctx.get(\"source_pdf\"), \"image\": ctx.get(\"image\")}\n",
    "                f.write(json.dumps(rec_out, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def handle_image(self, img_path: Path, dest_dir: Path, pdf_name: str, *, bypass_relevance: bool = False):\n",
    "        if not bypass_relevance and not self.is_relevant(img_path):\n",
    "            return False, \"Not relevant\"\n",
    "        df, ctx_extra = self.extract_table(img_path, dest_dir, pdf_name)\n",
    "        if df is None or df.empty:\n",
    "            return False, ctx_extra if isinstance(ctx_extra, str) else \"No data\"\n",
    "        # Build context and summary if possible\n",
    "        ctx = self._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "        try:\n",
    "            cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "            if len(df) >= 2 and cols:\n",
    "                def _pick_q(s):\n",
    "                    return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                _fq = str(df.iloc[0][\"Quarter\"])\n",
    "                _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                pieces = []\n",
    "                for col in cols[:2]:\n",
    "                    a = df.iloc[0][col]\n",
    "                    b = df.iloc[-1][col]\n",
    "                    if pd.notna(a) and pd.notna(b):\n",
    "                        suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                        pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                if pieces:\n",
    "                    ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "        except Exception:\n",
    "            pass\n",
    "        out_path = img_path.with_suffix(f\".{self.name}.jsonl\")\n",
    "        self._write_jsonl(out_path, ctx, df)\n",
    "        return True, str(out_path)\n",
    "\n",
    "class NIMExtractor(BaseChartExtractor):\n",
    "    name = \"nim\"\n",
    "    topic = \"Net Interest Margin\"\n",
    "    units = \"percent\"\n",
    "    entity = \"DBS\"\n",
    "    keywords = NIM_KEYWORDS\n",
    "\n",
    "    def extract_table(self, img_path: Path, dest_dir: Path, pdf_name: str):\n",
    "        # Reuse the existing pipeline\n",
    "        img_bgr = load_image(img_path)\n",
    "        img_up, gray, thr, scale = preprocess(img_bgr)\n",
    "        img_rgb = cv2.cvtColor(thr, cv2.COLOR_GRAY2RGB)\n",
    "        ocr = run_easyocr(img_rgb)\n",
    "        df_tokens = extract_numbers(ocr)\n",
    "        if df_tokens.empty:\n",
    "            return None, \"No numeric tokens detected\"\n",
    "        md_q = detect_qlabels_from_md(dest_dir, img_path.name)\n",
    "        nim_df, _nii_df = extract_series_from_df(df_tokens, img_up, ocr_results=ocr, qlabels_hint=md_q)\n",
    "        if nim_df is None or nim_df.empty:\n",
    "            return None, \"No NIM table detected\"\n",
    "        return nim_df, {\"topic\": self.topic, \"units\": self.units, \"entity\": self.entity}\n",
    "\n",
    "# Registry of extractors (add more later)\n",
    "EXTRACTORS: list[BaseChartExtractor] = [\n",
    "    NIMExtractor(),\n",
    "]\n",
    "# ============= End pluggable extractor framework =============\n",
    "\n",
    "# === Single-image rebuild/verify mode (optional) ===\n",
    "# Set single_image_mode=True and point single_image_path to a specific extracted image\n",
    "# to run the two-stage gate + extraction just for that file, then exit.\n",
    "single_image_mode = False\n",
    "single_image_paths: list[Path] = [\n",
    "   \n",
    "]\n",
    "# Optional singular fallback path (legacy): set to a string/Path if you want a single-image override\n",
    "single_image_path = None\n",
    "\n",
    "# Legacy fallback (ignored i\n",
    " # Toggle: if True → normal md5 skip; if False → always reprocess\n",
    "md5_check = True\n",
    "\n",
    "# 3. Define the path to the directory containing your PDF files\n",
    "pdf_directory = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All/\")\n",
    "\n",
    "# === Fast path: single image only ===\n",
    "# === Fast path: single/multi-image only ===\n",
    "if single_image_mode:\n",
    "    paths: list[Path] = []\n",
    "    if single_image_paths:\n",
    "        paths = [Path(p) for p in single_image_paths if p is not None]\n",
    "    elif single_image_path:\n",
    "        paths = [Path(single_image_path)]\n",
    "\n",
    "    if not paths:\n",
    "        print(\"❌ single_image_mode=True but no paths were provided.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"--- Multi-image mode ---\")\n",
    "    successes = 0\n",
    "    for img_path in paths:\n",
    "        if not img_path.exists():\n",
    "            print(f\"❌ Missing: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        dest_dir = img_path.parent\n",
    "        pdf_name = f\"{dest_dir.name}.pdf\"\n",
    "        print(f\"\\n🖼️  Image: {img_path.name}  |  PDF: {pdf_name}\")\n",
    "\n",
    "        # Quick quarter readout (EasyOCR-only, bottom axis)\n",
    "        try:\n",
    "            img_bgr_quarters = load_image(img_path)\n",
    "            q_xy = detect_quarters_easyocr(img_bgr_quarters)\n",
    "            if q_xy:\n",
    "                print(\"   📎 Quarters (EasyOCR):\", \", \".join([q for _,q in q_xy]))\n",
    "            else:\n",
    "                print(\"   📎 Quarters (EasyOCR): <none>\")\n",
    "        except Exception as _qe:\n",
    "            print(f\"   📎 Quarters (EasyOCR): error → {_qe}\")\n",
    "\n",
    "        any_hit = False\n",
    "\n",
    "        for ex in EXTRACTORS:\n",
    "            print(f\"   · [{ex.name}] quick gate…\", end=\" \")\n",
    "            if not ex.is_relevant(img_path):\n",
    "                print(\"⏭️  Not relevant\")\n",
    "                continue\n",
    "            print(\"✅ ok; strict gate…\", end=\" \")\n",
    "            ok_strict, reason = is_strict_nim_image(img_path)\n",
    "            if not ok_strict:\n",
    "                print(f\"⏭️  Failed strict ({reason})\")\n",
    "                continue\n",
    "            print(\"✅ Strict OK — extracting…\")\n",
    "\n",
    "            # Extract directly so we can print the table; still write JSONL\n",
    "            df, ctx_extra = ex.extract_table(img_path, dest_dir, pdf_name)\n",
    "            if df is None or df.empty:\n",
    "                print(\"   ⚠️ No data extracted.\")\n",
    "                continue\n",
    "\n",
    "            any_hit = True\n",
    "            successes += 1\n",
    "\n",
    "            # Build context + summary and write JSONL\n",
    "            ctx = ex._build_context(pdf_name, img_path, dest_dir, extra=ctx_extra if isinstance(ctx_extra, dict) else {})\n",
    "            try:\n",
    "                cols = [c for c in df.columns if c != \"Quarter\"]\n",
    "                if len(df) >= 2 and cols:\n",
    "                    def _pick_q(s):\n",
    "                        return s if QUARTER_PAT.match(str(s) or \"\") else None\n",
    "                    _fq = str(df.iloc[0][\"Quarter\"]); _lq = str(df.iloc[-1][\"Quarter\"])\n",
    "                    first_q = _pick_q(_fq) or (_fq if \"??\" not in _fq else \"start\")\n",
    "                    last_q  = _pick_q(_lq) or (_lq if \"??\" not in _lq else \"end\")\n",
    "                    pieces = []\n",
    "                    for col in cols[:2]:\n",
    "                        a = df.iloc[0][col]; b = df.iloc[-1][col]\n",
    "                        if pd.notna(a) and pd.notna(b):\n",
    "                            suffix = \"%\" if \"NIM\" in col or ctx.get(\"units\") == \"percent\" else \"\"\n",
    "                            pieces.append(f\"{col}: {a:.2f}{suffix} → {b:.2f}{suffix}\")\n",
    "                    if pieces:\n",
    "                        ctx[\"summary\"] = f\"Figure shows {', '.join(pieces)} from {first_q} to {last_q}.\"\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            out_path = img_path.with_suffix(f\".{ex.name}.jsonl\")\n",
    "            ex._write_jsonl(out_path, ctx, df)\n",
    "            print(f\"   💾 Saved JSONL → {out_path}\")\n",
    "\n",
    "            # Pretty-print the extracted table directly\n",
    "            try:\n",
    "                print(\"\\n   📊 Extracted table:\")\n",
    "                print(df.to_string(index=False))\n",
    "            except Exception:\n",
    "                print(df)\n",
    "\n",
    "        if not any_hit:\n",
    "            print(\"   ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "    print(f\"\\n✅ Done. Extracted from {successes} image(s).\")\n",
    "    # Prevent the pipeline (marker/md5) from running if notebook catches SystemExit\n",
    "    globals()[\"_STOP_AFTER_SINGLE\"] = True\n",
    "    sys.exit(0)\n",
    "    \n",
    "# Check if the directory exists before proceeding\n",
    "if not pdf_directory.is_dir():\n",
    "    print(f\"❌ ERROR: The directory was not found at '{pdf_directory}'.\")\n",
    "    sys.exit(1) # Exit the script if the directory doesn't exist\n",
    "\n",
    "# 4. Check if the 'marker_single' command is available\n",
    "if not shutil.which(\"marker_single\"):\n",
    "    print(\"❌ ERROR: The 'marker_single' command was not found.\")\n",
    "    print(\"Please ensure 'marker-pdf' is installed correctly in your environment's PATH.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Loop through every PDF file in the specified directory\n",
    "for pdf_path in pdf_directory.glob(\"*.pdf\"):\n",
    "    print(f\"--- Processing file: {pdf_path.name} ---\")\n",
    "\n",
    "    # 5. Let Marker create the <pdf_stem>/ subfolder automatically.\n",
    "    # Point --output_dir to the *parent* folder so we don't end up with Demo PDF/Demo PDF/.\n",
    "    output_parent = pdf_path.parent  # e.g., .../Demo/\n",
    "\n",
    "    # Determine the destination folder Marker will create and a checksum sidecar file\n",
    "    dest_dir = output_parent / pdf_path.stem\n",
    "    checksum_file = dest_dir / \".marker_md5\"\n",
    "\n",
    "    # Compute the current md5 of the source PDF\n",
    "    current_md5 = md5sum(pdf_path)\n",
    "\n",
    "    # Define the expected main outputs (Marker uses the same stem)\n",
    "    expected_md = dest_dir / f\"{pdf_path.stem}.md\"\n",
    "    expected_json = dest_dir / f\"{pdf_path.stem}.json\"\n",
    "    outputs_exist = expected_md.exists() and expected_json.exists()\n",
    "\n",
    "    # md5 two-mode logic\n",
    "    if md5_check:\n",
    "        # Normal: skip if checksum matches and key outputs exist\n",
    "        if dest_dir.is_dir() and checksum_file.exists() and outputs_exist:\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception:\n",
    "                saved_md5 = \"\"\n",
    "            if saved_md5 == current_md5:\n",
    "                print(f\"⏭️  Skipping {pdf_path.name}: up-to-date (md5 match). → {dest_dir}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"♻️  md5 mismatch → reprocessing {pdf_path.name}\")\n",
    "                print(f\"    Cleaning old outputs in: {dest_dir}\")\n",
    "                try:\n",
    "                    shutil.rmtree(dest_dir)\n",
    "                except Exception as _e:\n",
    "                    print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "        else:\n",
    "            print(\"ℹ️  No prior checksum or outputs → processing normally.\")\n",
    "    else:\n",
    "        # Force reprocess regardless of checksum\n",
    "        print(\"⚙️  md5_check=False → forcing reprocess (marker + OCR).\")\n",
    "        if dest_dir.exists():\n",
    "            print(f\"    Cleaning existing folder: {dest_dir}\")\n",
    "            try:\n",
    "                shutil.rmtree(dest_dir)\n",
    "            except Exception as _e:\n",
    "                print(f\"    ⚠️  Could not fully clean '{dest_dir}': {_e}\")\n",
    "\n",
    "    try:\n",
    "        # ======================================================================\n",
    "        # 1. Run the CLI command to generate JSON output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"Running CLI command for JSON output on {pdf_path.name}...\")\n",
    "        json_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            \"--output_format\", \"json\",\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        # By removing 'capture_output', the subprocess will stream its output directly to the console in real-time.\n",
    "        result_json = subprocess.run(json_command, check=True)\n",
    "        print(\"✅ JSON file generated successfully by CLI.\")\n",
    "\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2. Run the CLI command to generate Markdown and Image output (with real-time output)\n",
    "        # ======================================================================\n",
    "        print(f\"\\nRunning CLI command for Markdown and Image output on {pdf_path.name}...\")\n",
    "        md_command = [\n",
    "            \"marker_single\",\n",
    "            str(pdf_path),\n",
    "            # Default format is markdown, so we don't need to specify it\n",
    "            \"--output_dir\", str(output_parent)\n",
    "        ]\n",
    "        result_md = subprocess.run(md_command, check=True)\n",
    "        print(\"✅ Markdown file and images generated successfully by CLI.\")\n",
    "\n",
    "        print(f\"\\n✨ Files saved under '{output_parent / pdf_path.stem}'.\")\n",
    "        print(\"Note: Marker creates a subfolder named after the PDF automatically.\")\n",
    "\n",
    "        # === Post-processing: scan Marker images → filter relevant → save JSONL ===\n",
    "        print(\"🔎 Scanning extracted images for relevant charts/plots…\")\n",
    "        img_exts = (\".png\", \".jpg\", \".jpeg\")\n",
    "        img_files = [p for p in dest_dir.rglob(\"*\") if p.suffix.lower() in img_exts]\n",
    "        if not img_files:\n",
    "            print(\"   🖼️  No images found in extracted folder.\")\n",
    "        for img_path in sorted(img_files):\n",
    "            print(f\"   • {img_path.name}\")\n",
    "            any_hit = False\n",
    "            for ex in EXTRACTORS:\n",
    "                # Stage 1: quick keyword/title skim\n",
    "                print(f\"      · [{ex.name}] quick gate…\", end=\" \")\n",
    "                if not ex.is_relevant(img_path):\n",
    "                    print(\"⏭️  Not relevant\")\n",
    "                    continue\n",
    "                print(\"✅ ok; strict gate…\", end=\" \")\n",
    "\n",
    "                # Stage 2: strict verifier (geometry + numeric band + semantic anchors)\n",
    "                ok_strict, reason = is_strict_nim_image(img_path)\n",
    "                if not ok_strict:\n",
    "                    print(f\"⏭️  Failed strict ({reason})\")\n",
    "                    continue\n",
    "\n",
    "                any_hit = True\n",
    "                print(\"✅ Strict OK — extracting…\", end=\" \")\n",
    "                ok, msg = ex.handle_image(img_path, dest_dir, pdf_path.name, bypass_relevance=True)\n",
    "                if ok:\n",
    "                    print(f\"💾 Saved → {msg}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipped ({msg})\")\n",
    "            if not any_hit:\n",
    "                print(\"      ⏭️  No matching extractors for this image.\")\n",
    "\n",
    "        # After OCR completes, write/update checksum sidecar\n",
    "        try:\n",
    "            dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "            checksum_file.write_text(current_md5)\n",
    "            print(f\"🧾 Recorded checksum in: {checksum_file}\")\n",
    "        except Exception as _e:\n",
    "            print(f\"⚠️  Failed to write checksum file at '{checksum_file}': {_e}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n❌ An error occurred while processing {pdf_path.name}.\")\n",
    "        print(f\"Command: '{' '.join(e.cmd)}'\")\n",
    "        print(f\"Return Code: {e.returncode}\")\n",
    "        print(\"Note: Outputs (if any) may be incomplete; checksum not updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred while processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"--- Finished processing: {pdf_path.name} ---\\n\")\n",
    "\n",
    "print(\"🎉 All PDF files in the directory have been processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e064a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Scanning PDF directory: /Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All\n",
      "\n",
      "♻️  1Q24_CEO_presentation.pdf — updated md5 (old=03b389e2 → new=4df61135)\n",
      "♻️  1Q24_CFO_presentation.pdf — updated md5 (old=0f66e9e1 → new=79a0d8ac)\n",
      "♻️  1Q24_trading_update.pdf — updated md5 (old=b2ac3610 → new=806f76f1)\n",
      "♻️  1Q25_CEO_presentation.pdf — updated md5 (old=94c48e50 → new=eaa5b56d)\n",
      "♻️  1Q25_CFO_presentation.pdf — updated md5 (old=02e9f7f0 → new=2f7823c8)\n",
      "♻️  1Q25_trading_update.pdf — updated md5 (old=9a06349e → new=10aebe06)\n",
      "♻️  2Q24_CEO_presentation.pdf — updated md5 (old=c96bf72c → new=7ad7b14e)\n",
      "♻️  2Q24_CFO_presentation.pdf — updated md5 (old=1828d704 → new=7cda2c53)\n",
      "♻️  2Q24_performance_summary.pdf — updated md5 (old=954e1657 → new=57d1cb1e)\n",
      "♻️  2Q24_press_statement.pdf — updated md5 (old=925e3108 → new=b5bcb585)\n",
      "♻️  2Q25_CEO_presentation.pdf — updated md5 (old=e84a24b9 → new=4237d7bb)\n",
      "♻️  2Q25_CFO_presentation.pdf — updated md5 (old=b9f8c743 → new=7b6f63e4)\n",
      "♻️  2Q25_performance_summary.pdf — updated md5 (old=335d1df7 → new=a4049ee1)\n",
      "♻️  2Q25_press_statement.pdf — updated md5 (old=4ed7f249 → new=e5d73564)\n",
      "♻️  3Q24_CEO_presentation.pdf — updated md5 (old=9a8b03a1 → new=64a3aee4)\n",
      "♻️  3Q24_CFO_presentation.pdf — updated md5 (old=cbb74c9d → new=3d9944f1)\n",
      "♻️  3Q24_trading_update.pdf — updated md5 (old=73f35e7c → new=72db4eb4)\n",
      "♻️  4Q24_CEO_presentation.pdf — updated md5 (old=18326ada → new=f4a22c61)\n",
      "♻️  4Q24_CFO_presentation.pdf — updated md5 (old=ab3cba8a → new=c2c6c58c)\n",
      "♻️  4Q24_performance_summary.pdf — updated md5 (old=6bbb8756 → new=3045c9d5)\n",
      "♻️  4Q24_press_statement.pdf — updated md5 (old=af93e556 → new=e8aef5ea)\n",
      "♻️  dbs-annual-report-2022.pdf — updated md5 (old=7e8bc52e → new=b8c5eeed)\n",
      "♻️  dbs-annual-report-2023.pdf — updated md5 (old=b20e5157 → new=2dd228f1)\n",
      "♻️  dbs-annual-report-2024.pdf — updated md5 (old=c32c82e6 → new=5a7b7bce)\n",
      "\n",
      "🎉 Done verifying and updating all MD5 checksums.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import hashlib\n",
    "\n",
    "# === CONFIG ===\n",
    "root_dir = Path(\"/Users/marcusfoo/Documents/GitHub/PTO_ICT3113_Grp1/All\")\n",
    "\n",
    "# === Helper ===\n",
    "def md5sum(file_path: Path, chunk_size: int = 8192) -> str:\n",
    "    h = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# === Main Logic ===\n",
    "print(f\"📂 Scanning PDF directory: {root_dir}\\n\")\n",
    "\n",
    "pdfs = sorted(root_dir.glob(\"*.pdf\"))\n",
    "if not pdfs:\n",
    "    print(\"❌ No PDF files found in directory.\")\n",
    "else:\n",
    "    for pdf_path in pdfs:\n",
    "        pdf_name = pdf_path.stem\n",
    "        dest_dir = root_dir / pdf_name\n",
    "        checksum_file = dest_dir / \".marker_md5\"\n",
    "        current_md5 = md5sum(pdf_path)\n",
    "\n",
    "        # Ensure folder exists (since marker creates it per PDF)\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        saved_md5 = None\n",
    "        if checksum_file.exists():\n",
    "            try:\n",
    "                saved_md5 = checksum_file.read_text().strip()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Failed to read existing checksum for {pdf_name}: {e}\")\n",
    "\n",
    "        # Compare and update\n",
    "        if saved_md5 == current_md5:\n",
    "            print(f\"✅ {pdf_name}.pdf — up to date (md5 match: {current_md5})\")\n",
    "        else:\n",
    "            checksum_file.write_text(current_md5)\n",
    "            if saved_md5:\n",
    "                print(f\"♻️  {pdf_name}.pdf — updated md5 (old={saved_md5[:8]} → new={current_md5[:8]})\")\n",
    "            else:\n",
    "                print(f\"🆕 {pdf_name}.pdf — created new md5 ({current_md5})\")\n",
    "\n",
    "print(\"\\n🎉 Done verifying and updating all MD5 checksums.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
