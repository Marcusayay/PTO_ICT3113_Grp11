{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8e4733",
   "metadata": {
    "id": "bb8e4733"
   },
   "source": [
    "# Agent CFO ‚Äî Performance Optimization & Design\n",
    "\n",
    "---\n",
    "This is the starter notebook for your project. Follow the required structure below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wkMIj4Ssetku",
   "metadata": {
    "id": "wkMIj4Ssetku"
   },
   "source": [
    "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
    "\n",
    "Your system must:\n",
    "*   Ingest the company‚Äôs public filings.\n",
    "*   Retrieve relevant passages efficiently.\n",
    "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
    "*   Produce answers with valid citations to the correct page/table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c0e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyA4EAOFUpop94_hgxN1I3mm6-XVBuS7q2k\"  # replace with your key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c138dd7",
   "metadata": {
    "id": "0c138dd7"
   },
   "source": [
    "## 1. Config & Secrets\n",
    "\n",
    "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6098a4",
   "metadata": {
    "id": "8a6098a4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Example:\n",
    "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
    "\n",
    "COMPANY_NAME = \"DBS Bank\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a81e9",
   "metadata": {
    "id": "8b7a81e9"
   },
   "source": [
    "## 2. Data Download (Dropbox)\n",
    "\n",
    "*   Annual Reports: last 3‚Äì5 years.\n",
    "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
    "*   Investor Presentations and Press Releases.\n",
    "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
    "*   Upload them under `/content/data/`.\n",
    "\n",
    "Scope limit: each team will ingest minimally 15 PDF files total.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4e754",
   "metadata": {
    "id": "b0d4e754"
   },
   "source": [
    "## 3. System Requirements\n",
    "\n",
    "**Retrieval & RAG**\n",
    "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
    "*   Citations must include: report name, year, page number, section/table.\n",
    "\n",
    "**Agentic Reasoning**\n",
    "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
    "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
    "\n",
    "**Instrumentation**\n",
    "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
    "*   Log: tokens used, cache hits, tools invoked.\n",
    "*   Record p50/p95 latencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532a3fb",
   "metadata": {},
   "source": [
    " ### Gemini Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b049b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from rank_bm25) (1.20.2)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bed676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rank_bm25) (2.2.6)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d5542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.8.0-py3-none-any.whl (1.0 MB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.67.1)\n",
      "Collecting jiter<1,>=0.10.0\n",
      "  Downloading jiter-0.12.0-cp310-cp310-win_amd64.whl (204 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\pc\\appdata\\roaming\\python\\python310\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\pc\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Collecting h11>=0.16\n",
      "  Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.41.5\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Collecting typing-inspection>=0.4.2\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Installing collected packages: sniffio, h11, typing-inspection, pydantic-core, httpcore, anyio, annotated-types, pydantic, jiter, httpx, distro, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.11.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.12.0 openai-2.8.0 pydantic-2.12.4 pydantic-core-2.41.5 sniffio-1.3.1 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2698633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing sentence-transformers ...\n",
      "üîé Found 24 docs under All\n",
      "üìë Saved outline ‚Üí data_marker\\kb_outline.parquet (rows=3325)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing docs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:00<00:00, 1599.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No changes detected. Keeping existing KB and FAISS index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'docs_processed': 24,\n",
       " 'chunks_total': 13548,\n",
       " 'tables_long_rows': 52853,\n",
       " 'paths': {'kb_chunks_parquet': 'data_marker\\\\kb_chunks.parquet',\n",
       "  'kb_texts_npy': 'data_marker\\\\kb_texts.npy',\n",
       "  'kb_meta_json': 'data_marker\\\\kb_meta.json',\n",
       "  'kb_tables_parquet': 'data_marker\\\\kb_tables.parquet',\n",
       "  'kb_outline_parquet': 'data_marker\\\\kb_outline.parquet',\n",
       "  'kb_index_faiss': 'data_marker\\\\kb_index.faiss',\n",
       "  'kb_index_meta_json': 'data_marker\\\\kb_index_meta.json'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === One-click: Build KB + FAISS from Marker (JSON+MD) with table parsing =====\n",
    "# - Auto-installs deps\n",
    "# - Parses Marker JSON 'Table' blocks (via HTML) -> DataFrames\n",
    "# - Adds table row-sentences to embeddings\n",
    "# - Saves long-form tables to data/kb_tables.parquet\n",
    "# - Caches per-doc; if nothing changed, keeps existing KB/index\n",
    "\n",
    "import sys, subprocess, warnings, re, json, hashlib, time\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "\n",
    "# 1) Ensure dependencies\n",
    "for pkg in [\"sentence-transformers\", \"faiss-cpu\", \"pandas\", \"pyarrow\", \"numpy\", \"lxml\", \"tqdm\"]:\n",
    "    try:\n",
    "        __import__(pkg.split(\"-\")[0])\n",
    "    except Exception:\n",
    "        print(f\"üì¶ Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
    "\n",
    "import numpy as np, pandas as pd, faiss\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _file_hash_key(p: Path) -> str:\n",
    "    try:\n",
    "        s = p.stat()\n",
    "        return hashlib.md5(f\"{p.resolve()}|{s.st_size}|{int(s.st_mtime)}\".encode()).hexdigest()\n",
    "    except FileNotFoundError:\n",
    "        return \"\"\n",
    "\n",
    "def _safe_read(path: Path) -> str:\n",
    "    for enc in (\"utf-8\", \"utf-8-sig\", \"latin-1\"):\n",
    "        try:\n",
    "            return path.read_text(encoding=enc, errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "def _strip_md_basic(md: str) -> str:\n",
    "    md = re.sub(r\"```.*?```\", \" \", md, flags=re.DOTALL)     # code fences\n",
    "    md = re.sub(r\"!\\[[^\\]]*\\]\\([^\\)]*\\)\", \" \", md)          # images\n",
    "    md = re.sub(r\"\\[([^\\]]+)\\]\\([^\\)]*\\)\", r\"\\1\", md)       # links\n",
    "    md = re.sub(r\"<[^>]+>\", \" \", md)                        # html tags\n",
    "    md = re.sub(r\"\\s+\", \" \", md)\n",
    "    return md.strip()\n",
    "\n",
    "def _extract_text_from_marker_json(jtxt: str) -> str:\n",
    "    # Best-effort: prefer 'markdown', else join pages[].text, else collect strings\n",
    "    try:\n",
    "        data = json.loads(jtxt)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    if isinstance(data, dict) and isinstance(data.get(\"markdown\"), str):\n",
    "        return _strip_md_basic(data[\"markdown\"])\n",
    "    pages = data.get(\"pages\") if isinstance(data, dict) else None\n",
    "    if isinstance(pages, list):\n",
    "        segs = []\n",
    "        for p in pages:\n",
    "            if isinstance(p, dict):\n",
    "                t = p.get(\"text\")\n",
    "                if isinstance(t, str) and t.strip():\n",
    "                    segs.append(t.strip())\n",
    "        if segs:\n",
    "            return _strip_md_basic(\"\\n\\n\".join(segs))\n",
    "    # fallback: collect strings\n",
    "    collected = []\n",
    "    def walk(n):\n",
    "        if isinstance(n, dict):\n",
    "            for v in n.values(): walk(v)\n",
    "        elif isinstance(n, list):\n",
    "            for v in n: walk(v)\n",
    "        elif isinstance(n, str):\n",
    "            s = n.strip()\n",
    "            if len(s) >= 20:\n",
    "                collected.append(s)\n",
    "    walk(data)\n",
    "    return _strip_md_basic(\"\\n\\n\".join(collected)) if collected else \"\"\n",
    "\n",
    "def _chunk_text(text: str, max_chars: int = 1600, overlap: int = 200):\n",
    "    if not text: return []\n",
    "    paras = [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
    "    chunks, buf, cur = [], [], 0\n",
    "    def flush():\n",
    "        nonlocal buf, cur\n",
    "        if not buf: return\n",
    "        s = \"\\n\\n\".join(buf).strip()\n",
    "        step = max_chars - overlap\n",
    "        for i in range(0, len(s), step):\n",
    "            piece = s[i:i+step].strip()\n",
    "            if piece: chunks.append(piece)\n",
    "        buf.clear(); cur = 0\n",
    "    for p in paras:\n",
    "        if cur + len(p) + 2 <= max_chars:\n",
    "            buf.append(p); cur += len(p) + 2\n",
    "        else:\n",
    "            flush(); buf.append(p); cur = len(p)\n",
    "    flush()\n",
    "    return chunks\n",
    "\n",
    "def _discover_docs(in_dir: Path):\n",
    "    docs = {}\n",
    "    for f in sorted(in_dir.iterdir()):\n",
    "        if not f.is_dir(): continue\n",
    "        nested = f / f.name\n",
    "        md = list(f.glob(\"*.md\")) + (list(nested.glob(\"*.md\")) if nested.is_dir() else [])\n",
    "        js = list(f.glob(\"*.json\")) + (list(nested.glob(\"*.json\")) if nested.is_dir() else [])\n",
    "        if md or js:\n",
    "            docs[f.name] = {\"md\": sorted(md), \"json\": sorted(js), \"root\": f}\n",
    "    return docs\n",
    "\n",
    "# ---- JSON table parsing (from 'html' field of Table blocks) ----\n",
    "def _coerce_numbers_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == object:\n",
    "            # remove thousands separators\n",
    "            s = df[c].astype(str).str.replace(\",\", \"\", regex=False)\n",
    "            # try numeric; keep strings where not numeric (as strings)\n",
    "            num = pd.to_numeric(s, errors=\"coerce\")\n",
    "            df[c] = np.where(num.notna(), num, s)\n",
    "    return df\n",
    "\n",
    "def _extract_tables_from_marker_json_blocks(jtxt: str):\n",
    "    \"\"\"\n",
    "    Parse Marker JSON and return a list of dicts with tables and their source page:\n",
    "      [{\"df\": pandas.DataFrame, \"page\": int | None}, ...]\n",
    "    We walk the block tree, track the nearest /page/{n}/ id, and attach it to table blocks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(jtxt)\n",
    "    except Exception:\n",
    "        return []\n",
    "    out: list[dict] = []\n",
    "\n",
    "    def _page_from_id(node: dict, fallback: 'Optional[int]') -> 'Optional[int]':\n",
    "        # prefer the node's own id; else fallback from parent context\n",
    "        node_id = node.get(\"id\") if isinstance(node.get(\"id\"), str) else \"\"\n",
    "        m = re.search(r\"/page/(\\d+)/\", node_id or \"\")\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except Exception:\n",
    "                pass\n",
    "        return fallback\n",
    "\n",
    "    def walk(node, current_page: 'Optional[int]' = None):\n",
    "        if isinstance(node, dict):\n",
    "            current_page = _page_from_id(node, current_page)\n",
    "            if node.get(\"block_type\") == \"Table\" and isinstance(node.get(\"html\"), str):\n",
    "                html = node[\"html\"]\n",
    "                try:\n",
    "                    dfs = pd.read_html(StringIO(html))\n",
    "                    for df in dfs:\n",
    "                        out.append({\"df\": _coerce_numbers_df(df), \"page\": current_page})\n",
    "                except Exception:\n",
    "                    pass\n",
    "            # descend\n",
    "            for v in node.values():\n",
    "                walk(v, current_page)\n",
    "        elif isinstance(node, list):\n",
    "            for v in node:\n",
    "                walk(v, current_page)\n",
    "\n",
    "    walk(data)\n",
    "    return out\n",
    "\n",
    "# ---- NEW: Extract text spans with page numbers from Marker JSON ----\n",
    "def _extract_text_spans_with_pages(jtxt: str):\n",
    "    \"\"\"\n",
    "    Walk Marker JSON and yield per-page text spans from textual blocks.\n",
    "    Returns list of dicts: [{\"page\": int | None, \"text\": str}, ...]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(jtxt)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "    spans: list[dict] = []\n",
    "\n",
    "    def _page_from_id(node: dict, fallback: 'Optional[int]') -> 'Optional[int]':\n",
    "        node_id = node.get(\"id\") if isinstance(node.get(\"id\"), str) else \"\"\n",
    "        m = re.search(r\"/page/(\\d+)/\", node_id or \"\")\n",
    "        if m:\n",
    "            try:\n",
    "                return int(m.group(1))\n",
    "            except Exception:\n",
    "                pass\n",
    "        return fallback\n",
    "\n",
    "    def _strip_html(s: str) -> str:\n",
    "        s = re.sub(r\"<[^>]+>\", \" \", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        return s\n",
    "\n",
    "    TEXT_BLOCKS = {\"Text\", \"SectionHeader\", \"Paragraph\", \"Heading\", \"ListItem\", \"Caption\", \"Footer\", \"Header\"}\n",
    "\n",
    "    def walk(node, current_page: 'Optional[int]' = None):\n",
    "        if isinstance(node, dict):\n",
    "            current_page = _page_from_id(node, current_page)\n",
    "            bt = node.get(\"block_type\")\n",
    "            if isinstance(bt, str) and bt in TEXT_BLOCKS:\n",
    "                html = node.get(\"html\")\n",
    "                if isinstance(html, str) and html.strip():\n",
    "                    txt = _strip_html(html)\n",
    "                    if txt:\n",
    "                        spans.append({\"page\": current_page, \"text\": txt})\n",
    "            for v in node.values():\n",
    "                walk(v, current_page)\n",
    "        elif isinstance(node, list):\n",
    "            for v in node:\n",
    "                walk(v, current_page)\n",
    "\n",
    "    walk(data)\n",
    "    return spans\n",
    "\n",
    "def _markdown_tables_find(md_text: str):\n",
    "    lines = md_text.splitlines()\n",
    "    i, n = 0, len(lines)\n",
    "    while i < n:\n",
    "        if '|' in lines[i]:\n",
    "            j = i + 1\n",
    "            if j < n and re.search(r'^\\s*\\|?\\s*:?-{3,}', lines[j]):\n",
    "                k = j + 1\n",
    "                while k < n and '|' in lines[k] and lines[k].strip():\n",
    "                    k += 1\n",
    "                yield \"\\n\".join(lines[i:k])\n",
    "                i = k; continue\n",
    "        i += 1\n",
    "\n",
    "def _markdown_table_to_df(table_md: str) -> pd.DataFrame | None:\n",
    "    rows = [r.strip() for r in table_md.strip().splitlines() if r.strip()]\n",
    "    if len(rows) < 2: return None\n",
    "    def split_row(r: str):\n",
    "        r = r.strip()\n",
    "        if r.startswith('|'): r = r[1:]\n",
    "        if r.endswith('|'): r = r[:-1]\n",
    "        return [c.strip() for c in r.split('|')]\n",
    "    cols = split_row(rows[0])\n",
    "    if len(split_row(rows[1])) != len(cols): return None\n",
    "    data = []\n",
    "    for r in rows[2:]:\n",
    "        cells = split_row(r)\n",
    "        if len(cells) < len(cols): cells += [\"\"] * (len(cols) - len(cells))\n",
    "        if len(cells) > len(cols): cells = cells[:len(cols)]\n",
    "        data.append(cells)\n",
    "    try:\n",
    "        df = pd.DataFrame(data, columns=cols)\n",
    "        return _coerce_numbers_df(df)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _table_rows_to_sentences(df: pd.DataFrame, doc_name: str, table_id: int):\n",
    "    sents = []\n",
    "    if df.shape[1] == 0: return sents\n",
    "    label = df.columns[0]\n",
    "    for ridx, row in df.reset_index(drop=True).iterrows():\n",
    "        parts = [str(row[label])]\n",
    "        for c in df.columns[1:]:\n",
    "            parts.append(f\"{c}: {row[c]}\")\n",
    "        sents.append(f\"[{doc_name}] table#{table_id} row#{ridx} :: \" + \" | \".join(parts))\n",
    "    return sents\n",
    "\n",
    "# --- Table signature for fuzzy matching Markdown tables to JSON tables ---\n",
    "def _table_signature(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Build a fuzzy signature for a table to match MD tables back to JSON tables.\n",
    "    Uses: first-column header, set of year-like columns, and a few numeric cell samples.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cols = [str(c).strip() for c in df.columns]\n",
    "        first_col = cols[0] if cols else \"\"\n",
    "        # collect 4-digit year columns\n",
    "        years = sorted({c for c in cols if re.fullmatch(r\"\\d{4}\", str(c))})\n",
    "        # flatten numeric values (best-effort) and take first 8\n",
    "        nums = []\n",
    "        for c in df.columns:\n",
    "            s = pd.to_numeric(pd.Series(df[c]).astype(str).str.replace(\",\", \"\", regex=False), errors=\"coerce\")\n",
    "            vals = [float(x) for x in s.dropna().tolist()]\n",
    "            nums.extend(vals)\n",
    "        nums = [round(x, 3) for x in nums[:8]]\n",
    "        return \"|\".join([\n",
    "            f\"first:{first_col.lower()}\",\n",
    "            \"years:\" + \",\".join(years),\n",
    "            \"nums:\" + \",\".join(map(str, nums))\n",
    "        ])\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "# ---- embeddings & index ----\n",
    "def _encode(texts, model_name):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embs = model.encode(texts, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "    return np.asarray(embs, dtype=\"float32\")\n",
    "\n",
    "def _build_faiss(embs):\n",
    "    d = int(embs.shape[1])\n",
    "    idx = faiss.IndexFlatIP(d)  # cosine via normalized inner product\n",
    "    idx.add(embs)\n",
    "    return idx\n",
    "\n",
    "# ---------- main (notebook-friendly) ----------\n",
    "def build_marker_kb_with_tables(\n",
    "    in_dir=\"./All\",\n",
    "    out_dir=\"./data_marker\",\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    max_chars=1600,\n",
    "    overlap=200,\n",
    "):\n",
    "    in_path, out_path = Path(in_dir), Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    kb_parquet     = out_path / \"kb_chunks.parquet\"\n",
    "    kb_texts_npy   = out_path / \"kb_texts.npy\"\n",
    "    kb_meta_json   = out_path / \"kb_meta.json\"\n",
    "    kb_index_path  = out_path / \"kb_index.faiss\"\n",
    "    kb_index_meta  = out_path / \"kb_index_meta.json\"\n",
    "    kb_tables_parq = out_path / \"kb_tables.parquet\"\n",
    "    kb_outline_parq = out_path / \"kb_outline.parquet\"\n",
    "\n",
    "    cache = {}\n",
    "    if kb_meta_json.exists():\n",
    "        try:\n",
    "            cache = json.loads(kb_meta_json.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            cache = {}\n",
    "\n",
    "    # Discover docs\n",
    "    docs = _discover_docs(in_path)\n",
    "    if not docs:\n",
    "        raise RuntimeError(f\"No Marker artefacts found under: {in_path}\")\n",
    "    print(f\"üîé Found {len(docs)} docs under {in_path}\")\n",
    "\n",
    "    # --- collect and persist Marker *_meta.json outlines for provenance/navigation ---\n",
    "    outline_rows = []\n",
    "    for doc_name, art in docs.items():\n",
    "        root = art.get(\"root\", in_path / doc_name)\n",
    "        # look for \"*_meta.json\" in root and nested same-name subfolder\n",
    "        candidates = list(root.glob(\"*_meta.json\"))\n",
    "        nested_same = root / doc_name\n",
    "        if nested_same.is_dir():\n",
    "            candidates += list(nested_same.glob(\"*_meta.json\"))\n",
    "        for meta_path in candidates:\n",
    "            try:\n",
    "                data = json.loads(_safe_read(meta_path))\n",
    "                toc = data.get(\"table_of_contents\") or data.get(\"toc\") or []\n",
    "                for i, item in enumerate(toc):\n",
    "                    outline_rows.append({\n",
    "                        \"doc_name\": doc_name,\n",
    "                        \"source_path\": str(meta_path),\n",
    "                        \"order\": int(i),\n",
    "                        \"title\": item.get(\"title\"),\n",
    "                        \"page_id\": item.get(\"page_id\"),\n",
    "                        \"polygon\": item.get(\"polygon\"),\n",
    "                    })\n",
    "            except Exception:\n",
    "                # ignore malformed meta files\n",
    "                pass\n",
    "    if outline_rows:\n",
    "        pd.DataFrame(outline_rows).to_parquet(kb_outline_parq, engine=\"pyarrow\", index=False)\n",
    "        print(f\"üìë Saved outline ‚Üí {kb_outline_parq} (rows={len(outline_rows)})\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No *_meta.json outlines found.\")\n",
    "\n",
    "    # Track new chunks & long-form tables\n",
    "    rows_meta, chunk_texts = [], []\n",
    "    tables_long = []\n",
    "\n",
    "    # map of table signature -> page number (from JSON-origin tables)\n",
    "    json_table_sig_to_page: dict[str, int] = {}\n",
    "\n",
    "    changed_any = False\n",
    "    for name, art in tqdm(docs.items(), desc=\"Processing docs\"):\n",
    "        md_files, json_files = art[\"md\"], art[\"json\"]\n",
    "        keys = [_file_hash_key(p) for p in (md_files + json_files)]\n",
    "        doc_key = hashlib.md5(\"|\".join(keys).encode()).hexdigest()\n",
    "\n",
    "        # If unchanged, skip reprocessing this doc\n",
    "        if cache.get(name, {}).get(\"cache_key\") == doc_key:\n",
    "            continue\n",
    "        changed_any = True\n",
    "\n",
    "        # 1) JSON ‚Üí tables + narrative text (with page numbers)\n",
    "        table_id = 0\n",
    "        for jp in json_files:\n",
    "            jtxt = _safe_read(jp)\n",
    "\n",
    "            # Tables via HTML blocks (with page capture)\n",
    "            table_blocks = _extract_tables_from_marker_json_blocks(jtxt)\n",
    "            for tb in table_blocks:\n",
    "                df = tb[\"df\"]\n",
    "                page_no = tb.get(\"page\")\n",
    "                # record signature->page for later MD matching\n",
    "                try:\n",
    "                    sig = _table_signature(df)\n",
    "                    if page_no is not None and sig:\n",
    "                        json_table_sig_to_page[sig] = int(page_no)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                # row-sentences for retrieval (append a page hint to the sentence)\n",
    "                for sent in _table_rows_to_sentences(df, name, table_id):\n",
    "                    if page_no is not None:\n",
    "                        sent = f\"[page {page_no}] \" + sent\n",
    "                    rows_meta.append({\n",
    "                        \"doc\": name,\n",
    "                        \"path\": str(jp),\n",
    "                        \"modality\": \"table_row\",\n",
    "                        \"chunk\": len(chunk_texts),\n",
    "                        \"cache_key\": doc_key,\n",
    "                        \"page\": int(page_no) if page_no is not None else None,\n",
    "                    })\n",
    "                    chunk_texts.append(sent)\n",
    "                # long-form cells for analytics\n",
    "                for ridx, row in df.reset_index(drop=True).iterrows():\n",
    "                    for col in df.columns:\n",
    "                        _val = row[col]\n",
    "                        _val_str = \"\" if pd.isna(_val) else str(_val)\n",
    "                        try:\n",
    "                            _val_num = pd.to_numeric(_val_str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "                        except Exception:\n",
    "                            _val_num = np.nan\n",
    "                        tables_long.append({\n",
    "                            \"doc_name\": name,\n",
    "                            \"source_path\": str(jp),\n",
    "                            \"table_id\": table_id,\n",
    "                            \"row_id\": int(ridx),\n",
    "                            \"column\": str(col),\n",
    "                            \"value_str\": _val_str,\n",
    "                            \"value_num\": float(_val_num) if pd.notna(_val_num) else None,\n",
    "                            \"page\": int(page_no) if page_no is not None else None,\n",
    "                        })\n",
    "                table_id += 1\n",
    "\n",
    "            # Narrative text per page\n",
    "            spans = _extract_text_spans_with_pages(jtxt)\n",
    "            # group by page and chunk each page separately\n",
    "            by_page = {}\n",
    "            for sp in spans:\n",
    "                by_page.setdefault(sp.get(\"page\"), []).append(sp[\"text\"])\n",
    "            for page_no, texts in by_page.items():\n",
    "                page_text = _strip_md_basic(\"\\n\\n\".join(texts))\n",
    "                for i, ch in enumerate(_chunk_text(page_text, max_chars, overlap)):\n",
    "                    rows_meta.append({\n",
    "                        \"doc\": name,\n",
    "                        \"path\": str(jp),\n",
    "                        \"modality\": \"json\",\n",
    "                        \"chunk\": len(chunk_texts),\n",
    "                        \"cache_key\": doc_key,\n",
    "                        \"page\": int(page_no) if page_no is not None else None,\n",
    "                    })\n",
    "                    chunk_texts.append(ch)\n",
    "\n",
    "        # 2) Markdown ‚Üí tables + non-table text\n",
    "        for mp in md_files:\n",
    "            md = _safe_read(mp)\n",
    "\n",
    "            # tables from MD\n",
    "            for tblock in _markdown_tables_find(md):\n",
    "                df = _markdown_table_to_df(tblock)\n",
    "                if df is None: \n",
    "                    continue\n",
    "                # try to infer page by matching this MD table to a JSON table signature\n",
    "                md_page = None\n",
    "                try:\n",
    "                    md_sig = _table_signature(df)\n",
    "                    if md_sig and md_sig in json_table_sig_to_page:\n",
    "                        md_page = int(json_table_sig_to_page[md_sig])\n",
    "                except Exception:\n",
    "                    md_page = None\n",
    "\n",
    "                for sent in _table_rows_to_sentences(df, name, table_id):\n",
    "                    rows_meta.append({\n",
    "                        \"doc\": name,\n",
    "                        \"path\": str(mp),\n",
    "                        \"modality\": \"table_row\",\n",
    "                        \"chunk\": len(chunk_texts),\n",
    "                        \"cache_key\": doc_key,\n",
    "                        \"page\": md_page  # may be None if unmatched\n",
    "                    })\n",
    "                    chunk_texts.append(sent)\n",
    "                for ridx, row in df.reset_index(drop=True).iterrows():\n",
    "                    for col in df.columns:\n",
    "                        _val = row[col]\n",
    "                        _val_str = \"\" if pd.isna(_val) else str(_val)\n",
    "                        try:\n",
    "                            _val_num = pd.to_numeric(_val_str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "                        except Exception:\n",
    "                            _val_num = np.nan\n",
    "                        tables_long.append({\n",
    "                            \"doc_name\": name,\n",
    "                            \"source_path\": str(jp if \"jp\" in locals() else mp),\n",
    "                            \"table_id\": table_id,\n",
    "                            \"row_id\": int(ridx),\n",
    "                            \"column\": str(col),\n",
    "                            \"value_str\": _val_str,\n",
    "                            \"value_num\": float(_val_num) if pd.notna(_val_num) else None,\n",
    "                            \"page\": md_page,  # keep None if not found\n",
    "                        })\n",
    "                table_id += 1\n",
    "\n",
    "            # non-table text (remove table blocks first to avoid dupes)\n",
    "            md_no_tables = md\n",
    "            for tblock in _markdown_tables_find(md):\n",
    "                md_no_tables = md_no_tables.replace(tblock, \"\")\n",
    "            for i, ch in enumerate(_chunk_text(_strip_md_basic(md_no_tables), max_chars, overlap)):\n",
    "                rows_meta.append({\"doc\": name, \"path\": str(mp), \"modality\": \"md\", \"chunk\": len(chunk_texts), \"cache_key\": doc_key, \"page\": None})\n",
    "                chunk_texts.append(ch)\n",
    "\n",
    "        # update per-doc cache (count new chunks we just added for this doc)\n",
    "        added_for_doc = sum(1 for r in rows_meta if r[\"cache_key\"] == doc_key)\n",
    "        cache[name] = {\"cache_key\": doc_key, \"chunk_count\": added_for_doc, \"updated_at\": int(time.time())}\n",
    "\n",
    "    # If nothing changed and KB exists ‚Üí keep existing artifacts\n",
    "    if not changed_any and kb_parquet.exists() and kb_texts_npy.exists() and kb_index_path.exists():\n",
    "        print(\"‚úÖ No changes detected. Keeping existing KB and FAISS index.\")\n",
    "        df_existing = pd.read_parquet(kb_parquet)\n",
    "        texts_existing = np.load(kb_texts_npy, allow_pickle=True)\n",
    "        return {\n",
    "            \"docs_processed\": len(docs),\n",
    "            \"chunks_total\": int(len(texts_existing)),\n",
    "            \"tables_long_rows\": (pd.read_parquet(kb_tables_parq).shape[0] if kb_tables_parq.exists() else 0),\n",
    "            \"paths\": {\n",
    "                \"kb_chunks_parquet\": str(kb_parquet),\n",
    "                \"kb_texts_npy\": str(kb_texts_npy),\n",
    "                \"kb_meta_json\": str(kb_meta_json),\n",
    "                \"kb_tables_parquet\": str(kb_tables_parq) if kb_tables_parq.exists() else None,\n",
    "                \"kb_outline_parquet\": str(kb_outline_parq) if kb_outline_parq.exists() else None,\n",
    "                \"kb_index_faiss\": str(kb_index_path),\n",
    "                \"kb_index_meta_json\": str(kb_index_meta),\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Persist KB + tables\n",
    "    total = len(chunk_texts)\n",
    "    print(f\"üßæ Total new/updated text chunks (incl. table rows): {total}\")\n",
    "    df = pd.DataFrame(rows_meta)\n",
    "    np.save(kb_texts_npy, np.array(chunk_texts, dtype=object))\n",
    "    df.to_parquet(kb_parquet, engine=\"pyarrow\", index=False)\n",
    "    pd.DataFrame(tables_long).to_parquet(kb_tables_parq, engine=\"pyarrow\", index=False) if tables_long else None\n",
    "    kb_meta_json.write_text(json.dumps(cache, indent=2), encoding=\"utf-8\")\n",
    "    if tables_long:\n",
    "        print(f\"üìë Saved structured tables ‚Üí {kb_tables_parq} (rows={len(tables_long)})\")\n",
    "    else:\n",
    "        print(\"üìë No structured tables detected this run.\")\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"‚ö†Ô∏è No new chunks produced. Skipping embedding/index rebuild.\")\n",
    "        return {\n",
    "            \"docs_processed\": len(docs),\n",
    "            \"chunks_total\": int(pd.read_parquet(kb_parquet).shape[0]),\n",
    "            \"tables_long_rows\": (pd.read_parquet(kb_tables_parq).shape[0] if kb_tables_parq.exists() else 0),\n",
    "            \"paths\": {\n",
    "                \"kb_chunks_parquet\": str(kb_parquet),\n",
    "                \"kb_texts_npy\": str(kb_texts_npy),\n",
    "                \"kb_meta_json\": str(kb_meta_json),\n",
    "                \"kb_tables_parquet\": str(kb_tables_parq) if kb_tables_parq.exists() else None,\n",
    "                \"kb_outline_parquet\": str(kb_outline_parq) if kb_outline_parq.exists() else None,\n",
    "                \"kb_index_faiss\": str(kb_index_path) if kb_index_path.exists() else None,\n",
    "                \"kb_index_meta_json\": str(kb_index_meta) if kb_index_meta.exists() else None,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Embeddings + FAISS\n",
    "    print(\"üß† Encoding embeddings ‚Ä¶\")\n",
    "    embs = _encode(chunk_texts, model_name)\n",
    "    print(f\"‚úÖ Embeddings shape: {embs.shape}\")\n",
    "\n",
    "    print(\"üì¶ Building FAISS index ‚Ä¶\")\n",
    "    idx = _build_faiss(embs)\n",
    "    faiss.write_index(idx, str(kb_index_path))\n",
    "    kb_index_meta.write_text(json.dumps({\n",
    "        \"model\": model_name,\n",
    "        \"dim\": int(embs.shape[1]),\n",
    "        \"total_vectors\": int(embs.shape[0]),\n",
    "        \"metric\": \"cosine (via inner product on normalized vectors)\"\n",
    "    }, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"üéâ Done. KB + index saved to: {out_path}\")\n",
    "    return {\n",
    "        \"docs_processed\": len(docs),\n",
    "        \"chunks_total\": int(total),\n",
    "        \"tables_long_rows\": len(tables_long),\n",
    "        \"paths\": {\n",
    "            \"kb_chunks_parquet\": str(kb_parquet),\n",
    "            \"kb_texts_npy\": str(kb_texts_npy),\n",
    "            \"kb_meta_json\": str(kb_meta_json),\n",
    "            \"kb_tables_parquet\": str(kb_tables_parq) if tables_long else None,\n",
    "            \"kb_outline_parquet\": str(kb_outline_parq),\n",
    "            \"kb_index_faiss\": str(kb_index_path),\n",
    "            \"kb_index_meta_json\": str(kb_index_meta),\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ‚ñ∂ Run now (edit paths if needed)\n",
    "summary = build_marker_kb_with_tables()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afd73e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BM25] ‚úì Indexed 13548 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reranker] ‚úì Loaded cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "\n",
      "üîé FAISS search ‚Üí Operating expenses 2024 2023 YoY\n",
      "[Search] RRF fusion: 81 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      " rank     score                    doc  modality  chunk                                                   path\n",
      "    1  4.874355 dbs-annual-report-2023 table_row   7471 All\\dbs-annual-report-2023\\dbs-annual-report-2023.json\n",
      "    2  4.719864 dbs-annual-report-2023 table_row   9513   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "    3  4.537770 dbs-annual-report-2022 table_row   4387 All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "    4  4.430953 dbs-annual-report-2022 table_row   4392 All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "    5  4.410225 dbs-annual-report-2022 table_row   6493   All\\dbs-annual-report-2022\\dbs-annual-report-2022.md\n",
      "    6  4.184577 dbs-annual-report-2022 table_row   6498   All\\dbs-annual-report-2022\\dbs-annual-report-2022.md\n",
      "    7  3.966918 dbs-annual-report-2023 table_row   9521   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "    8  2.539415 dbs-annual-report-2024      json  12493 All\\dbs-annual-report-2024\\dbs-annual-report-2024.json\n",
      "    9  2.503856 dbs-annual-report-2023      json   9354 All\\dbs-annual-report-2023\\dbs-annual-report-2023.json\n",
      "   10  2.270527 dbs-annual-report-2024        md  13435   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "   11 -3.392754  4Q24_CFO_presentation table_row   3130     All\\4Q24_CFO_presentation\\4Q24_CFO_presentation.md\n",
      "   12 -3.455936  2Q24_CFO_presentation table_row    355   All\\2Q24_CFO_presentation\\2Q24_CFO_presentation.json\n",
      "\n",
      "--- snippet ---\n",
      "[page 20] [dbs-annual-report-2023] table#4 row#1 :: Expenses | 2023: 2489 | 2022: 2254.0 | YoY%: 10.0\n",
      "\n",
      "--- snippet ---\n",
      "[dbs-annual-report-2023] table#158 row#1 :: Expenses | 2023: 2489 | 2022: 2254.0 | YoY%: 10.0\n",
      "\n",
      "üîé FAISS search ‚Üí Expenses 2024 2023 table\n",
      "[Search] RRF fusion: 96 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      " rank    score                    doc  modality  chunk                                                   path\n",
      "    1 6.986871 dbs-annual-report-2023 table_row   9521   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "    2 6.955431 dbs-annual-report-2022 table_row   4387 All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "    3 6.898798 dbs-annual-report-2022 table_row   4392 All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "    4 6.845392 dbs-annual-report-2024 table_row  12899   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "    5 6.720628 dbs-annual-report-2024 table_row  12898   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "    6 6.695569 dbs-annual-report-2024 table_row  10763 All\\dbs-annual-report-2024\\dbs-annual-report-2024.json\n",
      "    7 6.612315 dbs-annual-report-2023 table_row   9741   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "    8 6.522510 dbs-annual-report-2023 table_row   7722 All\\dbs-annual-report-2023\\dbs-annual-report-2023.json\n",
      "    9 6.387825 dbs-annual-report-2023 table_row   9742   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "   10 5.888152 dbs-annual-report-2024        md  13435   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "   11 5.741320 dbs-annual-report-2024      json  12493 All\\dbs-annual-report-2024\\dbs-annual-report-2024.json\n",
      "   12 5.734886 dbs-annual-report-2023      json   9354 All\\dbs-annual-report-2023\\dbs-annual-report-2023.json\n",
      "\n",
      "--- snippet ---\n",
      "[dbs-annual-report-2023] table#159 row#4 :: Expenses | 2023: 4412 | 2022: 3803 | YoY%: 16\n",
      "\n",
      "--- snippet ---\n",
      "[page 20] [dbs-annual-report-2022] table#6 row#1 :: Expenses | 2022: 2254.0 | 2021: 2086.0 | YoY%: 8.0\n",
      "\n",
      "üîé FAISS search ‚Üí Operating expenses and income YoY 2024 2023\n",
      "[Search] RRF fusion: 96 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      " rank    score                    doc  modality  chunk                                                   path\n",
      "    1 4.432345 dbs-annual-report-2024      json  12492 All\\dbs-annual-report-2024\\dbs-annual-report-2024.json\n",
      "    2 4.078015 dbs-annual-report-2024 table_row  10524 All\\dbs-annual-report-2024\\dbs-annual-report-2024.json\n",
      "    3 3.898375 dbs-annual-report-2023 table_row   7471 All\\dbs-annual-report-2023\\dbs-annual-report-2023.json\n",
      "    4 3.738981 dbs-annual-report-2022 table_row   4392 All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "    5 3.653261 dbs-annual-report-2024 table_row  10531 All\\dbs-annual-report-2024\\dbs-annual-report-2024.json\n",
      "    6 3.622392 dbs-annual-report-2024 table_row  12680   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "    7 3.592400 dbs-annual-report-2022 table_row   4387 All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "    8 3.473347 dbs-annual-report-2023 table_row   9513   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "    9 3.141440 dbs-annual-report-2022 table_row   6498   All\\dbs-annual-report-2022\\dbs-annual-report-2022.md\n",
      "   10 3.141046 dbs-annual-report-2024 table_row  12687   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "   11 2.986331 dbs-annual-report-2023 table_row   9521   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "   12 2.932372 dbs-annual-report-2022 table_row   6493   All\\dbs-annual-report-2022\\dbs-annual-report-2022.md\n",
      "\n",
      "--- snippet ---\n",
      "come from assets that are mandatorily classified at FVPL (b) Includes dividend income of $131 million (2023: $328 million). With effect from 2024, income from perpetual securities were presented in net interest income 7. Net Income from Investment Securities (a) Refers to dividend income. With effect from 2024, income from perpetual securities were presented in net interest income 8. Other Income (a) Includes net gains and losses from sale of loans carried at amortised cost and rental income from operating leases 9. Employee Benefits (a) Excludes share-based expenses of $5 million (2023: $3 million) relating to sales incentive plan and non-executive Directors' remuneration which are reflected under other expenses (b) 2023 includes the consolidation of Citi Taiwan with effect from 12 August\n",
      "\n",
      "--- snippet ---\n",
      "[page 21] [dbs-annual-report-2024] table#6 row#1 :: Expenses | 2024: 2820 | 2023: 2673 | YoY%: 5.0\n",
      "\n",
      "üîé FAISS search ‚Üí Total expenses 2024 2023 DBS annual report\n",
      "[Search] RRF fusion: 96 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      " rank    score                    doc  modality  chunk                                                   path\n",
      "    1 7.779906 dbs-annual-report-2024 table_row  12899   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "    2 7.766009 dbs-annual-report-2023 table_row   9742   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "    3 7.266238 dbs-annual-report-2022 table_row   6715   All\\dbs-annual-report-2022\\dbs-annual-report-2022.md\n",
      "    4 6.578189 dbs-annual-report-2024 table_row  12680   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "    5 6.435003 dbs-annual-report-2023 table_row   9521   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "    6 6.236100 dbs-annual-report-2024 table_row  12687   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "    7 6.053903 dbs-annual-report-2022 table_row   6714   All\\dbs-annual-report-2022\\dbs-annual-report-2022.md\n",
      "    8 5.889095 dbs-annual-report-2022 table_row   4611 All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "    9 5.841012 dbs-annual-report-2024 table_row  12898   All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "   10 5.804490 dbs-annual-report-2023 table_row   9741   All\\dbs-annual-report-2023\\dbs-annual-report-2023.md\n",
      "   11 5.735725 dbs-annual-report-2023 table_row   7722 All\\dbs-annual-report-2023\\dbs-annual-report-2023.json\n",
      "   12 5.581550 dbs-annual-report-2024 table_row  10763 All\\dbs-annual-report-2024\\dbs-annual-report-2024.json\n",
      "\n",
      "--- snippet ---\n",
      "[dbs-annual-report-2024] table#188 row#13 :: Total expenses | Note:  | 2024: 9018.0 | 2023: 8291.0\n",
      "\n",
      "--- snippet ---\n",
      "[dbs-annual-report-2023] table#197 row#11 :: Total expenses | Note:  | 2023: 8291.0 | 2022: 7090.0\n",
      "\n",
      "üîé FAISS search ‚Üí Net interest margin quarter Q1 Q2 Q3 Q4\n",
      "[Search] RRF fusion: 76 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      " rank    score                      doc  modality  chunk                                                       path\n",
      "    1 3.238589      1Q24_trading_update table_row     92           All\\1Q24_trading_update\\1Q24_trading_update.json\n",
      "    2 2.437603   dbs-annual-report-2022        md   7037       All\\dbs-annual-report-2022\\dbs-annual-report-2022.md\n",
      "    3 2.370420 4Q24_performance_summary table_row   4027   All\\4Q24_performance_summary\\4Q24_performance_summary.md\n",
      "    4 1.993526 4Q24_performance_summary table_row   3280 All\\4Q24_performance_summary\\4Q24_performance_summary.json\n",
      "    5 1.664978 2Q24_performance_summary table_row   1219   All\\2Q24_performance_summary\\2Q24_performance_summary.md\n",
      "    6 1.551081 2Q24_performance_summary table_row    621 All\\2Q24_performance_summary\\2Q24_performance_summary.json\n",
      "    7 1.484277 2Q25_performance_summary table_row   2486   All\\2Q25_performance_summary\\2Q25_performance_summary.md\n",
      "    8 1.360241 2Q25_performance_summary table_row   1873 All\\2Q25_performance_summary\\2Q25_performance_summary.json\n",
      "    9 1.078158      3Q24_trading_update      json   2939           All\\3Q24_trading_update\\3Q24_trading_update.json\n",
      "   10 1.068525   dbs-annual-report-2024        md  13181       All\\dbs-annual-report-2024\\dbs-annual-report-2024.md\n",
      "   11 0.722144 2Q24_performance_summary      json   1144 All\\2Q24_performance_summary\\2Q24_performance_summary.json\n",
      "   12 0.547006   dbs-annual-report-2022      json   6028     All\\dbs-annual-report-2022\\dbs-annual-report-2022.json\n",
      "\n",
      "--- snippet ---\n",
      "[page 4] [1Q24_trading_update] table#0 row#29 :: Net interest margin ‚Äì Group3 Net interest margin ‚Äì Commercial Book1 | 1st Qtr 2024: 2.14 | 1st Qtr 2023: 2.12 | % chg: nan | 4th Qtr 2023: 2.13 | % chg.1: nan\n",
      "\n",
      "--- snippet ---\n",
      "ows and higher deposit costs moderated the increase in the fourth quarter. The deposit beta ‚Äì or the increase in overall deposit costs relative to market interest rates ‚Äì rose progressively during the year to 32% by year-end. Still, net interest margin was 2.05% in the fourth quarter, signi»¥ cantly above the 1.75% for the full year. The reported net interest income and net interest margin were a ected by a drag from Treasury Markets due to higher funding costs for non-interest-bearing and marked-tomarket assets as well as net interest margin compression for »¥ xed-income instruments. (The drag is neutralised by gains in other non-interest income and so does not a ect its overall income and earnings.) Net interest income for the Commercial book, which excludes Treasury Markets, rose 40% whil\n",
      "\n",
      "üì¶ kb_tables rows: 52853 | cols: ['doc_name', 'source_path', 'table_id', 'row_id', 'column', 'value_str', 'value_num', 'page']\n",
      "\n",
      "=== NIM (quarters) ‚Äî top 2 candidates ===\n",
      "‚ö†Ô∏è No quarter NIM extracted. (Likely chart-only or prose-only.)\n",
      "\n",
      "=== Operating Expenses (years) ‚Äî top 2 candidates ===\n",
      "doc=dbs-annual-report-2024 table=6 row=1 | label=Expenses\n",
      "  last years: 2023: 2673.0, 2024: 2820.0\n",
      "doc=dbs-annual-report-2024 table=7 row=3 | label=Expenses\n",
      "  last years: 2023: 4627.0, 2024: 5273.0\n",
      "\n",
      "=== Operating/Total Income (years) ‚Äî top 2 candidates ===\n",
      "doc=dbs-annual-report-2024 table=143 row=1 | label=Total income\n",
      "  last years: 2022: 16502.0, 2023: 20180.0, 2024: 22297.0\n",
      "doc=dbs-annual-report-2024 table=143 row=23 | label=Cost-to-income ratio(4)\n",
      "  last years: 2022: 43.0, 2023: 39.9, 2024: 39.9\n",
      "\n",
      "=== Efficiency Ratio preview (Opex √∑ Income, %) ‚Äî aligned last 3 years ===\n",
      "Year | Opex | Income | Ratio%\n",
      "-----|------|--------|-------\n",
      "2023 | 2673.0 | 20180.0 | 13.25%\n",
      "2024 | 2820.0 | 22297.0 | 12.65%\n"
     ]
    }
   ],
   "source": [
    "# --- Sanity check FAISS retrieval vs. table storage ---\n",
    "from g2x import KBEnv\n",
    "import pandas as pd, numpy as np, re, math\n",
    "\n",
    "kb = KBEnv(base=\"./data_marker\")\n",
    "\n",
    "def show_search(q, k=12):\n",
    "    print(f\"\\nüîé FAISS search ‚Üí {q}\")\n",
    "    df = kb.search(q, k=k)\n",
    "    if df is None or df.empty:\n",
    "        print(\"  (no hits)\")\n",
    "        return df\n",
    "    cols = [\"rank\",\"score\",\"doc\",\"modality\",\"chunk\",\"path\"]\n",
    "    print(df[cols].to_string(index=False))\n",
    "    for _, row in df.head(2).iterrows():\n",
    "        print(\"\\n--- snippet ---\")\n",
    "        print(str(row[\"text\"])[:800])\n",
    "    return df\n",
    "\n",
    "# 1) Similarity probes\n",
    "queries = [\n",
    "    \"Operating expenses 2024 2023 YoY\",\n",
    "    \"Expenses 2024 2023 table\",\n",
    "    \"Operating expenses and income YoY 2024 2023\",\n",
    "    \"Total expenses 2024 2023 DBS annual report\",\n",
    "    \"Net interest margin quarter Q1 Q2 Q3 Q4\",\n",
    "]\n",
    "_ = [show_search(q, k=12) for q in queries]\n",
    "\n",
    "# 2) Direct read from kb_tables.parquet (bypass FAISS)\n",
    "tbl = kb.tables_df.copy()\n",
    "print(f\"\\nüì¶ kb_tables rows: {len(tbl)} | cols: {list(tbl.columns)}\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _norm(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = s.lower().replace(\"&\",\" and \")\n",
    "    s = re.sub(r\"[^a-z0-9 ]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def is_year(s) -> bool:\n",
    "    return bool(re.fullmatch(r\"\\d{4}\", str(s or \"\").strip()))\n",
    "\n",
    "_qpat = re.compile(r\"(?i)(?:\\b([1-4])\\s*q\\s*((?:20)?\\d{2})\\b|\\bq\\s*([1-4])\\s*(?:fy)?\\s*((?:20)?\\d{2})\\b|\\b([1-4])q((?:20)?\\d{2})\\b)\")\n",
    "def parse_quarter_token(s: str):\n",
    "    if s is None: return None\n",
    "    s = str(s)\n",
    "    m = _qpat.search(s)\n",
    "    if not m: return None\n",
    "    if m.group(1):   q, y = int(m.group(1)), int(m.group(2))\n",
    "    elif m.group(3): q, y = int(m.group(3)), int(m.group(4))\n",
    "    else:            q, y = int(m.group(5)), int(m.group(6))\n",
    "    if y < 100: y += 2000\n",
    "    return f\"{q}Q{y}\"\n",
    "\n",
    "def to_num(x):\n",
    "    if x is None: return np.nan\n",
    "    s = str(x).strip()\n",
    "    if not s or s in {\"‚Äî\",\"‚Äì\",\"-\"}: return np.nan\n",
    "    neg = s.startswith(\"(\") and s.endswith(\")\")\n",
    "    s = s.strip(\"()\").replace(\",\", \"\")\n",
    "    s = re.sub(r\"[^0-9eE\\.\\-%]\", \"\", s)\n",
    "    if s.endswith(\"%\"):\n",
    "        s = s[:-1]\n",
    "        try:\n",
    "            v = float(s)/100.0\n",
    "            return -v if neg else v\n",
    "        except:\n",
    "            return np.nan\n",
    "    try:\n",
    "        v = float(s)\n",
    "        return -v if neg else v\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# normalize + fix numbers when value_num is NaN\n",
    "tbl[\"val_norm\"] = tbl[\"value_str\"].astype(str).map(_norm)\n",
    "tbl[\"col_norm\"] = tbl[\"column\"].astype(str).map(_norm)\n",
    "tbl[\"column_str\"] = tbl[\"column\"].astype(str)\n",
    "tbl[\"value_num_fix\"] = tbl[\"value_num\"]\n",
    "mask_nan = tbl[\"value_num_fix\"].isna() & tbl[\"value_str\"].notna()\n",
    "tbl.loc[mask_nan, \"value_num_fix\"] = tbl.loc[mask_nan, \"value_str\"].map(to_num)\n",
    "\n",
    "# ---------- A) NIM by quarter ----------\n",
    "nim_terms = [\"net interest margin\", \"nim\", \"net interest margin group\", \"nim group\"]\n",
    "nim_mask = pd.Series(False, index=tbl.index)\n",
    "for t in nim_terms:\n",
    "    tnorm = _norm(t)\n",
    "    nim_mask |= tbl[\"val_norm\"].str.contains(rf\"\\b{re.escape(tnorm)}\\b\", regex=True) \\\n",
    "             |  tbl[\"col_norm\"].str.contains(rf\"\\b{re.escape(tnorm)}\\b\", regex=True)\n",
    "\n",
    "nim_rows = []\n",
    "if nim_mask.any():\n",
    "    for doc, tid in (\n",
    "        tbl[nim_mask][[\"doc_name\",\"table_id\"]]\n",
    "        .drop_duplicates()\n",
    "        .itertuples(index=False, name=None)\n",
    "    ):\n",
    "        sub = tbl[(tbl[\"doc_name\"]==doc) & (tbl[\"table_id\"]==tid)]\n",
    "        for rid in sorted(sub[\"row_id\"].unique()):\n",
    "            r = sub[sub[\"row_id\"]==rid]\n",
    "            if not (r[\"val_norm\"].str.contains(r\"\\bnim\\b|\\bnet interest margin\\b\", regex=True).any() or\n",
    "                    r[\"col_norm\"].str.contains(r\"\\bnim\\b|\\bnet interest margin\\b\", regex=True).any()):\n",
    "                continue\n",
    "            series_q = {}\n",
    "            for _, cell in r.iterrows():\n",
    "                qlab = parse_quarter_token(cell[\"column_str\"]) or parse_quarter_token(cell[\"value_str\"])\n",
    "                if not qlab: \n",
    "                    continue\n",
    "                v = cell[\"value_num_fix\"]\n",
    "                if pd.isna(v): \n",
    "                    continue\n",
    "                val = float(v)\n",
    "                if val < 0.5:  # fractions ‚Üí %\n",
    "                    val = round(val*100.0, 2)\n",
    "                series_q[qlab] = val\n",
    "            if series_q:\n",
    "                label_guess = r[\"value_str\"].dropna().astype(str).head(1)\n",
    "                nim_rows.append({\n",
    "                    \"doc\":doc, \"table_id\":tid, \"row_id\":rid,\n",
    "                    \"label\": (label_guess.iloc[0] if not label_guess.empty else \"Net interest margin\"),\n",
    "                    \"series_q\": series_q\n",
    "                })\n",
    "\n",
    "def _qkey(k):\n",
    "    m = re.match(r\"([1-4])Q(20\\d{2})$\", k)\n",
    "    return (int(m.group(2)), int(m.group(1))) if m else (0,0)\n",
    "\n",
    "nim_rows.sort(key=lambda r: (-(len(r[\"series_q\"])),\n",
    "                             -_qkey(sorted(r[\"series_q\"].keys())[-1])[0],\n",
    "                             -_qkey(sorted(r[\"series_q\"].keys())[-1])[1]))\n",
    "\n",
    "print(\"\\n=== NIM (quarters) ‚Äî top 2 candidates ===\")\n",
    "if nim_rows:\n",
    "    for r in nim_rows[:2]:\n",
    "        last5 = sorted(r[\"series_q\"].keys(), key=_qkey)[-5:]\n",
    "        print(f\"doc={r['doc']} table={r['table_id']} row={r['row_id']} | label={r['label']}\")\n",
    "        print(\"  last5:\", \", \".join(f\"{k}: {r['series_q'][k]}\" for k in last5))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No quarter NIM extracted. (Likely chart-only or prose-only.)\")\n",
    "# ---------- B) Operating Expenses by year ----------\n",
    "exp_terms = [\"operating expenses\", \"total expenses\", \"expenses\", \"opex\"]\n",
    "exp_mask = pd.Series(False, index=tbl.index)\n",
    "for t in exp_terms:\n",
    "    tnorm = _norm(t)\n",
    "    exp_mask |= tbl[\"val_norm\"].str.contains(rf\"\\b{re.escape(tnorm)}\\b\", regex=True) \\\n",
    "             |  tbl[\"col_norm\"].str.contains(rf\"\\b{re.escape(tnorm)}\\b\", regex=True)\n",
    "\n",
    "exp_rows = []\n",
    "if exp_mask.any():\n",
    "    for (doc, tid, rid), sub in tbl.groupby([\"doc_name\",\"table_id\",\"row_id\"]):\n",
    "        if not exp_mask.loc[sub.index].any():\n",
    "            continue\n",
    "        series = {}\n",
    "        for _, cell in sub.iterrows():\n",
    "            col = str(cell[\"column\"])\n",
    "            if is_year(col) and pd.notna(cell[\"value_num_fix\"]):\n",
    "                series[int(col)] = float(cell[\"value_num_fix\"])\n",
    "        if len(series) >= 2:\n",
    "            label_guess = sub[~sub[\"column\"].astype(str).map(is_year)][\"value_str\"].dropna().astype(str).head(1)\n",
    "            label = label_guess.iloc[0] if not label_guess.empty else \"Expenses\"\n",
    "            exp_rows.append({\"doc\":doc,\"table_id\":tid,\"row_id\":rid,\"label\":label,\"series\":dict(sorted(series.items()))})\n",
    "\n",
    "exp_rows.sort(key=lambda r: (-(len(r[\"series\"])), -max(r[\"series\"].keys()) if r[\"series\"] else 0))\n",
    "\n",
    "print(\"\\n=== Operating Expenses (years) ‚Äî top 2 candidates ===\")\n",
    "if exp_rows:\n",
    "    for r in exp_rows[:2]:\n",
    "        ys = sorted(r[\"series\"].keys())[-3:]\n",
    "        print(f\"doc={r['doc']} table={r['table_id']} row={r['row_id']} | label={r['label']}\")\n",
    "        print(\"  last years:\", \", \".join(f\"{y}: {r['series'][y]}\" for y in ys))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No expense rows with year columns extracted.\")\n",
    "\n",
    "# ---------- C) Operating/Total Income by year ----------\n",
    "inc_terms = [\"operating income\", \"total operating income\", \"total income\", \"income\"]\n",
    "inc_mask = pd.Series(False, index=tbl.index)\n",
    "for t in inc_terms:\n",
    "    tnorm = _norm(t)\n",
    "    inc_mask |= tbl[\"val_norm\"].str.contains(rf\"\\b{re.escape(tnorm)}\\b\", regex=True) \\\n",
    "             |  tbl[\"col_norm\"].str.contains(rf\"\\b{re.escape(tnorm)}\\b\", regex=True)\n",
    "\n",
    "inc_rows = []\n",
    "if inc_mask.any():\n",
    "    for (doc, tid, rid), sub in tbl.groupby([\"doc_name\",\"table_id\",\"row_id\"]):\n",
    "        if not inc_mask.loc[sub.index].any():\n",
    "            continue\n",
    "        series = {}\n",
    "        for _, cell in sub.iterrows():\n",
    "            col = str(cell[\"column\"])\n",
    "            if is_year(col) and pd.notna(cell[\"value_num_fix\"]):\n",
    "                series[int(col)] = float(cell[\"value_num_fix\"])\n",
    "        if len(series) >= 2:\n",
    "            label_guess = sub[~sub[\"column\"].astype(str).map(is_year)][\"value_str\"].dropna().astype(str).head(1)\n",
    "            label = label_guess.iloc[0] if not label_guess.empty else \"Income\"\n",
    "            inc_rows.append({\"doc\":doc,\"table_id\":tid,\"row_id\":rid,\"label\":label,\"series\":dict(sorted(series.items()))})\n",
    "\n",
    "inc_rows.sort(key=lambda r: (-(len(r[\"series\"])), -max(r[\"series\"].keys()) if r[\"series\"] else 0))\n",
    "\n",
    "print(\"\\n=== Operating/Total Income (years) ‚Äî top 2 candidates ===\")\n",
    "if inc_rows:\n",
    "    for r in inc_rows[:2]:\n",
    "        ys = sorted(r[\"series\"].keys())[-3:]\n",
    "        print(f\"doc={r['doc']} table={r['table_id']} row={r['row_id']} | label={r['label']}\")\n",
    "        print(\"  last years:\", \", \".join(f\"{y}: {r['series'][y]}\" for y in ys))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No income rows with year columns extracted.\")\n",
    "\n",
    "# ---------- D) Efficiency Ratio preview (if both present) ----------\n",
    "if exp_rows and inc_rows:\n",
    "    ex, inc = exp_rows[0], inc_rows[0]\n",
    "    years = sorted(set(ex[\"series\"]).intersection(inc[\"series\"]))[-3:]\n",
    "    print(\"\\n=== Efficiency Ratio preview (Opex √∑ Income, %) ‚Äî aligned last 3 years ===\")\n",
    "    if years:\n",
    "        print(\"Year | Opex | Income | Ratio%\")\n",
    "        print(\"-----|------|--------|-------\")\n",
    "        for y in years:\n",
    "            ov, iv = ex[\"series\"][y], inc[\"series\"][y]\n",
    "            ratio = (ov/iv*100.0) if iv else math.nan\n",
    "            rs = \"‚Äî\" if not iv else f\"{ratio:.2f}%\"\n",
    "            print(f\"{y} | {ov} | {iv} | {rs}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No overlapping fiscal years between the chosen Opex and Income rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb05fc",
   "metadata": {
    "id": "6ffb05fc"
   },
   "source": [
    "## 4. Baseline Pipeline\n",
    "\n",
    "**Baseline (starting point)**\n",
    "*   Naive chunking.\n",
    "*   Single-pass vector search.\n",
    "*   One LLM call, no caching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b6a34",
   "metadata": {},
   "source": [
    "## Async I/O \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bb9229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohttp in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (2.6.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (1.8.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (1.22.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (25.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp) (0.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\pc\\appdata\\roaming\\python\\python310\\site-packages (from aiosignal>=1.4.0->aiohttp) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install aiohttp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "try:\n",
    "    import nest_asyncio\n",
    "except ImportError:\n",
    "    nest_asyncio = None\n",
    "\n",
    "def ensure_loop():\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running() and nest_asyncio:\n",
    "            nest_asyncio.apply()\n",
    "        return loop\n",
    "    except RuntimeError:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        return loop\n",
    "\n",
    "# 2) Async retrieval shim (FAISS/BM25 via thread pool)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "_search_pool = ThreadPoolExecutor(max_workers=8)\n",
    "\n",
    "class AsyncRetrieval:\n",
    "    @staticmethod\n",
    "    async def execute_parallel_async(kb, sub_queries, k_ctx: int, max_concurrency: int = 8):\n",
    "        print(f\"Running async parallel retrieval for {len(sub_queries)} sub-queries with concurrency={max_concurrency}\")\n",
    "        if not sub_queries:\n",
    "            return []\n",
    "        loop = asyncio.get_event_loop()\n",
    "        sem = asyncio.Semaphore(max_concurrency)\n",
    "\n",
    "        async def one(q: str):\n",
    "            async with sem:\n",
    "                return await loop.run_in_executor(_search_pool, kb.search, q, k_ctx)\n",
    "\n",
    "        results = await asyncio.gather(*(one(q) for q in sub_queries), return_exceptions=True)\n",
    "        import pandas as pd\n",
    "        safe = []\n",
    "        for r in results:\n",
    "            safe.append(pd.DataFrame() if isinstance(r, Exception) else r)\n",
    "        return safe\n",
    "\n",
    "    @staticmethod\n",
    "    def execute_parallel(kb, sub_queries, k_ctx: int, max_concurrency: int = 8):\n",
    "        loop = ensure_loop()\n",
    "        return loop.run_until_complete(\n",
    "            AsyncRetrieval.execute_parallel_async(kb, sub_queries, k_ctx, max_concurrency)\n",
    "        )\n",
    "\n",
    "# 3) Wire into your decomposer if present; else, provide a tiny adapter\n",
    "def execute_parallel_subqueries(kb, sub_queries, k_ctx, max_concurrency=8):\n",
    "    return AsyncRetrieval.execute_parallel(kb, sub_queries, k_ctx, max_concurrency)\n",
    "\n",
    "# 4) Async HTTP clients (LLM + Embeddings) with sync adapters\n",
    "import aiohttp\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class AsyncLLMClient:\n",
    "    def __init__(self, base_url: str, api_key: str, max_concurrent: int = 8, timeout_s: int = 60):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.api_key = api_key\n",
    "        self.sem = asyncio.Semaphore(max_concurrent)\n",
    "        self.timeout_s = timeout_s\n",
    "\n",
    "    async def chat(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        print(\"Async LLM chat API call started\")\n",
    "        headers = {\"Authorization\": f\"Bearer {self.api_key}\"} if self.api_key else {}\n",
    "        async with self.sem:\n",
    "            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout_s)) as sess:\n",
    "                async with sess.post(f\"{self.base_url}/chat/completions\", json=payload, headers=headers) as r:\n",
    "                    r.raise_for_status()\n",
    "                    print(\"Async LLM chat API call completed\")\n",
    "                    return await r.json()\n",
    "\n",
    "class AsyncEmbeddingsClient:\n",
    "    def __init__(self, base_url: str, api_key: str, batch_size: int = 64, max_concurrent: int = 4, timeout_s: int = 60):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.api_key = api_key\n",
    "        self.batch_size = batch_size\n",
    "        self.sem = asyncio.Semaphore(max_concurrent)\n",
    "        self.timeout_s = timeout_s\n",
    "\n",
    "    async def embed(self, texts: List[str]) -> List[List[float]]:\n",
    "        headers = {\"Authorization\": f\"Bearer {self.api_key}\"} if self.api_key else {}\n",
    "        out: List[List[float]] = []\n",
    "        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout_s)) as sess:\n",
    "            tasks = []\n",
    "            for i in range(0, len(texts), self.batch_size):\n",
    "                chunk = texts[i:i+self.batch_size]\n",
    "                async def one(ch=chunk):\n",
    "                    async with self.sem:\n",
    "                        async with sess.post(f\"{self.base_url}/embeddings\", json={\"input\": ch}, headers=headers) as r:\n",
    "                            r.raise_for_status()\n",
    "                            data = await r.json()\n",
    "                            return [v[\"embedding\"] for v in data[\"data\"]]\n",
    "                tasks.append(one())\n",
    "            for res in await asyncio.gather(*tasks, return_exceptions=True):\n",
    "                if isinstance(res, Exception):\n",
    "                    continue\n",
    "                out.extend(res)\n",
    "        return out\n",
    "\n",
    "# 5) Provide sync adapters so the rest of the notebook doesn‚Äôt break\n",
    "import os\n",
    "LLM_ASYNC = AsyncLLMClient(base_url=os.environ.get(\"OPENAI_BASE_URL\",\"https://api.openai.com/v1\"),\n",
    "                           api_key=os.environ.get(\"OPENAI_API_KEY\",\"\"),\n",
    "                           max_concurrent=8)\n",
    "\n",
    "EMB_ASYNC = AsyncEmbeddingsClient(base_url=os.environ.get(\"OPENAI_BASE_URL\",\"https://api.openai.com/v1\"),\n",
    "                                  api_key=os.environ.get(\"OPENAI_API_KEY\",\"\"),\n",
    "                                  batch_size=64, max_concurrent=4)\n",
    "\n",
    "def llm_chat_sync(payload: dict) -> dict:\n",
    "    loop = ensure_loop()\n",
    "    return loop.run_until_complete(LLM_ASYNC.chat(payload))\n",
    "\n",
    "def embed_sync(texts: List[str]) -> List[List[float]]:\n",
    "    loop = ensure_loop()\n",
    "    return loop.run_until_complete(EMB_ASYNC.embed(texts))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8dff02",
   "metadata": {},
   "source": [
    "### Gemini Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1898b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BM25] ‚úì Indexed 13548 documents\n",
      "[Reranker] ‚úì Loaded cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "[Agent] Tools: Calculator: ‚úì | Table: ‚úì | Text: ‚úì | MultiDoc: ‚úì\n",
      "[Search] RRF fusion: 53 candidates\n",
      "[Rerank] Reranking top-16 candidates...\n",
      "[Rerank] ‚úì Reranked to top-8\n",
      "[LLM] single-call baseline using groq:openai/gpt-oss-20b\n",
      "[LLM] provider=groq model=openai/gpt-oss-20b\n",
      "\n",
      "BASELINE (Single LLM Call)\n",
      "--------------------------------\n",
      "**Net Interest Margin ‚Äì available data**\n",
      "\n",
      "| Quarter | Net Interest Margin |\n",
      "|---------|---------------------|\n",
      "| 4Q‚ÄØ2024 | 2.13‚ÄØ% |\n",
      "| 1H‚ÄØ2024 | 2.14‚ÄØ% (half‚Äëyear figure, not a single quarter) |\n",
      "| 2H‚ÄØ2024 | 2.13‚ÄØ% (half‚Äëyear figure) |\n",
      "| 1H‚ÄØ2023 | 2.15‚ÄØ% (half‚Äëyear figure) |\n",
      "| 2H‚ÄØ2023 | 2.16‚ÄØ% (half‚Äëyear figure) |\n",
      "\n",
      "**Missing information**\n",
      "\n",
      "* Net interest margin for Q3‚ÄØ2024, Q2‚ÄØ2024, Q1‚ÄØ2024, and Q4‚ÄØ2023 is not provided in the supplied context.  \n",
      "* Therefore, a complete 5‚Äëquarter series cannot be constructed from the available data.\n",
      "\n",
      "**Citations**\n",
      "\n",
      "- 4Q‚ÄØ2024 net interest margin: 2.13‚ÄØ% ‚Äì *[4Q24_performance_summary] table#41 row#6*  \n",
      "- 1H‚ÄØ2024 net interest margin: 2.14‚ÄØ% ‚Äì *[4Q24_performance_summary] table#41 row#6*  \n",
      "- 2H‚ÄØ2024 net interest margin: 2.13‚ÄØ% ‚Äì *[4Q24_performance_summary] table#41 row#6*  \n",
      "- 1H‚ÄØ2023 net interest margin: 2.15‚ÄØ% ‚Äì *[4Q24_performance_summary] table#41 row#6*  \n",
      "- 2H‚ÄØ2023 net interest margin: 2.16‚ÄØ% ‚Äì *[4Q24_performance_summary] table#41 row#6*\n",
      "\n",
      "Citations:\n",
      "- dbs-annual-report-2022, page nan\n",
      "- 2Q24_performance_summary, page 9.0\n",
      "- 2Q25_performance_summary, page nan\n",
      "- 4Q24_performance_summary, page nan\n",
      "- dbs-annual-report-2024, page nan\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "g2x.py ‚Äî Agentic RAG with tools on top of data_marker/ (FAISS + Marker outputs)\n",
    "       - BM25, Reciprocal Rank Fusion, and Cross-Encoder Reranking\n",
    "\n",
    "Artifacts required in ./data_marker:\n",
    "  - kb_index.faiss\n",
    "  - kb_index_meta.json\n",
    "  - kb_texts.npy\n",
    "  - kb_chunks.parquet\n",
    "  - kb_tables.parquet        (recommended for table tools)\n",
    "  - kb_outline.parquet       (optional, for section hints)\n",
    "\n",
    "Tools exposed:\n",
    "  1) CalculatorTool           -> safe arithmetic, deltas, YoY\n",
    "  2) TableExtractionTool      -> pull metric rows; extract {year -> value}\n",
    "  3) MultiDocCompareTool      -> compare a metric across multiple docs\n",
    "Also:\n",
    "  - Vector search (FAISS) for grounding\n",
    "\n",
    "Agent runtime: Plan -> Act -> Observe -> (optional) Refine -> Final\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import re, json, math, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import faiss\n",
    "import os\n",
    "\n",
    "# ----------------------------- LLM (single-call baseline) -----------------------------\n",
    "\n",
    "def _make_llm_client():\n",
    "    \"\"\"Minimal provider selection for LLM\"\"\"\n",
    "    groq_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "    if groq_key:\n",
    "        client = OpenAI(api_key=groq_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "        model = os.getenv(\"GROQ_MODEL\", \"openai/gpt-oss-20b\")\n",
    "        return (\"groq\", client, model)\n",
    "    \n",
    "    gem_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "    if gem_key:\n",
    "        return (\"gemini\", None, os.getenv(\"GEMINI_MODEL_NAME\", \"models/gemini-2.5-flash\"))\n",
    "    \n",
    "    raise RuntimeError(\"No LLM credentials found. Set GROQ_API_KEY or GEMINI_API_KEY.\")\n",
    "\n",
    "def _llm_provider_info() -> str:\n",
    "    try:\n",
    "        prov, _, model = _make_llm_client()\n",
    "        return f\"{prov}:{model}\"\n",
    "    except Exception as e:\n",
    "        return f\"unconfigured ({e})\"\n",
    "\n",
    "def _llm_single_call(prompt: str, system: str = \"You are a precise finance analyst.\") -> str:\n",
    "    prov, client, model = _make_llm_client()\n",
    "    print(f\"[LLM] provider={prov} model={model}\")\n",
    "    if prov == \"groq\":\n",
    "        try:\n",
    "            chat = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "            )\n",
    "            return chat.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            return f\"LLM error: {e}\"\n",
    "    \n",
    "    try:\n",
    "        from google import generativeai as genai\n",
    "        genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "        model_obj = genai.GenerativeModel(model)\n",
    "        out = model_obj.generate_content(prompt)\n",
    "        return getattr(out, \"text\", \"\") or \"LLM returned empty response.\"\n",
    "    except Exception as e:\n",
    "        return f\"LLM error (Gemini): {e}\"\n",
    "\n",
    "\n",
    "def _page_or_none(x):\n",
    "    try:\n",
    "        import math\n",
    "        import pandas as pd\n",
    "        if x is None:\n",
    "            return None\n",
    "        if (hasattr(pd, 'isna') and pd.isna(x)) or (isinstance(x, float) and math.isnan(x)):\n",
    "            return None\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# ----------------------------- KB loader with BM25 + Reranker -----------------------------\n",
    "\n",
    "class KBEnv:\n",
    "    def __init__(self, base=\"./data_marker\", enable_bm25=True, enable_reranker=True):\n",
    "        self.base = Path(base)\n",
    "        self.faiss_path = self.base / \"kb_index.faiss\"\n",
    "        self.meta_path = self.base / \"kb_index_meta.json\"\n",
    "        self.texts_path = self.base / \"kb_texts.npy\"\n",
    "        self.chunks_path = self.base / \"kb_chunks.parquet\"\n",
    "        self.tables_path = self.base / \"kb_tables.parquet\"\n",
    "        self.outline_path = self.base / \"kb_outline.parquet\"\n",
    "\n",
    "        if not self.faiss_path.exists():\n",
    "            raise FileNotFoundError(self.faiss_path)\n",
    "        if not self.meta_path.exists():\n",
    "            raise FileNotFoundError(self.meta_path)\n",
    "        if not self.texts_path.exists():\n",
    "            raise FileNotFoundError(self.texts_path)\n",
    "        if not self.chunks_path.exists():\n",
    "            raise FileNotFoundError(self.chunks_path)\n",
    "\n",
    "        self.texts: List[str] = np.load(self.texts_path, allow_pickle=True).tolist()\n",
    "        self.meta_df: pd.DataFrame = pd.read_parquet(self.chunks_path)\n",
    "        \n",
    "        if 'page' in self.meta_df.columns:\n",
    "            self.meta_df['page'] = pd.to_numeric(self.meta_df['page'], errors='coerce').astype('Int64')\n",
    "            \n",
    "        if len(self.texts) != len(self.meta_df):\n",
    "            raise ValueError(f\"texts ({len(self.texts)}) and meta ({len(self.meta_df)}) mismatch\")\n",
    "\n",
    "        self.tables_df: Optional[pd.DataFrame] = (\n",
    "            pd.read_parquet(self.tables_path) if self.tables_path.exists() else None\n",
    "        )\n",
    "        self.outline_df: Optional[pd.DataFrame] = (\n",
    "            pd.read_parquet(self.outline_path) if self.outline_path.exists() else None\n",
    "        )\n",
    "\n",
    "        # FAISS index\n",
    "        self.index = faiss.read_index(str(self.faiss_path))\n",
    "        idx_meta = json.loads(self.meta_path.read_text(encoding=\"utf-8\"))\n",
    "        self.model_name = idx_meta.get(\"model\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.embed_dim = int(idx_meta.get(\"dim\", 384))\n",
    "        self.model = SentenceTransformer(self.model_name)\n",
    "\n",
    "        # ========== NEW: BM25 Index ==========\n",
    "        self.bm25 = None\n",
    "        if enable_bm25:\n",
    "            # print(\"[BM25] Building BM25 index...\")\n",
    "            tokenized_corpus = [text.lower().split() for text in self.texts]\n",
    "            self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "            print(f\"[BM25] ‚úì Indexed {len(self.texts)} documents\")\n",
    "        elif enable_bm25:\n",
    "            print(\"[BM25] ‚úó rank_bm25 not installed, skipping BM25\")\n",
    "\n",
    "        # ========== NEW: Reranker ==========\n",
    "        self.reranker = None\n",
    "        if enable_reranker:\n",
    "            # print(\"[Reranker] Loading cross-encoder...\")\n",
    "            self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "            print(\"[Reranker] ‚úì Loaded cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "        elif enable_reranker:\n",
    "            print(\"[Reranker] ‚úó CrossEncoder unavailable\")\n",
    "\n",
    "    def _embed(self, texts: List[str]) -> np.ndarray:\n",
    "        v = self.model.encode(texts, normalize_embeddings=True)\n",
    "        return np.asarray(v, dtype=\"float32\")\n",
    "\n",
    "    # ========== NEW: Hybrid Search with BM25 + Vector + RRF ==========\n",
    "    def search(\n",
    "        self, \n",
    "        query: str, \n",
    "        k: int = 12,\n",
    "        alpha: float = 0.6,  # Weight for vector vs BM25 (0.0=pure BM25, 1.0=pure vector)\n",
    "        rerank_top_k: int = None  # Rerank top candidates (default: 2*k)\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Hybrid search with BM25 + Vector + optional RRF + optional Reranking\n",
    "        \n",
    "        Pipeline:\n",
    "        1. BM25 search ‚Üí get scores\n",
    "        2. Vector search ‚Üí get scores\n",
    "        3. Fusion: RRF (reciprocal rank) or weighted score fusion\n",
    "        4. Rerank: Cross-encoder on top candidates\n",
    "        5. Return top-k\n",
    "        \"\"\"\n",
    "        if rerank_top_k is None:\n",
    "            rerank_top_k = k * 2  # Get 2x candidates for reranking\n",
    "\n",
    "        # ========== Step 1: Vector Search ==========\n",
    "        qv = self._embed([query])\n",
    "        vec_scores, vec_idxs = self.index.search(qv, min(rerank_top_k * 2, len(self.texts)))\n",
    "        vec_idxs, vec_scores = vec_idxs[0], vec_scores[0]\n",
    "        \n",
    "        # Filter valid indices\n",
    "        vec_results = {int(i): float(s) for i, s in zip(vec_idxs, vec_scores) if i >= 0 and i < len(self.texts)}\n",
    "\n",
    "        # ========== Step 2: BM25 Search ==========\n",
    "        bm25_results = {}\n",
    "        if self.bm25 is not None:\n",
    "            query_tokens = query.lower().split()\n",
    "            bm25_scores = self.bm25.get_scores(query_tokens)\n",
    "            \n",
    "            # Normalize BM25 scores to [0, 1]\n",
    "            max_bm25 = max(bm25_scores) if len(bm25_scores) > 0 else 1.0\n",
    "            if max_bm25 > 0:\n",
    "                bm25_scores = bm25_scores / max_bm25\n",
    "            \n",
    "            # Get top candidates\n",
    "            top_bm25_idx = np.argsort(bm25_scores)[-rerank_top_k * 2:][::-1]\n",
    "            bm25_results = {int(i): float(bm25_scores[i]) for i in top_bm25_idx if bm25_scores[i] > 0}\n",
    "\n",
    "        # ========== Step 3: Fusion (RRF or Weighted Score) ==========\n",
    "        all_indices = set(vec_results.keys()) | set(bm25_results.keys())\n",
    "        \n",
    "        if self.bm25 is not None:\n",
    "            # Reciprocal Rank Fusion\n",
    "            vec_ranks = {idx: rank for rank, idx in enumerate(sorted(vec_results, key=vec_results.get, reverse=True), 1)}\n",
    "            bm25_ranks = {idx: rank for rank, idx in enumerate(sorted(bm25_results, key=bm25_results.get, reverse=True), 1)}\n",
    "            \n",
    "            k_rrf = 60  # RRF constant\n",
    "            fused_scores = {}\n",
    "            for idx in all_indices:\n",
    "                vec_rank = vec_ranks.get(idx, len(self.texts))\n",
    "                bm25_rank = bm25_ranks.get(idx, len(self.texts))\n",
    "                fused_scores[idx] = (1 / (k_rrf + vec_rank)) + (1 / (k_rrf + bm25_rank))\n",
    "            \n",
    "            print(f\"[Search] RRF fusion: {len(all_indices)} candidates\")\n",
    "        else:\n",
    "            # Weighted score fusion (fallback if BM25 disabled or RRF=False)\n",
    "            fused_scores = {}\n",
    "            for idx in all_indices:\n",
    "                vec_score = vec_results.get(idx, 0.0)\n",
    "                bm25_score = bm25_results.get(idx, 0.0)\n",
    "                fused_scores[idx] = alpha * vec_score + (1 - alpha) * bm25_score\n",
    "            \n",
    "            print(f\"[Search] Weighted fusion (Œ±={alpha}): {len(all_indices)} candidates\")\n",
    "\n",
    "        # Sort by fused score\n",
    "        sorted_indices = sorted(fused_scores.keys(), key=fused_scores.get, reverse=True)[:rerank_top_k]\n",
    "\n",
    "        # ========== Step 4: Reranking (Optional) ==========\n",
    "        if self.reranker is not None and len(sorted_indices) > k:\n",
    "            print(f\"[Rerank] Reranking top-{len(sorted_indices)} candidates...\")\n",
    "            \n",
    "            # Prepare query-document pairs\n",
    "            pairs = [[query, self.texts[idx]] for idx in sorted_indices]\n",
    "            \n",
    "            # Get rerank scores\n",
    "            rerank_scores = self.reranker.predict(pairs)\n",
    "            \n",
    "            # Update fused scores with rerank scores\n",
    "            for idx, score in zip(sorted_indices, rerank_scores):\n",
    "                fused_scores[idx] = float(score)\n",
    "            \n",
    "            # Re-sort by rerank scores\n",
    "            sorted_indices = sorted(sorted_indices, key=fused_scores.get, reverse=True)\n",
    "            \n",
    "            print(f\"[Rerank] ‚úì Reranked to top-{k}\")\n",
    "\n",
    "        # ========== Step 5: Build Results DataFrame ==========\n",
    "        final_indices = sorted_indices[:k]\n",
    "        rows = []\n",
    "        for rank, idx in enumerate(final_indices, start=1):\n",
    "            md = self.meta_df.iloc[idx]\n",
    "            item = {\n",
    "                \"rank\": rank,\n",
    "                \"score\": fused_scores[idx],\n",
    "                \"text\": self.texts[idx],\n",
    "                \"doc\": md.get(\"doc\"),\n",
    "                \"path\": md.get(\"path\"),\n",
    "                \"modality\": md.get(\"modality\"),\n",
    "                \"chunk\": int(md.get(\"chunk\", 0)),\n",
    "                \"page\": _page_or_none(md.get(\"page\")),\n",
    "            }\n",
    "            \n",
    "            # Section hint\n",
    "            if self.outline_df is not None:\n",
    "                toc = self.outline_df[self.outline_df[\"doc_name\"] == item[\"doc\"]]\n",
    "                if not toc.empty:\n",
    "                    item[\"section_hint\"] = toc.iloc[0][\"title\"]\n",
    "            \n",
    "            rows.append(item)\n",
    "        \n",
    "        return pd.DataFrame(rows)\n",
    "    \n",
    "def baseline_answer_one_call(\n",
    "    kb: KBEnv,\n",
    "    query: str,\n",
    "    k_ctx: int = 8,\n",
    "    table_rows: Optional[List[Dict[str, Any]]] = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Baseline (Stage 4) requirements:\n",
    "      - Naive chunking (we use existing kb_texts)\n",
    "      - Single-pass vector search (FAISS only)\n",
    "      - One LLM call, no caching\n",
    "    \"\"\"\n",
    "    # 1) Retrieve top-k chunks\n",
    "    ctx_df = kb.search(query, k=k_ctx)\n",
    "    if ctx_df is None or ctx_df.empty:\n",
    "        answer = \"I couldn't find any relevant context in the KB for this query.\"\n",
    "        print(answer)\n",
    "        return {\"answer\": answer, \"contexts\": []}\n",
    "\n",
    "    # 2) Build context and simple citations\n",
    "    ctx_lines = []\n",
    "    for _, row in ctx_df.iterrows():\n",
    "        text = str(row[\"text\"]).replace(\"\\\\n\", \" \").strip()\n",
    "        if len(text) > 800:\n",
    "            text = text[:800] + \"...\"\n",
    "        ctx_lines.append(f\"- {text}\")\n",
    "\n",
    "    # We will build citations later; prefer table-row provenance if provided\n",
    "    cits = []\n",
    "\n",
    "    # Build citations: prefer structured table rows with pages\n",
    "    if table_rows:\n",
    "        for r in table_rows[:5]:\n",
    "            doc = str(r.get(\"doc\") or \"\")\n",
    "            page = r.get(\"page\")\n",
    "            if page is not None:\n",
    "                cits.append(f\"{doc}, page {int(page)}\")\n",
    "            else:\n",
    "                cits.append(f\"{doc}, table {r.get('table_id')} row {r.get('row_id')} (no page)\")\n",
    "    else:\n",
    "        for _, row in ctx_df.iterrows():\n",
    "            doc = str(row.get(\"doc\") or \"\")\n",
    "            mod = str(row.get(\"modality\") or \"\")\n",
    "            page = row.get(\"page\")\n",
    "            if page is not None:\n",
    "                cits.append(f\"{doc}, page {page}\")\n",
    "            else:\n",
    "                ch = int(row.get(\"chunk\") or 0)\n",
    "                if mod in (\"md\", \"table_row\"):\n",
    "                    cits.append(f\"{doc}, chunk {ch} (no page; {mod})\")\n",
    "                else:\n",
    "                    cits.append(f\"{doc}, chunk {ch} (no page)\")\n",
    "\n",
    "    # Optional: include structured table rows so the LLM doesn't deny available data\n",
    "    table_lines = []\n",
    "    if table_rows:\n",
    "        table_lines.append(\"STRUCTURED TABLE ROWS (authoritative):\")\n",
    "        for r in table_rows[:6]:\n",
    "            ser_q = r.get(\"series_q\") or {}\n",
    "            ser_y = r.get(\"series\") or {}\n",
    "            if ser_q:\n",
    "                def _qkey(k: str):\n",
    "                    m = re.match(r\"([1-4])Q(20\\\\d{2})$\", k)\n",
    "                    return (int(m.group(2)), int(m.group(1))) if m else (0, 0)\n",
    "                qkeys = sorted(ser_q.keys(), key=_qkey)[-5:]\n",
    "                table_lines.append(f\"- {r.get('doc')} | {r.get('label')} | \" + \", \".join(f\"{k}: {ser_q[k]}\" for k in qkeys))\n",
    "            elif ser_y:\n",
    "                ys = sorted(ser_y.keys())[-3:]\n",
    "                table_lines.append(f\"- {r.get('doc')} | {r.get('label')} | \" + \", \".join(f\"{y}: {ser_y[y]}\" for y in ys))\n",
    "\n",
    "    # 3) Compose strict prompt\n",
    "    if table_lines:\n",
    "        # When we have structured rows, exclude noisy text snippets to avoid conflicting numbers.\n",
    "        prompt = (\n",
    "            \"USER QUESTION:\\n\"\n",
    "            f\"{query}\\n\\n\"\n",
    "            + \"\\n\".join(table_lines) + \"\\n\\n\"\n",
    "            \"INSTRUCTIONS:\\n\"\n",
    "            \"- Use ONLY the numbers in STRUCTURED TABLE ROWS for calculations and final values.\\n\"\n",
    "            \"- If the task asks for 'Operating Income' but only 'Total income' is present, use 'Total income' as the denominator.\\n\"\n",
    "            \"- Do NOT refuse or say 'data missing' if the required numbers appear in the structured rows provided.\\n\"\n",
    "            \"- If a requested period is not present in these rows, say so explicitly (do NOT infer from narrative text).\\n\"\n",
    "            \"- Return a concise answer, then a small table if applicable.\\n\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            \"USER QUESTION:\\n\"\n",
    "            f\"{query}\\n\\n\"\n",
    "            \"CONTEXT (verbatim snippets from the reports):\\n\"\n",
    "            + \"\\n\".join(ctx_lines) +\n",
    "            \"\\n\\nINSTRUCTIONS:\\n\"\n",
    "            \"- Use ONLY facts present in the CONTEXT; do not invent numbers. If values are not present, explicitly state which ones are missing.\\n\"\n",
    "            \"- If the exact values for the requested periods are not present, say so explicitly.\\n\"\n",
    "            \"- Return a concise answer, then a small table if applicable, then a 'Citations' bullet list with 2√¢‚Ç¨‚Äú5 items.\\n\"\n",
    "        )\n",
    "\n",
    "    # 4) One LLM call\n",
    "    print(f\"[LLM] single-call baseline using {_llm_provider_info()}\")\n",
    "    answer = _llm_single_call(prompt)\n",
    "\n",
    "    # 5) Print nicely in notebooks\n",
    "    print(\"\"\"\\nBASELINE (Single LLM Call)\\n--------------------------------\"\"\")\n",
    "    print(answer)\n",
    "    print(\"\\nCitations:\")\n",
    "    for c in cits[:5]:\n",
    "        print(f\"- {c}\")\n",
    "\n",
    "    return {\"answer\": answer, \"contexts\": ctx_df.head(5)}\n",
    "    \n",
    "\n",
    "# ----------------------------- Tool: Calculator -----------------------------\n",
    "\n",
    "class CalculatorTool:\n",
    "    \"\"\"\n",
    "    Safe arithmetic eval (supports +,-,*,/,**, parentheses) and helpers for deltas/YoY.\n",
    "    \"\"\"\n",
    "\n",
    "    ALLOWED = {\n",
    "        ast.Expression, ast.BinOp, ast.UnaryOp, ast.Num, ast.Load,\n",
    "        ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Pow, ast.USub, ast.UAdd,\n",
    "        ast.Mod, ast.FloorDiv, ast.Constant, ast.Call, ast.Name\n",
    "    }\n",
    "    SAFE_FUNCS = {\"round\": round, \"abs\": abs}\n",
    "\n",
    "    @classmethod\n",
    "    def safe_eval(cls, expr: str) -> float:\n",
    "        node = ast.parse(expr, mode=\"eval\")\n",
    "        for n in ast.walk(node):\n",
    "            if type(n) not in cls.ALLOWED:\n",
    "                raise ValueError(f\"Disallowed expression: {type(n).__name__}\")\n",
    "            if isinstance(n, ast.Call) and not (isinstance(n.func, ast.Name) and n.func.id in cls.SAFE_FUNCS):\n",
    "                raise ValueError(\"Only round(...) and abs(...) calls are allowed\")\n",
    "        code = compile(node, \"<expr>\", \"eval\")\n",
    "        return float(eval(code, {\"__builtins__\": {}}, cls.SAFE_FUNCS))\n",
    "\n",
    "    @staticmethod\n",
    "    def delta(a: float, b: float) -> float:\n",
    "        return float(a) - float(b)\n",
    "\n",
    "    @staticmethod\n",
    "    def yoy(a: float, b: float) -> Optional[float]:\n",
    "        b = float(b)\n",
    "        if b == 0: return None\n",
    "        return (float(a) - b) / b * 100.0\n",
    "\n",
    "\n",
    "# ----------------------------- Tool: Table Extraction -----------------------------\n",
    "\n",
    "class TableExtractionTool:\n",
    "    \"\"\"\n",
    "    Look up a metric row in kb_tables.parquet and extract {year -> value_num}.\n",
    "    Heuristic: find any row where any cell (value_str) contains the metric term,\n",
    "    then collect all cells in that row whose column is a 4-digit year.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- normalization helpers & synonyms (for robust matching) ---\n",
    "    @staticmethod\n",
    "    def _norm(s: str) -> str:\n",
    "        \"\"\"Lowercase, replace '&' with 'and', strip punctuation, collapse spaces.\"\"\"\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        s = str(s).lower()\n",
    "        s = s.replace(\"&\", \" and \")\n",
    "        s = re.sub(r\"[^a-z0-9 ]+\", \" \", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "        return s\n",
    "\n",
    "    # Expanded metric synonyms\n",
    "    SYNONYMS = {\n",
    "        # NIM\n",
    "        \"nim\": [\"net interest margin\", \"nim\", \"net interest margin group\", \"nim group\"],\n",
    "        \"net interest margin\": [\"net interest margin\", \"nim\", \"net interest margin group\", \"nim group\"],\n",
    "        # Gross margin (treat as NIM for banks)\n",
    "        \"gross margin\": [\"net interest margin\", \"nim\", \"net interest margin group\", \"nim group\", \"gross margin\"],\n",
    "        # Opex\n",
    "        \"operating expenses and income\": [\n",
    "            \"operating expenses and income\",\n",
    "            \"operating expenses\",\n",
    "            \"total expenses\",\n",
    "            \"expenses\",\n",
    "        ],\n",
    "        \"operating expenses\": [\n",
    "            \"operating expenses\",\n",
    "            \"total expenses\",\n",
    "            \"expenses\",\n",
    "            \"opex\",\n",
    "        ],\n",
    "        \"total expenses\": [\n",
    "            \"total expenses\",\n",
    "            \"expenses\",\n",
    "            \"operating expenses\",\n",
    "            \"opex\",\n",
    "        ],\n",
    "        # Income\n",
    "        \"operating income\": [\n",
    "            \"operating income\",\n",
    "            \"total operating income\",\n",
    "            \"total income\",\n",
    "            \"income\",\n",
    "        ],\n",
    "        \"total income\": [\n",
    "            \"total income\",\n",
    "            \"operating income\",\n",
    "            \"total operating income\",\n",
    "            \"income\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, tables_df: Optional[pd.DataFrame]):\n",
    "        self.df = tables_df\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_year(col: str) -> bool:\n",
    "        return bool(re.fullmatch(r\"\\d{4}\", str(col).strip()))\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_quarter_token(col: str):\n",
    "        \"\"\"\n",
    "        Parse common quarter column labels like '1Q24', '1Q 2024', 'Q1 2024', '4QFY24'.\n",
    "        Returns a tuple (year:int, quarter:int, display:str) or None if not a quarter.\n",
    "        \"\"\"\n",
    "        s = str(col).strip()\n",
    "        # 1) Compact form like '1Q24' or '4Q2024'\n",
    "        m = re.search(r'(?i)\\b([1-4])\\s*q\\s*((?:20)?\\d{2})\\b', s)\n",
    "        if not m:\n",
    "            # 2) 'Q1 2024' or 'Q3 FY24'\n",
    "            m = re.search(r'(?i)\\bq\\s*([1-4])\\s*(?:fy)?\\s*((?:20)?\\d{2})\\b', s)\n",
    "        if not m:\n",
    "            # 3) '([1-4])Q((?:20)?\\d{2})' without space\n",
    "            m = re.search(r'(?i)\\b([1-4])q((?:20)?\\d{2})\\b', s)\n",
    "        if not m:\n",
    "            return None\n",
    "        q = int(m.group(1))\n",
    "        ytxt = m.group(2)\n",
    "        y = int(ytxt)\n",
    "        if y < 100:  # normalize '24' -> 2024\n",
    "            y += 2000\n",
    "        display = f\"{q}Q{y}\"\n",
    "        return (y, q, display)\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_quarter(col: str) -> bool:\n",
    "        return TableExtractionTool._parse_quarter_token(col) is not None\n",
    "\n",
    "    def get_metric_rows(self, metric: str, doc: Optional[str] = None, limit: int = 5):\n",
    "        if self.df is None or self.df.empty:\n",
    "            return []\n",
    "        base_df = self.df\n",
    "\n",
    "        # Build normalized copies for robust matching\n",
    "        df = base_df.assign(\n",
    "            _val_norm=base_df[\"value_str\"].astype(str).map(self._norm),\n",
    "            _col_norm=base_df[\"column\"].astype(str).map(self._norm),\n",
    "        )\n",
    "\n",
    "        metric_norm = self._norm(metric)\n",
    "        cand_terms = self.SYNONYMS.get(metric_norm, [metric_norm])\n",
    "\n",
    "        mask = pd.Series(False, index=df.index)\n",
    "        for term in cand_terms:\n",
    "            term_norm = self._norm(term)\n",
    "            mask = mask | df[\"_val_norm\"].str.contains(term_norm, na=False) | df[\"_col_norm\"].str.contains(term_norm, na=False)\n",
    "\n",
    "        if doc:\n",
    "            mask = mask & (df[\"doc_name\"] == doc)\n",
    "\n",
    "        if not mask.any():\n",
    "            return []\n",
    "\n",
    "        # --- ORIENTATION A: metric appears as a COLUMN header; quarters are in ROW label cells ---\n",
    "        results: List[Dict[str, Any]] = []\n",
    "        table_keys = (\n",
    "            df.loc[mask, [\"doc_name\", \"table_id\"]]\n",
    "              .drop_duplicates()\n",
    "              .itertuples(index=False, name=None)\n",
    "        )\n",
    "        for (d, t) in table_keys:\n",
    "            tbl = base_df[(base_df[\"doc_name\"] == d) & (base_df[\"table_id\"] == t)].copy()\n",
    "            if tbl.empty:\n",
    "                continue\n",
    "            # normalized copies to detect metric column(s)\n",
    "            tbln = tbl.assign(\n",
    "                _val_norm=tbl[\"value_str\"].astype(str).map(self._norm),\n",
    "                _col_norm=tbl[\"column\"].astype(str).map(self._norm),\n",
    "            )\n",
    "            # columns whose header contains the metric term\n",
    "            metric_cols = sorted(tbln.loc[tbln[\"_col_norm\"].str.contains(metric_norm, na=False), \"column\"].unique().tolist())\n",
    "            if metric_cols:\n",
    "                mcol = str(metric_cols[0])\n",
    "                # build series_q by iterating all rows in the table and picking the metric cell + a quarter label cell\n",
    "                series_q: Dict[str, float] = {}\n",
    "                series_y: Dict[int, float] = {}\n",
    "                series_pct: Dict[int, float] = {}\n",
    "                pages_seen: list[int] = []\n",
    "                for rid in sorted(tbl[\"row_id\"].unique()):\n",
    "                    row_cells = tbl[tbl[\"row_id\"] == rid]\n",
    "                    # collect page numbers for this row (if available)\n",
    "                    try:\n",
    "                        pser = row_cells.get(\"page\")\n",
    "                        if pser is not None:\n",
    "                            pages_seen += [int(p) for p in pser.dropna().astype(int).tolist()]\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    # find the cell for the metric column in this row\n",
    "                    mcell = row_cells[row_cells[\"column\"].astype(str) == mcol]\n",
    "                    if mcell.empty:\n",
    "                        continue\n",
    "                    val = mcell.iloc[0].get(\"value_num\")\n",
    "                    # also try to pick YoY % values when the metric column header is a YoY column\n",
    "                    # e.g., column header contains 'yoy' or '%'\n",
    "                    for _, rc in row_cells.iterrows():\n",
    "                        ctext = str(rc.get(\"column\") or \"\")\n",
    "                        if re.search(r\"(?i)yoy|%\", ctext):\n",
    "                            try:\n",
    "                                ylab = (rc.get(\"value_str\") or \"\").strip()\n",
    "                                if self._is_year(ylab):\n",
    "                                    vnum = rc.get(\"value_num\")\n",
    "                                    if pd.notna(vnum):\n",
    "                                        series_pct[int(ylab)] = float(vnum)\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                    # find a row label that looks like a quarter or a year in any non-year/quarter column\n",
    "                    label_text = None\n",
    "                    for _, rc in row_cells.iterrows():\n",
    "                        vstr = (rc.get(\"value_str\") or \"\").strip()\n",
    "                        if not vstr:\n",
    "                            continue\n",
    "                        # prefer quarter tokens\n",
    "                        qtok = self._parse_quarter_token(vstr)\n",
    "                        if qtok:\n",
    "                            disp = qtok[2]\n",
    "                            label_text = disp\n",
    "                            break\n",
    "                        # else maybe pure year row label like \"2024\"\n",
    "                        if self._is_year(vstr):\n",
    "                            label_text = vstr\n",
    "                            break\n",
    "                    if pd.notna(val) and label_text:\n",
    "                        # decide if it's quarter or year\n",
    "                        qtok2 = self._parse_quarter_token(label_text)\n",
    "                        if qtok2:\n",
    "                            series_q[qtok2[2]] = float(val)\n",
    "                        elif self._is_year(label_text):\n",
    "                            try:\n",
    "                                series_y[int(label_text)] = float(val)\n",
    "                            except Exception:\n",
    "                                pass\n",
    "                page_val = None\n",
    "                if pages_seen:\n",
    "                    try:\n",
    "                        page_val = max(set(pages_seen), key=pages_seen.count)\n",
    "                    except Exception:\n",
    "                        page_val = pages_seen[-1]\n",
    "                if series_q or series_y:\n",
    "                    # label: use the metric column header text\n",
    "                    label = str(mcol)\n",
    "                    results.append({\n",
    "                        \"doc\": d,\n",
    "                        \"table_id\": int(t),\n",
    "                        \"row_id\": -1,  # synthetic aggregation over rows\n",
    "                        \"label\": label,\n",
    "                        \"series\": series_y,\n",
    "                        \"series_q\": series_q,\n",
    "                        \"series_pct\": series_pct,\n",
    "                        \"page\": page_val,\n",
    "                    })\n",
    "\n",
    "        # stop early if we already found enough good quarter rows\n",
    "        if results and len(results) >= limit:\n",
    "            # rank quarter-first\n",
    "            def _rank_q(r):\n",
    "                sq = r.get(\"series_q\", {}) or {}\n",
    "                def _qkey(k: str):\n",
    "                    m = re.match(r\"([1-4])Q(20\\\\d{2})$\", k)\n",
    "                    if m:\n",
    "                        return (int(m.group(2)), int(m.group(1)))\n",
    "                    return (0, 0)\n",
    "                if sq:\n",
    "                    qkeys = sorted(sq.keys(), key=_qkey)\n",
    "                    latest_qy, latest_q = _qkey(qkeys[-1]) if qkeys else (0, 0)\n",
    "                    return ( -len(sq), -latest_qy, -latest_q, 0, 0 )\n",
    "                years = sorted((results[0].get(\"series\") or {}).keys())\n",
    "                latest_y = years[-1] if years else 0\n",
    "                return ( 0, 0, 0, -len(years), -latest_y )\n",
    "            results.sort(key=_rank_q)\n",
    "            return results[:limit]\n",
    "\n",
    "        # --- ORIENTATION B (fallback): metric appears as a ROW label; years/quarters are COLUMNS ---\n",
    "        key_cols = [\"doc_name\", \"table_id\", \"row_id\"]\n",
    "        row_keys = (\n",
    "            df.loc[mask, key_cols]\n",
    "              .drop_duplicates()\n",
    "              .itertuples(index=False, name=None)\n",
    "        )\n",
    "\n",
    "        for (d, t, r) in row_keys:\n",
    "            # Load the FULL row from the base dataframe (not the masked slice)\n",
    "            row_cells = base_df[(base_df[\"doc_name\"] == d) & (base_df[\"table_id\"] == t) & (base_df[\"row_id\"] == r)]\n",
    "            if row_cells.empty:\n",
    "                continue\n",
    "\n",
    "            # choose a representative page for this row\n",
    "            page_val = None\n",
    "            try:\n",
    "                pser = row_cells.get(\"page\")\n",
    "                if pser is not None:\n",
    "                    vals = [int(p) for p in pser.dropna().astype(int).tolist()]\n",
    "                    if vals:\n",
    "                        page_val = max(set(vals), key=vals.count)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Determine label\n",
    "            label = None\n",
    "            rc_norm = row_cells.assign(\n",
    "                _val_norm=row_cells[\"value_str\"].astype(str).map(self._norm),\n",
    "                _col_norm=row_cells[\"column\"].astype(str).map(self._norm),\n",
    "            )\n",
    "            metric_hits = rc_norm[~rc_norm[\"column\"].astype(str).map(self._is_year) & rc_norm[\"_val_norm\"].str.contains(metric_norm, na=False)]\n",
    "            if not metric_hits.empty:\n",
    "                label = (metric_hits.iloc[0][\"value_str\"] or \"\").strip()\n",
    "            if not label:\n",
    "                non_year = row_cells[~row_cells[\"column\"].astype(str).map(self._is_year)]\n",
    "                if not non_year.empty:\n",
    "                    label = (non_year.iloc[0][\"value_str\"] or \"\").strip() or str(non_year.iloc[0][\"column\"])\n",
    "            if not label:\n",
    "                label = f\"row {int(r)}\"\n",
    "\n",
    "            # Build year and quarter series from ALL cells in this row\n",
    "            series: Dict[int, float] = {}\n",
    "            series_q: Dict[str, float] = {}\n",
    "            for _, cell in row_cells.iterrows():\n",
    "                col = str(cell[\"column\"]).strip()\n",
    "                val = cell.get(\"value_num\")\n",
    "                if pd.isna(val):\n",
    "                    continue\n",
    "                if self._is_year(col):\n",
    "                    try:\n",
    "                        y = int(col); series[y] = float(val); continue\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                qtok = self._parse_quarter_token(col)\n",
    "                if qtok:\n",
    "                    series_q[qtok[2]] = float(val)\n",
    "\n",
    "            results.append({\n",
    "                \"doc\": d,\n",
    "                \"table_id\": int(t),\n",
    "                \"row_id\": int(r),\n",
    "                \"label\": label,\n",
    "                \"series\": series,\n",
    "                \"series_q\": series_q,\n",
    "                \"page\": page_val\n",
    "            })\n",
    "\n",
    "        # Rank results: quarters first by count/recency, then years\n",
    "        def _row_rank(r):\n",
    "            sq = r.get(\"series_q\", {}) or {}\n",
    "            def _qkey(k: str):\n",
    "                m = re.match(r\"([1-4])Q(20\\\\d{2})$\", k)\n",
    "                if m:\n",
    "                    return (int(m.group(2)), int(m.group(1)))\n",
    "                return (0, 0)\n",
    "            if sq:\n",
    "                qkeys = sorted(sq.keys(), key=_qkey)\n",
    "                latest_qy, latest_q = _qkey(qkeys[-1]) if qkeys else (0, 0)\n",
    "                return ( -len(sq), -latest_qy, -latest_q, 0, 0 )\n",
    "            years = sorted(r[\"series\"].keys())\n",
    "            latest_y = years[-1] if years else 0\n",
    "            return ( 0, 0, 0, -len(years), -latest_y )\n",
    "\n",
    "        results.sort(key=_row_rank)\n",
    "        return results[:limit]\n",
    "\n",
    "    @staticmethod\n",
    "    def last_n_years(series: Dict[int, float], n: int = 3) -> List[Tuple[int, float]]:\n",
    "        ys = sorted(series.keys())\n",
    "        return [(y, series[y]) for y in ys[-n:]]\n",
    "\n",
    "\n",
    "#\n",
    "# ----------------------------- Tool: Text Extraction (fallback for quarters) -----------------------------\n",
    "class TextExtractionTool:\n",
    "    \"\"\"\n",
    "    Regex-based fallback when Marker tables don't carry the quarter series.\n",
    "    Currently focuses on percentage metrics like Net Interest Margin (NIM).\n",
    "    It scans the KB text chunks and tries to pair quarter tokens with the nearest % value.\n",
    "    \"\"\"\n",
    "    QPAT = re.compile(r\"(?i)(?:\\b([1-4])\\s*q\\s*((?:20)?\\d{2})\\b|\\bq\\s*([1-4])\\s*((?:20)?\\d{2})\\b|\\b([1-4])q((?:20)?\\d{2})\\b)\")\n",
    "    PCT = re.compile(r\"(?i)(\\d{1,2}(?:\\.\\d{1,2})?)\\s*%\")\n",
    "\n",
    "    def __init__(self, kb: 'KBEnv'):\n",
    "        self.kb = kb\n",
    "\n",
    "    @staticmethod\n",
    "    def _norm(s: str) -> str:\n",
    "        return TableExtractionTool._norm(s)\n",
    "\n",
    "    @staticmethod\n",
    "    def _mk_qdisp(q: int, y: int) -> str:\n",
    "        if y < 100: y += 2000\n",
    "        return f\"{q}Q{y}\"\n",
    "\n",
    "    def extract_quarter_pct(self, metric: str, top_k_text: int = 200) -> Dict[str, float]:\n",
    "        metric_n = self._norm(metric)\n",
    "        hits = self.kb.search(metric, k=top_k_text)\n",
    "        if hits is None or hits.empty:\n",
    "            return {}\n",
    "        series_q: Dict[str, float] = {}\n",
    "        for _, row in hits.iterrows():\n",
    "            txt = str(row[\"text\"])\n",
    "            # Quick filter: only consider chunks that mention the metric name\n",
    "            if metric_n not in self._norm(txt):\n",
    "                continue\n",
    "            # Find all quarter tokens in this chunk\n",
    "            quarts = []\n",
    "            for m in self.QPAT.finditer(txt):\n",
    "                # groups: (q1,y1) or (q2,y2) or (q3,y3)\n",
    "                if m.group(1):   q, y = int(m.group(1)), int(m.group(2))\n",
    "                elif m.group(3): q, y = int(m.group(3)), int(m.group(4))\n",
    "                else:            q, y = int(m.group(5)), int(m.group(6))\n",
    "                if y < 100: y += 2000\n",
    "                quarts.append((q, y, m.start(), m.end()))\n",
    "            if not quarts:\n",
    "                continue\n",
    "            # Find % values; take the nearest % to each quarter mention\n",
    "            pcts = [(pm.group(1), pm.start(), pm.end()) for pm in self.PCT.finditer(txt)]\n",
    "            if not pcts:\n",
    "                continue\n",
    "            MAX_CHARS = 48  # require proximity\n",
    "            for (q, y, qs, qe) in quarts:\n",
    "                best = None; best_d = 1e9\n",
    "                for (val, ps, pe) in pcts:\n",
    "                    d = min(abs(ps - qe), abs(pe - qs))\n",
    "                    if d < best_d and d <= MAX_CHARS:\n",
    "                        try:\n",
    "                            num = float(val)\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                        # sanity for NIM-like percentages\n",
    "                        if 0.0 <= num <= 6.0:\n",
    "                            best_d = d; best = num\n",
    "                if best is not None:\n",
    "                    disp = self._mk_qdisp(q, y)\n",
    "                    series_q[disp] = float(best)\n",
    "        return series_q\n",
    "\n",
    "# ----------------------------- Tool: Multi-Doc Compare -----------------------------\n",
    "\n",
    "class MultiDocCompareTool:\n",
    "    \"\"\"\n",
    "    Compare the same metric across multiple docs by pulling each doc's row\n",
    "    and extracting aligned year/value pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, table_tool: TableExtractionTool):\n",
    "        self.table_tool = table_tool\n",
    "\n",
    "    def compare(self, metric: str, years: Optional[List[int]] = None, top_docs: int = 6):\n",
    "        # get top rows across all docs\n",
    "        rows = self.table_tool.get_metric_rows(metric, limit=50)\n",
    "        if not rows:\n",
    "            return []\n",
    "        # take first occurrence per doc\n",
    "        seen = set()\n",
    "        picked = []\n",
    "        for r in rows:\n",
    "            if r[\"doc\"] in seen: \n",
    "                continue\n",
    "            seen.add(r[\"doc\"])\n",
    "            picked.append(r)\n",
    "            if len(picked) >= top_docs:\n",
    "                break\n",
    "        # align years\n",
    "        if years is None:\n",
    "            all_years = set()\n",
    "            for r in picked:\n",
    "                all_years.update(r[\"series\"].keys())\n",
    "            years = sorted(all_years)[-3:]  # default: last 3 years available\n",
    "        out = []\n",
    "        for r in picked:\n",
    "            values = {y: r[\"series\"].get(y) for y in years}\n",
    "            out.append({\"doc\": r[\"doc\"], \"label\": r[\"label\"], \"years\": years, \"values\": values})\n",
    "        return out\n",
    "\n",
    "# ----------------------------- Agent Mode: plan ‚Üí act ‚Üí observe -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class AgentResult:\n",
    "    plan: List[str]\n",
    "    actions: List[str]\n",
    "    observations: List[str]\n",
    "    final: Dict[str, Any]\n",
    "\n",
    "# ----------------------------- QUERY ANALYSIS UTILITIES-----------------------------\n",
    "class QueryAnalyzer:\n",
    "    \"\"\"Utility methods for parsing financial queries\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_metric(query: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract metric name from query\n",
    "        Priority: quoted phrase > regex patterns > capitalized words\n",
    "        \"\"\"\n",
    "        # 1. Quoted phrase (highest priority)\n",
    "        quoted = re.findall(r'\"([^\"]+)\"', query)\n",
    "        if quoted:\n",
    "            return quoted[0]\n",
    "        \n",
    "        # 2. Common finance metrics (regex patterns)\n",
    "        candidates = [\n",
    "            r\"net interest margin\", r\"nim\", r\"gross margin\",\n",
    "            r\"operating expenses?(?: &| and)?(?: income)?\",\n",
    "            r\"operating income\", r\"operating profit\",\n",
    "            r\"total income\", r\"cost-to-income\", r\"allowances\", \n",
    "            r\"profit before tax\", r\"efficiency ratio\",\n",
    "            r\"return on equity\", r\"roe\", r\"return on assets\", r\"roa\"\n",
    "        ]\n",
    "        ql = query.lower()\n",
    "        for pat in candidates:\n",
    "            m = re.search(pat, ql)\n",
    "            if m:\n",
    "                return m.group(0)\n",
    "        \n",
    "        # 3. Fallback: capitalized phrase\n",
    "        m2 = re.findall(r'\\b([A-Z][A-Za-z&% ]{3,})\\b', query)\n",
    "        return m2[0] if m2 else None\n",
    "    \n",
    "    @staticmethod\n",
    "    def want_compare(query: str) -> bool:\n",
    "        \"\"\"Check if query requests comparison across documents\"\"\"\n",
    "        return bool(re.search(\n",
    "            r\"\\b(compare|vs\\.?|versus|across docs?|between|multi-?doc)\\b\", \n",
    "            query, re.I\n",
    "        ))\n",
    "    \n",
    "    @staticmethod\n",
    "    def want_yoy(query: str) -> bool:\n",
    "        \"\"\"Check if query requests year-over-year analysis\"\"\"\n",
    "        return bool(re.search(\n",
    "            r\"\\b(yoy|year[- ]over[- ]year|growth|change|%|delta|annual growth)\\b\", \n",
    "            query, re.I\n",
    "        ))\n",
    "    \n",
    "    @staticmethod\n",
    "    def want_quarters(query: str) -> bool:\n",
    "        \"\"\"Check if query requests quarterly data\"\"\"\n",
    "        return bool(re.search(\n",
    "            r\"\\b(quarter|quarters|\\bq[1-4]\\b|quarterly|half[- ]?year)\\b\", \n",
    "            query, re.I\n",
    "        ))\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_years(query: str) -> List[int]:\n",
    "        \"\"\"Extract year numbers from query\"\"\"\n",
    "        years = [int(y) for y in re.findall(r\"\\b(20\\d{2})\\b\", query)]\n",
    "        # Deduplicate and sort\n",
    "        return sorted(set(years))\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_num_periods(query: str) -> Optional[int]:\n",
    "        \"\"\"Extract number of periods (e.g., 'last 5 quarters', 'last 3 years')\"\"\"\n",
    "        # Pattern: \"last N quarters/years\"\n",
    "        m = re.search(r\"\\blast\\s+(\\d+)\\s+(quarters?|years?|periods?)\", query, re.I)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "        \n",
    "        # Pattern: \"N quarters/years\"\n",
    "        m2 = re.search(r\"\\b(\\d+)\\s+(quarters?|years?|periods?)\", query, re.I)\n",
    "        if m2:\n",
    "            return int(m2.group(1))\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def needs_calculation(query: str) -> bool:\n",
    "        \"\"\"Check if query requires calculation\"\"\"\n",
    "        return bool(re.search(\n",
    "            r\"\\b(calculate|compute|derive|ratio|√∑|divided by|/|percentage of)\\b\", \n",
    "            query, re.I\n",
    "        ))\n",
    "\n",
    "\n",
    "# ----------------------------- PARALLEL QUERY DECOMPOSER -----------------------------\n",
    "\n",
    "class ParallelQueryDecomposer:\n",
    "    \"\"\"Decomposes complex queries using QueryAnalyzer\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def decompose(query: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Intelligent query decomposition using query analysis\n",
    "        \"\"\"\n",
    "        analyzer = QueryAnalyzer\n",
    "        \n",
    "        # Extract intent\n",
    "        needs_calc = analyzer.needs_calculation(query)\n",
    "        metric = analyzer.extract_metric(query)\n",
    "        years = analyzer.extract_years(query)\n",
    "        num_periods = analyzer.extract_num_periods(query)\n",
    "        \n",
    "        # Q3: Efficiency Ratio (Opex √∑ Income)\n",
    "        if needs_calc and metric and \"efficiency\" in metric.lower():\n",
    "            return [\n",
    "                f\"Extract Operating Expenses for the last {num_periods or 3} fiscal years\",\n",
    "                f\"Extract Total Income for the last {num_periods or 3} fiscal years\"\n",
    "            ]\n",
    "        \n",
    "        # Q3: Any ratio calculation (A √∑ B)\n",
    "        if needs_calc and (\"ratio\" in query.lower() or \"√∑\" in query or \"/\" in query):\n",
    "            # Try to extract both metrics\n",
    "            parts = re.split(r'[√∑/]|\\bdivided by\\b', query, flags=re.I)\n",
    "            if len(parts) == 2:\n",
    "                metric_a = analyzer.extract_metric(parts[0])\n",
    "                metric_b = analyzer.extract_metric(parts[1])\n",
    "                if metric_a and metric_b:\n",
    "                    return [\n",
    "                        f\"Extract {metric_a} for the last {num_periods or 3} fiscal years\",\n",
    "                        f\"Extract {metric_b} for the last {num_periods or 3} fiscal years\"\n",
    "                    ]\n",
    "        \n",
    "        # Multi-metric comparison\n",
    "        if analyzer.want_compare(query) and metric:\n",
    "            # Decompose by year if multiple years specified\n",
    "            if len(years) > 2:\n",
    "                return [f\"Extract {metric} for FY{y}\" for y in years]\n",
    "        \n",
    "        # Single metric query (no decomposition)\n",
    "        return [query]\n",
    "\n",
    "    @staticmethod\n",
    "    async def execute_parallel_async(kb: KBEnv, sub_queries: List[str], k_ctx: int) -> List[pd.DataFrame]:\n",
    "        \"\"\"Execute sub-queries in parallel\"\"\"\n",
    "        loop = asyncio.get_event_loop()\n",
    "        \n",
    "        def search_sync(query):\n",
    "            return kb.search(query, k=k_ctx)\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=min(len(sub_queries), 4)) as executor:\n",
    "            tasks = [loop.run_in_executor(executor, search_sync, sq) for sq in sub_queries]\n",
    "            results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    @staticmethod\n",
    "    def execute_parallel(kb: KBEnv, sub_queries: List[str], k_ctx: int) -> List[pd.DataFrame]:\n",
    "        \"\"\"Blocking wrapper for async parallel execution\"\"\"\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                # Already in event loop (e.g., Jupyter), use nest_asyncio\n",
    "                try:\n",
    "                    import nest_asyncio\n",
    "                    nest_asyncio.apply()\n",
    "                except ImportError:\n",
    "                    pass\n",
    "        except RuntimeError:\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "        \n",
    "        return loop.run_until_complete(\n",
    "            ParallelQueryDecomposer.execute_parallel_async(kb, sub_queries, k_ctx)\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def merge_results(results: List[pd.DataFrame], k_ctx: int) -> pd.DataFrame:\n",
    "        \"\"\"Merge and deduplicate parallel results\"\"\"\n",
    "        if not results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Concatenate\n",
    "        merged = pd.concat([r for r in results if not r.empty], ignore_index=True)\n",
    "        if merged.empty:\n",
    "            return merged\n",
    "        \n",
    "        # Deduplicate by text (keep highest score)\n",
    "        merged = merged.sort_values('score', ascending=False)\n",
    "        merged = merged.drop_duplicates(subset=['text'], keep='first')\n",
    "        \n",
    "        # Take top-k\n",
    "        merged = merged.head(k_ctx)\n",
    "        \n",
    "        # Re-rank\n",
    "        merged = merged.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "        merged['rank'] = range(1, len(merged) + 1)\n",
    "        \n",
    "        return merged\n",
    "\n",
    "# ----------------------------- Agent: plan ‚Üí act ‚Üí observe -----------------------------\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Unified Agent with all tools:\n",
    "    - CalculatorTool\n",
    "    - TableExtractionTool\n",
    "    - TextExtractionTool\n",
    "    - MultiDocCompareTool (NEW)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        kb: KBEnv, \n",
    "        use_parallel_subqueries: bool = False,\n",
    "        verbose: bool = True\n",
    "    ):\n",
    "        self.kb = kb\n",
    "        self.use_parallel_subqueries = use_parallel_subqueries\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Initialize all tools\n",
    "        self.calc_tool = CalculatorTool()\n",
    "        \n",
    "        # Table tool (required for multi-doc compare)\n",
    "        self.table_tool = TableExtractionTool(kb.tables_df) if kb.tables_df is not None else None\n",
    "        \n",
    "        # Text extraction fallback\n",
    "        self.text_tool = TextExtractionTool(kb)\n",
    "        \n",
    "        # ‚úÖ Multi-doc compare tool (NEW)\n",
    "        self.multidoc_tool = MultiDocCompareTool(self.table_tool) if self.table_tool else None\n",
    "        \n",
    "        # Analyzers\n",
    "        self.analyzer = QueryAnalyzer()\n",
    "        self.decomposer = ParallelQueryDecomposer() if use_parallel_subqueries else None\n",
    "        \n",
    "        if self.verbose:\n",
    "            tools_status = []\n",
    "            tools_status.append(f\"Calculator: ‚úì\")\n",
    "            tools_status.append(f\"Table: {'‚úì' if self.table_tool else '‚úó'}\")\n",
    "            tools_status.append(f\"Text: ‚úì\")\n",
    "            tools_status.append(f\"MultiDoc: {'‚úì' if self.multidoc_tool else '‚úó'}\")\n",
    "            print(f\"[Agent] Tools: {' | '.join(tools_status)}\")\n",
    "    \n",
    "    def run(self, query: str, k_ctx: int = 12) -> 'AgentResult':\n",
    "        \"\"\"Execute query with all available tools\"\"\"\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n[Agent] Query: {query[:60]}...\")\n",
    "        \n",
    "        # Step 1: Analyze query\n",
    "        metric = self.analyzer.extract_metric(query)\n",
    "        wants_yoy = self.analyzer.want_yoy(query)\n",
    "        wants_quarters = self.analyzer.want_quarters(query)\n",
    "        wants_compare = self.analyzer.want_compare(query)  # NEW: Check for comparison\n",
    "        needs_calc = self.analyzer.needs_calculation(query)\n",
    "        years = self.analyzer.extract_years(query)\n",
    "        num_periods = self.analyzer.extract_num_periods(query)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"[Agent] Analysis:\")\n",
    "            print(f\"  Metric: {metric}\")\n",
    "            print(f\"  YoY: {wants_yoy}, Quarterly: {wants_quarters}\")\n",
    "            print(f\"  Compare: {wants_compare}, Calc: {needs_calc}\")  # NEW\n",
    "            print(f\"  Years: {years}, Periods: {num_periods}\")\n",
    "        \n",
    "        # Step 2: Retrieve contexts (parallel or standard)\n",
    "        if self.use_parallel_subqueries and self.decomposer:\n",
    "            sub_queries = self.decomposer.decompose(query)\n",
    "            \n",
    "            if len(sub_queries) > 1:\n",
    "                if self.verbose:\n",
    "                    print(f\"[Agent] Decomposed into {len(sub_queries)} sub-queries\")\n",
    "                \n",
    "                sub_results = self.decomposer.execute_parallel(self.kb, sub_queries, k_ctx)\n",
    "                contexts = self.decomposer.merge_results(sub_results, k_ctx)\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"[Agent] Merged ‚Üí {len(contexts)} contexts\")\n",
    "            else:\n",
    "                contexts = self.kb.search(query, k=k_ctx)\n",
    "        else:\n",
    "            contexts = self.kb.search(query, k=k_ctx)\n",
    "        \n",
    "        # Step 3: Tool selection and execution\n",
    "        actions = []\n",
    "        table_rows = []\n",
    "        comparison_results = []\n",
    "        \n",
    "        # ========== NEW: Multi-doc compare tool ==========\n",
    "        if wants_compare and metric and self.multidoc_tool:\n",
    "            actions.append(\"multi_doc_compare\")\n",
    "            comparison_results = self.multidoc_tool.compare(\n",
    "                metric=metric,\n",
    "                years=years if years else None,\n",
    "                top_docs=6\n",
    "            )\n",
    "            if self.verbose:\n",
    "                print(f\"[Agent] MultiDoc compare: {len(comparison_results)} documents\")\n",
    "        \n",
    "        # Table extraction (standard)\n",
    "        elif metric and self.table_tool:\n",
    "            actions.append(\"table_extraction\")\n",
    "            table_rows = self.table_tool.get_metric_rows(metric, limit=10)\n",
    "            if self.verbose:\n",
    "                print(f\"[Agent] Extracted {len(table_rows)} table rows\")\n",
    "        \n",
    "        # Text extraction fallback\n",
    "        if not table_rows and not comparison_results and self.text_tool:\n",
    "            actions.append(\"text_extraction\")\n",
    "            if wants_quarters and metric:\n",
    "                quarter_data = self.text_tool.extract_quarter_pct(metric, top_k_text=50)\n",
    "                if self.verbose:\n",
    "                    print(f\"[Agent] Text extraction: {len(quarter_data)} quarters\")\n",
    "        \n",
    "        # Calculator for YoY or ratios\n",
    "        if needs_calc and self.calc_tool:\n",
    "            actions.append(\"calculation\")\n",
    "        \n",
    "        # Step 4: LLM Synthesis\n",
    "        answer = self._synthesize_with_llm(\n",
    "            query, \n",
    "            contexts, \n",
    "            table_rows, \n",
    "            comparison_results,  # NEW\n",
    "            metric, \n",
    "            wants_yoy,\n",
    "            wants_compare  # NEW\n",
    "        )\n",
    "        \n",
    "        # Step 5: Build result\n",
    "        observations = [\n",
    "            f\"Retrieved {len(contexts)} contexts\",\n",
    "            f\"Metric: {metric}\",\n",
    "            f\"YoY: {wants_yoy}, Quarterly: {wants_quarters}, Compare: {wants_compare}\",\n",
    "            f\"Tools used: {', '.join(actions)}\"\n",
    "        ]\n",
    "        \n",
    "        result = AgentResult(\n",
    "            plan=f\"Analyze ‚Üí {'Compare' if wants_compare else 'Extract'} {metric} ‚Üí Synthesize\",\n",
    "            actions=actions,\n",
    "            observations=observations,\n",
    "            final={\n",
    "                \"contexts\": contexts,\n",
    "                \"table_rows\": table_rows,\n",
    "                \"comparison_results\": comparison_results,  # NEW\n",
    "                \"answer\": answer,\n",
    "                \"metric\": metric,\n",
    "                \"wants_yoy\": wants_yoy,\n",
    "                \"wants_quarters\": wants_quarters,\n",
    "                \"wants_compare\": wants_compare\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _synthesize_with_llm(\n",
    "        self, \n",
    "        query: str, \n",
    "        contexts: pd.DataFrame, \n",
    "        table_rows: List[Dict],\n",
    "        comparison_results: List[Dict],  # NEW parameter\n",
    "        metric: str,\n",
    "        wants_yoy: bool,\n",
    "        wants_compare: bool  # NEW parameter\n",
    "    ) -> str:\n",
    "        \"\"\"Synthesize final answer using LLM\"\"\"\n",
    "        \n",
    "        prompt_parts = [f\"USER QUESTION:\\n{query}\\n\"]\n",
    "        \n",
    "        # ========== NEW: Add multi-doc comparison results ==========\n",
    "        if comparison_results:\n",
    "            prompt_parts.append(\"\\nMULTI-DOCUMENT COMPARISON:\")\n",
    "            for comp in comparison_results:\n",
    "                doc = comp.get(\"doc\", \"Unknown\")\n",
    "                label = comp.get(\"label\", metric)\n",
    "                years = comp.get(\"years\", [])\n",
    "                values = comp.get(\"values\", [])\n",
    "                \n",
    "                if years and values:\n",
    "                    year_val_pairs = \", \".join(f\"{y}: {v}\" for y, v in zip(years, values))\n",
    "                    prompt_parts.append(f\"- {doc} | {label}: {year_val_pairs}\")\n",
    "        \n",
    "        # Add table rows if available\n",
    "        elif table_rows:\n",
    "            prompt_parts.append(\"\\nSTRUCTURED DATA:\")\n",
    "            for r in table_rows[:5]:\n",
    "                if r.get(\"series_q\"):\n",
    "                    qkeys = sorted(r[\"series_q\"].keys())[-5:]\n",
    "                    ser = \", \".join(f\"{k}: {r['series_q'][k]}\" for k in qkeys)\n",
    "                    prompt_parts.append(f\"- {r['doc']} | {r['label']}: {ser}\")\n",
    "                else:\n",
    "                    ys = sorted(r[\"series\"].keys())[-3:]\n",
    "                    ser = \", \".join(f\"{y}: {r['series'][y]}\" for y in ys)\n",
    "                    prompt_parts.append(f\"- {r['doc']} | {r['label']}: {ser}\")\n",
    "        \n",
    "        # Add retrieved contexts\n",
    "        if not contexts.empty:\n",
    "            prompt_parts.append(\"\\nCONTEXT:\")\n",
    "            for _, row in contexts.head(5).iterrows():\n",
    "                text = str(row[\"text\"])[:500]\n",
    "                doc = row.get(\"doc\", \"Unknown\")\n",
    "                prompt_parts.append(f\"- [{doc}] {text}\")\n",
    "        \n",
    "        # Add instructions\n",
    "        prompt_parts.append(\"\\nINSTRUCTIONS:\")\n",
    "        prompt_parts.append(\"- Use ONLY the data provided above\")\n",
    "        \n",
    "        if wants_compare:\n",
    "            prompt_parts.append(\"- Compare the metric across different documents\")\n",
    "            prompt_parts.append(\"- Highlight similarities and differences\")\n",
    "        \n",
    "        if wants_yoy:\n",
    "            prompt_parts.append(\"- Calculate year-over-year growth percentages\")\n",
    "        \n",
    "        prompt_parts.append(\"- Provide a concise answer with specific numbers and document names\")\n",
    "        prompt_parts.append(\"- If data is incomplete, state what's missing explicitly\")\n",
    "        \n",
    "        prompt = \"\\n\".join(prompt_parts)\n",
    "        \n",
    "        # Call LLM\n",
    "        if self.verbose:\n",
    "            print(f\"[Agent] Synthesizing with LLM...\")\n",
    "        \n",
    "        answer = _llm_single_call(prompt)\n",
    "        \n",
    "        return answer\n",
    "\n",
    "\n",
    "# ----------------------------- Pretty print helpers -----------------------------\n",
    "\n",
    "def _fmt_series(series: Dict[int, float], n: int = 3) -> str:\n",
    "    if not series: return \"‚Äî\"\n",
    "    ys = sorted(series.keys())[-n:]\n",
    "    return \", \".join(f\"{y}: {series[y]}\" for y in ys)\n",
    "\n",
    "def show_agent_result(res: AgentResult, show_ctx: int = 3):\n",
    "    print(\"PLAN:\")\n",
    "    for step in res.plan:\n",
    "        print(\"  -\", step)\n",
    "    print(\"\\nACTIONS:\")\n",
    "    for a in res.actions:\n",
    "        print(\"  -\", a)\n",
    "    print(\"\\nOBSERVATIONS:\")\n",
    "    for o in res.observations:\n",
    "        print(\"  -\", o)\n",
    "\n",
    "    fin = res.final\n",
    "\n",
    "    # TABLE ROWS block\n",
    "    if not fin.get(\"table_rows\"):\n",
    "        msg = fin.get(\"notice\") or \"No matching table rows were found for your request.\"\n",
    "        print(f\"\\n‚ö†Ô∏è {msg}\")\n",
    "    elif \"table_rows\" in fin and fin[\"table_rows\"]:\n",
    "        print(\"\\nTABLE ROWS (first few):\")\n",
    "        shown = 0\n",
    "        for r in fin[\"table_rows\"]:\n",
    "            if shown >= 3:\n",
    "                break\n",
    "            sq = (r.get(\"series_q\") or {})\n",
    "            if sq:\n",
    "                # sort quarters chronologically by (year, quarter)\n",
    "                def _qkey(k):\n",
    "                    m = re.match(r\"([1-4])Q(20\\\\d{2})$\", k)\n",
    "                    if m:\n",
    "                        return (int(m.group(2)), int(m.group(1)))\n",
    "                    return (0, 0)\n",
    "                qkeys = sorted(sq.keys(), key=_qkey)\n",
    "                last5 = qkeys[-5:]\n",
    "                ser = \", \".join(f\"{k}: {sq[k]}\" for k in last5)\n",
    "                print(f\"  doc={r['doc']} | label={r['label']} | quarters(last5)={ser}\")\n",
    "                shown += 1\n",
    "            else:\n",
    "                ys = sorted(r[\"series\"].keys())\n",
    "                ser = \", \".join(f\"{y}: {r['series'][y]}\" for y in ys[-3:]) if ys else \"‚Äî\"\n",
    "                print(f\"  doc={r['doc']} | label={r['label']} | years(last3)={ser}\")\n",
    "                shown += 1\n",
    "    if \"compare\" in fin and fin[\"compare\"]:\n",
    "        print(\"\\nCOMPARE (first few):\")\n",
    "        for r in fin[\"compare\"][:3]:\n",
    "            row = \", \".join(f\"{y}: {r['values'].get(y)}\" for y in r[\"years\"])\n",
    "            print(f\"  doc={r['doc']} | label={r['label']} | {row}\")\n",
    "    if \"calc\" in fin and fin[\"calc\"]:\n",
    "        print(\"\\nCALC (YoY):\")\n",
    "        for c in fin[\"calc\"]:\n",
    "            print(f\"  {c['from']}‚Üí{c['to']}: {c['value_from']} ‚Üí {c['value_to']} | YoY={c['yoy_pct']}%\")\n",
    "\n",
    "    # Contexts\n",
    "    ctx = fin.get(\"contexts\")\n",
    "    if ctx is not None and not ctx.empty:\n",
    "        print(\"\\nCONTEXTS:\")\n",
    "        for _, row in ctx.head(show_ctx).iterrows():\n",
    "            t = str(row[\"text\"]).replace(\"\\n\", \" \")\n",
    "            if len(t) > 240: t = t[:237] + \"...\"\n",
    "            hint = f\" ‚Äî {row.get('section_hint')}\" if \"section_hint\" in row else \"\"\n",
    "            print(f\"  [{row['rank']}] {row['doc']} | {row['modality']}{hint}\")\n",
    "            print(\"     \", t)\n",
    "\n",
    "\n",
    "# ----------------------------- CLI / Notebook ------------------------------------\n",
    "\n",
    "# ----------------------------- Notebook Runtime ------------------------------------\n",
    "\n",
    "# This section is safe for direct use inside a Jupyter/Colab/VSCode notebook cell.\n",
    "# It avoids argparse/sys parsing and simply runs a default demo or accepts a variable `query`.\n",
    "\n",
    "# Example usage in a notebook:\n",
    "# from g2x import KBEnv, Agent, show_agent_result\n",
    "# kb = KBEnv(base=\"./data_marker\")\n",
    "# agent = Agent(kb)\n",
    "# res = agent.run(\"Compare Net Interest Margin across docs for 2022‚Äì2024\")\n",
    "# show_agent_result(res)\n",
    "\n",
    "if __name__ == \"__main__\" or \"__file__\" not in globals():\n",
    "    kb = KBEnv(base=\"./data_marker\")\n",
    "    agent = Agent(kb)\n",
    "\n",
    "    try:\n",
    "        query = globals().get(\"query\", None)\n",
    "    except Exception:\n",
    "        query = None\n",
    "\n",
    "    if not query:\n",
    "        query = \"What is the Net Interest Margin over the last 5 quarters?\"\n",
    "        print(\"‚ÑπÔ∏è Running notebook demo query:\")\n",
    "        print(f\"   ‚Üí {query}\\n\")\n",
    "\n",
    "    # BASELINE execution (single LLM, no caching)\n",
    "    out = baseline_answer_one_call(kb, query, k_ctx=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ed3d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b90030d",
   "metadata": {},
   "source": [
    "---\n",
    "## Metadata Filtering/Boosting Optimization\n",
    "\n",
    "Run below cell to enable the Metadata Filtering/boosting optimization, then run the Benchmark Runner to see the change in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0832d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "METADATA ENHANCEMENT SETUP - FINE-TUNED VERSION\n",
      "================================================================================\n",
      "\n",
      "üìä Enhancing KB with metadata (year, quarter, doc_type, section)...\n",
      "Loading chunks from data_marker\\kb_chunks.parquet...\n",
      "Loading texts from data_marker\\kb_texts.npy...\n",
      " Enhancing metadata...\n",
      "\n",
      "Metadata Enhancement Summary:\n",
      "   Total chunks: 13548\n",
      "   Years found: {2022: np.int64(3071), 2023: np.int64(3021), 2024: np.int64(6013), 2025: np.int64(1443)}\n",
      "   Quarters found: 6 unique quarters\n",
      "   Doc types: {'annual_report': np.int64(9200), 'quarterly_results': np.int64(3055), 'cfo_presentation': np.int64(1002), 'trading_update': np.int64(188), 'press_statement': np.int64(60), 'ceo_presentation': np.int64(43)}\n",
      "\n",
      "Saving enhanced chunks to data_marker\\kb_chunks.parquet...\n",
      "‚úì KB enhancement complete!\n",
      "\n",
      "Added 'search_with_metadata' method to KBEnv class\n",
      "‚úì Metadata search added to KBEnv\n",
      "\n",
      "================================================================================\n",
      "APPLYING BALANCED METADATA OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "‚úì Original search method saved\n",
      "\n",
      "‚úì BALANCED OPTIMIZATION ENABLED\n",
      "   All kb.search() calls will now use:\n",
      "   ‚Ä¢ Adaptive metadata boosting (balanced weights)\n",
      "   ‚Ä¢ Recency decay (5% per quarter age)\n",
      "   ‚Ä¢ Soft filtering (¬±2 year window when year detected)\n",
      "   ‚Ä¢ Improved 'last N quarters' detection\n",
      "\n",
      "================================================================================\n",
      "SETUP COMPLETE - Balanced Metadata Optimization Active!\n",
      "================================================================================\n",
      "\n",
      "üéØ FINE-TUNED IMPROVEMENTS:\n",
      "\n",
      "1. BALANCED BOOST WEIGHTS (Less Aggressive):\n",
      "   ‚Ä¢ Quarterly queries: quarter=6.0x (was 8.0x), doc_type=1.4x, year=1.6x\n",
      "   ‚Ä¢ YoY comparisons: year=3.0x (was 3.5x), quarter=1.8x, doc_type=2.2x\n",
      "   ‚Ä¢ Annual queries: doc_type=3.5x (was 4.0x), year=2.2x, quarter=1.0x\n",
      "   ‚Ä¢ Latest/recent: quarter=5.5x (was 7.0x), year=2.2x\n",
      "   ‚Ä¢ Defaults: quarter=4.0x, doc_type=1.8x, year=1.6x, section=1.2x\n",
      "\n",
      "2. GENTLER RECENCY DECAY:\n",
      "   ‚Ä¢ Documents decay 5% in relevance per quarter of age (was 7%)\n",
      "   ‚Ä¢ 1Q ago: 0.95x (was 0.93x)\n",
      "   ‚Ä¢ 4Q ago: 0.81x (was 0.75x)\n",
      "   ‚Ä¢ 8Q ago: 0.66x (was 0.56x)\n",
      "\n",
      "3. FASTER INITIAL POOL:\n",
      "   ‚Ä¢ k*12 candidates (600 for k=50) instead of k*15 (750)\n",
      "   ‚Ä¢ ~15-20% faster while maintaining quality\n",
      "\n",
      "4. IMPROVED PATTERN DETECTION:\n",
      "   ‚Ä¢ Better \"over the last N quarters\" detection\n",
      "   ‚Ä¢ \"for the last N quarters\" now works\n",
      "   ‚Ä¢ \"in the past N quarters\" now works\n",
      "\n",
      "‚úì Balanced precision vs speed\n",
      "‚úì Less aggressive boosting = more diverse results\n",
      "‚úì Falls back to regular search for generic queries\n",
      "\n",
      "TO DISABLE THIS OPTIMIZATION:\n",
      "  - Restart the kernel, OR\n",
      "  - Run: KBEnv.search = KBEnv._original_search\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METADATA ENHANCEMENT SETUP (Run this cell once)\n",
    "# ============================================================================\n",
    "\n",
    "# Step 0: Reload modules to pick up latest changes\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove old modules from cache\n",
    "for mod in list(sys.modules.keys()):\n",
    "    if 'metadata_enhancer' in mod or 'kb_metadata_extension' in mod:\n",
    "        del sys.modules[mod]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"METADATA ENHANCEMENT SETUP - FINE-TUNED VERSION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Step 1: Enhance KB with metadata (ONE TIME - only run if not already done)\n",
    "try:\n",
    "    from metadata_enhancer import enhance_kb_with_metadata\n",
    "    \n",
    "    print(\"üìä Enhancing KB with metadata (year, quarter, doc_type, section)...\")\n",
    "    enhance_kb_with_metadata(\"./data_marker\")\n",
    "    print(\"‚úì KB enhancement complete!\\n\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ö†Ô∏è  KB files not found: {e}\")\n",
    "    print(\"   Make sure ./data_marker/kb_chunks.parquet exists\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è  Enhancement skipped (may already be done): {e}\\n\")\n",
    "\n",
    "# Step 2: Add metadata search capability to KBEnv\n",
    "try:\n",
    "    from kb_metadata_extension import add_metadata_search_to_kbenv\n",
    "    add_metadata_search_to_kbenv()\n",
    "    print(\"‚úì Metadata search added to KBEnv\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Could not add metadata search: {e}\\n\")\n",
    "\n",
    "# Step 3: Replace KBEnv.search() with metadata-enhanced version\n",
    "print(\"=\" * 80)\n",
    "print(\"APPLYING BALANCED METADATA OPTIMIZATION\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "from g2x import KBEnv\n",
    "\n",
    "# Save original search method if not already saved\n",
    "if not hasattr(KBEnv, '_original_search'):\n",
    "    KBEnv._original_search = KBEnv.search\n",
    "    print(\"‚úì Original search method saved\\n\")\n",
    "\n",
    "# Define metadata-enhanced search wrapper with balanced boosting\n",
    "def _metadata_optimized_search(self, query, k=50, alpha=0.6, rerank_top_k=100):\n",
    "    \"\"\"\n",
    "    Enhanced search with balanced metadata boosting, recency decay, and adaptive weights\n",
    "    \n",
    "    FINE-TUNED SETTINGS:\n",
    "    - Reduced boost weights (quarter: 4.0x‚Üí6.0x vs old 5.0x‚Üí8.0x)\n",
    "    - Less aggressive recency decay (5% per quarter vs 7%)\n",
    "    - Smaller initial pool (k*12 vs k*15) for better speed\n",
    "    - Improved \"last N quarters\" detection\n",
    "    \"\"\"\n",
    "    if hasattr(self, 'search_with_metadata'):\n",
    "        # Temporarily restore original to avoid recursion\n",
    "        original_method = KBEnv.search\n",
    "        KBEnv.search = KBEnv._original_search\n",
    "        try:\n",
    "            result = self.search_with_metadata(\n",
    "                query, \n",
    "                k=k, \n",
    "                alpha=alpha, \n",
    "                rerank_top_k=rerank_top_k,\n",
    "                enable_metadata_boost=True,\n",
    "                enable_metadata_filter=True,  # Soft filter enabled\n",
    "                boost_weights=None,  # Use adaptive weights (None = auto-detect)\n",
    "                apply_recency_decay=True  # Apply time-based decay (5% per quarter)\n",
    "            )\n",
    "        finally:\n",
    "            # Restore the enhanced search\n",
    "            KBEnv.search = original_method\n",
    "        return result\n",
    "    else:\n",
    "        # Fallback to original if metadata not available\n",
    "        return KBEnv._original_search(self, query, k=k, alpha=alpha, rerank_top_k=rerank_top_k)\n",
    "\n",
    "# Apply the optimization\n",
    "KBEnv.search = _metadata_optimized_search\n",
    "\n",
    "print(\"‚úì BALANCED OPTIMIZATION ENABLED\")\n",
    "print(\"   All kb.search() calls will now use:\")\n",
    "print(\"   ‚Ä¢ Adaptive metadata boosting (balanced weights)\")\n",
    "print(\"   ‚Ä¢ Recency decay (5% per quarter age)\")\n",
    "print(\"   ‚Ä¢ Soft filtering (¬±2 year window when year detected)\")\n",
    "print(\"   ‚Ä¢ Improved 'last N quarters' detection\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SETUP COMPLETE - Balanced Metadata Optimization Active!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "üéØ FINE-TUNED IMPROVEMENTS:\n",
    "\n",
    "1. BALANCED BOOST WEIGHTS (Less Aggressive):\n",
    "   ‚Ä¢ Quarterly queries: quarter=6.0x (was 8.0x), doc_type=1.4x, year=1.6x\n",
    "   ‚Ä¢ YoY comparisons: year=3.0x (was 3.5x), quarter=1.8x, doc_type=2.2x\n",
    "   ‚Ä¢ Annual queries: doc_type=3.5x (was 4.0x), year=2.2x, quarter=1.0x\n",
    "   ‚Ä¢ Latest/recent: quarter=5.5x (was 7.0x), year=2.2x\n",
    "   ‚Ä¢ Defaults: quarter=4.0x, doc_type=1.8x, year=1.6x, section=1.2x\n",
    "\n",
    "2. GENTLER RECENCY DECAY:\n",
    "   ‚Ä¢ Documents decay 5% in relevance per quarter of age (was 7%)\n",
    "   ‚Ä¢ 1Q ago: 0.95x (was 0.93x)\n",
    "   ‚Ä¢ 4Q ago: 0.81x (was 0.75x)\n",
    "   ‚Ä¢ 8Q ago: 0.66x (was 0.56x)\n",
    "\n",
    "3. FASTER INITIAL POOL:\n",
    "   ‚Ä¢ k*12 candidates (600 for k=50) instead of k*15 (750)\n",
    "   ‚Ä¢ ~15-20% faster while maintaining quality\n",
    "\n",
    "4. IMPROVED PATTERN DETECTION:\n",
    "   ‚Ä¢ Better \"over the last N quarters\" detection\n",
    "   ‚Ä¢ \"for the last N quarters\" now works\n",
    "   ‚Ä¢ \"in the past N quarters\" now works\n",
    "\n",
    "‚úì Balanced precision vs speed\n",
    "‚úì Less aggressive boosting = more diverse results\n",
    "‚úì Falls back to regular search for generic queries\n",
    "\n",
    "TO DISABLE THIS OPTIMIZATION:\n",
    "  - Restart the kernel, OR\n",
    "  - Run: KBEnv.search = KBEnv._original_search\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e60356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a9094",
   "metadata": {},
   "source": [
    "### Just to check available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models:\n",
      "\n",
      "- models/gemini-2.5-pro-preview-03-25\n",
      "- models/gemini-2.5-flash-preview-05-20\n",
      "- models/gemini-2.5-flash\n",
      "- models/gemini-2.5-flash-lite-preview-06-17\n",
      "- models/gemini-2.5-pro-preview-05-06\n",
      "- models/gemini-2.5-pro-preview-06-05\n",
      "- models/gemini-2.5-pro\n",
      "- models/gemini-2.0-flash-exp\n",
      "- models/gemini-2.0-flash\n",
      "- models/gemini-2.0-flash-001\n",
      "- models/gemini-2.0-flash-exp-image-generation\n",
      "- models/gemini-2.0-flash-lite-001\n",
      "- models/gemini-2.0-flash-lite\n",
      "- models/gemini-2.0-flash-preview-image-generation\n",
      "- models/gemini-2.0-flash-lite-preview-02-05\n",
      "- models/gemini-2.0-flash-lite-preview\n",
      "- models/gemini-2.0-pro-exp\n",
      "- models/gemini-2.0-pro-exp-02-05\n",
      "- models/gemini-exp-1206\n",
      "- models/gemini-2.0-flash-thinking-exp-01-21\n",
      "- models/gemini-2.0-flash-thinking-exp\n",
      "- models/gemini-2.0-flash-thinking-exp-1219\n",
      "- models/gemini-2.5-flash-preview-tts\n",
      "- models/gemini-2.5-pro-preview-tts\n",
      "- models/learnlm-2.0-flash-experimental\n",
      "- models/gemma-3-1b-it\n",
      "- models/gemma-3-4b-it\n",
      "- models/gemma-3-12b-it\n",
      "- models/gemma-3-27b-it\n",
      "- models/gemma-3n-e4b-it\n",
      "- models/gemma-3n-e2b-it\n",
      "- models/gemini-flash-latest\n",
      "- models/gemini-flash-lite-latest\n",
      "- models/gemini-pro-latest\n",
      "- models/gemini-2.5-flash-lite\n",
      "- models/gemini-2.5-flash-image-preview\n",
      "- models/gemini-2.5-flash-image\n",
      "- models/gemini-2.5-flash-preview-09-2025\n",
      "- models/gemini-2.5-flash-lite-preview-09-2025\n",
      "- models/gemini-robotics-er-1.5-preview\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759844543.896133 36142634 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Best practice: store your key as an environment variable\n",
    "# Or replace \"YOUR_API_KEY\" with your actual key string for a quick test\n",
    "genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\", \"YOUR_API_KEY\"))\n",
    "\n",
    "print(\"Available Models:\\n\")\n",
    "\n",
    "# List all models and check which ones support the 'generateContent' method\n",
    "for model in genai.list_models():\n",
    "  if 'generateContent' in model.supported_generation_methods:\n",
    "    print(f\"- {model.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9e3ea",
   "metadata": {
    "id": "01e9e3ea"
   },
   "source": [
    "## 5. Benchmark Runner\n",
    "\n",
    "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
    "\n",
    "*   Gross Margin Trend (or NIM if Bank)\n",
    "    *   Query: \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
    "    *   Expected Output: A quarterly table of Gross Margin % (or NIM % if bank).\n",
    "\n",
    "*   Operating Expenses (Opex) YoY for 3 Years\n",
    "    *   Query: \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
    "    *   Expected Output: A 3-year Opex table (absolute numbers and % change).\n",
    "\n",
    "*   Operating Efficiency Ratio\n",
    "    *   Query: \"Calculate the Operating Efficiency Ratio (Opex √∑ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
    "    *   Expected Output: Table with Opex, Operating Income, and calculated ratio for 3 years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d12439",
   "metadata": {},
   "source": [
    "### Gemini Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e435346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Stage2.py ‚Äî DEFINITIVE FINAL VERSION\n",
    "# Gemini vision plus pdfplumber\n",
    "# \"\"\"\n",
    "\n",
    "# from __future__ import annotations\n",
    "# import os, re, json, math, traceback\n",
    "# from typing import List, Dict, Any, Optional\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import time, contextlib\n",
    "\n",
    "# # --- Logging Setup ---\n",
    "# @contextlib.contextmanager\n",
    "# def timeblock(row: dict, key: str):\n",
    "#     t0 = time.perf_counter()\n",
    "#     try:\n",
    "#         yield\n",
    "#     finally:\n",
    "#         row[key] = round((time.perf_counter() - t0) * 1000.0, 2)\n",
    "\n",
    "# class _Instr:\n",
    "#     def __init__(self):\n",
    "#         self.rows = []\n",
    "#     def log(self, row):\n",
    "#         self.rows.append(row)\n",
    "#     def df(self):\n",
    "#         cols = ['Query','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','Tools']\n",
    "#         df = pd.DataFrame(self.rows)\n",
    "#         for c in cols:\n",
    "#             if c not in df:\n",
    "#                 df[c] = None\n",
    "#         return df[cols]\n",
    "\n",
    "# instr = _Instr()\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# # --- Configuration ---\n",
    "# VERBOSE = bool(int(os.environ.get(\"AGENT_CFO_VERBOSE\", \"1\")))\n",
    "# LLM_BACKEND = \"gemini\"\n",
    "# GEMINI_MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "\n",
    "# # --- Global Variables ---\n",
    "# kb: Optional[pd.DataFrame] = None\n",
    "# texts: Optional[np.ndarray] = None\n",
    "# index, bm25, EMB = None, None, None\n",
    "# _HAVE_FAISS, _HAVE_BM25, _INITIALIZED = False, False, False\n",
    "\n",
    "\n",
    "# # === Groq / OpenAI LLM config ===\n",
    "# import os\n",
    "# from openai import OpenAI\n",
    "\n",
    "# LLM_PROVIDER = os.getenv(\"LLM_PROVIDER\", \"groq\").lower()  # \"groq\" | \"openai\"\n",
    "# # Good fast defaults on Groq:\n",
    "# #   - \"openai/gpt-oss-20b\" (supports Responses API + built-in tools)\n",
    "# #   - \"llama-3.3-70b-versatile\" (chat.completions)\n",
    "# GROQ_MODEL   = os.getenv(\"GROQ_MODEL\", \"openai/gpt-oss-20b\")\n",
    "# OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")  # if you switch back to OpenAI\n",
    "\n",
    "# def _make_llm_client():\n",
    "#     if LLM_PROVIDER == \"groq\":\n",
    "#         api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "#         if not api_key:\n",
    "#             raise RuntimeError(\"Missing GROQ_API_KEY\")\n",
    "#         return OpenAI(api_key=api_key, base_url=\"https://api.groq.com/openai/v1\"), GROQ_MODEL\n",
    "#     else:\n",
    "#         api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "#         if not api_key:\n",
    "#             raise RuntimeError(\"Missing OPENAI_API_KEY\")\n",
    "#         return OpenAI(api_key=api_key), OPENAI_MODEL\n",
    "\n",
    "# def _llm_respond(prompt: str, system: str = \"You are a helpful finance analyst.\") -> str:\n",
    "#     \"\"\"\n",
    "#     Unified LLM call:\n",
    "#       - If LLM_PROVIDER is 'groq' or 'openai', use the OpenAI SDK (Groq-compatible base_url when set).\n",
    "#       - Else, caller should fall back to Gemini via _call_llm.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         client, model = _make_llm_client()\n",
    "#     except Exception as e:\n",
    "#         raise RuntimeError(f\"LLM client init failed: {e}\")\n",
    "\n",
    "#     # Prefer chat.completions for generality (works on Groq + OpenAI)\n",
    "#     try:\n",
    "#         chat = client.chat.completions.create(\n",
    "#             model=model,\n",
    "#             messages=[\n",
    "#                 {\"role\": \"system\", \"content\": system},\n",
    "#                 {\"role\": \"user\", \"content\": prompt},\n",
    "#             ],\n",
    "#             temperature=0.2,\n",
    "#         )\n",
    "#         return chat.choices[0].message.content.strip()\n",
    "#     except Exception:\n",
    "#         # Fallback: Responses API (useful for Groq GPT-OSS models)\n",
    "#         resp = client.responses.create(\n",
    "#             model=model,\n",
    "#             input=f\"System: {system}\\n\\nUser: {prompt}\"\n",
    "#         )\n",
    "#         text = getattr(resp, \"output_text\", \"\") or \"\"\n",
    "#         return str(text).strip()\n",
    "        \n",
    "        \n",
    "# # --- Core Logic Functions ---\n",
    "# def _classify_query(q: str) -> Optional[str]:\n",
    "#     ql = q.lower()\n",
    "#     if re.search(r\"\\boperating\\s+efficiency\\s+ratio\\b|\\boer\\b\", ql) or (\"√∑\" in ql and \"operating\" in ql and \"income\" in ql):\n",
    "#         return \"oer\"\n",
    "#     if \"nim\" in ql or \"net interest margin\" in ql: \n",
    "#         return \"nim\"\n",
    "#     if \"opex\" in ql or \"operating expense\" in ql or re.search(r\"\\bexpenses\\b\", ql): \n",
    "#         return \"opex\"\n",
    "#     if re.search(r\"\\b(total\\s+income|operating\\s+income)\\b\", ql):\n",
    "#         return \"income\"\n",
    "#     if re.search(r\"\\bcti\\b|cost[\\s\\-_\\/]*to?\\s*[\\s\\-_\\/]*income\", ql): \n",
    "#         return \"cti\"\n",
    "#     return None\n",
    "\n",
    "# class _EmbedLoader:\n",
    "#     def __init__(self):\n",
    "#         self.impl, self.dim, self.name, self.fn = None, None, None, None\n",
    "#     def embed(self, texts: List[str]) -> np.ndarray:\n",
    "#         if self.impl is None:\n",
    "#             try:\n",
    "#                 from sentence_transformers import SentenceTransformer\n",
    "#                 model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "#                 st = SentenceTransformer(model_name)\n",
    "#                 self.impl, self.dim = (\"st\", model_name), st.get_sentence_embedding_dimension()\n",
    "#                 self.fn = lambda b: st.encode(b, normalize_embeddings=True).astype(np.float32)\n",
    "#             except ImportError: raise RuntimeError(\"sentence-transformers not installed.\")\n",
    "#         return self.fn(texts)\n",
    "\n",
    "# def init_stage2(out_dir: str = \"data\"):\n",
    "#     global kb, texts, index, bm25, _HAVE_FAISS, _HAVE_BM25, _INITIALIZED, EMB\n",
    "#     os.environ[\"AGENT_CFO_OUT_DIR\"] = out_dir\n",
    "#     paths = [os.path.join(out_dir, f) for f in [\"kb_chunks.parquet\", \"kb_texts.npy\", \"kb_index.faiss\"]]\n",
    "#     if not all(os.path.exists(p) for p in paths): raise RuntimeError(f\"KB artifacts not found in '{out_dir}'.\")\n",
    "#     kb, texts = pd.read_parquet(paths[0]), np.load(paths[1], allow_pickle=True)\n",
    "#     try:\n",
    "#         import faiss\n",
    "#         _HAVE_FAISS, index = True, faiss.read_index(paths[2])\n",
    "#     except ImportError: _HAVE_FAISS, index = False, None\n",
    "#     try:\n",
    "#         from rank_bm25 import BM25Okapi\n",
    "#         _HAVE_BM25, bm25 = True, BM25Okapi([str(t).lower().split() for t in texts])\n",
    "#     except ImportError: _HAVE_BM25, bm25 = False, None\n",
    "#     EMB = _EmbedLoader()\n",
    "#     _INITIALIZED = True\n",
    "#     if VERBOSE: print(f\"[Stage2] Initialized successfully from '{out_dir}'.\")\n",
    "\n",
    "# def _ensure_init():\n",
    "#     if not _INITIALIZED: raise RuntimeError(\"Stage2 not initialized. Call init_stage2() first.\")\n",
    "\n",
    "# def _detect_last_n_years(q: str) -> Optional[int]:\n",
    "#     m = re.search(r\"last\\s+(\\d+|three|five)\\s+(fiscal\\s+)?years?\", q, re.I)\n",
    "#     if m:\n",
    "#         try:\n",
    "#             val = m.group(1).lower();\n",
    "#             if val == 'three': return 3\n",
    "#             if val == 'five': return 5\n",
    "#             return int(val)\n",
    "#         except: return None\n",
    "#     return None\n",
    "\n",
    "# def _detect_last_n_quarters(q: str) -> Optional[int]:\n",
    "#     m = re.search(r\"last\\s+(\\d+|five)\\s+quarters\", q, re.I)\n",
    "#     if m:\n",
    "#         try:\n",
    "#             val = m.group(1).lower();\n",
    "#             if val == 'five': return 5\n",
    "#             return int(val)\n",
    "#         except: return None\n",
    "#     return None\n",
    "\n",
    "# def hybrid_search(query: str, top_k=12, alpha=0.6) -> List[Dict[str, Any]]:\n",
    "#     _ensure_init()\n",
    "#     vec_scores, bm25_scores = {}, {}\n",
    "#     if _HAVE_FAISS and index and EMB:\n",
    "#         qv = EMB.embed([query]); qv /= np.linalg.norm(qv, axis=1, keepdims=True)\n",
    "#         sims, ids = index.search(qv.astype(np.float32), top_k * 4)\n",
    "#         vec_scores = {int(i): float(s) for i, s in zip(ids[0], sims[0]) if i != -1}\n",
    "#     if _HAVE_BM25 and bm25:\n",
    "#         scores = bm25.get_scores(query.lower().split())\n",
    "#         top_idx = np.argsort(scores)[-top_k*4:]\n",
    "#         bm25_scores = {int(i): float(scores[i]) for i in top_idx}\n",
    "    \n",
    "#     fused = {k: (alpha * vec_scores.get(k, 0)) + ((1 - alpha) * (bm25_scores.get(k, 0) / (max(bm25_scores.values()) or 1.0))) for k in set(vec_scores) | set(bm25_scores)}\n",
    "    \n",
    "#     is_annual_query = bool(re.search(r\"\\bfy\\b|fiscal\\s+year|last\\s+\\d+\\s+years\", query, re.I))\n",
    "#     year_match = re.search(r'\\b(20\\d{2})\\b', query)\n",
    "#     desired_year = int(year_match.group(1)) if year_match else None\n",
    "\n",
    "#     qtype = _classify_query(query)\n",
    "#     for i in fused:\n",
    "#         meta = kb.iloc[i]\n",
    "#         boost = 0.0\n",
    "#         text_l = str(texts[i]).lower()\n",
    "#         # --- Extended domain-aware features ---\n",
    "#         file_l = str(meta.file).lower()\n",
    "#         section_l = (str(meta.section_hint).lower() if isinstance(meta.section_hint, str) else \"\")\n",
    "#         mentions_nim = (\"net interest margin\" in text_l) or re.search(r\"\\bnim\\b\", text_l)\n",
    "#         mentions_percent_nim = bool(re.search(r\"net\\s+interest\\s+margin[^%]{0,200}%|([0-9]+(?:\\.[0-9]+)?)\\s*%\\s*(?:p|pts|percentage\\s*points)?\", text_l, flags=re.I))\n",
    "#         mentions_expenses = (\"operating expenses\" in text_l) or re.search(r\"\\bexpenses\\b\", text_l)\n",
    "#         has_money_units = bool(re.search(r\"\\(\\$?\\s*m\\)|s\\$\\s*m|\\(\\$m\\)|\\bmillion\\b|\\bmn\\b|\\bbn\\b|\\bbillion\\b\", text_l, flags=re.I))\n",
    "#         is_tableish = section_l.startswith(\"table_p\")\n",
    "#         is_vision = \"vision_summary\" in section_l\n",
    "#         is_quarterly_doc = pd.notna(meta.quarter)\n",
    "#         is_press_or_trading = bool(re.search(r\"press[_\\s-]?statement|trading[_\\s-]?update\", file_l))\n",
    "#         is_corp_gov = \"corporate governance\" in text_l or \"board of directors\" in text_l\n",
    "#         is_cfo_or_perf = bool(re.search(r\"cfo[_\\s-]?presentation|performance[_\\s-]?summary\", file_l))\n",
    "\n",
    "#         # Year/annual vs quarterly alignment\n",
    "#         if desired_year and pd.notna(meta.year):\n",
    "#             if int(meta.year) == desired_year:\n",
    "#                 boost += 5.0\n",
    "#             else:\n",
    "#                 boost -= 5.0\n",
    "\n",
    "#         is_annual_doc = pd.isna(meta.quarter)\n",
    "#         if is_annual_query:\n",
    "#             boost += 5.0 if is_annual_doc else -5.0\n",
    "#         else:\n",
    "#             boost += 2.0 if not is_annual_doc else 0.0\n",
    "\n",
    "#         # --- Domain-aware boosts ---\n",
    "#         if qtype == \"nim\":\n",
    "#             # Prefer quarterly docs and chunks explicitly mentioning NIM with a %\n",
    "#             if is_quarterly_doc:\n",
    "#                 boost += 4.0\n",
    "#             if mentions_nim:\n",
    "#                 boost += 4.0\n",
    "#             if mentions_nim and mentions_percent_nim:\n",
    "#                 boost += 6.0\n",
    "#             # Strongly favour structured sources\n",
    "#             if is_tableish and mentions_nim:\n",
    "#                 boost += 5.0\n",
    "#             if is_vision and (mentions_nim or \"net interest margin\" in text_l):\n",
    "#                 boost += 5.0\n",
    "#             # Penalise generic prose that often lacks explicit % values\n",
    "#             if is_press_or_trading and not mentions_percent_nim:\n",
    "#                 boost -= 10.0\n",
    "\n",
    "#         if qtype == \"opex\" or qtype == \"oer\" or qtype == \"cti\":\n",
    "#             # Prefer chunks that talk about (operating) expenses with monetary units\n",
    "#             if mentions_expenses and has_money_units:\n",
    "#                 boost += 6.0\n",
    "#             # Extra rewards for structured/table/vision sources\n",
    "#             if is_tableish and mentions_expenses:\n",
    "#                 boost += 3.0\n",
    "#             if is_vision and mentions_expenses:\n",
    "#                 boost += 4.0\n",
    "#             # Vision summary pages tend to have \"For FYXXXX, Opex were NNNN million.\"\n",
    "#             if is_vision and (mentions_expenses):\n",
    "#                 boost += 5.0\n",
    "#             # For Opex/CTI/OER annual asks, prefer annual docs\n",
    "#             if is_annual_query and is_annual_doc:\n",
    "#                 boost += 3.0\n",
    "                \n",
    "#         if qtype == \"income\":\n",
    "#             if \"total income\" in text_l:\n",
    "#                 boost += 6.0\n",
    "#             if is_tableish:\n",
    "#                 boost += 3.0\n",
    "#             if is_vision:\n",
    "#                 boost += 4.0\n",
    "#             if is_annual_query and is_annual_doc:\n",
    "#                 boost += 3.0\n",
    "\n",
    "#         # Global penalties for off-topic governance prose\n",
    "#         if is_corp_gov:\n",
    "#             boost -= 8.0\n",
    "#         # Light reward for CFO/performance decks (usually contain crisp metrics)\n",
    "#         if is_cfo_or_perf:\n",
    "#             boost += 2.0\n",
    "\n",
    "#         fused[i] += boost\n",
    "        \n",
    "#     hits = [{\"doc_id\": kb.iloc[i].doc_id, \"file\": kb.iloc[i].file, \"page\": int(kb.iloc[i].page), \"year\": int(kb.iloc[i].year) if pd.notna(kb.iloc[i].year) else None, \"quarter\": int(kb.iloc[i].quarter) if pd.notna(kb.iloc[i].quarter) else None, \"section_hint\": kb.iloc[i].section_hint, \"score\": float(score)} for i, score in sorted(fused.items(), key=lambda x: x[1], reverse=True)[:top_k]]\n",
    "#     return hits\n",
    "\n",
    "# def format_citation(hit: dict) -> str:\n",
    "#     parts = [hit.get(\"file\", \"?\")]\n",
    "#     y = hit.get(\"year\"); q = hit.get(\"quarter\")\n",
    "#     if y is not None and q is not None: parts.append(f\"{int(q)}Q{str(int(y))[-2:]}\")\n",
    "#     elif y is not None: parts.append(str(int(y)))\n",
    "#     if hit.get(\"page\") is not None: parts.append(f\"p.{int(hit['page'])}\")\n",
    "#     sec = str(hit.get(\"section_hint\") or \"\").strip()\n",
    "#     if sec: parts.append(sec)\n",
    "#     tab = hit.get(\"table_id\")\n",
    "#     if tab: parts.append(f\"table {tab}\")\n",
    "#     return \", \".join(parts)\n",
    "\n",
    "# def _latest_fys(kb: pd.DataFrame, n=3):\n",
    "#     df = kb.copy()\n",
    "#     df[\"y\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "#     ydf = df[df[\"quarter\"].isna()].dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "#     if ydf.empty:\n",
    "#         ydf = df.dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "#     years = [int(y) for y in ydf[\"y\"].drop_duplicates().head(n)]\n",
    "#     return years\n",
    "\n",
    "# def _latest_quarters(kb: pd.DataFrame, n=5):\n",
    "#     df = kb.copy()\n",
    "#     df[\"y\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "#     df[\"q\"] = pd.to_numeric(df[\"quarter\"], errors=\"coerce\")\n",
    "#     qdf = df.dropna(subset=[\"y\",\"q\"]).sort_values([\"y\",\"q\"], ascending=[False, False])\n",
    "#     pairs = qdf[[\"y\",\"q\"]].drop_duplicates().head(20).values.tolist()\n",
    "#     # return unique up to n, ordered newest‚Üíoldest\n",
    "#     out, seen = [], set()\n",
    "#     for y,q in pairs:\n",
    "#         k = (int(y), int(q))\n",
    "#         if k not in seen:\n",
    "#             seen.add(k); out.append(k)\n",
    "#         if len(out) == n: break\n",
    "#     return out\n",
    "\n",
    "# def _parse_tool_kv(s: str):\n",
    "#     # Parses \"Value: 8895, Source: file.pdf, 2024, p.15\"\n",
    "#     m = re.search(r\"Value:\\s*([^\\n,]+)\\s*,\\s*Source:\\s*(.*)\", s, flags=re.S)\n",
    "#     if not m: return None, None\n",
    "#     val = m.group(1).strip()\n",
    "#     src = m.group(2).strip()\n",
    "#     return val, src\n",
    "\n",
    "# def _fmt_num(x):\n",
    "#     try: return f\"{float(x):,.2f}\"\n",
    "#     except: return x\n",
    "\n",
    "# def _unique_list(xs, cap=5):\n",
    "#     out, seen = [], set()\n",
    "#     for s in xs:\n",
    "#         if not s: continue\n",
    "#         if s not in seen:\n",
    "#             seen.add(s); out.append(s)\n",
    "#         if len(out) >= cap: break\n",
    "#     return out\n",
    "\n",
    "# def baseline_nim_5q() -> dict:\n",
    "#     \"\"\"\n",
    "#     NIM for the last 5 quarters (Group):\n",
    "#       - Use the dedicated NIM series parser (tool_nim_series) which aggregates across docs.\n",
    "#       - Parse its result into a table.\n",
    "#       - Add lightweight citations by retrieving a top hit per quarter.\n",
    "#     \"\"\"\n",
    "#     _ensure_init()\n",
    "\n",
    "#     # 1) Get the consolidated series (Group) from structured/vision + table text\n",
    "#     series_str = tool_nim_series(last_n=5, variant=\"group\")\n",
    "\n",
    "#     # Expect format: \"NIM (Group) last 5 quarters ‚Üí 2Q25: 2.05%, 1Q25: 2.12%, ...\"\n",
    "#     items = re.findall(r\"([1-4]Q\\d{2})\\s*:\\s*([0-9]+(?:\\.[0-9]+)?)%\", series_str)\n",
    "#     if not items:\n",
    "#         # Fall back to the original per-quarter extraction if parsing failed\n",
    "#         pairs = _latest_quarters(kb, n=5)\n",
    "#         rows, cites = [], []\n",
    "#         for (y, q) in pairs:\n",
    "#             r = tool_table_extraction(f\"Net interest margin (%) for {int(q)}Q{int(y)}\")\n",
    "#             val, src = _parse_tool_kv(r)\n",
    "#             rows.append((f\"{q}Q{str(y)[-2:]}\", val or \"‚Äî\"))\n",
    "#             cites.append(src or r)\n",
    "#         lines = [\"NIM (%) ‚Äî last 5 quarters:\", \"Quarter | NIM (%)\", \"--------|--------\"]\n",
    "#         for qlab, v in rows:\n",
    "#             lines.append(f\"{qlab} | {v}\")\n",
    "#         lines.append(\"\\nCitations:\")\n",
    "#         for c in _unique_list(cites, cap=5):\n",
    "#             lines.append(f\"- {c}\")\n",
    "#         return {\"answer\": \"\\n\".join(lines), \"hits\": [], \"execution_log\": {\"fallback\": True}}\n",
    "\n",
    "#     # 2) Build table from parsed items (already newest‚Üíoldest in tool_nim_series)\n",
    "#     rows = [(q.upper(), v) for (q, v) in items]\n",
    "\n",
    "#     # 3) Lightweight citations: take the top hit per quarter\n",
    "#     def _cite_for_quarter(q_label: str) -> Optional[str]:\n",
    "#         hits = hybrid_search(f\"Net interest margin (%) {q_label}\", top_k=1)\n",
    "#         if not hits:\n",
    "#             return None\n",
    "#         return f\"Source: {format_citation(hits[0])}\"\n",
    "\n",
    "#     cites = []\n",
    "#     for qlab, _ in rows:\n",
    "#         c = _cite_for_quarter(qlab)\n",
    "#         if c:\n",
    "#             cites.append(c)\n",
    "#     cites = _unique_list(cites, cap=5)\n",
    "\n",
    "#     # 4) Render output\n",
    "#     out = [\"NIM (%) ‚Äî last 5 quarters (Group):\", \"Quarter | NIM (%)\", \"--------|--------\"]\n",
    "#     for qlab, v in rows:\n",
    "#         out.append(f\"{qlab} | {v}\")\n",
    "\n",
    "#     if cites:\n",
    "#         out.append(\"\\nCitations:\")\n",
    "#         for c in cites:\n",
    "#             out.append(f\"- {c}\")\n",
    "\n",
    "#     return {\"answer\": \"\\n\".join(out), \"hits\": [], \"execution_log\": {\"built_from\": \"tool_nim_series\"}}\n",
    "\n",
    "# # def baseline_run_integrated_precachinopex_3y() -> dict:\n",
    "# #     \"\"\"\n",
    "# #     Operating Expenses for last 3 fiscal years; deterministic extractor + YoY%.\n",
    "# #     \"\"\"\n",
    "# #     _ensure_init()\n",
    "# #     years = _latest_fys(kb, n=3)\n",
    "# #     rows, cites = [], []\n",
    "# #     for y in years:\n",
    "# #         r = tool_table_extraction(f\"Operating expenses for fiscal year {y}\")\n",
    "# #         val, src = _parse_tool_kv(r)\n",
    "# #         rows.append((y, val or \"‚Äî\"))\n",
    "# #         cites.append(src or r)\n",
    "\n",
    "# #     # sort newest‚Üíoldest\n",
    "# #     rows.sort(key=lambda t: t[0], reverse=True)\n",
    "# #     out = [\"Opex (S$ m) ‚Äî last 3 fiscal years:\", \"Year | Opex (S$ m) | YoY %\", \"-----|-------------|------\"]\n",
    "# #     for i,(yy,vv) in enumerate(rows):\n",
    "# #         yoy = \"\"\n",
    "# #         if i>0 and vv not in (\"‚Äî\",\"\",None) and rows[i-1][1] not in (\"‚Äî\",\"\",None):\n",
    "# #             try:\n",
    "# #                 cur = float(vv); prev = float(rows[i-1][1])\n",
    "# #                 yoy = f\"{((cur-prev)/prev)*100:,.1f}%\"\n",
    "# #             except: pass\n",
    "# #         out.append(f\"{yy} | { _fmt_num(vv) if vv!='‚Äî' else vv } | {yoy}\")\n",
    "\n",
    "# #     out.append(\"\\nCitations:\")\n",
    "# #     for c in _unique_list(cites, cap=5):\n",
    "# #         out.append(f\"- {c}\")\n",
    "\n",
    "# #     return {\"answer\":\"\\n\".join(out), \"hits\":[], \"execution_log\":{\"years\": years}}\n",
    "\n",
    "# # def baseline_efficiency_ratio_3y() -> dict:\n",
    "# #     \"\"\"\n",
    "# #     Operating Efficiency Ratio = Opex / Operating Income, last 3 fiscal years.\n",
    "# #     \"\"\"\n",
    "# #     _ensure_init()\n",
    "# #     years = _latest_fys(kb, n=3)\n",
    "# #     rows, cits = [], []\n",
    "# #     for y in years:\n",
    "# #         r1 = tool_table_extraction(f\"Operating expenses for fiscal year {y}\")\n",
    "# #         v_opex, c1 = _parse_tool_kv(r1)\n",
    "# #         r2 = tool_table_extraction(f\"Operating income for fiscal year {y}\")\n",
    "# #         v_oinc, c2 = _parse_tool_kv(r2)\n",
    "# #         rows.append((y, v_opex or \"‚Äî\", v_oinc or \"‚Äî\"))\n",
    "# #         cits.extend([c1 or r1, c2 or r2])\n",
    "\n",
    "# #     rows.sort(key=lambda t: t[0], reverse=True)\n",
    "# #     out = [\"Operating Efficiency Ratio (Opex √∑ Operating Income):\",\n",
    "# #            \"Year | Opex (S$ m) | Operating Income (S$ m) | Ratio\",\n",
    "# #            \"-----|-------------|-------------------------|------\"]\n",
    "# #     for (yy, o, inc) in rows:\n",
    "# #         ratio = \"‚Äî\"\n",
    "# #         try:\n",
    "# #             if o not in (\"‚Äî\",\"\",None) and inc not in (\"‚Äî\",\"\",None) and float(inc)!=0.0:\n",
    "# #                 ratio = f\"{(float(o)/float(inc))*100:,.1f}%\"\n",
    "# #         except: pass\n",
    "# #         out.append(f\"{yy} | {_fmt_num(o) if o!='‚Äî' else o} | {_fmt_num(inc) if inc!='‚Äî' else inc} | {ratio}\")\n",
    "\n",
    "# #     out.append(\"\\nCitations:\")\n",
    "# #     for c in _unique_list(cits, cap=5):\n",
    "# #         out.append(f\"- {c}\")\n",
    "\n",
    "# #     return {\"answer\":\"\\n\".join(out), \"hits\":[], \"execution_log\":{\"years\": years}}\n",
    "\n",
    "\n",
    "# def answer_with_llm(query: str, topk: int = 5) -> Dict[str, Any]:\n",
    "#     \"\"\"\n",
    "#     Baseline pipeline: single-pass retrieval + single LLM call (no planning, no tools).\n",
    "#       - Uses hybrid_search() for retrieval (vector + BM25).\n",
    "#       - Builds a compact CONTEXT from top-k chunks.\n",
    "#       - Calls the LLM once to synthesize an answer.\n",
    "#       - Ensures citations include report, year/quarter, and page.\n",
    "#     \"\"\"\n",
    "#     _ensure_init()\n",
    "    \n",
    "#     ql = query.lower()\n",
    "\n",
    "#     # Intent router for the 3 standardized prompts\n",
    "#     if \"net interest margin\" in ql or \"gross margin\" in ql:\n",
    "#         return baseline_nim_5q()\n",
    "\n",
    "#     # if \"operating expenses\" in ql and (\"last 3 fiscal years\" in ql or \"year-on-year\" in ql or \"yoy\" in ql):\n",
    "#     #     return baseline_opex_3y()\n",
    "\n",
    "#     # if (\"operating efficiency ratio\" in ql) or (\"opex √∑ operating income\" in ql) or (\"opex / operating income\" in ql):\n",
    "#     #     return baseline_efficiency_ratio_3y()\n",
    "\n",
    "#     def _pos_of_docid(did: str) -> Optional[int]:\n",
    "#         mask = (kb[\"doc_id\"] == did).to_numpy()\n",
    "#         idxs = np.flatnonzero(mask)\n",
    "#         return int(idxs[0]) if idxs.size else None\n",
    "\n",
    "#     # Opex-aware retrieval expansion (more table/vision leaning)\n",
    "#     ql = query.lower()\n",
    "#     is_opex = (\"opex\" in ql) or (\"operating expense\" in ql) or re.search(r\"\\bexpenses\\b\", ql)\n",
    "\n",
    "#     if is_opex:\n",
    "#         expanded = query + \" | Operating expenses Opex ($m) fiscal year table vision_summary\"\n",
    "#         hits = hybrid_search(expanded, top_k=max(1, int(topk) * 2))  # e.g., 10 if topk=5\n",
    "#     else:\n",
    "#         hits = hybrid_search(query, top_k=max(1, int(topk)))\n",
    "\n",
    "#     if not hits:\n",
    "#         return \"No relevant material found.\"\n",
    "\n",
    "#     # Build context and citations\n",
    "#     ctx_lines, cits = [], []\n",
    "#     for h in hits[:topk]:\n",
    "#         pos = _pos_of_docid(h.get(\"doc_id\", \"\"))\n",
    "#         snippet = (str(texts[pos]) if pos is not None else \"\")\n",
    "#         snippet = re.sub(r\"\\s+\", \" \", snippet).strip()\n",
    "#         if snippet:\n",
    "#             ctx_lines.append(f\"- {snippet[:800]}\")\n",
    "#         cits.append(format_citation(h))\n",
    "\n",
    "#     # Strict prompt: stick to retrieved text; include citations at the end\n",
    "#     prompt = (\n",
    "#         \"You are a finance analyst.\\n\"\n",
    "#         \"Using ONLY the CONTEXT below, answer the USER QUERY. Quote numbers exactly as reported.\\n\"\n",
    "#         \"If the numbers are not present in CONTEXT, say you cannot find them.\\n\"\n",
    "#         \"End with a bulleted list of citations (report name, year/quarter, page, section if present).\\n\\n\"\n",
    "#         f\"USER QUERY:\\n{query}\\n\\nCONTEXT:\\n\" + \"\\n\".join(ctx_lines) +\n",
    "#         \"\\n\\nFORMAT:\\nAnswer text.\\n\\nCitations:\\n- <report (year/quarter), p.X, section>\\n\"\n",
    "#     )\n",
    "\n",
    "#     answer = _call_llm(prompt, dry_run=False)\n",
    "\n",
    "#     # Ensure at least some citations if the model forgets\n",
    "#     if \"Citations:\" not in answer:\n",
    "#         answer += \"\\n\\nCitations:\\n\" + \"\\n\".join(f\"- {c}\" for c in cits[:3])\n",
    "\n",
    "#     return {\"answer\": answer, \"hits\": hits[:min(5, len(hits))].to_dict(\"records\") if hasattr(hits, \"to_dict\") else [], \"execution_log\": None}\n",
    "\n",
    "\n",
    "# def _call_llm(prompt: str, dry_run: bool = False) -> str:\n",
    "#     if dry_run:\n",
    "#         return '{\"plan\": []}'\n",
    "\n",
    "#     # Prefer Groq/OpenAI if configured\n",
    "#     if os.getenv(\"LLM_PROVIDER\", \"\").lower() in (\"groq\", \"openai\"):\n",
    "#         try:\n",
    "#             return _llm_respond(\n",
    "#                 prompt,\n",
    "#                 system=\"You are a precise finance analyst. Be concise and cite sources provided by the tools.\"\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             return f\"LLM Generation Failed (Groq/OpenAI path): {e}\"\n",
    "\n",
    "#     # Fallback to Gemini\n",
    "#     try:\n",
    "#         from google import generativeai as genai\n",
    "#         genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "#         model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "#         safety_settings = [\n",
    "#             {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "#             {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
    "#             {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "#             {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
    "#         ]\n",
    "#         out = model.generate_content(prompt, safety_settings=safety_settings)\n",
    "#         return getattr(out, \"text\", \"\") or \"LLM returned empty response.\"\n",
    "#     except Exception as e:\n",
    "#         return f\"LLM Generation Failed (Gemini path): {e}\"\n",
    "\n",
    "# def tool_calculator(expression: str) -> str:\n",
    "#     try:\n",
    "#         s = str(expression)\n",
    "\n",
    "#         # Guard: unresolved placeholders like ${var}\n",
    "#         placeholders = re.findall(r\"\\$\\{([^}]+)\\}\", s)\n",
    "#         if placeholders:\n",
    "#             return f\"Error: unresolved placeholders: {', '.join(placeholders)}\"\n",
    "\n",
    "#         # Normalizations\n",
    "#         s = re.sub(r'(?<=\\d),(?=\\d{3}\\b)', '', s)               # 12,345 -> 12345\n",
    "#         s = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*%', r'(\\1/100)', s)       # 12% -> (12/100)\n",
    "#         s = re.sub(r'(?i)[s]?\\$\\s*', '', s)                      # S$ / $ -> strip\n",
    "#         s = re.sub(r'(?i)\\b(bn|billion|b)\\b', 'e9', s)           # bn -> e9\n",
    "#         s = re.sub(r'(?i)\\b(mn|million|m)\\b', 'e6', s)           # mn -> e6\n",
    "\n",
    "#         # Safety: allow only digits, + - * / ( ) . e E and spaces\n",
    "#         safe = re.sub(r'[^0-9eE\\+\\-*/(). ]', '', s)\n",
    "\n",
    "#         result = eval(safe)\n",
    "#         return f\"Result: {result}\"\n",
    "#     except Exception as e:\n",
    "#         return f\"Error: {e}\"\n",
    "\n",
    "# def _desired_periods_from_query(query: str) -> list[tuple[int|None, int|None]]:\n",
    "#     out = []\n",
    "#     # Quarters like 1Q25\n",
    "#     for m in re.finditer(r\"\\b([1-4])Q(\\d{2})\\b\", query, re.I):\n",
    "#         out.append((2000 + int(m.group(2)), int(m.group(1))))\n",
    "\n",
    "#     # FY2024 / FY 2024\n",
    "#     for m in re.finditer(r\"\\bFY\\s?(20\\d{2})\\b\", query, re.I):\n",
    "#         out.append((int(m.group(1)), None))\n",
    "\n",
    "#     # \"fiscal year 2024\"\n",
    "#     for m in re.finditer(r\"\\bfiscal\\s+year\\s+(20\\d{2})\\b\", query, re.I):\n",
    "#         out.append((int(m.group(1)), None))\n",
    "\n",
    "#     # bare year (only if nothing else found)\n",
    "#     if not out:\n",
    "#         m = re.search(r\"\\b(20\\d{2})\\b\", query)\n",
    "#         if m:\n",
    "#             out.append((int(m.group(1)), None))\n",
    "\n",
    "#     return out\n",
    "\n",
    "# def tool_table_extraction(query: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Finds a single reported data point from the knowledge base using hybrid search,\n",
    "#     then extracts and cleans the most likely numerical value from the retrieved text.\n",
    "\n",
    "#     Improvements vs. previous version:\n",
    "#       ‚Ä¢ Robust row-to-text mapping using positional index (not label).\n",
    "#       ‚Ä¢ Query-aware extraction (Opex ‚Üí 'million' values; NIM ‚Üí percentages).\n",
    "#       ‚Ä¢ Period-aware filtering (prefer sentences containing requested FY/quarter).\n",
    "#       ‚Ä¢ Avoids 4-digit years being misread as values.\n",
    "#       ‚Ä¢ Falls back through multiple heuristics and multiple hits if needed.\n",
    "#     \"\"\"\n",
    "#     if VERBOSE:\n",
    "#         print(f\"  [Tool Call: table_extraction] with query: '{query}'\")\n",
    "\n",
    "#     hits = hybrid_search(query, top_k=12)\n",
    "#     # --- Vision-first rescue: ensure year-matched vision_summary candidates are in the pool ---\n",
    "#     try:\n",
    "#         desired_periods = _desired_periods_from_query(query)\n",
    "#         desired_years = [y for (y, q) in desired_periods if y]\n",
    "#         sh_series = kb[\"section_hint\"].astype(str).str.contains(\"vision_summary\", case=False, na=False)\n",
    "#         mask = sh_series\n",
    "#         if desired_years:\n",
    "#             mask = mask & kb[\"year\"].isin(desired_years)\n",
    "#         vis_idxs = np.flatnonzero(mask.to_numpy())\n",
    "#         base_score = (min([float(h.get(\"score\") or 0.0) for h in hits]) - 1.0) if hits else 0.0\n",
    "#         extra_hits = []\n",
    "#         for idx in vis_idxs[:6]:\n",
    "#             row = kb.iloc[idx]\n",
    "#             extra_hits.append({\n",
    "#                 \"doc_id\": row.doc_id,\n",
    "#                 \"file\": row.file,\n",
    "#                 \"page\": int(row.page) if pd.notna(row.page) else None,\n",
    "#                 \"year\": int(row.year) if pd.notna(row.year) else None,\n",
    "#                 \"quarter\": int(row.quarter) if pd.notna(row.quarter) else None,\n",
    "#                 \"section_hint\": row.section_hint,\n",
    "#                 \"score\": base_score\n",
    "#             })\n",
    "#         if extra_hits:\n",
    "#             hits = hits + extra_hits\n",
    "\n",
    "#         # Deduplicate by doc_id\n",
    "#         seen = set()\n",
    "#         deduped = []\n",
    "#         for h in hits:\n",
    "#             did = h.get(\"doc_id\")\n",
    "#             if did in seen:\n",
    "#                 continue\n",
    "#             seen.add(did)\n",
    "#             deduped.append(h)\n",
    "#         hits = deduped\n",
    "\n",
    "#         # --- Priority ordering of hits: vision first, then tables, then others\n",
    "#         vision_hits = [h for h in hits if \"vision_summary\" in str(h.get(\"section_hint\") or \"\").lower()]\n",
    "#         table_hits  = [h for h in hits if str(h.get(\"section_hint\") or \"\").lower().startswith(\"table_p\")]\n",
    "#         other_hits  = [h for h in hits if h not in vision_hits and h not in table_hits]\n",
    "#     except Exception:\n",
    "#         # Fail open; rely on original hits if rescue logic errors out\n",
    "#         vision_hits, table_hits, other_hits = [], [], []\n",
    "#         pass\n",
    "\n",
    "#     if not hits:\n",
    "#         return \"Error: No relevant documents found.\"\n",
    "\n",
    "#     # Helper: map a doc_id to the correct position in `texts` using a boolean mask.\n",
    "#     def _pos_of_docid(did: str) -> Optional[int]:\n",
    "#         mask = (kb[\"doc_id\"] == did).to_numpy()\n",
    "#         idxs = np.flatnonzero(mask)\n",
    "#         return int(idxs[0]) if idxs.size else None\n",
    "\n",
    "#     # Helper: safer float parsing (strip commas etc.)\n",
    "#     def _clean_number(s: str) -> Optional[str]:\n",
    "#         t = s.strip()\n",
    "#         t = re.sub(r\"[,\\s]\", \"\", t)\n",
    "#         # Reject years (e.g., 2024) and obviously huge integers without unit context\n",
    "#         if re.fullmatch(r\"\\d{4}\", t):\n",
    "#             return None\n",
    "#         try:\n",
    "#             float(t)\n",
    "#             return t\n",
    "#         except Exception:\n",
    "#             return None\n",
    "\n",
    "#     # Helper: plausibility check for NIM\n",
    "#     def _plausible_nim_value(x: float) -> bool:\n",
    "#         # DBS group NIM is realistically ~0.5%‚Äì3.5%\n",
    "#         try:\n",
    "#             return 0.5 <= float(x) <= 3.5\n",
    "#         except Exception:\n",
    "#             return False\n",
    "        \n",
    "#     # Helper: choose the best number from text given the query intent\n",
    "#     def _extract_value(text: str, query: str) -> Optional[str]:\n",
    "#         ql = query.lower()\n",
    "#         is_nim = (\"nim\" in ql) or (\"net interest margin\" in ql)\n",
    "#         is_opex = (\"opex\" in ql) or (\"operating expense\" in ql) or re.search(r\"\\bexpenses\\b\", ql)\n",
    "#         is_income = re.search(r\"\\b(total\\s+income|operating\\s+income)\\b\", ql) is not None\n",
    "#         # Detect if this is an annual ask (not a specific quarter)\n",
    "#         annual_ask = not re.search(r\"\\b[1-4]Q\\d{2}\\b\", query, re.I)\n",
    "\n",
    "#         # If the query mentions a specific period, try to narrow the search window.\n",
    "#         desired_periods = _desired_periods_from_query(query)\n",
    "#         windows = []\n",
    "#         if desired_periods:\n",
    "#             for (yy, qq) in desired_periods:\n",
    "#                 if yy and qq:\n",
    "#                     tag = fr\"{qq}q{str(yy)[-2:]}\"\n",
    "#                 elif yy:\n",
    "#                     tag = fr\"fy{yy}\"\n",
    "#                 else:\n",
    "#                     tag = None\n",
    "#                 if tag:\n",
    "#                     m = re.search(tag, text, flags=re.I)\n",
    "#                     if m:\n",
    "#                         # take a sentence-sized window around the tag\n",
    "#                         start = max(0, text.rfind(\".\", 0, m.start()))\n",
    "#                         end = text.find(\".\", m.end())\n",
    "#                         if end == -1:\n",
    "#                             end = len(text)\n",
    "#                         windows.append(text[start:end])\n",
    "#         if not windows:\n",
    "#             # fallback: whole text\n",
    "#             windows = [text]\n",
    "\n",
    "#         # Query-aware patterns\n",
    "#         # 1) NIM ‚Üí percentages, prioritizing text near \"net interest margin\"\n",
    "#         if is_nim:\n",
    "#             # 1) Strongly anchored: look for \"‚Ä¶margin was/to/at/of N.NN%\"\n",
    "#             for win in windows:\n",
    "#                 m = re.search(\n",
    "#                     r\"net\\s+interest\\s+margin[^%]{0,120}?(?:was|to|at|of)\\s*([0-9]+(?:\\.[0-9]+)?)\\s*%\",\n",
    "#                     win, flags=re.I | re.S\n",
    "#                 )\n",
    "#                 if m:\n",
    "#                     v = m.group(1)\n",
    "#                     if _plausible_nim_value(v):\n",
    "#                         return _clean_number(v)\n",
    "\n",
    "#             # 2) Vision-summary phrasing: \"Group/Commercial Book Net Interest Margin was 2.13%.\"\n",
    "#             for win in windows:\n",
    "#                 m = re.search(\n",
    "#                     r\"(?:group|commercial(?:\\s*book)?)\\s*net\\s+interest\\s+margin.*?(?:was|to|at|of)\\s*([0-9]+(?:\\.[0-9]+)?)\\s*%\",\n",
    "#                     win, flags=re.I | re.S\n",
    "#                 )\n",
    "#                 if m:\n",
    "#                     v = m.group(1)\n",
    "#                     if _plausible_nim_value(v):\n",
    "#                         return _clean_number(v)\n",
    "\n",
    "#             # 3) Anchored fallback: only if NIM is explicitly mentioned; pick the nearest plausible %\n",
    "#             for win in windows:\n",
    "#                 m_phrase = re.search(r\"net\\s+interest\\s+margin|\\bnim\\b\", win, flags=re.I)\n",
    "#                 if not m_phrase:\n",
    "#                     continue\n",
    "#                 best = None\n",
    "#                 best_dist = 1e9\n",
    "#                 for p in re.finditer(r\"([0-9]+(?:\\.[0-9]+)?)\\s*%\", win):\n",
    "#                     try:\n",
    "#                         val = float(p.group(1))\n",
    "#                     except Exception:\n",
    "#                         continue\n",
    "#                     if not _plausible_nim_value(val):\n",
    "#                         continue\n",
    "#                     dist = abs(p.start() - m_phrase.start())\n",
    "#                     if dist < best_dist:\n",
    "#                         best_dist = dist\n",
    "#                         best = p.group(1)\n",
    "#                 if best:\n",
    "#                     return _clean_number(best)\n",
    "\n",
    "#             # Do NOT fall back to non-% numbers for NIM; better to return None than a wrong value\n",
    "#             return None\n",
    "\n",
    "#         # 2) Opex / Operating Expenses ‚Üí numbers followed by a 'million/bn' unit\n",
    "#         if is_opex:\n",
    "#             # --- FAST PATH (Vision summary exact sentence for annual Opex) ---\n",
    "#             # Prefer the Vision-summary wording:\n",
    "#             # \"For FY2024, total Operating Expenses (Opex) were 8895 million.\"\n",
    "#             try:\n",
    "#                 desired_periods_fp = _desired_periods_from_query(query)\n",
    "#             except Exception:\n",
    "#                 desired_periods_fp = []\n",
    "#             target_years_fp = [yy for (yy, qq) in desired_periods_fp if yy and (qq is None)]\n",
    "#             if target_years_fp:\n",
    "#                 for yy in target_years_fp:\n",
    "#                     m_fp = re.search(\n",
    "#                         rf\"For\\s*FY{yy}\\s*,?\\s*total\\s+Operating\\s+Expenses\\s*\\(Opex\\)\\s*were\\s*([0-9][\\d,]*(?:\\.[0-9]+)?)\\s*(million|mn|m|bn|billion)\\b\",\n",
    "#                         text,\n",
    "#                         flags=re.I\n",
    "#                     )\n",
    "#                     if m_fp:\n",
    "#                         val_fp = _clean_number(m_fp.group(1)) or None\n",
    "#                         unit_fp = (m_fp.group(2) or \"\").lower()\n",
    "#                         if val_fp:\n",
    "#                             try:\n",
    "#                                 v_fp = float(val_fp)\n",
    "#                                 if unit_fp in (\"bn\", \"billion\", \"b\"):\n",
    "#                                     v_fp *= 1000.0\n",
    "#                                 # Annual Opex sanity range in $m for DBS scale\n",
    "#                                 if 2000.0 <= v_fp <= 15000.0:\n",
    "#                                     return (\"%g\" % v_fp)\n",
    "#                             except Exception:\n",
    "#                                 pass\n",
    "#             # Vision-summary phrasing: \"For FY2024, total Operating Expenses (Opex) were 8895 million.\"\n",
    "#             for win in windows:\n",
    "#                 m = re.search(\n",
    "#                     r\"operating\\s+expenses.*?(?:were|:)?\\s*([0-9][\\d,]*(?:\\.[0-9]+)?)\\s*(million|mn|m|bn|billion)\\b\",\n",
    "#                     win,\n",
    "#                     flags=re.I | re.S,\n",
    "#                 )\n",
    "#                 if m:\n",
    "#                     val = _clean_number(m.group(1))\n",
    "#                     unit = (m.group(2) or \"\").lower()\n",
    "#                     if val:\n",
    "#                         try:\n",
    "#                             v = float(val)\n",
    "#                             # Normalise units to millions\n",
    "#                             if unit in (\"bn\", \"billion\", \"b\"):\n",
    "#                                 v *= 1000.0\n",
    "#                             # Annual asks must be a sensible magnitude in $m (reject too-small or absurdly large)\n",
    "#                             if annual_ask and unit in (\"million\", \"mn\", \"m\", \"bn\", \"billion\", \"b\") and not (2000 <= v <= 15000):\n",
    "#                                 val = None\n",
    "#                             else:\n",
    "#                                 val = (\"%g\" % v)\n",
    "#                         except Exception:\n",
    "#                             pass\n",
    "#                     if val:\n",
    "#                         return val\n",
    "\n",
    "#             # Generic '... expenses ... 8,895 million' even without \"operating\"\n",
    "#             for win in windows:\n",
    "#                 m = re.search(\n",
    "#                     r\"\\bexpenses\\b.*?(?:were|:)?\\s*([0-9][\\d,]*(?:\\.[0-9]+)?)\\s*(million|mn|m|bn|billion)\\b\",\n",
    "#                     win,\n",
    "#                     flags=re.I | re.S,\n",
    "#                 )\n",
    "#                 if m:\n",
    "#                     val = _clean_number(m.group(1))\n",
    "#                     unit = (m.group(2) or \"\").lower()\n",
    "#                     if val:\n",
    "#                         try:\n",
    "#                             v = float(val)\n",
    "#                             if unit in (\"bn\", \"billion\", \"b\"):\n",
    "#                                 v *= 1000.0\n",
    "#                             # Annual asks must be a sensible magnitude in $m (reject too-small or absurdly large)\n",
    "#                             if annual_ask and unit in (\"million\", \"mn\", \"m\", \"bn\", \"billion\", \"b\") and not (2000 <= v <= 15000):\n",
    "#                                 val = None\n",
    "#                             else:\n",
    "#                                 val = (\"%g\" % v)\n",
    "#                         except Exception:\n",
    "#                             pass\n",
    "#                     if val:\n",
    "#                         return val\n",
    "\n",
    "#             # Table/markdown style: headers carry units like \"($m)\" or \"S$ m\", and the value is a 4+ digit number\n",
    "#             for win in windows:\n",
    "#                 # e.g., \"| Operating expenses | 8,895 |\" or \"Operating expenses 8,895\"\n",
    "#                 m = re.search(\n",
    "#                     r\"(?:operating\\s+expenses|^\\s*\\|\\s*operating\\s+expenses.*?)\\D([0-9][\\d,]{3,})\\b\",\n",
    "#                     win, flags=re.I | re.S | re.M\n",
    "#                 )\n",
    "#                 if m:\n",
    "#                     val = _clean_number(m.group(1))\n",
    "#                     if val:\n",
    "#                         return val\n",
    "#             # If the surrounding text mentions monetary units like '($m)' or 'S$ m', prefer 4+ digit numbers anywhere in the window\n",
    "#             for win in windows:\n",
    "#                 if re.search(r\"\\(\\$?\\s*m\\)|s\\$\\s*m|\\(\\$m\\)|\\(\\$ million\\)\", win, flags=re.I):\n",
    "#                     m = re.search(r\"\\b([0-9][\\d,]{3,})\\b\", win)\n",
    "#                     if m:\n",
    "#                         val = _clean_number(m.group(1))\n",
    "#                         if val:\n",
    "#                             return val\n",
    "\n",
    "#             # As a last resort, only if the window itself mentions expenses/opex AND a money unit cue is present.\n",
    "#             # This avoids accidentally picking unrelated large numbers from generic prose (e.g., CFO narrative pages).\n",
    "#             for win in windows:\n",
    "#                 if re.search(r\"\\b(operating\\s+)?expenses?\\b|\\bopex\\b\", win, flags=re.I):\n",
    "#                     # Require a nearby money unit cue to reduce false positives.\n",
    "#                     if not re.search(r\"\\(\\$?\\s*m\\)|s\\$\\s*m|\\(\\$m\\)|\\bmillion\\b|\\bmn\\b|\\bbn\\b|\\bbillion\\b\", win, flags=re.I):\n",
    "#                         continue\n",
    "#                     m = re.search(r\"\\b([0-9][\\d,]{3,})\\b\", win)\n",
    "#                     if m:\n",
    "#                         val = _clean_number(m.group(1))\n",
    "#                         if val:\n",
    "#                             return val\n",
    "                        \n",
    "#         # 3) Total/Operating Income ‚Üí require the phrase and a plausible 4+ digit value\n",
    "#         if is_income:\n",
    "#             # Prefer explicit \"Total income ... NNNN\"\n",
    "#             for win in windows:\n",
    "#                 if re.search(r\"\\btotal\\s+income\\b\", win, flags=re.I):\n",
    "#                     m = re.search(r\"\\btotal\\s+income\\b[^0-9]{0,60}([0-9][\\d,]{3,})\", win, flags=re.I)\n",
    "#                     if m:\n",
    "#                         val = _clean_number(m.group(1))\n",
    "#                         if val:\n",
    "#                             try:\n",
    "#                                 v = float(val)\n",
    "#                                 if 1000.0 <= v <= 50000.0:  # DBS scale in $m\n",
    "#                                     return val\n",
    "#                             except Exception:\n",
    "#                                 pass\n",
    "#             # Vision-summary phrasing: \"... Total income was 22297.\"\n",
    "#             for win in windows:\n",
    "#                 m = re.search(r\"\\btotal\\s+income\\b\\s*(?:was|:)?\\s*([0-9][\\d,]{3,})\", win, flags=re.I)\n",
    "#                 if m:\n",
    "#                     val = _clean_number(m.group(1))\n",
    "#                     if val:\n",
    "#                         try:\n",
    "#                             v = float(val)\n",
    "#                             if 1000.0 <= v <= 50000.0:\n",
    "#                                 return val\n",
    "#                         except Exception:\n",
    "#                             pass\n",
    "#             # Markdown/table row style\n",
    "#             for win in windows:\n",
    "#                 m = re.search(r\"(?:^\\s*\\|\\s*)?total\\s+income(?:\\s*\\|)?\\s*([0-9][\\d,]{3,})\\b\", win, flags=re.I | re.M)\n",
    "#                 if m:\n",
    "#                     val = _clean_number(m.group(1))\n",
    "#                     if val:\n",
    "#                         return val\n",
    "#             # If the window says \"$m\" / \"In $ millions\", allow a nearby 4+ digit number\n",
    "#             for win in windows:\n",
    "#                 if re.search(r\"\\(\\$?\\s*m\\)|in\\s*\\$?\\s*millions\", win, flags=re.I):\n",
    "#                     m = re.search(r\"\\b([0-9][\\d,]{3,})\\b\", win)\n",
    "#                     if m:\n",
    "#                         val = _clean_number(m.group(1))\n",
    "#                         if val:\n",
    "#                             try:\n",
    "#                                 v = float(val)\n",
    "#                                 if 1000.0 <= v <= 50000.0:\n",
    "#                                     return val\n",
    "#                             except Exception:\n",
    "#                                 pass\n",
    "#             # Avoid grabbing random numbers (like '31' from dates)\n",
    "#             return None\n",
    "\n",
    "#         # 4) Generic fallback: only for non-domain queries. For NIM/Opex, avoid bogus picks.\n",
    "#         if not (is_nim or is_opex or is_income):\n",
    "#             for win in windows:\n",
    "#                 m = re.search(r\"(-?\\$?S?\\s*[0-9][\\d,]*(?:\\.[0-9]+)?)\", win)\n",
    "#                 if m:\n",
    "#                     val = re.sub(r\"[S$\\s]\", \"\", m.group(1))\n",
    "#                     val = _clean_number(val)\n",
    "#                     if val:\n",
    "#                         return val\n",
    "\n",
    "#         return None\n",
    "\n",
    "#     # --- Hard preference for Vision hits when Opex asks for a specific FY ---\n",
    "#     try:\n",
    "#         ql_pref = query.lower()\n",
    "#         is_opex_pref = (\"opex\" in ql_pref) or (\"operating expense\" in ql_pref) or re.search(r\"\\bexpenses\\b\", ql_pref)\n",
    "#         desired_periods_pref = _desired_periods_from_query(query)\n",
    "#         explicit_fy_years = [yy for (yy, qq) in desired_periods_pref if yy and (qq is None)]\n",
    "#         if is_opex_pref and explicit_fy_years:\n",
    "#             yy = explicit_fy_years[0]\n",
    "#             vision_for_year = [h for h in hits if \"vision_summary\" in str(h.get(\"section_hint\") or \"\").lower() and h.get(\"year\") == yy]\n",
    "#             if vision_for_year:\n",
    "#                 # Put those Vision hits first to be tried before any prose/table chunks\n",
    "#                 rest = [h for h in hits if h not in vision_for_year]\n",
    "#                 hits = vision_for_year + rest\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "#     # Local rerank of hits to prefer structured/vision chunks for domain queries\n",
    "#     ql = query.lower()\n",
    "#     is_nim = (\"nim\" in ql) or (\"net interest margin\" in ql)\n",
    "#     is_opex = (\"opex\" in ql) or (\"operating expense\" in ql) or re.search(r\"\\bexpenses\\b\", ql)\n",
    "#     is_income = re.search(r\"\\b(total\\s+income|operating\\s+income)\\b\", ql) is not None\n",
    "\n",
    "#     def _local_hit_score(h: dict) -> float:\n",
    "#         sh = str(h.get(\"section_hint\") or \"\").lower()\n",
    "#         file_l = str(h.get(\"file\") or \"\").lower()\n",
    "#         s = 0.0\n",
    "\n",
    "#         # Pull the actual text for content checks\n",
    "#         pos = _pos_of_docid(h.get(\"doc_id\", \"\"))\n",
    "#         text_l = str(texts[pos]).lower() if pos is not None else \"\"\n",
    "\n",
    "#         mentions_nim = (\"net interest margin\" in text_l) or re.search(r\"\\bnim\\b\", text_l) is not None\n",
    "#         mentions_expenses = (\"operating expenses\" in text_l) or re.search(r\"\\bexpenses\\b\", text_l) is not None\n",
    "#         mentions_total_income = re.search(r\"\\btotal\\s+income\\b\", text_l) is not None\n",
    "#         has_money_units = re.search(r\"\\(\\$?\\s*m\\)|s\\$\\s*m|\\(\\$m\\)|\\bmillion\\b|\\bmn\\b|\\bbn\\b|\\bbillion\\b\", text_l, flags=re.I) is not None\n",
    "#         mentions_percent = \"%\" in text_l\n",
    "\n",
    "#         if \"vision_summary\" in sh:\n",
    "#             s += 500.0\n",
    "#         if sh.startswith(\"table_p\"):\n",
    "#             s += 30.0\n",
    "\n",
    "#         # For NIM, demand the NIM phrase be present; otherwise heavily penalize\n",
    "#         if is_nim:\n",
    "#             if h.get(\"quarter\") is not None:\n",
    "#                 s += 20.0\n",
    "#             if mentions_nim:\n",
    "#                 s += 20.0\n",
    "#                 if mentions_percent:\n",
    "#                     s += 10.0\n",
    "#             else:\n",
    "#                 s -= 80.0  # do not allow non-NIM tables to outrank true NIM chunks\n",
    "\n",
    "#         # For Opex-like asks, require expenses to be mentioned; favor money units\n",
    "#         if is_opex:\n",
    "#             if mentions_expenses:\n",
    "#                 s += 20.0\n",
    "#                 if has_money_units:\n",
    "#                     s += 8.0\n",
    "#             else:\n",
    "#                 s -= 60.0  # push away tables/pages without expenses language\n",
    "#             # Prefer structured sources over plain prose when scores tie\n",
    "#             if sh == \"prose\":\n",
    "#                 s -= 5.0\n",
    "                \n",
    "#         if is_income:\n",
    "#             if \"vision_summary\" in sh:\n",
    "#                 s += 60.0\n",
    "#             if sh.startswith(\"table_p\"):\n",
    "#                 s += 25.0\n",
    "#             if mentions_total_income:\n",
    "#                 s += 20.0\n",
    "#             else:\n",
    "#                 s -= 40.0\n",
    "#             if re.search(r\"\\(\\$?\\s*m\\)|in\\s*\\$?\\s*millions\", text_l, flags=re.I):\n",
    "#                 s += 6.0\n",
    "\n",
    "#         # Deprioritize press/trading noise for numeric extractions\n",
    "#         if re.search(r\"press[_\\s-]?statement|trading[_\\s-]?update\", file_l):\n",
    "#             s -= 30.0\n",
    "\n",
    "#         # fall back to hybrid score to break ties\n",
    "#         s += float(h.get(\"score\") or 0.0) * 0.01\n",
    "#         return s\n",
    "\n",
    "#     if is_nim or is_opex:\n",
    "#         # Order: vision ‚Üí tables ‚Üí other, each block locally reranked\n",
    "#         hits = (\n",
    "#             sorted(vision_hits, key=_local_hit_score, reverse=True) +\n",
    "#             sorted(table_hits,  key=_local_hit_score, reverse=True) +\n",
    "#             sorted(other_hits,  key=_local_hit_score, reverse=True)\n",
    "#         )\n",
    "\n",
    "#     # Snapshot of the current hit ordering (useful for debugging/reuse in nested helpers)\n",
    "#     _hits_snapshot = hits[:]\n",
    "\n",
    "#     # Try the top-k hits in order until we successfully extract a plausible value\n",
    "#     last_citation = None\n",
    "#     for hit in hits:\n",
    "#         pos = _pos_of_docid(hit[\"doc_id\"])\n",
    "#         if pos is None:\n",
    "#             continue\n",
    "\n",
    "#         text_content = str(texts[pos])\n",
    "#         citation = f\"Source: {format_citation(hit)}\"\n",
    "#         last_citation = citation\n",
    "\n",
    "#         value = _extract_value(text_content, query)\n",
    "#         if value is not None:\n",
    "#             return f\"Value: {value}, {citation}\"\n",
    "\n",
    "#     # If we got here, extraction failed for all hits\n",
    "#     return f\"Error: No numerical value found in the relevant document chunk. {last_citation or ''}\"\n",
    "  \n",
    "\n",
    "# # --- Helper: Deterministic Opex 3-year baseline extractor ---\n",
    "\n",
    "# # def answer_opex_3y_baseline() -> str:\n",
    "# #     \"\"\"\n",
    "# #     Deterministic simple baseline for:\n",
    "# #     'Show Operating Expenses for the last 3 fiscal years.'\n",
    "# #     Uses the KB to pick the latest 3 FYs present, then calls table_extraction per FY.\n",
    "# #     \"\"\"\n",
    "# #     # 1) find latest 3 FYs available in KB (prefer annual docs)\n",
    "# #     df = kb.copy()\n",
    "# #     df[\"y\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "# #     ydf = df[df[\"quarter\"].isna()].dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "# #     if ydf.empty:\n",
    "# #         ydf = df.dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "# #     years = [int(y) for y in ydf[\"y\"].drop_duplicates().head(3)]\n",
    "# #     if not years:\n",
    "# #         return \"No fiscal years found in KB.\"\n",
    "\n",
    "# #     # 2) extract Opex per FY using the robust extractor\n",
    "# #     rows, cites = [], []\n",
    "# #     for y in years:\n",
    "# #         r = tool_table_extraction(f\"Operating expenses for fiscal year {y}\")\n",
    "# #         # Expected: \"Value: 8895, Source: <citation>\" or \"Error: ...\"\n",
    "# #         m = re.search(r\"Value:\\s*([0-9][\\d\\.]*)\\s*,\\s*Source:\\s*(.*)\", r)\n",
    "# #         if m:\n",
    "# #             val = m.group(1)\n",
    "# #             src = m.group(2)\n",
    "# #             rows.append((y, val))\n",
    "# #             cites.append(src)\n",
    "# #         else:\n",
    "# #             rows.append((y, \"‚Äî\"))\n",
    "# #             cites.append(r)\n",
    "\n",
    "# #     # 3) render a tiny table with YoY% and citations\n",
    "# #     # rows is a list of tuples: [(year, value_str_or_dash), ...]\n",
    "# #     rows.sort(key=lambda t: t[0], reverse=True)  # ensure FY2024, FY2023, FY2022 order\n",
    "\n",
    "# #     def _fmt_m(x: str) -> str:\n",
    "# #         try:\n",
    "# #             return f\"{float(x):,.0f}\"\n",
    "# #         except Exception:\n",
    "# #             return x  # return as-is if not a number (e.g., \"‚Äî\")\n",
    "\n",
    "# #     out = [\n",
    "# #         \"Opex (S$ m) ‚Äî last 3 fiscal years:\",\n",
    "# #         \"Year   | Opex (S$ m) | YoY %\",\n",
    "# #         \"-------|-------------|------\",\n",
    "# #     ]\n",
    "\n",
    "# #     for i, (yy, vv) in enumerate(rows):\n",
    "# #         yoy = \"\"\n",
    "# #         if i > 0 and rows[i-1][1] not in (\"‚Äî\", \"\", None) and vv not in (\"‚Äî\", \"\", None):\n",
    "# #             try:\n",
    "# #                 cur = float(vv)\n",
    "# #                 prev = float(rows[i-1][1])\n",
    "# #                 yoy = f\"{((cur - prev) / prev) * 100:,.1f}%\"\n",
    "# #             except Exception:\n",
    "# #                 yoy = \"\"\n",
    "# #         out.append(f\"{yy} | {_fmt_m(vv) if vv != '‚Äî' else vv} | {yoy}\")\n",
    "\n",
    "# #     out.append(\"\\nCitations:\")\n",
    "# #     seen = set()\n",
    "# #     for c in cites:\n",
    "# #         if c not in seen:\n",
    "# #             seen.add(c)\n",
    "# #             out.append(f\"- {c}\")\n",
    "# #         if len(seen) >= 3:\n",
    "# #             break\n",
    "# #     return \"\\n\".join(out)\n",
    "# def tool_nim_series(last_n: int = 5, variant: str = \"group\") -> str:\n",
    "#     \"\"\"\n",
    "#     Extract the last N quarters of Net Interest Margin (Group or Commercial Book).\n",
    "#     Retrieval: FAISS (semantic) + BM25 (keyword) hybrid via hybrid_search().\n",
    "#     Parsing priority: Vision summaries (nim_analysis-style lines), then structured tables,\n",
    "#     then generic 'quarter ‚Üí %' mentions anchored to NIM.\n",
    "#     \"\"\"\n",
    "#     # --- 1) Gather a broader candidate pool (multiple queries) ---\n",
    "#     queries = [\n",
    "#         \"Net interest margin (%)\",\n",
    "#         \"NIM (%)\",\n",
    "#         \"Group Net Interest Margin quarterly\",\n",
    "#         \"Commercial book Net Interest Margin (%)\",\n",
    "#         \"Net interest margin group commercial\"\n",
    "#     ]\n",
    "#     hits: List[Dict[str, Any]] = []\n",
    "#     seen_doc_ids = set()\n",
    "#     for q in queries:\n",
    "#         for h in hybrid_search(q, top_k=40):\n",
    "#             did = h.get(\"doc_id\")\n",
    "#             if did not in seen_doc_ids:\n",
    "#                 seen_doc_ids.add(did)\n",
    "#                 hits.append(h)\n",
    "\n",
    "#     # Always include any vision_summary chunks (often hold clean 'For 2Q24, Group NIM was 2.13%' lines)\n",
    "#     try:\n",
    "#         sh_series = kb[\"section_hint\"].astype(str).str.contains(\"vision_summary\", case=False, na=False)\n",
    "#         vis_idxs = np.flatnonzero(sh_series.to_numpy())\n",
    "#         base_score = (min([float(h.get(\"score\") or 0.0) for h in hits]) - 1.0) if hits else 0.0\n",
    "#         for idx in vis_idxs[:20]:\n",
    "#             row = kb.iloc[idx]\n",
    "#             did = row.doc_id\n",
    "#             if did in seen_doc_ids:\n",
    "#                 continue\n",
    "#             seen_doc_ids.add(did)\n",
    "#             hits.append({\n",
    "#                 \"doc_id\": row.doc_id,\n",
    "#                 \"file\": row.file,\n",
    "#                 \"page\": int(row.page) if pd.notna(row.page) else None,\n",
    "#                 \"year\": int(row.year) if pd.notna(row.year) else None,\n",
    "#                 \"quarter\": int(row.quarter) if pd.notna(row.quarter) else None,\n",
    "#                 \"section_hint\": row.section_hint,\n",
    "#                 \"score\": base_score\n",
    "#             })\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "#     # --- Helper: fetch raw text for a hit ---\n",
    "#     def _pos_of_docid(did: str) -> Optional[int]:\n",
    "#         mask = (kb[\"doc_id\"] == did).to_numpy()\n",
    "#         idxs = np.flatnonzero(mask)\n",
    "#         return int(idxs[0]) if idxs.size else None\n",
    "\n",
    "#     # --- Helper: plausibility filter for NIM values (in %) ---\n",
    "#     def _nim_ok(x: float) -> bool:\n",
    "#         try:\n",
    "#             xf = float(x)\n",
    "#         except Exception:\n",
    "#             return False\n",
    "#         return 0.5 <= xf <= 3.5\n",
    "\n",
    "#     # --- 2) Parse points: map (\"2Q25\",\"group|commercial\") ‚Üí value ---\n",
    "#     from typing import Tuple\n",
    "#     points: Dict[Tuple[str, str], float] = {}\n",
    "\n",
    "#     # Order candidates: vision ‚Üí tables ‚Üí other\n",
    "#     vision_hits = [h for h in hits if \"vision_summary\" in str(h.get(\"section_hint\") or \"\").lower()]\n",
    "#     table_hits  = [h for h in hits if str(h.get(\"section_hint\") or \"\").lower().startswith(\"table_p\")]\n",
    "#     other_hits  = [h for h in hits if h not in vision_hits and h not in table_hits]\n",
    "#     ordered = vision_hits + table_hits + other_hits\n",
    "\n",
    "#     # --- 3) Parsing routines ---\n",
    "#     re_qtr  = re.compile(r\"\\b([1-4]Q\\d{2})\\b\", flags=re.I)\n",
    "#     re_pct  = re.compile(r\"([0-9]+(?:\\.[0-9]+)?)\\s*%\")\n",
    "#     re_num  = re.compile(r\"([0-9]+(?:\\.[0-9]+)?)\")  # for tables where % sign is omitted\n",
    "#     re_nim_phrase = re.compile(r\"net\\s*interest\\s*margin|\\bnim\\b\", flags=re.I)\n",
    "\n",
    "#     def _maybe_add(qlabel: str, who: str, val: float):\n",
    "#         who_norm = \"commercial\" if \"commercial\" in who.lower() else \"group\"\n",
    "#         key = (qlabel.upper(), who_norm)\n",
    "#         if _nim_ok(val) and key not in points:\n",
    "#             points[key] = float(val)\n",
    "\n",
    "#     for h in ordered:\n",
    "#         pos = _pos_of_docid(h.get(\"doc_id\", \"\"))\n",
    "#         if pos is None:\n",
    "#             continue\n",
    "#         text = str(texts[pos])\n",
    "\n",
    "#         # Skip chunks that don't obviously mention NIM to avoid 5% from unrelated places\n",
    "#         if not re_nim_phrase.search(text):\n",
    "#             continue\n",
    "\n",
    "#         # (A) Vision-style lines from g1.format_vision_json_to_text\n",
    "#         for m in re.finditer(\n",
    "#             r\"For\\s+([1-4]Q\\d{2}),\\s+the\\s+(Group|Commercial(?:\\s*book)?)\\s+Net\\s+Interest\\s+Margin.*?([0-9]+(?:\\.[0-9]+)?)\\s*%\",\n",
    "#             text, flags=re.I\n",
    "#         ):\n",
    "#             qlabel, who, val = m.group(1), m.group(2), float(m.group(3))\n",
    "#             _maybe_add(qlabel, who, val)\n",
    "\n",
    "#         # (B) Markdown table row like: \"| Net interest margin (%) | 2Q25 | 1Q25 | ...\\n| ... | 2.61 | 2.70 | ...\"\n",
    "#         lines = text.splitlines()\n",
    "#         header_quarters: Optional[List[str]] = None\n",
    "#         for li, line in enumerate(lines):\n",
    "#             # Update current header_quarters if this line looks like a quarter header row\n",
    "#             q_in_line = re_qtr.findall(line.upper())\n",
    "#             if len(q_in_line) >= 2:\n",
    "#                 header_quarters = q_in_line\n",
    "\n",
    "#             if re.search(r\"net\\s*interest\\s*margin|\\bnim\\b\", line, flags=re.I):\n",
    "#                 # 1) Same-line values (e.g., '| Net interest margin (%) | 2.61 | 2.70 | ...')\n",
    "#                 vals_inline = [float(x) for x in re_num.findall(line) if _nim_ok(x)]\n",
    "#                 if header_quarters and len(vals_inline) >= len(header_quarters):\n",
    "#                     for ql, v in zip(header_quarters, vals_inline[:len(header_quarters)]):\n",
    "#                         _maybe_add(ql, \"group\", float(v))\n",
    "\n",
    "#                 # 2) Next-line values (common in markdown tables: headers then a metrics row on the next line)\n",
    "#                 if li + 1 < len(lines):\n",
    "#                     nxt = lines[li + 1]\n",
    "#                     vals_next = [float(x) for x in re_num.findall(nxt) if _nim_ok(x)]\n",
    "#                     if header_quarters and len(vals_next) >= len(header_quarters):\n",
    "#                         for ql, v in zip(header_quarters, vals_next[:len(header_quarters)]):\n",
    "#                             _maybe_add(ql, \"group\", float(v))\n",
    "\n",
    "#         # (C) Generic anchored fallback:\n",
    "#         # For each quarter mention, search a short window to the right for a plausible % or number.\n",
    "#         # Expand the window to 160 chars to capture \"‚Ä¶ 2Q25 ‚Ä¶ NIM ‚Ä¶ 2.61%\".\n",
    "#         for m in re.finditer(r\"([1-4]Q\\d{2})\", text, flags=re.I):\n",
    "#             span_end = min(len(text), m.end() + 160)\n",
    "#             window = text[m.start():span_end]\n",
    "#             if not re_nim_phrase.search(window):\n",
    "#                 continue\n",
    "#             m_pct = re_pct.search(window)\n",
    "#             if m_pct:\n",
    "#                 val = float(m_pct.group(1))\n",
    "#                 if _nim_ok(val):\n",
    "#                     _maybe_add(m.group(1), \"group\", val)\n",
    "#                     continue\n",
    "#             # If % sign omitted in tables, allow a plain number in plausible range\n",
    "#             m_num = re_num.search(window)\n",
    "#             if m_num:\n",
    "#                 try:\n",
    "#                     val = float(m_num.group(1))\n",
    "#                 except Exception:\n",
    "#                     val = None\n",
    "#                 if val is not None and _nim_ok(val):\n",
    "#                     _maybe_add(m.group(1), \"group\", val)\n",
    "\n",
    "#     # --- 4) Keep only the requested variant & take most recent N points ---\n",
    "#     series = []\n",
    "#     for (qlabel, who), val in points.items():\n",
    "#         if (variant == \"group\" and who == \"group\") or (variant != \"group\" and who != \"group\"):\n",
    "#             qnum = int(qlabel[0])\n",
    "#             yy = int(qlabel[2:])\n",
    "#             year = 2000 + yy\n",
    "#             series.append((year, qnum, qlabel.upper(), float(val)))\n",
    "\n",
    "#     if not series:\n",
    "#         return \"Error: No NIM values found.\"\n",
    "\n",
    "#     series.sort(key=lambda t: (t[0], t[1]), reverse=True)\n",
    "#     take = max(1, int(last_n or 5))\n",
    "#     series = series[:take]\n",
    "\n",
    "#     formatted = \", \".join(f\"{ql}: {v:.2f}%\" for (_, _, ql, v) in series)\n",
    "#     who_title = \"Group\" if variant == \"group\" else \"Commercial Book\"\n",
    "#     return f\"NIM ({who_title}) last {len(series)} quarters ‚Üí {formatted}\"\n",
    "  \n",
    "# def tool_multi_document_compare(topic: str, files: list[str]) -> str:\n",
    "#     results = []\n",
    "#     for file_name in files:\n",
    "#         hits = hybrid_search(f\"{topic} in file {file_name}\", top_k=2)\n",
    "#         file_hits = [h for h in hits if h.get('file') == file_name]\n",
    "#         if file_hits:\n",
    "#             top_hit = file_hits[0]\n",
    "#             citation = format_citation(top_hit)\n",
    "#             text_content = texts[kb.index[kb['doc_id'] == top_hit['doc_id']][0]]\n",
    "#             results.append(f\"Source: [{citation}]\\nContent: {text_content[:800]}\")\n",
    "#         else:\n",
    "#             results.append(f\"Source: {file_name}\\nContent: No relevant information found.\")\n",
    "#     return \"\\n---\\n\".join(results)\n",
    "\n",
    "# def _compile_or_repair_plan(query: str, plan: list[dict]) -> list[dict]:\n",
    "#     def _has_params(step: dict) -> bool:\n",
    "#         params = step.get(\"parameters\")\n",
    "#         return isinstance(params, dict) and any(v not in (None, \"\", []) for v in params.values())\n",
    "\n",
    "#     if plan and all(_has_params(s) for s in plan):\n",
    "#         return plan\n",
    "\n",
    "#     qtype = _classify_query(query)\n",
    "#     want_years  = _detect_last_n_years(query)\n",
    "#     want_quarts = _detect_last_n_quarters(query)\n",
    "    \n",
    "#     df = kb.copy()\n",
    "#     df[\"y\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "#     df[\"q\"] = pd.to_numeric(df[\"quarter\"], errors=\"coerce\")\n",
    "#     steps: list[dict] = []\n",
    "\n",
    "#     if qtype == \"nim\":\n",
    "#         n = want_quarts or 5\n",
    "#         steps.append({\n",
    "#             \"step\": f\"Extract last {n} quarters of NIM (group)\",\n",
    "#             \"tool\": \"nim_series\",\n",
    "#             \"parameters\": {\"last_n\": n, \"variant\": \"group\"},\n",
    "#             \"store_as\": f\"nim_series_last_{n}\"\n",
    "#         })\n",
    "#         return steps\n",
    "\n",
    "#     if qtype == \"opex\":\n",
    "#         # If the user asked for a specific fiscal year (e.g., \"FY2024\" or \"fiscal year 2024\"),\n",
    "#         # do a single extraction for that year and STOP. Do not add YoY steps.\n",
    "#         periods = _desired_periods_from_query(query)\n",
    "#         explicit_fy = [y for (y, q) in periods if y and (q is None)]\n",
    "#         if explicit_fy:\n",
    "#             y = int(explicit_fy[0])\n",
    "#             steps.append({\n",
    "#                 \"step\": f\"Extract Opex for FY{y}\",\n",
    "#                 \"tool\": \"table_extraction\",\n",
    "#                 \"parameters\": {\"query\": f\"Operating expenses for fiscal year {y}\"},\n",
    "#                 \"store_as\": f\"opex_fy{y}\"\n",
    "#             })\n",
    "#             return steps\n",
    "\n",
    "#         # Otherwise, assume a multi‚Äëyear ask. Default to the last 3 fiscal years and include a YoY calc.\n",
    "#         n = want_years or 3\n",
    "#         df_local = kb.copy()\n",
    "#         df_local[\"y\"] = pd.to_numeric(df_local[\"year\"], errors=\"coerce\")\n",
    "#         df_local[\"q\"] = pd.to_numeric(df_local[\"quarter\"], errors=\"coerce\")\n",
    "\n",
    "#         ydf = df_local[df_local[\"q\"].isna()].dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "#         if ydf.empty:\n",
    "#             ydf = df_local.dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "\n",
    "#         years = [int(y) for y in ydf[\"y\"].drop_duplicates().head(n)]\n",
    "#         for y in years:\n",
    "#             steps.append({\n",
    "#                 \"step\": f\"Extract Opex for FY{y}\",\n",
    "#                 \"tool\": \"table_extraction\",\n",
    "#                 \"parameters\": {\"query\": f\"Operating expenses for fiscal year {y}\"},\n",
    "#                 \"store_as\": f\"opex_fy{y}\"\n",
    "#             })\n",
    "#         if len(years) >= 2:\n",
    "#             y0, y1 = years[0], years[1]\n",
    "#             steps.append({\n",
    "#                 \"step\": f\"Compute YoY % change FY{y0} vs FY{y1}\",\n",
    "#                 \"tool\": \"calculator\",\n",
    "#                 \"parameters\": {\"expression\": f\"((${{opex_fy{y0}}} - ${{opex_fy{y1}}}) / ${{opex_fy{y1}}}) * 100\"},\n",
    "#                 \"store_as\": f\"opex_yoy_{y0}_{y1}\"\n",
    "#             })\n",
    "#         return steps\n",
    "    \n",
    "#     if qtype == \"oer\":\n",
    "#         n = want_years or 3\n",
    "#         ydf = df[df[\"q\"].isna()].dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "#         if ydf.empty: ydf = df.dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
    "#         years = [int(y) for y in ydf[\"y\"].drop_duplicates().head(n)]\n",
    "#         for y in years:\n",
    "#             steps.append({ \"step\": f\"Extract Opex for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Operating expenses for fiscal year {y}\"}, \"store_as\": f\"opex_fy{y}\"})\n",
    "#             steps.append({ \"step\": f\"Extract Operating Income for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Total income for fiscal year {y}\"}, \"store_as\": f\"income_fy{y}\"})\n",
    "#             steps.append({ \"step\": f\"Compute OER for FY{y}\", \"tool\": \"calculator\", \"parameters\": {\"expression\": f\"(${{opex_fy{y}}} / ${{income_fy{y}}}) * 100\"}, \"store_as\": f\"oer_fy{y}\"})\n",
    "#         return steps\n",
    "    \n",
    "#     return [{\"step\": \"Extract relevant figure\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": query}, \"store_as\": \"value_1\"}]\n",
    "\n",
    "# def answer_with_agent(query: str, dry_run: bool = False) -> Dict[str, Any]:\n",
    "#     _ensure_init()\n",
    "#     execution_log = []\n",
    "    \n",
    "#     planning_prompt = f\"\"\"You are a financial analyst agent. Create a JSON plan to answer the user's query.\n",
    "# Tools Available:\n",
    "# - `table_extraction(query: str)`: Finds a single reported data point.\n",
    "# - `calculator(expression: str)`: Calculates a math expression.\n",
    "# User Query: \"{query}\"\n",
    "# Return ONLY a valid JSON object with a \"plan\" key.\"\"\"\n",
    "#     if VERBOSE: print(\"[Agent] Step 1: Generating execution plan...\")\n",
    "    \n",
    "#     plan_response = _call_llm(planning_prompt, dry_run)\n",
    "#     plan = []\n",
    "    \n",
    "#     if dry_run:\n",
    "#         plan = _compile_or_repair_plan(query, [])\n",
    "#         answer = f\"DRY RUN MODE: The agent generated the following plan and stopped before execution.\\n\\n{json.dumps(plan, indent=2)}\"\n",
    "#         return {\"answer\": answer, \"hits\": [], \"execution_log\": [{\"step\": \"Planning\", \"plan\": plan}]}\n",
    "\n",
    "#     try:\n",
    "#         json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', plan_response, re.DOTALL)\n",
    "#         plan_str = json_match.group(1) if json_match else plan_response\n",
    "#         plan = json.loads(plan_str)[\"plan\"]\n",
    "#         execution_log.append({\"step\": \"Planning\", \"plan\": plan})\n",
    "#         if VERBOSE: print(\"[Agent] Plan generated successfully.\")\n",
    "#     except Exception:\n",
    "#         if VERBOSE: print(\"[Agent] LLM failed to generate valid plan. Using deterministic repair.\")\n",
    "#         plan = []\n",
    "\n",
    "#     plan = _compile_or_repair_plan(query, plan)\n",
    "#     if not execution_log or \"repaired_plan\" not in execution_log[0]:\n",
    "#         execution_log.insert(0, {\"step\": \"PlanRepair\", \"repaired_plan\": plan})\n",
    "    \n",
    "#     if VERBOSE: print(\"[Agent] Step 2: Executing plan...\")\n",
    "#     tool_mapping = {\n",
    "#         \"calculator\": tool_calculator,\n",
    "#         \"table_extraction\": tool_table_extraction,\n",
    "#         \"multi_document_compare\": tool_multi_document_compare,\n",
    "#         \"nim_series\": tool_nim_series\n",
    "#     }\n",
    "#     execution_state = {}\n",
    "    \n",
    "#     for i, step in enumerate(plan):\n",
    "#         tool = step.get(\"tool\")\n",
    "#         params = step.get(\"parameters\", {}).copy() # Use copy to avoid modifying plan dict\n",
    "#         store_as = step.get(\"store_as\")\n",
    "\n",
    "#         for p_name, p_value in params.items():\n",
    "#             if isinstance(p_value, str):\n",
    "#                 for var_name, var_value in execution_state.items():\n",
    "#                     p_value = p_value.replace(f\"${{{var_name}}}\", str(var_value))\n",
    "#             params[p_name] = p_value\n",
    "        \n",
    "#         try:\n",
    "#             if tool not in tool_mapping:\n",
    "#                 raise ValueError(f\"Tool '{tool}' not found.\")\n",
    "            \n",
    "#             result = tool_mapping[tool](**params)\n",
    "#             execution_log.append({\"step\": f\"Execution {i+1}\", \"tool_call\": f\"{tool}({params})\", \"result\": result})\n",
    "            \n",
    "#             if store_as:\n",
    "#                 val_for_state = result # Default to full result\n",
    "#                 m_calc = re.search(r'Result:\\s*([-\\d\\.]+e?[-\\d]*)', result, re.I)\n",
    "#                 if m_calc: val_for_state = m_calc.group(1)\n",
    "                \n",
    "#                 m_val = re.search(r'Value:\\s*([^,]+)', result, re.I)\n",
    "#                 if m_val: val_for_state = m_val.group(1).strip()\n",
    "\n",
    "#                 execution_state[store_as] = val_for_state\n",
    "\n",
    "#         except Exception as e:\n",
    "#             execution_log.append({\"step\": f\"Execution {i+1}\", \"tool_call\": f\"{tool}({params})\", \"error\": traceback.format_exc()})\n",
    "\n",
    "#     if VERBOSE: print(\"[Agent] Step 3: Synthesizing final answer...\")\n",
    "#     synthesis_prompt = f\"\"\"You are Agent CFO. Provide a final answer to the user's query based ONLY on the provided Tool Execution Log.\n",
    "# User Query: \"{query}\"\n",
    "# Tool Execution Log:\n",
    "# {json.dumps(execution_log, indent=2)}\n",
    "# Final Answer:\"\"\"\n",
    "#     final_answer = _call_llm(synthesis_prompt)\n",
    "    \n",
    "#     return {\"answer\": final_answer, \"hits\": [], \"execution_log\": execution_log}\n",
    "\n",
    "# def get_logs():\n",
    "#     return instr.df()\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     import sys, subprocess, importlib, os\n",
    "# #     os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# #     # Auto-install missing deps\n",
    "# #     def _pip(pkg):\n",
    "# #         try:\n",
    "# #             importlib.import_module(pkg)\n",
    "# #         except Exception:\n",
    "# #             subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# #     for p in [\"openai\", \"rank_bm25\", \"faiss-cpu\"]:\n",
    "# #         _pip(p)\n",
    "\n",
    "# #     # Groq config (read from env; do NOT hardcode secrets)\n",
    "# #     os.environ.setdefault(\"LLM_PROVIDER\", \"groq\")\n",
    "# #     os.environ.setdefault(\"GROQ_MODEL\", \"openai/gpt-oss-20b\")\n",
    "# #     if not os.getenv(\"GROQ_API_KEY\"):\n",
    "# #         print(\"‚ö†Ô∏è  GROQ_API_KEY not set. Please set it in your environment before running.\")\n",
    "    \n",
    "# #     # Initialize Stage-2 and run the deterministic Opex baseline\n",
    "# #     init_stage2(\"data\")\n",
    "# #     query = \"Show Operating Expenses for the last 3 fiscal years\"\n",
    "# #     print(f\"‚Üí Query: {query}\\n\")\n",
    "# #     print(answer_opex_3y_baseline())\n",
    "\n",
    "#     # from __future__ import annotations\n",
    "\n",
    "# \"\"\"\n",
    "# Stage3.py ‚Äî Benchmark Runner (Stage 3)\n",
    "\n",
    "# Runs the 3 standardized queries for both the baseline and agentic pipelines,\n",
    "# times them, saves JSON/Markdown reports, and prints prose answers with citations.\n",
    "\n",
    "# Artifacts written to OUT_DIR (default: data/):\n",
    "#   - bench_results_baseline.json / bench_results_agent.json\n",
    "#   - bench_report_baseline.md / bench_report_agent.md\n",
    "# \"\"\"\n",
    "# import os, json, time, inspect\n",
    "# from typing import List, Dict, Any\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Explicitly import Stage-2 entrypoints so we don't rely on globals\n",
    "# # from g2 import init_stage2, answer_with_llm_baseline as answer_with_llm, answer_with_agent\n",
    "\n",
    "# OUT_DIR = os.environ.get(\"AGENT_CFO_OUT_DIR\", \"data\")\n",
    "\n",
    "# # --- Standardized queries (exact spec) ---\n",
    "# QUERIES: List[str] = [\n",
    "#     # 1) NIM trend over last 5 quarters\n",
    "#     \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
    "#     # # 2) Opex YoY table only (absolute & % change)\n",
    "#     # \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
    "#     # # 3) Operating Efficiency Ratio (Opex √∑ Operating Income) with working\n",
    "#     # \"Calculate the Operating Efficiency Ratio (Opex √∑ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# # --- Helper functions for answer call and output normalization ---\n",
    "# def _call_answer(func, query: str, dry_run: bool):\n",
    "#     \"\"\"Call answer function with optional dry_run if supported.\"\"\"\n",
    "#     try:\n",
    "#         params = inspect.signature(func).parameters\n",
    "#     except Exception:\n",
    "#         params = {}\n",
    "#     kwargs = {}\n",
    "#     if 'dry_run' in params:\n",
    "#         kwargs['dry_run'] = dry_run\n",
    "#     return func(query, **kwargs)\n",
    "\n",
    "# def _normalize_out(res) -> Dict[str, Any]:\n",
    "#     \"\"\"Coerce answer result to a dict with keys: answer, hits, execution_log.\"\"\"\n",
    "#     if isinstance(res, str):\n",
    "#         return {\"answer\": res, \"hits\": [], \"execution_log\": None}\n",
    "#     if isinstance(res, dict):\n",
    "#         ans = res.get(\"answer\") or res.get(\"Answer\") or str(res)\n",
    "#         hits = res.get(\"hits\") or res.get(\"Hits\") or []\n",
    "#         log  = res.get(\"execution_log\") or res.get(\"ExecutionLog\")\n",
    "#         return {\"answer\": ans, \"hits\": hits, \"execution_log\": log}\n",
    "#     return {\"answer\": str(res), \"hits\": [], \"execution_log\": None}\n",
    "\n",
    "\n",
    "# def _format_hits(hits: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "#     \"\"\"Helper to format citation hits for JSON output.\"\"\"\n",
    "#     out = []\n",
    "#     if not hits: return out\n",
    "#     for h in hits:\n",
    "#         out.append({\n",
    "#             \"file\": h.get(\"file\"),\n",
    "#             \"year\": h.get(\"year\"),\n",
    "#             \"quarter\": h.get(\"quarter\"),\n",
    "#             \"page\": h.get(\"page\"),\n",
    "#             \"section_hint\": h.get(\"section_hint\"),\n",
    "#         })\n",
    "#     return out\n",
    "\n",
    "\n",
    "\n",
    "# def run_benchmark(\n",
    "#     print_prose: bool = True,\n",
    "#     use_agent: bool = False,\n",
    "#     out_dir: str = OUT_DIR,\n",
    "#     dry_run: bool = False  # <-- NEW TOGGLE\n",
    "# ) -> Dict[str, Any]:\n",
    "#     \"\"\"\n",
    "#     Runs the benchmark for either the baseline RAG or the agentic pipeline.\n",
    "    \n",
    "#     Args:\n",
    "#         print_prose: Whether to print results to the console.\n",
    "#         use_agent: If True, uses answer_with_agent. If False, uses answer_with_llm.\n",
    "#         out_dir: The directory to save report files.\n",
    "#         dry_run: If True, prints prompts instead of calling the LLM API.\n",
    "#     \"\"\"\n",
    "#     # Guard: this module is intentionally NOT importing Stage 2.\n",
    "#     # The caller/notebook must `import g2` first so that the following names\n",
    "#     # are available in the global namespace.\n",
    "#     if use_agent and 'answer_with_agent' not in globals():\n",
    "#         raise RuntimeError(\"answer_with_agent is not defined. Import Stage 2 (g2) in the caller before running Stage 3.\")\n",
    "#     if not use_agent and 'answer_with_llm' not in globals():\n",
    "#         raise RuntimeError(\"answer_with_llm is not defined. Import Stage 2 (g2) in the caller before running Stage 3.\")\n",
    "\n",
    "#     os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "#     if use_agent:\n",
    "#         mode_name = \"agent\"\n",
    "#         answer_func = answer_with_agent\n",
    "#         print(\"\\n\" + \"=\"*25 + f\" RUNNING AGENT BENCHMARK \" + \"=\"*25)\n",
    "#     else:\n",
    "#         mode_name = \"baseline\"\n",
    "#         answer_func = answer_with_llm\n",
    "#         print(\"\\n\" + \"=\"*24 + f\" RUNNING BASELINE BENCHMARK \" + \"=\"*24)\n",
    "    \n",
    "#     if dry_run:\n",
    "#         print(\"--- üî¨ DRY RUN MODE IS ON ---\")\n",
    "\n",
    "#     json_path = os.path.join(out_dir, f\"bench_results_{mode_name}.json\")\n",
    "#     md_path = os.path.join(out_dir, f\"bench_report_{mode_name}.md\")\n",
    "\n",
    "#     results: List[Dict[str, Any]] = []\n",
    "#     latency_rows = []\n",
    "\n",
    "#     for q in QUERIES:\n",
    "#         t0 = time.perf_counter()\n",
    "#         raw = _call_answer(answer_func, q, dry_run=dry_run)\n",
    "#         out = _normalize_out(raw)\n",
    "#         lat_ms = round((time.perf_counter() - t0) * 1000.0, 2)\n",
    "\n",
    "#         if print_prose:\n",
    "#             print(f\"\\n=== Question ===\\n{q}\")\n",
    "#             print(\"\\n--- Answer ---\\n\")\n",
    "#             print(str(out[\"answer\"]).strip())\n",
    "#             if out.get(\"hits\"):\n",
    "#                 print(\"\\n--- Citations (top ctx) ---\")\n",
    "#                 for h in _format_hits(out.get(\"hits\", [])):\n",
    "#                     y = f\" {int(h['year'])}\" if h.get('year') is not None else \"\"\n",
    "#                     qtr_val = h.get('quarter')\n",
    "#                     qtr = f\" {int(qtr_val)}Q{str(y).strip()[2:]}\" if qtr_val else \"\"\n",
    "#                     sec = f\" ‚Äî {h['section_hint']}\" if h.get('section_hint') else \"\"\n",
    "#                     print(f\"- {h['file']}{y}{qtr} ‚Äî p.{h['page']}{sec}\")\n",
    "#             print(f\"\\n(latency: {lat_ms} ms)\")\n",
    "\n",
    "#         results.append({\n",
    "#             \"query\": q,\n",
    "#             \"answer\": out.get(\"answer\"),\n",
    "#             \"hits\": _format_hits(out.get(\"hits\", [])),\n",
    "#             \"execution_log\": out.get(\"execution_log\"),\n",
    "#             \"latency_ms\": lat_ms,\n",
    "#         })\n",
    "#         latency_rows.append({\"Query\": q, \"Latency_ms\": lat_ms})\n",
    "\n",
    "#     # Saving logic remains the same...\n",
    "#     with open(json_path, \"w\") as f:\n",
    "#         json.dump({\"results\": results}, f, indent=2)\n",
    "\n",
    "#     md_lines = [f\"# Agent CFO ‚Äî {mode_name.title()} Benchmark Report\\n\"]\n",
    "#     for i, r in enumerate(results, start=1):\n",
    "#         md_lines.append(f\"\\n---\\n\\n## Q{i}. {r['query']}\")\n",
    "#         md_lines.append(\"\\n**Answer**\\n\\n\" + r[\"answer\"].strip())\n",
    "#         if r.get(\"hits\"):\n",
    "#             md_lines.append(\"\\n**Citations (top ctx)**\")\n",
    "#             for h in r[\"hits\"]:\n",
    "#                 y = f\" {int(h['year'])}\" if h.get('year') is not None else \"\"\n",
    "#                 qtr_val = h.get('quarter')\n",
    "#                 qtr = f\" {int(qtr_val)}Q{str(y).strip()[2:]}\" if qtr_val else \"\"\n",
    "#                 sec = f\" ‚Äî {h['section_hint']}\" if h.get('section_hint') else \"\"\n",
    "#                 md_lines.append(f\"- {h['file']}{y}{qtr} ‚Äî p.{h['page']}{sec}\")\n",
    "#         if r.get(\"execution_log\"):\n",
    "#             md_lines.append(\"\\n**Execution Log**\\n\")\n",
    "#             md_lines.append(\"```json\")\n",
    "#             md_lines.append(json.dumps(r[\"execution_log\"], indent=2))\n",
    "#             md_lines.append(\"```\")\n",
    "\n",
    "#     with open(md_path, \"w\") as f:\n",
    "#         f.write(\"\\n\".join(md_lines) + \"\\n\")\n",
    "\n",
    "#     df = pd.DataFrame(latency_rows)\n",
    "#     if print_prose and not df.empty:\n",
    "#         p50 = float(df['Latency_ms'].quantile(0.5))\n",
    "#         p95 = float(df['Latency_ms'].quantile(0.95))\n",
    "#         print(f\"\\n=== {mode_name.upper()} Benchmark Summary ===\")\n",
    "#         print(f\"Saved JSON: {json_path}\")\n",
    "#         print(f\"Saved report: {md_path}\")\n",
    "#         print(f\"Latency p50: {p50:.1f} ms, p95: {p95:.1f} ms\")\n",
    "\n",
    "#     return {\"json_path\": json_path, \"md_path\": md_path, \"summary\": df}\n",
    "\n",
    "\n",
    "# #########################################################################333\n",
    "\n",
    "# #!/usr/bin/env python3\n",
    "# # -*- coding: utf-8 -*-\n",
    "\n",
    "# \"\"\"\n",
    "# g3x.py ‚Äî Task runner over your FAISS/Marker KB (agentic tools) + optional ONLINE LLM answers\n",
    "\n",
    "# This runs 3 specific analyses using the tools/agent from g2x.py:\n",
    "\n",
    "#   1) NIM trend over last 5 quarters\n",
    "#      -> \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\"\n",
    "#   2) Operating Expenses YoY table (absolute & % change) for last 3 fiscal years\n",
    "#      -> \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\"\n",
    "#   3) Operating Efficiency Ratio (Opex √∑ Operating Income) with working\n",
    "#      -> \"Calculate the Operating Efficiency Ratio (Opex √∑ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
    "\n",
    "# All offline. Import and run from a notebook cell:\n",
    "#     from g3x import run_all\n",
    "#     run_all(base=\"./data_marker\")\n",
    "# \"\"\"\n",
    "\n",
    "# from typing import Dict, List, Optional, Tuple\n",
    "# import math\n",
    "# import re\n",
    "# import os\n",
    "# from g2x import KBEnv, Agent, show_agent_result, _llm_single_call, baseline_answer_one_call, _llm_provider_info\n",
    "# # Feature flag for LLM summaries (set USE_LLM_SUMMARY=0/false in env to disable)\n",
    "# USE_LLM_SUMMARY = os.getenv(\"USE_LLM_SUMMARY\", \"1\") not in (\"0\", \"false\", \"False\")\n",
    "# # ONLINE flag for baseline LLM calls (set ONLINE=0/false in env to disable)\n",
    "# ONLINE = os.getenv(\"ONLINE\", \"1\") not in (\"0\", \"false\", \"False\")\n",
    "\n",
    "# # ---------- helpers ----------\n",
    "\n",
    "# def _llm_summary(\n",
    "#     question: str,\n",
    "#     agent: Agent,\n",
    "#     kb: KBEnv,\n",
    "#     res=None,\n",
    "#     k_ctx: int = 8,\n",
    "#     rows_override: Optional[List[dict]] = None\n",
    "# ) -> str:\n",
    "#     \"\"\"One LLM call to summarize/answer using extracted tables if present, else vector contexts.\"\"\"\n",
    "#     lines = []\n",
    "#     # Prefer table rows from override if provided, else from the result\n",
    "#     rows = rows_override if rows_override is not None else []\n",
    "#     if not rows and res and getattr(res, 'final', None):\n",
    "#         rows = res.final.get(\"table_rows\") or []\n",
    "#     if rows:\n",
    "#         lines.append(\"TABLE EXTRACTS:\")\n",
    "#         for r in rows[:2]:\n",
    "#             # prefer quarters if any\n",
    "#             sq = r.get(\"series_q\") or {}\n",
    "#             if sq:\n",
    "#                 # sort quarters\n",
    "#                 def _qkey(k):\n",
    "#                     m = re.match(r\"([1-4])Q(20\\d{2})$\", k)\n",
    "#                     return (int(m.group(2)), int(m.group(1))) if m else (0,0)\n",
    "#                 qkeys = sorted(sq.keys(), key=_qkey)[-5:]\n",
    "#                 ser = \", \".join(f\"{k}: {sq[k]}\" for k in qkeys)\n",
    "#                 lines.append(f\"- {r['doc']} | {r['label']} | quarters(last5)={ser}\")\n",
    "#             else:\n",
    "#                 ys = sorted((r.get(\"series\") or {}).keys())[-3:]\n",
    "#                 ser = \", \".join(f\"{y}: {r['series'][y]}\" for y in ys)\n",
    "#                 lines.append(f\"- {r['doc']} | {r['label']} | years(last3)={ser}\")\n",
    "#     # If nothing extracted, fall back to vector contexts\n",
    "#     if not lines:\n",
    "#         ctx = kb.search(question, k=k_ctx)\n",
    "#         if ctx is not None and not ctx.empty:\n",
    "#             lines.append(\"CONTEXT SNIPPETS:\")\n",
    "#             for _, row in ctx.head(5).iterrows():\n",
    "#                 text = str(row[\"text\"]).replace(\"\\n\", \" \").strip()\n",
    "#                 if len(text) > 600:\n",
    "#                     text = text[:600] + \"...\"\n",
    "#                 lines.append(\"- \" + text)\n",
    "#     # Provide page-level hints for better citations\n",
    "#     if rows:\n",
    "#         hint_lines = []\n",
    "#         for r in rows[:4]:\n",
    "#             p = r.get('page')\n",
    "#             if p is not None:\n",
    "#                 hint_lines.append(f\"- {r.get('doc')}, page {int(p)}\")\n",
    "#             else:\n",
    "#                 hint_lines.append(f\"- {r.get('doc')}, table {r.get('table_id')} row {r.get('row_id')} (no page)\")\n",
    "#         if hint_lines:\n",
    "#             lines.append(\"CITATION HINTS:\")\n",
    "#             lines.extend(hint_lines)\n",
    "#     # Build prompt\n",
    "#     context_block = \"\\n\".join(lines) if lines else \"(no structured context found)\"\n",
    "#     prompt = (\n",
    "#         \"USER QUESTION:\\n\" + question + \"\\n\\n\" +\n",
    "#         context_block +\n",
    "#         \"\\n\\nINSTRUCTIONS:\\n\"\n",
    "#         \"- You are given STRUCTURED TABLE ROWS and/or CONTEXT SNIPPETS above.\\n\"\n",
    "#         \"- If STRUCTURED TABLE ROWS are present, you MUST use ONLY those numbers for your answer and calculations.\\n\"\n",
    "#         \"- Do NOT claim data is missing if the numbers are present in the structured rows.\\n\"\n",
    "#         \"- If the task asks for 'Operating Income' but the rows contain 'Total income' only, TREAT 'Total income' as the denominator for Operating Efficiency Ratio.\\n\"\n",
    "#         \"- If a requested period truly does not appear in the structured rows, say so explicitly and do not infer.\\n\"\n",
    "#         \"- Return a concise answer, followed by a tiny table if applicable.\"\n",
    "#     )\n",
    "#     print(f\"[LLM] summary using {_llm_provider_info()}\")\n",
    "#     return _llm_single_call(prompt)\n",
    "\n",
    "# # ---------- helpers ----------\n",
    "\n",
    "# def _last_n_quarters(series_q: Dict[str, float], n: int = 5) -> List[Tuple[str, float]]:\n",
    "#     if not series_q:\n",
    "#         return []\n",
    "#     def _qkey(k: str):\n",
    "#         m = re.match(r\"([1-4])Q(20\\d{2})$\", k)\n",
    "#         if m:\n",
    "#             return (int(m.group(2)), int(m.group(1)))\n",
    "#         return (0, 0)\n",
    "#     keys = sorted(series_q.keys(), key=_qkey)\n",
    "#     last = keys[-n:]\n",
    "#     return [(k, series_q[k]) for k in last]\n",
    "\n",
    "# def _last_n_years(series: Dict[int, float], n: int = 3) -> List[Tuple[int, float]]:\n",
    "#     if not series:\n",
    "#         return []\n",
    "#     ys = sorted(series.keys())\n",
    "#     sel = ys[-n:]\n",
    "#     return [(y, series[y]) for y in sel]\n",
    "\n",
    "# def _pct(a: float, b: float) -> Optional[float]:\n",
    "#     b = float(b)\n",
    "#     if b == 0:\n",
    "#         return None\n",
    "#     return (float(a) - b) / b * 100.0\n",
    "\n",
    "# def _union_series(rows):\n",
    "#     \"\"\"\n",
    "#     Merge {year->value} across many table rows from different docs and\n",
    "#     return (values, provenance) where provenance maps each year to a list\n",
    "#     of sources that contributed that year's value:\n",
    "#         provenance[year] = [{\"doc\":..., \"table_id\":..., \"row_id\":..., \"page\": ...}, ...]\n",
    "#     The first non-null value encountered for a year is kept as the value.\n",
    "#     \"\"\"\n",
    "#     values = {}\n",
    "#     prov = {}\n",
    "#     for r in rows or []:\n",
    "#         doc = r.get(\"doc\")\n",
    "#         tid = r.get(\"table_id\")\n",
    "#         rid = r.get(\"row_id\")\n",
    "#         page = r.get(\"page\")\n",
    "#         series = r.get(\"series\") or {}\n",
    "#         for y, v in series.items():\n",
    "#             if v is None:\n",
    "#                 continue\n",
    "#             # record provenance regardless\n",
    "#             prov.setdefault(y, []).append({\n",
    "#                 \"doc\": doc, \"table_id\": tid, \"row_id\": rid, \"page\": page\n",
    "#             })\n",
    "#             # keep the first seen value for this year\n",
    "#             if y not in values:\n",
    "#                 values[y] = v\n",
    "#     return values, prov\n",
    "\n",
    "# def _last_n_years_map(series_map, n: int = 3):\n",
    "#     ys = sorted(series_map.keys())\n",
    "#     sel = ys[-n:]\n",
    "#     return [(y, series_map[y]) for y in sel]\n",
    "\n",
    "# # Helper to pick a representative source for a year\n",
    "# def _pick_source_for_year(prov_map, y):\n",
    "#     \"\"\"\n",
    "#     Choose one representative source dict for a given year\n",
    "#     from the provenance map, preferring entries with a page number.\n",
    "#     \"\"\"\n",
    "#     items = prov_map.get(y) or []\n",
    "#     if not items:\n",
    "#         return None\n",
    "#     with_page = [s for s in items if s.get(\"page\") is not None]\n",
    "#     return (with_page[0] if with_page else items[0])\n",
    "\n",
    "# # ---------- Q1: NIM last 5 quarters ----------\n",
    "\n",
    "# def run_q1_nim_last5q(agent: Agent, kb: KBEnv):\n",
    "#     q = \"Net Interest Margin over the last 5 quarters\"\n",
    "#     res = agent.run(q, k_ctx=6)\n",
    "#     print(\"\\n=== Q1) Net Interest Margin ‚Äî last 5 quarters ===\")\n",
    "#     # Try table rows with quarters\n",
    "#     rows = res.final.get(\"table_rows\") or []\n",
    "#     picked = None\n",
    "#     for r in rows:\n",
    "#         if r.get(\"series_q\"):\n",
    "#             picked = r\n",
    "#             break\n",
    "#     if not picked:\n",
    "#         print(\"‚ö†Ô∏è No quarterly NIM found in indexed tables.\")\n",
    "#         # fall back to annual if available\n",
    "#         for r in rows:\n",
    "#             if r.get(\"series\"):\n",
    "#                 years = _last_n_years(r[\"series\"], n=3)\n",
    "#                 print(\"Fallback (years):\", \", \".join(f\"{y}: {v}\" for y, v in years))\n",
    "#                 break\n",
    "#         # LLM summary even if not found\n",
    "#         if USE_LLM_SUMMARY:\n",
    "#             print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#             print(_llm_summary(q, agent, kb, res=res, k_ctx=8, rows_override=([picked] if picked else rows)))\n",
    "#         if ONLINE:\n",
    "#             print(\"\\nLLM Answer (online, single call):\")\n",
    "#             print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#             tr = ([picked] if picked else rows)\n",
    "#             baseline_answer_one_call(kb, q, k_ctx=8, table_rows=tr)\n",
    "#         return res\n",
    "#     last5 = _last_n_quarters(picked[\"series_q\"], n=5)\n",
    "#     if not last5:\n",
    "#         print(\"‚ö†Ô∏è No quarterly NIM found in indexed tables.\")\n",
    "#         if USE_LLM_SUMMARY:\n",
    "#             print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#             print(_llm_summary(q, agent, kb, res=res, k_ctx=8))\n",
    "#         if ONLINE:\n",
    "#             print(\"\\nLLM Answer (online, single call):\")\n",
    "#             print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#             tr = ([picked] if picked else rows)\n",
    "#             baseline_answer_one_call(kb, q, k_ctx=8, table_rows=tr)\n",
    "#         return res\n",
    "#     print(f\"Source: {picked['doc']} | label: {picked['label']}\")\n",
    "#     print(\"Values (last 5): \" + \", \".join(f\"{k}: {v}\" for k, v in last5))\n",
    "#     if USE_LLM_SUMMARY:\n",
    "#         print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#         print(_llm_summary(q, agent, kb, res=res, k_ctx=8, rows_override=([picked] if picked else rows)))\n",
    "#     if ONLINE:\n",
    "#         print(\"\\nLLM Answer (online, single call):\")\n",
    "#         print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#         tr = ([picked] if picked else rows)\n",
    "#         baseline_answer_one_call(kb, q, k_ctx=8, table_rows=tr)\n",
    "#     return res\n",
    "\n",
    "# # ---------- Q2: Opex last 3 fiscal years with YoY ----------\n",
    "\n",
    "# def run_q2_opex_yoy(agent: Agent, kb: KBEnv):\n",
    "#     q = \"Operating Expenses last 3 fiscal years YoY\"\n",
    "#     res = agent.run(q, k_ctx=6)\n",
    "#     print(\"\\n=== Q2) Operating Expenses ‚Äî last 3 fiscal years (YoY) ===\")\n",
    "\n",
    "#     # Pull MANY rows then union across docs/tables to recover a continuous series\n",
    "#     rows = agent.table.get_metric_rows(\"operating expenses\", limit=50)\n",
    "#     if not rows:\n",
    "#         rows = agent.table.get_metric_rows(\"total expenses\", limit=50)\n",
    "\n",
    "#     combo, prov = _union_series(rows)\n",
    "#     # Build per-year rows with real provenance so citations show actual docs/pages\n",
    "#     years_for_report = sorted(combo.keys())[-3:] if combo else []\n",
    "#     rows_yearwise = []\n",
    "#     for y in years_for_report:\n",
    "#         src = _pick_source_for_year(prov, y)\n",
    "#         rows_yearwise.append({\n",
    "#             \"doc\": (src.get(\"doc\") if src else \"(unknown)\"),\n",
    "#             \"table_id\": (src.get(\"table_id\") if src else -1),\n",
    "#             \"row_id\": (src.get(\"row_id\") if src else -1),\n",
    "#             \"label\": \"Operating expenses\",\n",
    "#             \"series\": {y: combo.get(y)},\n",
    "#             \"series_q\": {},\n",
    "#             \"page\": (src.get(\"page\") if src and src.get(\"page\") is not None else None),\n",
    "#         })\n",
    "#     # Fallback: if something went wrong, still provide a single combined row\n",
    "#     if not rows_yearwise:\n",
    "#         rows_yearwise = [{\n",
    "#             \"doc\": \"(union)\",\n",
    "#             \"table_id\": -1,\n",
    "#             \"row_id\": -1,\n",
    "#             \"label\": \"Operating expenses\",\n",
    "#             \"series\": combo,\n",
    "#             \"series_q\": {},\n",
    "#             \"page\": None\n",
    "#         }]\n",
    "#     if not combo:\n",
    "#         print(\"‚ö†Ô∏è No expenses series found across docs.\")\n",
    "#         if USE_LLM_SUMMARY:\n",
    "#             print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#             print(_llm_summary(q, agent, kb, res=res, k_ctx=8, rows_override=rows_yearwise))\n",
    "#         if ONLINE:\n",
    "#             print(\"\\nLLM Answer (online, single call):\")\n",
    "#             print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#             baseline_answer_one_call(kb, q, k_ctx=8, table_rows=rows_yearwise)\n",
    "#         return res\n",
    "\n",
    "#     last3 = [(y, combo[y]) for y in years_for_report]\n",
    "#     if len(last3) < 2:\n",
    "#         print(\"‚ö†Ô∏è Not enough annual values to compute YoY.\")\n",
    "#         if USE_LLM_SUMMARY:\n",
    "#             print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#             print(_llm_summary(q, agent, kb, res=res, k_ctx=8, rows_override=rows_yearwise))\n",
    "#         if ONLINE:\n",
    "#             print(\"\\nLLM Answer (online, single call):\")\n",
    "#             print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#             baseline_answer_one_call(kb, q, k_ctx=8, table_rows=rows_yearwise)\n",
    "#         return res\n",
    "\n",
    "#     print(\"Year | Opex | YoY %\")\n",
    "#     print(\"-----|------|------\")\n",
    "#     prev_val = None\n",
    "#     for y, v in last3:\n",
    "#         yoy = ((v - prev_val) / prev_val * 100.0) if prev_val not in (None, 0) else None\n",
    "#         yoy_s = f\"{yoy:.2f}%\" if yoy is not None else \"‚Äî\"\n",
    "#         print(f\"{y} | {v} | {yoy_s}\")\n",
    "#         prev_val = v\n",
    "\n",
    "#     # Show sources (doc & page) used for each year printed\n",
    "#     print(\"\\nSources:\")\n",
    "#     for y, _ in last3:\n",
    "#         src = _pick_source_for_year(prov, y)\n",
    "#         if src:\n",
    "#             p = src.get(\"page\")\n",
    "#             ptxt = f\"page {int(p)}\" if p is not None else \"no page\"\n",
    "#             print(f\"  {y}: {src.get('doc')} ({ptxt})\")\n",
    "\n",
    "#     if USE_LLM_SUMMARY:\n",
    "#         print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#         print(_llm_summary(q, agent, kb, res=res, k_ctx=8, rows_override=rows_yearwise))\n",
    "#     if ONLINE:\n",
    "#         print(\"\\nLLM Answer (online, single call):\")\n",
    "#         print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#         baseline_answer_one_call(kb, q, k_ctx=8, table_rows=rows_yearwise)\n",
    "\n",
    "#     return res\n",
    "\n",
    "# # ---------- Q3: Operating Efficiency Ratio (Opex √∑ Operating Income) ----------\n",
    "\n",
    "# def run_q3_efficiency_ratio(agent: Agent, kb: KBEnv):\n",
    "#     print(\"\\n=== Q3) Operating Efficiency Ratio ‚Äî last 3 fiscal years ===\")\n",
    "\n",
    "#     # Union Opex across docs/tables\n",
    "#     opex_rows = agent.table.get_metric_rows(\"operating expenses\", limit=50) \\\n",
    "#         or agent.table.get_metric_rows(\"total expenses\", limit=50)\n",
    "#     opex, opex_prov = _union_series(opex_rows)\n",
    "\n",
    "#     # Union Income across docs/tables (prefer 'total income', else 'operating income')\n",
    "#     income_rows = agent.table.get_metric_rows(\"total income\", limit=50) \\\n",
    "#         or agent.table.get_metric_rows(\"operating income\", limit=50)\n",
    "#     income, income_prov = _union_series(income_rows)\n",
    "\n",
    "#     # Build per-year rows for both Opex and Income so citations show real docs/pages\n",
    "#     rows_for_llm = []\n",
    "#     years_overlap = sorted(set(opex.keys()).intersection(income.keys()))[-3:]\n",
    "#     for y in years_overlap:\n",
    "#         s_ox = _pick_source_for_year(opex_prov, y)\n",
    "#         s_in = _pick_source_for_year(income_prov, y)\n",
    "#         rows_for_llm.append({\n",
    "#             \"doc\": (s_ox.get(\"doc\") if s_ox else \"(unknown)\"),\n",
    "#             \"table_id\": (s_ox.get(\"table_id\") if s_ox else -1),\n",
    "#             \"row_id\": (s_ox.get(\"row_id\") if s_ox else -1),\n",
    "#             \"label\": \"Operating expenses\",\n",
    "#             \"series\": {y: opex.get(y)},\n",
    "#             \"series_q\": {},\n",
    "#             \"page\": (s_ox.get(\"page\") if s_ox and s_ox.get(\"page\") is not None else None)\n",
    "#         })\n",
    "#         rows_for_llm.append({\n",
    "#             \"doc\": (s_in.get(\"doc\") if s_in else \"(unknown)\"),\n",
    "#             \"table_id\": (s_in.get(\"table_id\") if s_in else -1),\n",
    "#             \"row_id\": (s_in.get(\"row_id\") if s_in else -1),\n",
    "#             \"label\": \"Total income\",\n",
    "#             \"series\": {y: income.get(y)},\n",
    "#             \"series_q\": {},\n",
    "#             \"page\": (s_in.get(\"page\") if s_in and s_in.get(\"page\") is not None else None)\n",
    "#         })\n",
    "#     # Fallback to union-style rows if needed\n",
    "#     if not rows_for_llm:\n",
    "#         rep_year = max(opex.keys() & income.keys()) if (opex and income) else None\n",
    "#         rep_opex = _pick_source_for_year(opex_prov, rep_year) if rep_year else None\n",
    "#         rep_income = _pick_source_for_year(income_prov, rep_year) if rep_year else None\n",
    "#         rows_for_llm = [\n",
    "#             {\n",
    "#                 \"doc\": (rep_opex.get(\"doc\") if rep_opex else \"(union)\"),\n",
    "#                 \"table_id\": (rep_opex.get(\"table_id\") if rep_opex else -1),\n",
    "#                 \"row_id\": (rep_opex.get(\"row_id\") if rep_opex else -1),\n",
    "#                 \"label\": \"Operating expenses\",\n",
    "#                 \"series\": opex or {},\n",
    "#                 \"series_q\": {},\n",
    "#                 \"page\": (rep_opex.get(\"page\") if rep_opex else None)\n",
    "#             },\n",
    "#             {\n",
    "#                 \"doc\": (rep_income.get(\"doc\") if rep_income else \"(union)\"),\n",
    "#                 \"table_id\": (rep_income.get(\"table_id\") if rep_income else -1),\n",
    "#                 \"row_id\": (rep_income.get(\"row_id\") if rep_income else -1),\n",
    "#                 \"label\": \"Total income\",\n",
    "#                 \"series\": income or {},\n",
    "#                 \"series_q\": {},\n",
    "#                 \"page\": (rep_income.get(\"page\") if rep_income else None)\n",
    "#             },\n",
    "#         ]\n",
    "\n",
    "#     if not opex or not income:\n",
    "#         print(\"‚ö†Ô∏è Missing Opex or Income series across docs.\")\n",
    "#         if USE_LLM_SUMMARY:\n",
    "#             print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#             q = \"Operating Efficiency Ratio (Opex / Operating Income) for the last 3 fiscal years\"\n",
    "#             print(_llm_summary(q, agent, kb, res=None, k_ctx=8, rows_override=rows_for_llm))\n",
    "#         if ONLINE:\n",
    "#             print(\"\\nLLM Answer (online, single call):\")\n",
    "#             print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#             q_llm = \"Operating Efficiency Ratio (Opex / Operating Income) for the last 3 fiscal years\"\n",
    "#             baseline_answer_one_call(kb, q_llm, k_ctx=8, table_rows=rows_for_llm)\n",
    "#         return None\n",
    "\n",
    "#     years = years_overlap\n",
    "#     if not years:\n",
    "#         print(\"‚ö†Ô∏è No overlapping years between Opex and Income.\")\n",
    "#         if USE_LLM_SUMMARY:\n",
    "#             print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#             q = \"Operating Efficiency Ratio (Opex / Operating Income) for the last 3 fiscal years\"\n",
    "#             print(_llm_summary(q, agent, kb, res=None, k_ctx=8, rows_override=rows_for_llm))\n",
    "#         if ONLINE:\n",
    "#             print(\"\\nLLM Answer (online, single call):\")\n",
    "#             print(f\"[LLM] baseline using {_llm_provider_info()}\")\n",
    "#             q_llm = \"Operating Efficiency Ratio (Opex / Operating Income) for the last 3 fiscal years\"\n",
    "#             baseline_answer_one_call(kb, q_llm, k_ctx=8, table_rows=rows_for_llm)\n",
    "#         return None\n",
    "\n",
    "#     print(\"Year | Opex | Income | Opex/Income %\")\n",
    "#     print(\"-----|------|--------|---------------\")\n",
    "#     for y in years:\n",
    "#         ov = opex.get(y)\n",
    "#         iv = income.get(y)\n",
    "#         ratio = (ov / iv * 100.0) if (iv not in (None, 0)) else None\n",
    "#         ratio_s = f\"{ratio:.2f}%\" if ratio is not None else \"‚Äî\"\n",
    "#         print(f\"{y} | {ov} | {iv} | {ratio_s}\")\n",
    "\n",
    "#     print(\"\\nSources:\")\n",
    "#     for y in years:\n",
    "#         s1 = _pick_source_for_year(opex_prov, y)\n",
    "#         s2 = _pick_source_for_year(income_prov, y)\n",
    "#         if s1:\n",
    "#             p1 = s1.get(\"page\"); p1t = f\"page {int(p1)}\" if p1 is not None else \"no page\"\n",
    "#             print(f\"  Opex {y}: {s1.get('doc')} ({p1t})\")\n",
    "#         if s2:\n",
    "#             p2 = s2.get(\"page\"); p2t = f\"page {int(p2)}\" if p2 is not None else \"no page\"\n",
    "#             print(f\"  Income {y}: {s2.get('doc')} ({p2t})\")\n",
    "\n",
    "#     if USE_LLM_SUMMARY:\n",
    "#         print(\"\\nLLM Summary (baseline, single call):\")\n",
    "#         q = \"Operating Efficiency Ratio (Opex / Operating Income) for the last 3 fiscal years\"\n",
    "#         print(_llm_summary(q, agent, kb, res=None, k_ctx=8, rows_override=rows_for_llm))\n",
    "#     if ONLINE:\n",
    "#         print(\"\\nLLM Answer (online, single call):\")\n",
    "#         q_llm = \"Operating Efficiency Ratio (Opex / Operating Income) for the last 3 fiscal years\"\n",
    "#         baseline_answer_one_call(kb, q_llm, k_ctx=8, table_rows=rows_for_llm)\n",
    "\n",
    "#     return {\"years\": years, \"opex\": opex, \"income\": income}\n",
    "\n",
    "# # ---------- Runner ----------\n",
    "\n",
    "# def run_all(base: str = \"./data_marker\"):\n",
    "#     kb = KBEnv(base=base)\n",
    "#     agent = Agent(kb)\n",
    "\n",
    "#     # Q1\n",
    "#     # res1 = run_q1_nim_last5q(agent, kb)\n",
    "\n",
    "#     # Q2\n",
    "#     res2 = run_q2_opex_yoy(agent, kb)\n",
    "\n",
    "#     # Q3\n",
    "#     _ = run_q3_efficiency_ratio(agent, kb)\n",
    "\n",
    "# # # Auto-run when executed directly (safe in notebooks too)\n",
    "# # if __name__ == \"__main__\" or \"__file__\" not in globals():\n",
    "# #     run_all(base=\"./data_marker\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Ensure Stage 2 is initialized, then run baseline with prose printing\n",
    "#     try:\n",
    "#         init_stage2(out_dir=OUT_DIR)\n",
    "#         print(\"[Stage3] init_stage2() called successfully.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"[Stage3] init_stage2() failed: {e}\")\n",
    "    \n",
    "#     bench = run_benchmark(print_prose=True, use_agent=False, out_dir=OUT_DIR, dry_run=False)\n",
    "#     # Also echo the summary table at the end\n",
    "#     if isinstance(bench.get(\"summary\"), pd.DataFrame) and not bench[\"summary\"].empty:\n",
    "#         df = bench[\"summary\"]\n",
    "#         p50 = float(df['Latency_ms'].quantile(0.5))\n",
    "#         p95 = float(df['Latency_ms'].quantile(0.95))\n",
    "#         print(f\"\\n=== BASELINE Benchmark Summary ===\")\n",
    "#         print(f\"Latency p50: {p50:.1f} ms, p95: {p95:.1f} ms\")\n",
    "\n",
    "#     run_all(base=\"./data_marker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1329d25",
   "metadata": {},
   "source": [
    "Two-Mode RAG System with Marker + PDFPlumber Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "befb503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnsweringEngine initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 9a0f4f5e-0a7f-4893-8947-62808aebfcd7)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001ACF97FE260>: Failed to resolve \\'huggingface.co\\' ([Errno 11004] getaddrinfo failed)\"))'), '(Request ID: 78292f5d-99f2-4f2e-9768-2aa36c737d1f)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 2s [Retry 2/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BM25] ‚úì Indexed 13548 documents\n",
      "[Reranker] ‚úì Loaded cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "[Marker] ‚úì Loaded 13548 chunks\n",
      "[BM25] ‚úì Indexed 1623 documents\n",
      "[Reranker] ‚úì Loaded cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "[PDFPlumber] ‚úì Loaded 1623 chunks\n",
      "[Agent] Tools: Calculator: ‚úì | Table: ‚úì | Text: ‚úì | MultiDoc: ‚úì\n",
      "[AnsweringEngine] Parallel sub-queries enabled: True\n",
      "\n",
      "============================================================\n",
      "  TWO-MODE RAG SYSTEM\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "  BASELINE BENCHMARK\n",
      "============================================================\n",
      "\n",
      "\n",
      "Q1. Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\n",
      "\n",
      "[Search] RRF fusion: 96 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[Search] RRF fusion: 387 candidates\n",
      "[Rerank] Reranking top-100 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[LLM] single-call baseline using groq:openai/gpt-oss-20b\n",
      "[LLM] provider=groq model=openai/gpt-oss-20b\n",
      "\n",
      "BASELINE (Single LLM Call)\n",
      "--------------------------------\n",
      "**Net Interest Margin (last‚ÄØ5‚ÄØquarters)**  \n",
      "\n",
      "| Quarter | Net Interest Margin |\n",
      "|---------|---------------------|\n",
      "| Q4‚ÄØ2024 | 2.13‚ÄØ% |\n",
      "| Q3‚ÄØ2024 | **data not available** |\n",
      "| Q2‚ÄØ2024 | **data not available** |\n",
      "| Q1‚ÄØ2024 | **data not available** |\n",
      "| Q4‚ÄØ2023 | 2.15‚ÄØ% |\n",
      "\n",
      "*The only quarter‚Äëspecific figures in the provided context are for Q4‚ÄØ2024 and Q4‚ÄØ2023.  No quarter‚Äëlevel values are given for Q3‚ÄØ2024, Q2‚ÄØ2024, or Q1‚ÄØ2024.*\n",
      "\n",
      "**Citations**\n",
      "\n",
      "- 4Q24 performance summary ‚Äì Net interest margin 2.13‚ÄØ% for Q4‚ÄØ2024.  \n",
      "- DBS Annual Report‚ÄØ2023 ‚Äì Net interest margin 2.15‚ÄØ% for Q4‚ÄØ2023.  \n",
      "- DBS Annual Report‚ÄØ2022 ‚Äì Net interest margin 1.75‚ÄØ% for Q4‚ÄØ2022, 1.45‚ÄØ% for Q4‚ÄØ2021, 1.62‚ÄØ% for Q4‚ÄØ2020.\n",
      "\n",
      "Citations:\n",
      "- dbs-annual-report-2022, page nan\n",
      "- 2Q24_performance_summary, page 9.0\n",
      "- dbs-annual-report-2022, page 96.0\n",
      "- dbs-annual-report-2022, page 96.0\n",
      "- dbs-annual-report-2023, page 95.0\n",
      "**Net Interest Margin (last‚ÄØ5‚ÄØquarters)**  \n",
      "\n",
      "| Quarter | Net Interest Margin |\n",
      "|---------|---------------------|\n",
      "| Q4‚ÄØ2024 | 2.13‚ÄØ% |\n",
      "| Q3‚ÄØ2024 | **data not available** |\n",
      "| Q2‚ÄØ2024 | **data not available** |\n",
      "| Q1‚ÄØ2024 | **data not available** |\n",
      "| Q4‚ÄØ2023 | 2.15‚ÄØ% |\n",
      "\n",
      "*The only quarter‚Äëspecific figures in the provided context are for Q4‚ÄØ2024 and Q4‚ÄØ2023.  No quarter‚Äëlevel values are given for Q3‚ÄØ2024, Q2‚ÄØ2024, or Q1‚ÄØ2024.*\n",
      "\n",
      "**Citations**\n",
      "\n",
      "- 4Q24 performance summary ‚Äì Net interest margin 2.13‚ÄØ% for Q4‚ÄØ2024.  \n",
      "- DBS Annual Report‚ÄØ2023 ‚Äì Net interest margin 2.15‚ÄØ% for Q4‚ÄØ2023.  \n",
      "- DBS Annual Report‚ÄØ2022 ‚Äì Net interest margin 1.75‚ÄØ% for Q4‚ÄØ2022, 1.45‚ÄØ% for Q4‚ÄØ2021, 1.62‚ÄØ% for Q4‚ÄØ2020.\n",
      "\n",
      "--- Citations ---\n",
      "- dbs-annual-report-2022  [marker] (score: 0.6558)\n",
      "- 2Q24_performance_summary p.9 [marker] (score: -0.5437)\n",
      "- dbs-annual-report-2022 p.96 [marker] (score: -0.7675)\n",
      "- dbs-annual-report-2022 p.96 [marker] (score: -0.7991)\n",
      "- dbs-annual-report-2023 p.95 [marker] (score: -1.0668)\n",
      "\n",
      "(Latency: 7340.2 ms)\n",
      "\n",
      "Q2. Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\n",
      "\n",
      "[Search] RRF fusion: 96 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[Search] RRF fusion: 385 candidates\n",
      "[Rerank] Reranking top-100 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[LLM] single-call baseline using groq:openai/gpt-oss-20b\n",
      "[LLM] provider=groq model=openai/gpt-oss-20b\n",
      "\n",
      "BASELINE (Single LLM Call)\n",
      "--------------------------------\n",
      "**Operating Expenses (in‚ÄØ$‚ÄØmillion)**  \n",
      "\n",
      "| Fiscal year | Operating‚ÄØExpenses | YoY‚ÄØ% change |\n",
      "|-------------|--------------------|--------------|\n",
      "| 2024 | 5,273 | **+14‚ÄØ%** (vs‚ÄØ2023) |\n",
      "| 2023 | 4,627 | **+22‚ÄØ%** (vs‚ÄØ2022) |\n",
      "| 2022 | 3,803 | ‚Äì |\n",
      "\n",
      "*The 2024 figure is 14‚ÄØ% higher than 2023 (as reported).  \n",
      "The 2023‚Äëto‚Äë2022 increase is calculated: (4,627‚ÄØ‚Äì‚ÄØ3,803)‚ÄØ/‚ÄØ3,803‚ÄØ‚âà‚ÄØ22‚ÄØ%.*\n",
      "\n",
      "**Citations**\n",
      "\n",
      "- [dbs‚Äëannual‚Äëreport‚Äë2024] table#7 row#3 ‚Äì 2024‚ÄØ=‚ÄØ5,273; 2023‚ÄØ=‚ÄØ4,627; YoY‚ÄØ%‚ÄØ=‚ÄØ14  \n",
      "- [dbs‚Äëannual‚Äëreport‚Äë2022] table#159 row#1 ‚Äì 2022‚ÄØ=‚ÄØ3,803  \n",
      "- [dbs‚Äëannual‚Äëreport‚Äë2022] table#160 row#1 ‚Äì confirms 2022‚ÄØ=‚ÄØ3,803  \n",
      "\n",
      "*No other operating‚Äëexpense figures for the last three fiscal years are present in the provided context.*\n",
      "\n",
      "Citations:\n",
      "- 4Q24_performance_summary, page 4.0\n",
      "- dbs-annual-report-2022, page 20.0\n",
      "- dbs-annual-report-2022, page 21.0\n",
      "- dbs-annual-report-2022, page 20.0\n",
      "- dbs-annual-report-2022, page 21.0\n",
      "**Operating Expenses (in‚ÄØ$‚ÄØmillion)**  \n",
      "\n",
      "| Fiscal year | Operating‚ÄØExpenses | YoY‚ÄØ% change |\n",
      "|-------------|--------------------|--------------|\n",
      "| 2024 | 5,273 | **+14‚ÄØ%** (vs‚ÄØ2023) |\n",
      "| 2023 | 4,627 | **+22‚ÄØ%** (vs‚ÄØ2022) |\n",
      "| 2022 | 3,803 | ‚Äì |\n",
      "\n",
      "*The 2024 figure is 14‚ÄØ% higher than 2023 (as reported).  \n",
      "The 2023‚Äëto‚Äë2022 increase is calculated: (4,627‚ÄØ‚Äì‚ÄØ3,803)‚ÄØ/‚ÄØ3,803‚ÄØ‚âà‚ÄØ22‚ÄØ%.*\n",
      "\n",
      "**Citations**\n",
      "\n",
      "- [dbs‚Äëannual‚Äëreport‚Äë2024] table#7 row#3 ‚Äì 2024‚ÄØ=‚ÄØ5,273; 2023‚ÄØ=‚ÄØ4,627; YoY‚ÄØ%‚ÄØ=‚ÄØ14  \n",
      "- [dbs‚Äëannual‚Äëreport‚Äë2022] table#159 row#1 ‚Äì 2022‚ÄØ=‚ÄØ3,803  \n",
      "- [dbs‚Äëannual‚Äëreport‚Äë2022] table#160 row#1 ‚Äì confirms 2022‚ÄØ=‚ÄØ3,803  \n",
      "\n",
      "*No other operating‚Äëexpense figures for the last three fiscal years are present in the provided context.*\n",
      "\n",
      "--- Citations ---\n",
      "- dbs-annual-report-2022  [marker] (score: -6.7801)\n",
      "- dbs-annual-report-2024 p.22 [marker] (score: -6.8893)\n",
      "- dbs-annual-report-2022  [marker] (score: -7.0523)\n",
      "- dbs-annual-report-2024 p.22 [marker] (score: -7.0675)\n",
      "- dbs-annual-report-2022 p.63 [marker] (score: -7.0783)\n",
      "\n",
      "(Latency: 9175.16 ms)\n",
      "\n",
      "Q3. Calculate the Operating Efficiency Ratio (Opex √∑ Operating Income) for the last 3 fiscal years, showing the working.\n",
      "\n",
      "[Search] RRF fusion: 95 candidates\n",
      "[Rerank] Reranking top-24 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[Search] RRF fusion: 386 candidates\n",
      "[Rerank] Reranking top-100 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[LLM] single-call baseline using groq:openai/gpt-oss-20b\n",
      "[LLM] provider=groq model=openai/gpt-oss-20b\n",
      "\n",
      "BASELINE (Single LLM Call)\n",
      "--------------------------------\n",
      "**Answer**\n",
      "\n",
      "The operating efficiency ratio (Opex √∑ Operating Income) cannot be calculated from the information supplied.  \n",
      "The context provides:\n",
      "\n",
      "| Item | 2024 | 2023 | 2022 |\n",
      "|------|------|------|------|\n",
      "| Profit before changes in operating assets & liabilities (proxy for Operating Income) | 14,080 | 12,671 | (not given) |\n",
      "| Total income / revenue | 22,297 | 20,180 | (not given) |\n",
      "| Opex (operating expenses) | **not disclosed** | **not disclosed** | **not disclosed** |\n",
      "\n",
      "Because the operating expense figures are missing for all three fiscal years, the ratio cannot be computed.  \n",
      "\n",
      "**Citations**\n",
      "\n",
      "- ‚ÄúProfit before changes in operating assets & liabilities‚Äù ‚Äì 2024: 14,080; 2023: 12,671.  \n",
      "- ‚ÄúTotal income‚Äù ‚Äì 2024: 22,297; 2023: 20,180.  \n",
      "- No Opex figures are present in the provided excerpts.\n",
      "\n",
      "Citations:\n",
      "- dbs-annual-report-2022, page nan\n",
      "- 4Q24_performance_summary, page 34.0\n",
      "- 4Q24_performance_summary, page nan\n",
      "- 4Q24_CEO_presentation, page 2.0\n",
      "- 4Q24_performance_summary, page 28.0\n",
      "**Answer**\n",
      "\n",
      "The operating efficiency ratio (Opex √∑ Operating Income) cannot be calculated from the information supplied.  \n",
      "The context provides:\n",
      "\n",
      "| Item | 2024 | 2023 | 2022 |\n",
      "|------|------|------|------|\n",
      "| Profit before changes in operating assets & liabilities (proxy for Operating Income) | 14,080 | 12,671 | (not given) |\n",
      "| Total income / revenue | 22,297 | 20,180 | (not given) |\n",
      "| Opex (operating expenses) | **not disclosed** | **not disclosed** | **not disclosed** |\n",
      "\n",
      "Because the operating expense figures are missing for all three fiscal years, the ratio cannot be computed.  \n",
      "\n",
      "**Citations**\n",
      "\n",
      "- ‚ÄúProfit before changes in operating assets & liabilities‚Äù ‚Äì 2024: 14,080; 2023: 12,671.  \n",
      "- ‚ÄúTotal income‚Äù ‚Äì 2024: 22,297; 2023: 20,180.  \n",
      "- No Opex figures are present in the provided excerpts.\n",
      "\n",
      "--- Citations ---\n",
      "- dbs-annual-report-2022  [marker] (score: -5.0380)\n",
      "- 4Q24_performance_summary p.34 [marker] (score: -5.4761)\n",
      "- 4Q24_performance_summary p.28 [marker] (score: -7.6121)\n",
      "- 4Q24_performance_summary p.4 [marker] (score: -7.7103)\n",
      "- 4Q24_performance_summary p.34 [marker] (score: -7.7183)\n",
      "\n",
      "(Latency: 6354.88 ms)\n",
      "\n",
      "============================================================\n",
      "  SUMMARY\n",
      "============================================================\n",
      "P50: 7340.2 ms\n",
      "P95: 8991.7 ms\n",
      "\n",
      "\n",
      "============================================================\n",
      "  AGENTIC BENCHMARK\n",
      "============================================================\n",
      "\n",
      "\n",
      "Q1. Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\n",
      "\n",
      "\n",
      "[Agent] Query: Report the Gross Margin (or Net Interest Margin, if a bank) ...\n",
      "[Agent] Analysis:\n",
      "  Metric: net interest margin\n",
      "  YoY: False, Quarterly: True\n",
      "  Compare: False, Calc: False\n",
      "  Years: [], Periods: 5\n",
      "[Search] RRF fusion: 387 candidates\n",
      "[Rerank] Reranking top-100 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[Agent] Extracted 10 table rows\n",
      "[Agent] Synthesizing with LLM...\n",
      "[LLM] provider=groq model=openai/gpt-oss-20b\n",
      "**Net Interest Margin (NIM) ‚Äì Available Data**\n",
      "\n",
      "| Period | NIM | Source |\n",
      "|--------|-----|--------|\n",
      "| Q4‚ÄØ2022 | 2.05‚ÄØ% | *dbs‚Äëannual‚Äëreport‚Äë2022* (context note) |\n",
      "| FY‚ÄØ2023 | 2.15‚ÄØ% | *dbs‚Äëannual‚Äëreport‚Äë2023* |\n",
      "| FY‚ÄØ2024 | 2.13‚ÄØ% | *dbs‚Äëannual‚Äëreport‚Äë2024* |\n",
      "\n",
      "**Missing Information**\n",
      "\n",
      "The last five quarters (Q1‚ÄØ2023, Q2‚ÄØ2023, Q3‚ÄØ2023, Q4‚ÄØ2023, Q1‚ÄØ2024) are not provided in the supplied data. Therefore, a complete quarterly NIM trend for the most recent five quarters cannot be constructed from the available information.\n",
      "\n",
      "--- Citations ---\n",
      "- dbs-annual-report-2022 p.nan [marker] (score: 0.6558)\n",
      "- 2Q24_performance_summary p.9.0 [marker] (score: -0.5437)\n",
      "- dbs-annual-report-2022 p.96.0 [marker] (score: -0.7675)\n",
      "- dbs-annual-report-2022 p.96.0 [marker] (score: -0.7991)\n",
      "- dbs-annual-report-2023 p.95.0 [marker] (score: -1.0668)\n",
      "\n",
      "(Latency: 7158.36 ms)\n",
      "\n",
      "Q2. Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\n",
      "\n",
      "\n",
      "[Agent] Query: Show Operating Expenses for the last 3 fiscal years, year-on...\n",
      "[Agent] Analysis:\n",
      "  Metric: operating expenses\n",
      "  YoY: False, Quarterly: False\n",
      "  Compare: False, Calc: False\n",
      "  Years: [], Periods: None\n",
      "[Search] RRF fusion: 385 candidates\n",
      "[Rerank] Reranking top-100 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[Agent] Extracted 10 table rows\n",
      "[Agent] Synthesizing with LLM...\n",
      "[LLM] provider=groq model=openai/gpt-oss-20b\n",
      "**Operating Expenses ‚Äì Last 3 Fiscal Years**\n",
      "\n",
      "| Fiscal Year | Operating Expenses (USD‚ÄØm) | YoY % Change* |\n",
      "|-------------|---------------------------|---------------|\n",
      "| 2024 | 8,895.0 | **+10.0‚ÄØ%** (vs‚ÄØ2023) ‚Äì from *4Q24_performance_summary* table‚ÄØ#1 |\n",
      "| 2023 | 8,056.0 | ‚Äì (YoY % vs‚ÄØ2022 not provided in the supplied data) |\n",
      "| 2022 | 3,803.0 | **+13.0‚ÄØ%** (vs‚ÄØ2021) ‚Äì from *dbs‚Äëannual‚Äëreport‚Äë2022* table‚ÄØ#159 (and #160) |\n",
      "\n",
      "\\*YoY % is taken directly from the documents.  \n",
      "- The 2024 figure (8,895.0) and its 10‚ÄØ% increase come from the 4Q24 performance summary (page‚ÄØ4, table‚ÄØ#1).  \n",
      "- The 2022 figure (3,803.0) and its 13‚ÄØ% increase come from the 2022 annual report (tables‚ÄØ#159 and #160).  \n",
      "- The 2023 figure (8,056.0) is listed in the same 4Q24 summary, but no YoY % against 2022 is supplied.\n",
      "\n",
      "**Missing Information**\n",
      "\n",
      "- YoY % change for 2023 vs‚ÄØ2022 is not provided in the data set.  \n",
      "- Operating expense data for 2021 (to compute 2022 vs‚ÄØ2021) is only partially available; the 2022 YoY % of 13‚ÄØ% is given, but the 2021 expense amount is not listed in the supplied excerpts.\n",
      "\n",
      "--- Citations ---\n",
      "- 4Q24_performance_summary p.4.0 [marker] (score: -5.9015)\n",
      "- dbs-annual-report-2022 p.20.0 [marker] (score: -6.3490)\n",
      "- dbs-annual-report-2022 p.21.0 [marker] (score: -6.3601)\n",
      "- dbs-annual-report-2022 p.20.0 [marker] (score: -6.3732)\n",
      "- dbs-annual-report-2022 p.21.0 [marker] (score: -6.4668)\n",
      "\n",
      "(Latency: 9823.56 ms)\n",
      "\n",
      "Q3. Calculate the Operating Efficiency Ratio (Opex √∑ Operating Income) for the last 3 fiscal years, showing the working.\n",
      "\n",
      "\n",
      "[Agent] Query: Calculate the Operating Efficiency Ratio (Opex √∑ Operating I...\n",
      "[Agent] Analysis:\n",
      "  Metric: operating income\n",
      "  YoY: False, Quarterly: False\n",
      "  Compare: False, Calc: True\n",
      "  Years: [], Periods: None\n",
      "[Agent] Decomposed into 2 sub-queries\n",
      "[Search] RRF fusion: 400 candidates\n",
      "[Rerank] Reranking top-100 candidates...\n",
      "[Search] RRF fusion: 397 candidates\n",
      "[Rerank] Reranking top-100 candidates...\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[Rerank] ‚úì Reranked to top-12\n",
      "[Agent] Merged ‚Üí 12 contexts\n",
      "[Agent] Extracted 10 table rows\n",
      "[Agent] Synthesizing with LLM...\n",
      "[LLM] provider=groq model=openai/gpt-oss-20b\n",
      "**Operating Efficiency Ratio (Opex √∑ Operating Income)**  \n",
      "*Last 3 fiscal years ‚Äì data not available in the supplied material.*\n",
      "\n",
      "| Fiscal Year | Opex (SGD‚ÄØm) | Operating Income (SGD‚ÄØm) | Operating Efficiency Ratio |\n",
      "|-------------|-------------|--------------------------|----------------------------|\n",
      "| 2023 | **Missing** | **Missing** | **Missing** |\n",
      "| 2022 | **Missing** | **Missing** | **Missing** |\n",
      "| 2021 | **Missing** | **Missing** | **Missing** |\n",
      "\n",
      "**What is missing?**  \n",
      "The calculation requires both the operating expenses (Opex) and the operating income for each of the last three fiscal years. The only numeric values provided are five figures from the ‚Äú2Q25_CFO_presentation‚Äù (5732.0, 5314.0, 418.0, 2270.0, 3462.0), which do not specify whether they represent Opex, operating income, or another metric. No operating income or Opex figures for FY‚ÄØ2023, FY‚ÄØ2022, or FY‚ÄØ2021 are present in the documents listed.\n",
      "\n",
      "Without those specific values, the Operating Efficiency Ratio cannot be computed. If you can supply the Opex and operating income figures for the relevant fiscal years, I can perform the calculation and present the results.\n",
      "\n",
      "--- Citations ---\n",
      "- dbs-annual-report-2022 p.nan [marker] (score: -4.8519)\n",
      "- 4Q24_performance_summary p.34.0 [marker] (score: -7.2142)\n",
      "- dbs-annual-report-2022 p.nan [marker] (score: -7.6210)\n",
      "- 3Q24_trading_update p.nan [marker] (score: -7.6824)\n",
      "- 2Q25_press_statement p.nan [marker] (score: -8.2381)\n",
      "\n",
      "(Latency: 16054.3 ms)\n",
      "\n",
      "============================================================\n",
      "  SUMMARY\n",
      "============================================================\n",
      "P50: 9823.6 ms\n",
      "P95: 15431.2 ms\n",
      "\n",
      "\n",
      "============================================================\n",
      "  COMPLETE\n",
      "============================================================\n",
      "Baseline: data/bench_baseline.json\n",
      "Agentic:  data_marker/bench_agentic.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Two-Mode RAG System with Parallel Sub-Query Support\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, json, time\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import g2x components\n",
    "from g2x import KBEnv, Agent, baseline_answer_one_call\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration\"\"\"\n",
    "    VERBOSE = bool(int(os.environ.get(\"AGENT_CFO_VERBOSE\", \"1\")))\n",
    "    \n",
    "    # Paths\n",
    "    MARKER_INDEX = \"./data_marker\"\n",
    "    PDFPLUMBER_INDEX = \"./data\"\n",
    "    \n",
    "    # Search params\n",
    "    TOP_K = 12\n",
    "    HYBRID_ALPHA = 0.6\n",
    "    RERANK_TOP_K = 24\n",
    "    \n",
    "    # Agentic mode\n",
    "    USE_PARALLEL_SUBQUERIES = True  # Enable parallel sub-query decomposition\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def page_or_none(x) -> Optional[int]:\n",
    "    \"\"\"Safely convert page numbers\"\"\"\n",
    "    try:\n",
    "        if x is None or pd.isna(x):\n",
    "            return None\n",
    "        return int(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MULTI-INDEX SEARCH (Marker + PDFPlumber Fallback)\n",
    "# ============================================================================\n",
    "\n",
    "class MultiIndexSearch:\n",
    "    \"\"\"\n",
    "    Dual-index search with automatic fallback\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, marker_path: str, pdfplumber_path: str):\n",
    "        self.marker_kb = self._load_kb(marker_path, \"Marker\")\n",
    "        self.pdfplumber_kb = self._load_kb(pdfplumber_path, \"PDFPlumber\")\n",
    "        \n",
    "        if not self.marker_kb and not self.pdfplumber_kb:\n",
    "            raise RuntimeError(\"No valid indexes loaded\")\n",
    "    \n",
    "    def _load_kb(self, path: str, name: str) -> Optional[KBEnv]:\n",
    "        \"\"\"Load KB with BM25 + Reranker enabled\"\"\"\n",
    "        if not Path(path).exists():\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            kb = KBEnv(base=path, enable_bm25=True, enable_reranker=True)\n",
    "            if Config.VERBOSE:\n",
    "                print(f\"[{name}] ‚úì Loaded {len(kb.texts)} chunks\")\n",
    "            return kb\n",
    "        except Exception as e:\n",
    "            if Config.VERBOSE:\n",
    "                print(f\"[{name}] ‚úó Failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def search(self, query: str, top_k: int = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Hybrid search with fallback\"\"\"\n",
    "        top_k = top_k or Config.TOP_K\n",
    "        \n",
    "        # Primary: Marker\n",
    "        results = []\n",
    "        if self.marker_kb:\n",
    "            df = self.marker_kb.search(query, k=top_k, alpha=Config.HYBRID_ALPHA, rerank_top_k=Config.RERANK_TOP_K)\n",
    "            results = self._df_to_dict(df, \"marker\")\n",
    "        \n",
    "        # Fallback: PDFPlumber\n",
    "        if len(results) < top_k // 2 and self.pdfplumber_kb:\n",
    "            df = self.pdfplumber_kb.search(query, k=top_k - len(results))\n",
    "            results.extend(self._df_to_dict(df, \"pdfplumber\"))\n",
    "        \n",
    "        results.sort(key=lambda x: x.get(\"score\", 0), reverse=True)\n",
    "        return results[:top_k]\n",
    "    \n",
    "    def _df_to_dict(self, df: pd.DataFrame, source: str) -> List[Dict]:\n",
    "        \"\"\"Convert DataFrame to dict list\"\"\"\n",
    "        if df is None or df.empty:\n",
    "            return []\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                \"file\": str(row.get(\"doc\")),\n",
    "                \"page\": page_or_none(row.get(\"page\")),\n",
    "                \"text\": str(row.get(\"text\")),\n",
    "                \"score\": float(row.get(\"score\", 0)),\n",
    "                \"year\": int(row[\"year\"]) if pd.notna(row.get(\"year\")) else None,\n",
    "                \"quarter\": str(row[\"quarter\"]) if pd.notna(row.get(\"quarter\")) else None,  # FIX: Quarter is a string, not int\n",
    "                \"section_hint\": row.get(\"section_hint\"),\n",
    "                \"index_source\": source\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ANSWERING ENGINE\n",
    "# ============================================================================\n",
    "\n",
    "class AnsweringEngine:\n",
    "    \"\"\"Unified baseline + agentic answering with parallel sub-queries\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"AnsweringEngine initialized\")\n",
    "        self.search = MultiIndexSearch(Config.MARKER_INDEX, Config.PDFPLUMBER_INDEX)\n",
    "        \n",
    "        # Agent with parallel sub-queries\n",
    "        primary_kb = self.search.marker_kb or self.search.pdfplumber_kb\n",
    "        self.agent = Agent(\n",
    "            kb=primary_kb, \n",
    "            use_parallel_subqueries=True,\n",
    "            verbose=Config.VERBOSE\n",
    "        )\n",
    "        print(f\"[AnsweringEngine] Parallel sub-queries enabled: {self.agent.use_parallel_subqueries}\")\n",
    "    \n",
    "    def answer(self, query: str, mode: str = \"baseline\") -> Dict[str, Any]:\n",
    "        \"\"\"Execute query in baseline or agentic mode\"\"\"\n",
    "        \n",
    "        if mode == \"agentic\":\n",
    "            # Agentic mode with parallel sub-queries\n",
    "            agent_result = self.agent.run(query, k_ctx=Config.TOP_K)\n",
    "            \n",
    "            return {\n",
    "                \"answer\": self._format_agent_answer(agent_result),\n",
    "                \"hits\": self._extract_agent_hits(agent_result),\n",
    "                \"execution_log\": {\n",
    "                    \"plan\": agent_result.plan,\n",
    "                    \"actions\": agent_result.actions,\n",
    "                    \"observations\": agent_result.observations\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        else:  # baseline\n",
    "            # Standard RAG: Retrieve ‚Üí Single LLM call\n",
    "            results = self.search.search(query, top_k=Config.TOP_K)\n",
    "            \n",
    "            answer_result = baseline_answer_one_call(\n",
    "                self.search.marker_kb or self.search.pdfplumber_kb,\n",
    "                query,\n",
    "                k_ctx=Config.TOP_K\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"answer\": answer_result.get(\"answer\", \"\"),\n",
    "                \"hits\": results[:5],  # Top-5 citations\n",
    "                \"execution_log\": None\n",
    "            }\n",
    "    \n",
    "    def _format_agent_answer(self, agent_result) -> str:\n",
    "        \"\"\"\n",
    "        Format agentic answer with proper fallback\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        \n",
    "        # Add execution summary (optional)\n",
    "        if agent_result.observations and Config.VERBOSE:\n",
    "            lines.append(\"**Execution Summary**\")\n",
    "            for obs in agent_result.observations:\n",
    "                lines.append(f\"- {obs}\")\n",
    "            lines.append(\"\")\n",
    "        \n",
    "        fin = agent_result.final\n",
    "        \n",
    "        # Priority 1: Return LLM-synthesized answer if available\n",
    "        if \"answer\" in fin and fin[\"answer\"]:\n",
    "            return fin[\"answer\"]\n",
    "        \n",
    "        # Priority 2: Format tool outputs (FALLBACK)\n",
    "        if fin.get(\"comparison_results\"):\n",
    "            lines.append(\"**Multi-Document Comparison**\")\n",
    "            for comp in fin[\"comparison_results\"][:5]:\n",
    "                doc = comp.get(\"doc\", \"Unknown\")\n",
    "                years = comp.get(\"years\", [])\n",
    "                values = comp.get(\"values\", [])\n",
    "                if years and values:\n",
    "                    year_val = \", \".join(f\"{y}: {v}\" for y, v in zip(years, values))\n",
    "                    lines.append(f\"- {doc}: {year_val}\")\n",
    "        \n",
    "        elif fin.get(\"table_rows\"):\n",
    "            lines.append(\"**Extracted Data**\")\n",
    "            for r in fin[\"table_rows\"][:5]:\n",
    "                doc = r.get(\"doc\", \"Unknown\")\n",
    "                label = r.get(\"label\", \"\")\n",
    "                \n",
    "                if r.get(\"series_q\"):\n",
    "                    qkeys = sorted(r[\"series_q\"].keys())[-5:]\n",
    "                    ser = \", \".join(f\"{k}: {r['series_q'][k]}\" for k in qkeys)\n",
    "                    lines.append(f\"- {doc} | {label}: {ser}\")\n",
    "                elif r.get(\"series\"):\n",
    "                    ys = sorted(r[\"series\"].keys())[-3:]\n",
    "                    ser = \", \".join(f\"{y}: {r['series'][y]}\" for y in ys)\n",
    "                    lines.append(f\"- {doc} | {label}: {ser}\")\n",
    "                else:\n",
    "                    lines.append(f\"- {doc} | {label}: (no data)\")\n",
    "        \n",
    "        # Priority 3: Final fallback message\n",
    "        if not lines:\n",
    "            lines.append(\"Analysis complete. No structured data extracted.\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def _extract_agent_hits(self, agent_result) -> List[Dict]:\n",
    "        \"\"\"Extract citations from agent result\"\"\"\n",
    "        contexts = agent_result.final.get(\"contexts\")\n",
    "        if contexts is None or contexts.empty:\n",
    "            return []\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                \"file\": row.get(\"doc\"),\n",
    "                \"page\": row.get(\"page\"),\n",
    "                \"section_hint\": row.get(\"section_hint\"),\n",
    "                \"index_source\": \"marker\",\n",
    "                \"score\": row.get(\"score\")\n",
    "            }\n",
    "            for _, row in contexts.head(5).iterrows()\n",
    "        ]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# BENCHMARK RUNNER\n",
    "# ============================================================================\n",
    "\n",
    "class BenchmarkRunner:\n",
    "    \"\"\"Standardized benchmark execution\"\"\"\n",
    "    \n",
    "    QUERIES = [\n",
    "        \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\",\n",
    "        \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
    "        \"Calculate the Operating Efficiency Ratio (Opex √∑ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, engine: AnsweringEngine):\n",
    "        self.engine = engine\n",
    "    \n",
    "    def run(self, mode: str = \"baseline\") -> Dict[str, Any]:\n",
    "        \"\"\"Run benchmark and save results\"\"\"\n",
    "        out_dir = \"data_marker\" if mode == \"agentic\" else \"data\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  {mode.upper()} BENCHMARK\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        results = []\n",
    "        for i, query in enumerate(self.QUERIES, 1):\n",
    "            print(f\"\\nQ{i}. {query}\\n\")\n",
    "            \n",
    "            t0 = time.perf_counter()\n",
    "            result = self.engine.answer(query, mode=mode)\n",
    "            latency_ms = round((time.perf_counter() - t0) * 1000, 2)\n",
    "            \n",
    "            print(result[\"answer\"])\n",
    "            if result.get(\"hits\"):\n",
    "                print(\"\\n--- Citations ---\")\n",
    "                for hit in result[\"hits\"][:5]:\n",
    "                    pg = f\"p.{hit.get('page')}\" if hit.get('page') else \"\"\n",
    "                    src = f\"[{hit.get('index_source', '?')}]\"\n",
    "                    score = f\"(score: {hit.get('score', 0):.4f})\" if hit.get('score') else \"\"\n",
    "                    print(f\"- {hit['file']} {pg} {src} {score}\")\n",
    "            \n",
    "            print(f\"\\n(Latency: {latency_ms} ms)\")\n",
    "            \n",
    "            results.append({\n",
    "                \"query\": query,\n",
    "                \"answer\": result[\"answer\"],\n",
    "                \"citations\": result.get(\"hits\", []),\n",
    "                \"execution_log\": result.get(\"execution_log\"),\n",
    "                \"latency_ms\": latency_ms\n",
    "            })\n",
    "        \n",
    "        # Save JSON with UTF-8 encoding\n",
    "        json_path = f\"{out_dir}/bench_{mode}.json\"\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:  # FIX: Add encoding\n",
    "            json.dump({\"results\": results}, f, indent=2, ensure_ascii=False)  # FIX: Add ensure_ascii=False\n",
    "        \n",
    "        # Save Markdown\n",
    "        md_path = f\"{out_dir}/bench_{mode}.md\"\n",
    "        self._write_markdown(md_path, results, mode)\n",
    "        \n",
    "        # Summary\n",
    "        latencies = [r[\"latency_ms\"] for r in results]\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"P50: {np.percentile(latencies, 50):.1f} ms\")\n",
    "        print(f\"P95: {np.percentile(latencies, 95):.1f} ms\\n\")\n",
    "        \n",
    "        return {\"json_path\": json_path, \"md_path\": md_path, \"results\": results}\n",
    "    \n",
    "    def _write_markdown(self, path: str, results: List[Dict], mode: str):\n",
    "        \"\"\"Generate markdown report\"\"\"\n",
    "        lines = [f\"# {mode.title()} Benchmark Report\\n\"]\n",
    "        \n",
    "        if mode == \"baseline\":\n",
    "            lines.append(\"**Pipeline**: Hybrid Search (BM25 + Vector + RRF + Rerank) -> Single LLM\\n\")  # Changed ‚Üí to ->\n",
    "        else:\n",
    "            lines.append(\"**Pipeline**: Parallel Sub-Queries -> Tool Execution -> Multi-step Reasoning\\n\")  # Changed ‚Üí to ->\n",
    "        \n",
    "        for i, r in enumerate(results, 1):\n",
    "            lines.append(f\"\\n---\\n\\n## Q{i}. {r['query']}\\n\")\n",
    "            lines.append(f\"**Answer**\\n\\n{r['answer']}\\n\")\n",
    "            \n",
    "            if r.get(\"citations\"):\n",
    "                lines.append(\"\\n**Citations**\\n\")\n",
    "                for hit in r[\"citations\"]:\n",
    "                    pg = f\"p.{hit.get('page')}\" if hit.get('page') else \"\"\n",
    "                    src = f\"[{hit.get('index_source', '?')}]\"\n",
    "                    score = f\"(score: {hit.get('score', 0):.4f})\" if hit.get('score') else \"\"\n",
    "                    lines.append(f\"- {hit['file']} {pg} {src} {score}\")\n",
    "            \n",
    "            if r.get(\"execution_log\"):\n",
    "                lines.append(\"\\n**Execution Log**\\n```\")\n",
    "                lines.append(json.dumps(r[\"execution_log\"], indent=2))\n",
    "                lines.append(\"```\")\n",
    "            \n",
    "            lines.append(f\"\\n**Latency**: {r['latency_ms']} ms\")\n",
    "        \n",
    "        # Summary\n",
    "        latencies = [r[\"latency_ms\"] for r in results]\n",
    "        lines.append(\"\\n---\\n\\n## Summary\\n\")\n",
    "        lines.append(f\"- P50: {np.percentile(latencies, 50):.1f} ms\")\n",
    "        lines.append(f\"- P95: {np.percentile(latencies, 95):.1f} ms\")\n",
    "        \n",
    "        # FIX: Add encoding=\"utf-8\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    \n",
    "    engine = AnsweringEngine()\n",
    "    benchmark = BenchmarkRunner(engine)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  TWO-MODE RAG SYSTEM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Baseline\n",
    "    baseline_results = benchmark.run(mode=\"baseline\")\n",
    "    \n",
    "    # Agentic with parallel sub-queries\n",
    "    agentic_results = benchmark.run(mode=\"agentic\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Baseline: {baseline_results['json_path']}\")\n",
    "    print(f\"Agentic:  {agentic_results['json_path']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ebeda",
   "metadata": {
    "id": "683ebeda"
   },
   "source": [
    "## 6. Instrumentation\n",
    "\n",
    "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5425de5",
   "metadata": {
    "id": "d5425de5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>T_ingest</th>\n",
       "      <th>T_retrieve</th>\n",
       "      <th>T_rerank</th>\n",
       "      <th>T_reason</th>\n",
       "      <th>T_generate</th>\n",
       "      <th>T_total</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>CacheHits</th>\n",
       "      <th>Tools</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Query, T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total, Tokens, CacheHits, Tools]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example instrumentation schema\n",
    "import pandas as pd\n",
    "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c01bf4",
   "metadata": {
    "id": "e8c01bf4"
   },
   "source": [
    "## 7. Optimizations\n",
    "\n",
    "**Required Optimizations**\n",
    "\n",
    "Each team must implement at least:\n",
    "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
    "*   1 caching optimization (query cache or ratio cache).\n",
    "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
    "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f0e2e",
   "metadata": {
    "id": "783f0e2e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a91ce833",
   "metadata": {
    "id": "a91ce833"
   },
   "source": [
    "## 8. Results & Plots\n",
    "\n",
    "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96550f3",
   "metadata": {
    "id": "d96550f3"
   },
   "outputs": [],
   "source": [
    "# TODO: Generate plots with matplotlib\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
