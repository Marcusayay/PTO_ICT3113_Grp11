{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f9b203",
   "metadata": {},
   "source": [
    "# Demo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ff5d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scanned all pages → out/pdfplumber_scan_all.json\n",
      "✅ Wrote metrics → out/metrics_all_pages.json\n",
      "\n",
      "=== Page metrics summary ===\n",
      "Source: All\\2Q25_CFO_presentation.pdf\n",
      "Total pages indexed: 29\n",
      "\n",
      "\n",
      "=== Detailed extracts (pages with extracted data) ===\n",
      "\n",
      "[Page 1] Record first-half income  (table)\n",
      "headers: ['Record', 'first-half', 'income']\n",
      "['', '', '']\n",
      "['a', 'nd pre-ta', 'x profit']\n",
      "['', '', '']\n",
      "['', 'DBS Group', 'Holdings']\n",
      "['', '', '']\n",
      "['2Q', '2025 financi', 'al results']\n",
      "['', '', '']\n",
      "['', 'Augu', 'st 7, 2025']\n",
      "... (+2 more rows)\n",
      "\n",
      "[Page 2] 2Q pre-tax profit up 5% YoY to $3.39bn; net profit up 1% to $2.82bn despite heightened uncertainty,  (table)\n",
      "headers: ['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7']\n",
      "['', '', '', '', '', '', '']\n",
      "['sharp Sora and', 'Hibor d', 'eclin', 'es, significant', 'curren', 'cy fluctuations, and globa', 'l minimum']\n",
      "['', '', '', '', '', '', '']\n",
      "['\\uf0a7\\nTotal income', 'up 5% Yo', 'Y to', '$5.73bn', '', '', '']\n",
      "['', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '']\n",
      "['NII rises\\no', '2%, supp', 'orted', 'by strong depo', 'sit gro', 'wth and proactive balance s', 'heet hedgin']\n",
      "['', '', '', '', '', '', '']\n",
      "... (+22 more rows)\n",
      "\n",
      "[Page 3] 2Q net profit up 1% YoY  (stacked-bar)\n",
      "{\n",
      "  \"2Q25\": {\n",
      "    \"Markets trading\": 418.0,\n",
      "    \"Commercial book\": 5314.0,\n",
      "    \"Total\": 5732.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 4] 2Q net profit declines 3% QoQ  (stacked-bar)\n",
      "{\n",
      "  \"2Q25\": {\n",
      "    \"Markets trading\": 418.0,\n",
      "    \"Commercial book\": 5314.0,\n",
      "    \"Total\": 5732.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 5] 1H pre-tax profit up 3% to new high  (stacked-bar)\n",
      "{\n",
      "  \"1H25\": {\n",
      "    \"Markets trading\": 2.0,\n",
      "    \"Commercial book\": 2.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 6] Net interest margin (%)  (line-like)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"group_nim\": 2.14,\n",
      "    \"commercial_nim\": 2.8\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"group_nim\": 2.08,\n",
      "    \"commercial_nim\": 2.61\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"group_nim\": 2.14,\n",
      "    \"commercial_nim\": 2.83\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"group_nim\": 2.11,\n",
      "    \"commercial_nim\": 2.83\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"group_nim\": 2.15,\n",
      "    \"commercial_nim\": 2.77\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"group_nim\": 2.12,\n",
      "    \"commercial_nim\": 2.68\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"group_nim\": 2.05,\n",
      "    \"commercial_nim\": 2.55\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 7] Loans up 1% QoQ, 3% over first half  (stacked-bar)\n",
      "{\n",
      "  \"1H25\": {\n",
      "    \"Trade\": -0.0,\n",
      "    \"Total\": 3.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"Trade\": -1.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 8] Deposits up 2% QoQ, 5% over first half  (stacked-bar)\n",
      "{\n",
      "  \"1H25\": {\n",
      "    \"Total\": 5.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 9] 2Q fee income up YoY led by wealth management, 1H at record  (stacked-bar)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"Investment banking\": 37.0,\n",
      "    \"Loan-related\": 371.0,\n",
      "    \"Cards\": 614.0,\n",
      "    \"Transaction services\": 459.0,\n",
      "    \"Total\": 42.0\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"Loan-related\": 412.0,\n",
      "    \"Cards\": 599.0,\n",
      "    \"Transaction services\": 467.0,\n",
      "    \"Total\": 30.0\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"Investment banking\": 19.0,\n",
      "    \"Loan-related\": 186.0,\n",
      "    \"Cards\": 313.0,\n",
      "    \"Transaction services\": 228.0,\n",
      "    \"Total\": 37.0\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"Investment banking\": 31.0,\n",
      "    \"Loan-related\": 146.0,\n",
      "    \"Cards\": 302.0,\n",
      "    \"Transaction services\": 227.0,\n",
      "    \"Total\": 55.0\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"Investment banking\": 33.0,\n",
      "    \"Loan-related\": 127.0,\n",
      "    \"Cards\": 324.0,\n",
      "    \"Transaction services\": 232.0,\n",
      "    \"Total\": 41.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"Investment banking\": 724.0,\n",
      "    \"Loan-related\": 227.0,\n",
      "    \"Cards\": 297.0,\n",
      "    \"Transaction services\": 239.0,\n",
      "    \"Total\": 35.0\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"Investment banking\": 31.0,\n",
      "    \"Loan-related\": 185.0,\n",
      "    \"Cards\": 302.0,\n",
      "    \"Transaction services\": 228.0,\n",
      "    \"Total\": 25.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 10] Net interest income 1,333 649 600  (stacked-bar)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"Net interest income\": 1333.0,\n",
      "    \"Non-interest income\": 46.0,\n",
      "    \"Total\": 447.0\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"Net interest income\": 1224.0,\n",
      "    \"Non-interest income\": 26.0,\n",
      "    \"Total\": 493.0\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"Net interest income\": 661.0,\n",
      "    \"Non-interest income\": 44.0,\n",
      "    \"Total\": 447.0\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"Net interest income\": 649.0,\n",
      "    \"Non-interest income\": 52.0,\n",
      "    \"Total\": 452.0\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"Net interest income\": 639.0,\n",
      "    \"Non-interest income\": 36.0,\n",
      "    \"Total\": 477.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"Net interest income\": 624.0,\n",
      "    \"Non-interest income\": 32.0,\n",
      "    \"Total\": 483.0\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"Net interest income\": 600.0,\n",
      "    \"Non-interest income\": 19.0,\n",
      "    \"Total\": 493.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 11] 2Q commercial book non-interest income rises 11% YoY,  (stacked-bar)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"Markets trading\": 750.0,\n",
      "    \"Net fee income\": 2091.0,\n",
      "    \"Total\": 3190.0\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"Markets trading\": 1070.0,\n",
      "    \"Net fee income\": 2442.0,\n",
      "    \"Total\": 3512.0\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"Markets trading\": 362.0,\n",
      "    \"Net fee income\": 1048.0,\n",
      "    \"Total\": 1526.0\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"Markets trading\": 530.0,\n",
      "    \"Net fee income\": 1109.0,\n",
      "    \"Total\": 1626.0\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"Markets trading\": 261.0,\n",
      "    \"Net fee income\": 968.0,\n",
      "    \"Commercial book\": 11.0,\n",
      "    \"Non-interest income\": 11.0,\n",
      "    \"Total\": 1516.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"Markets trading\": 548.0,\n",
      "    \"Net fee income\": 1275.0,\n",
      "    \"Total\": 1823.0\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"Markets trading\": 395.0,\n",
      "    \"Net fee income\": 1167.0,\n",
      "    \"Total\": 1689.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 12] 1H CBG / WM income up 4%  (stacked-bar)\n",
      "{\n",
      "  \"1H25\": {\n",
      "    \"Cards\": 455.0,\n",
      "    \"Others\": 28.0,\n",
      "    \"Total\": 442.0\n",
      "  },\n",
      "  \"1H24\": {\n",
      "    \"Cards\": 420.0,\n",
      "    \"Others\": 23.0,\n",
      "    \"CBG / WM\": 4.0,\n",
      "    \"Total\": 396.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 13] 1H IBG income declines 4%  (stacked-bar)\n",
      "{\n",
      "  \"1H25\": {\n",
      "    \"Investment banking\": 586.0,\n",
      "    \"Trade\": 315.0,\n",
      "    \"Total\": 4506.0\n",
      "  },\n",
      "  \"1H24\": {\n",
      "    \"Investment banking\": 544.0,\n",
      "    \"Trade\": 320.0,\n",
      "    \"Total\": 4687.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 14] 1H treasury customer income up 14% to record, Markets trading  (stacked-bar)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"Markets trading\": 433.0,\n",
      "    \"Total\": 1609.0\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"Markets trading\": 781.0,\n",
      "    \"Total\": 2126.0\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"Markets trading\": 187.0,\n",
      "    \"Total\": 751.0\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"Markets trading\": 331.0,\n",
      "    \"Total\": 924.0\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"Markets trading\": 158.0,\n",
      "    \"Total\": 704.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"Markets trading\": 363.0,\n",
      "    \"Total\": 1055.0\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"Markets trading\": 418.0,\n",
      "    \"Total\": 1072.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 15] 1H Hong Kong net profit up 11% YoY to record  (stacked-bar)\n",
      "{\n",
      "  \"1H25\": {\n",
      "    \"Profit Before Allowances 1,144 9 11\": 1.0,\n",
      "    \"Expenses 636 2 4\": 1.0,\n",
      "    \"Total\": 8.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 16] NPA declines 4% QoQ as repayments and write-offs more than  (stacked-bar)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"CBG / WM\": 48.0,\n",
      "    \"Total\": 5077.0\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"CBG / WM\": 37.0,\n",
      "    \"Total\": 5036.0\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"CBG / WM\": 5.0,\n",
      "    \"Total\": 5221.0\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"Total\": 5077.0\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"Others\": 81.0,\n",
      "    \"CBG / WM\": 101.0,\n",
      "    \"Other IBG\": 81.0,\n",
      "    \"Total\": 5036.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"CBG / WM\": 19.0,\n",
      "    \"Total\": 5036.0\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"CBG / WM\": 18.0,\n",
      "    \"Total\": 4861.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 17] 2Q SP at 15bp, 1H at 12bp  (stacked-bar)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"CBG / WM\": 196.0,\n",
      "    \"Total\": 212.0\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"Others\": 58.0,\n",
      "    \"CBG / WM\": 209.0,\n",
      "    \"Other IBG\": 58.0,\n",
      "    \"Total\": 260.0\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"CBG / WM\": 100.0,\n",
      "    \"Total\": 97.0\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"Others\": 43.0,\n",
      "    \"CBG / WM\": 110.0,\n",
      "    \"Other IBG\": 43.0,\n",
      "    \"Total\": 120.0\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"Others\": 106.0,\n",
      "    \"CBG / WM\": 113.0,\n",
      "    \"Other IBG\": 106.0,\n",
      "    \"Total\": 228.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"CBG / WM\": 117.0,\n",
      "    \"Total\": 111.0\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"Others\": 72.0,\n",
      "    \"CBG / WM\": 92.0,\n",
      "    \"Other IBG\": 72.0,\n",
      "    \"Total\": 149.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 18] Allowance coverage ratio at 137%  (table)\n",
      "headers: ['Allowance co', 'v', 'erage ra', 'tio at 137', '%', '', '']\n",
      "['', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '6,650', '']\n",
      "['(S$m)', '6', ',550', '', '6,514', '', '6,441']\n",
      "['', '', '', '6,323', '', '', '']\n",
      "['', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '']\n",
      "... (+13 more rows)\n",
      "\n",
      "[Page 19] (%) 18.8  (table)\n",
      "headers: ['Strong CET-1 and le', 'verage', 'ratios', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['(%)', '', '18.8', '18.6', '1', '8.6', '', '']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '', '18.2']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['', '', '0.9', '0.9', '', '1.0', '', '']\n",
      "['', '', '', '', '', '', '', '']\n",
      "... (+27 more rows)\n",
      "\n",
      "[Page 20] 2Q total dividend of 75¢ per share, comprising 60¢ ordinary  (bar-like)\n",
      "{\n",
      "  \"1Q24\": 2023.0\n",
      "}\n",
      "\n",
      "[Page 21] ROE of 17% despite global minimum tax reflects deepening customer  (table)\n",
      "headers: ['In summar']\n",
      "['']\n",
      "['Strong first-h']\n",
      "['']\n",
      "['Ability to man']\n",
      "['']\n",
      "['opportunities']\n",
      "['']\n",
      "['ROE of 17% d']\n",
      "... (+8 more rows)\n",
      "\n",
      "[Page 22] Supplementary slides  (table)\n",
      "headers: ['slides']\n",
      "['']\n",
      "['Holdings']\n",
      "['']\n",
      "['al results']\n",
      "['']\n",
      "['st 7, 2025']\n",
      "\n",
      "[Page 23] 1H pre-tax profit up 3% to record $6.83bn  (stacked-bar)\n",
      "{\n",
      "  \"1H25\": {\n",
      "    \"Markets trading\": 781.0,\n",
      "    \"Net fee income\": 2442.0,\n",
      "    \"Commercial book\": 10856.0,\n",
      "    \"Net interest income\": 781.0,\n",
      "    \"Non-interest income\": 796.0,\n",
      "    \"Total\": 7153.0\n",
      "  },\n",
      "  \"1H24\": {\n",
      "    \"Markets trading\": 433.0,\n",
      "    \"Net fee income\": 2091.0,\n",
      "    \"Commercial book\": 10606.0,\n",
      "    \"Net interest income\": 433.0,\n",
      "    \"Non-interest income\": 750.0,\n",
      "    \"Total\": 6788.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 24] Net interest margin (%) 1.75 1.80  (table)\n",
      "headers: ['(S$m)', '1H25', '1H24 Yo', 'Y % Yo', 'Y']\n",
      "['', '', '', '', '']\n",
      "['Total income', '1,780', '1,679', '6', '8']\n",
      "['', '', '', '', '']\n",
      "['Net interest income', '1,007', '1,034', '(3)', '(1']\n",
      "['', '', '', '', '']\n",
      "['Net fee and commission income', '505', '411', '23', '25']\n",
      "['', '', '', '', '']\n",
      "['Other non-interest income', '268', '234', '15', '17']\n",
      "... (+22 more rows)\n",
      "\n",
      "[Page 25] NPL ratio at 1.0%, allowance coverage above 100%  (table)\n",
      "headers: ['NPL ratio at 1.0%,', 'allowance co', 'verage ab', 'ove 100%', '', '']\n",
      "['', '', '', '', '', '']\n",
      "['', '', '', '', '', '']\n",
      "['', '1.1', '1.0', '1.1', '1.1', '1.0']\n",
      "['', '', '', '', '', '']\n",
      "['NPL ratio (%)', '', '', '', '', '']\n",
      "['', '', '', '', '', '']\n",
      "['NPA (S$m)', '5,077', '4,680', '5,036', '4,861', '4,686']\n",
      "['', '', '', '', '', '']\n",
      "... (+21 more rows)\n",
      "\n",
      "[Page 26] Fixed income duration remains short  (table)\n",
      "headers: ['($m)', 'Jun 25', '']\n",
      "['', '', '']\n",
      "['', 'FVOCI', 'HTC']\n",
      "['', '', '']\n",
      "['Government securities', '28,407', '44,229']\n",
      "['', '', '']\n",
      "['Less than 3 years', '22,292', '31,014']\n",
      "['', '', '']\n",
      "['3 to 5 years', '2,895', '5,098']\n",
      "... (+8 more rows)\n",
      "\n",
      "[Page 27] Jun 25 Reported Underlying Reported Underlying  (table)\n",
      "headers: ['', '(S$bn)', '', 'HoH (', '%)', 'YoY', '(', '%)']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['', 'Jun 25', '', 'Reported', 'Underlying', 'Reported', '', 'Underlying']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['eposits', '574', '', '2', '5', '4', '', '7']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['y product', '', '', '', '', '', '', '']\n",
      "['', '', '', '', '', '', '', '']\n",
      "['Casa', '301', '', '3', '6', '8', '', '10']\n",
      "... (+24 more rows)\n",
      "\n",
      "[Page 28] 1H GTS income down 10%  (stacked-bar)\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"Total Income\": 2402.0,\n",
      "    \"Trade Assets 47 44\": 47.0\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"Total Income\": 2164.0,\n",
      "    \"Trade Assets 47 44\": 44.0,\n",
      "    \"1h Gts Income Down 10%\": 10.0\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"Total Income\": 1204.0,\n",
      "    \"Trade Assets 47 44\": 47.0\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"Total Income\": 1170.0,\n",
      "    \"Trade Assets 47 44\": 46.0\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"Total Income\": 1144.0,\n",
      "    \"Trade Assets 47 44\": 48.0\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"Trade Assets 47 44\": 46.0\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"Trade Assets 47 44\": 44.0\n",
      "  }\n",
      "}\n",
      "\n",
      "[Page 29] Record first-half income  (table)\n",
      "headers: ['Record', 'first-half', 'income']\n",
      "['', '', '']\n",
      "['a', 'nd pre-ta', 'x profit']\n",
      "['', '', '']\n",
      "['', 'DBS Group', 'Holdings']\n",
      "['', '', '']\n",
      "['2Q', '2025 financi', 'al results']\n",
      "['', '', '']\n",
      "['', 'Augu', 'st 7, 2025']\n",
      "... (+2 more rows)\n",
      "\n",
      "[NIM] page 6\n",
      "{\n",
      "  \"1H24\": {\n",
      "    \"group_nim\": 2.14,\n",
      "    \"commercial_nim\": 2.8\n",
      "  },\n",
      "  \"1H25\": {\n",
      "    \"group_nim\": 2.08,\n",
      "    \"commercial_nim\": 2.61\n",
      "  },\n",
      "  \"2Q24\": {\n",
      "    \"group_nim\": 2.14,\n",
      "    \"commercial_nim\": 2.83\n",
      "  },\n",
      "  \"3Q24\": {\n",
      "    \"group_nim\": 2.11,\n",
      "    \"commercial_nim\": 2.83\n",
      "  },\n",
      "  \"4Q24\": {\n",
      "    \"group_nim\": 2.15,\n",
      "    \"commercial_nim\": 2.77\n",
      "  },\n",
      "  \"1Q25\": {\n",
      "    \"group_nim\": 2.12,\n",
      "    \"commercial_nim\": 2.68\n",
      "  },\n",
      "  \"2Q25\": {\n",
      "    \"group_nim\": 2.05,\n",
      "    \"commercial_nim\": 2.55\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === ALL-PAGES EXTRACTOR (pdfplumber only; no OCR/vision) ===\n",
    "# - Scans all pages: text, words (with x/y), table candidates (two strategies)\n",
    "# - Binds chart-like content:\n",
    "#     * \"Net interest margin (%)\" → line-like (quarters → {group_nim, commercial_nim})\n",
    "#     * Bar-like metrics (e.g., \"Net interest income (S$m)\") → {quarter → value}\n",
    "# - Outputs:\n",
    "#     1) out/pdfplumber_scan_all.json        (raw per-page index)\n",
    "#     2) out/metrics_all_pages.json          (clean per-page metrics)\n",
    "\n",
    "import json, re, csv, os, statistics\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "\n",
    "# --------- CONFIG ---------\n",
    "TARGET_PDF = \"All/2Q25_CFO_presentation.pdf\"\n",
    "OUT_SCAN_JSON = \"out/pdfplumber_scan_all.json\"\n",
    "OUT_METRICS_JSON = \"out/metrics_all_pages.json\"\n",
    "DUMP_TABLES_DIR = \"out/tables_by_page\"   # set to None to disable CSV dumps\n",
    "\n",
    "PREVIEW_FIRST_N_PAGES = 0                # set >0 to print quick previews\n",
    "# --------------------------\n",
    "\n",
    "# Known stacked-bar categories often used in DBS decks\n",
    "CATEGORY_LABELS = [\n",
    "    # Fee income page (e.g., page 9)\n",
    "    \"Investment banking\",\n",
    "    \"Wealth management\",\n",
    "    \"Loan-related\",\n",
    "    \"Cards\",\n",
    "    \"Transaction services\",\n",
    "    # Commercial book non-interest income page (e.g., page 11)\n",
    "    \"Markets trading\",\n",
    "    \"Other non-interest income\",\n",
    "    \"Net fee income\",\n",
    "    \"Commercial book\",\n",
    "    # Loans page (e.g., page 7)\n",
    "    \"Others\",\n",
    "    \"CBG / WM\",\n",
    "    \"Other IBG\",\n",
    "    \"Trade\",\n",
    "    # Deposits page (e.g., page 8)\n",
    "    \"FD and others\",\n",
    "    \"FCY Casa\",\n",
    "    \"SGD Casa\",\n",
    "    # Two-band stacks on WM page (e.g., page 10)\n",
    "    \"Net interest income\",\n",
    "    \"Non-interest income\",\n",
    "]\n",
    "\n",
    "# ---- Table extraction helpers ----\n",
    "def extract_tables_with_settings(page, setting_name, table_settings):\n",
    "    results = []\n",
    "    try:\n",
    "        found = page.find_tables(table_settings=table_settings)\n",
    "    except Exception as e:\n",
    "        return [{\"setting\": setting_name, \"error\": f\"find_tables error: {e}\", \"rows\": [], \"headers\": [], \"bbox\": None}]\n",
    "\n",
    "    for t in found:\n",
    "        try:\n",
    "            data = t.extract(x_tolerance=2, y_tolerance=2)\n",
    "        except Exception as e:\n",
    "            results.append({\"setting\": setting_name, \"error\": f\"extract error: {e}\", \"rows\": [], \"headers\": [], \"bbox\": getattr(t, \"bbox\", None)})\n",
    "            continue\n",
    "\n",
    "        if not data or len(data) < 2 or not any(data[0]):\n",
    "            results.append({\"setting\": setting_name, \"warning\": \"empty_or_headerless_table\", \"rows\": [], \"headers\": [], \"bbox\": getattr(t, \"bbox\", None)})\n",
    "            continue\n",
    "\n",
    "        header_row = [\"\" if h is None else str(h).strip() for h in data[0]]\n",
    "        body_rows = [[(\"\" if c is None else str(c)) for c in row] for row in data[1:]]\n",
    "        # If header row looks numeric-heavy, fall back to generic headers\n",
    "        if sum(bool(re.search(r\"\\d\", h or \"\")) for h in header_row) > len(header_row) // 2:\n",
    "            header_row = [f\"col_{i+1}\" for i in range(len(header_row))]\n",
    "\n",
    "        results.append({\n",
    "            \"setting\": setting_name,\n",
    "            \"bbox\": getattr(t, \"bbox\", None),\n",
    "            \"headers\": header_row,\n",
    "            \"rows\": body_rows,\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# ---- Scan ALL pages into a single JSON ----\n",
    "pdf_path = Path(TARGET_PDF)\n",
    "if not pdf_path.exists():\n",
    "    raise FileNotFoundError(f\"PDF not found: {pdf_path}\")\n",
    "\n",
    "doc = {\"source\": str(pdf_path), \"pages\": []}\n",
    "\n",
    "with pdfplumber.open(str(pdf_path)) as pdf:\n",
    "    for idx, page in enumerate(pdf.pages, start=1):\n",
    "        try:\n",
    "            text = page.extract_text() or \"\"\n",
    "        except Exception as e:\n",
    "            text, text_error = \"\", f\"text error: {e}\"\n",
    "        else:\n",
    "            text_error = None\n",
    "\n",
    "        try:\n",
    "            words = page.extract_words() or []\n",
    "        except Exception as e:\n",
    "            words, words_error = [], f\"words error: {e}\"\n",
    "        else:\n",
    "            words_error = None\n",
    "\n",
    "        # Two table strategies\n",
    "        settings_A = dict(vertical_strategy=\"lines\", horizontal_strategy=\"lines\",\n",
    "                          snap_tolerance=3, join_tolerance=3, edge_min_length=15,\n",
    "                          intersection_tolerance=3)\n",
    "        settings_B = dict(vertical_strategy=\"text\", horizontal_strategy=\"text\",\n",
    "                          text_tolerance=2, snap_tolerance=3, join_tolerance=3,\n",
    "                          intersection_tolerance=3)\n",
    "\n",
    "        tables_A = extract_tables_with_settings(page, \"A_lines\", settings_A)\n",
    "        tables_B = extract_tables_with_settings(page, \"B_text\", settings_B)\n",
    "\n",
    "        page_entry = {\n",
    "            \"page_number\": idx,\n",
    "            \"width\": page.width,\n",
    "            \"height\": page.height,\n",
    "            \"text_error\": text_error,\n",
    "            \"words_error\": words_error,\n",
    "            \"text\": text,\n",
    "            \"words\": [\n",
    "                {\n",
    "                    \"text\": w.get(\"text\", \"\"),\n",
    "                    \"x0\": w.get(\"x0\"),\n",
    "                    \"top\": w.get(\"top\"),\n",
    "                    \"x1\": w.get(\"x1\"),\n",
    "                    \"bottom\": w.get(\"bottom\"),\n",
    "                    \"upright\": w.get(\"upright\"),\n",
    "                    \"direction\": w.get(\"direction\"),\n",
    "                    \"fontname\": w.get(\"fontname\"),\n",
    "                    \"size\": w.get(\"size\"),\n",
    "                }\n",
    "                for w in words\n",
    "            ],\n",
    "            \"tables\": tables_A + tables_B,\n",
    "        }\n",
    "        doc[\"pages\"].append(page_entry)\n",
    "\n",
    "        # Optional: dump tables per page\n",
    "        if DUMP_TABLES_DIR:\n",
    "            outdir = Path(DUMP_TABLES_DIR) / f\"page_{idx:02d}\"\n",
    "            outdir.mkdir(parents=True, exist_ok=True)\n",
    "            for i, t in enumerate(page_entry[\"tables\"], start=1):\n",
    "                if not t.get(\"rows\"):\n",
    "                    continue\n",
    "                csv_path = outdir / f\"table-{i}_{t['setting']}.csv\"\n",
    "                with csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as cf:\n",
    "                    writer = csv.writer(cf)\n",
    "                    writer.writerow(t.get(\"headers\", []))\n",
    "                    writer.writerows(t.get(\"rows\", []))\n",
    "\n",
    "# Save scan JSON\n",
    "Path(OUT_SCAN_JSON).parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUT_SCAN_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(doc, f, ensure_ascii=False, indent=2)\n",
    "print(f\"✅ Scanned all pages → {OUT_SCAN_JSON}\")\n",
    "\n",
    "if PREVIEW_FIRST_N_PAGES > 0:\n",
    "    for p in doc[\"pages\"][:PREVIEW_FIRST_N_PAGES]:\n",
    "        print(f\"\\n=== Page {p['page_number']} preview ===\")\n",
    "        print((p[\"text\"] or \"\")[:400], \"...\" if len(p[\"text\"] or \"\") > 400 else \"\")\n",
    "\n",
    "# =========================\n",
    "#   METRICS CONSOLIDATION\n",
    "# =========================\n",
    "\n",
    "QTR_PAT     = re.compile(r\"^(?:[1-4]Q|[12]H)\\d{2}$\", re.IGNORECASE)  # 2Q24, 1Q25, 1H25, 2H24\n",
    "NUM_PAT     = re.compile(r\"^\\s*(-?\\d{1,3}(?:,\\d{3})*|\\d+)(?:\\.(\\d+))?\\s*%?\\s*$\")\n",
    "\n",
    "def word_cx(w): \n",
    "    x0, x1 = w.get(\"x0\"), w.get(\"x1\")\n",
    "    return (x0 + x1) / 2.0 if x0 is not None and x1 is not None else None\n",
    "\n",
    "def to_float(s):\n",
    "    m = NUM_PAT.match(s or \"\")\n",
    "    if not m: return None\n",
    "    whole = m.group(1).replace(\",\", \"\")\n",
    "    frac  = m.group(2)\n",
    "    return float(f\"{whole}.{frac}\" if frac else whole)\n",
    "\n",
    "\n",
    "def split_words(words):\n",
    "    quarters=[]; numbers=[]; plain=[]\n",
    "    for w in words:\n",
    "        t=(w.get(\"text\") or \"\").strip()\n",
    "        if not t: continue\n",
    "        if QTR_PAT.match(t):\n",
    "            cx=word_cx(w); \n",
    "            if cx is not None: quarters.append({**w,\"_cx\":cx})\n",
    "        else:\n",
    "            val=to_float(t)\n",
    "            if val is not None:\n",
    "                cx=word_cx(w); \n",
    "                if cx is not None: numbers.append({**w,\"_cx\":cx,\"_num\":val})\n",
    "            else:\n",
    "                plain.append(w)\n",
    "    return quarters, numbers, plain\n",
    "\n",
    "# --- Helper: find category label bands for stacked-bar charts\n",
    "def find_category_bands(words):\n",
    "    \"\"\"\n",
    "    Return dict of {label: y_center} for known stacked-bar categories by matching\n",
    "    left-side text labels. More robust by grouping words into lines and requiring\n",
    "    all tokens of the label to appear on the same line. Wider left-margin tolerance.\n",
    "    \"\"\"\n",
    "    bands = {}\n",
    "    if not words:\n",
    "        return bands\n",
    "\n",
    "    # Group words into 'lines' by quantized y (top)\n",
    "    lines = {}  # key: y_bucket -> list[word]\n",
    "    for w in words:\n",
    "        t = (w.get(\"text\") or \"\").strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        top = w.get(\"top\")\n",
    "        if top is None:\n",
    "            continue\n",
    "        yb = round(top / 3.0)  # bucket size ~3pt\n",
    "        lines.setdefault(yb, []).append(w)\n",
    "\n",
    "    # For each line, build a lowercase string and compute average y and min x0\n",
    "    line_infos = []\n",
    "    for yb, ws in lines.items():\n",
    "        txt = \" \".join((ww.get(\"text\") or \"\").strip().lower() for ww in ws if (ww.get(\"text\") or \"\").strip())\n",
    "        if not txt:\n",
    "            continue\n",
    "        avg_y = sum((ww.get(\"top\", 0.0) + ww.get(\"bottom\", 0.0)) / 2.0 for ww in ws) / len(ws)\n",
    "        min_x0 = min((ww.get(\"x0\") for ww in ws if ww.get(\"x0\") is not None), default=1e9)\n",
    "        line_infos.append({\"yb\": yb, \"txt\": txt, \"avg_y\": avg_y, \"min_x0\": min_x0})\n",
    "\n",
    "    # Wider left margin tolerance: labels can sit up to ~420pt from left\n",
    "    LEFT_X_MAX = 420.0\n",
    "\n",
    "    for label in CATEGORY_LABELS:\n",
    "        tokens = [tok for tok in label.lower().split() if tok]\n",
    "        # find a line on the left that contains ALL tokens (in any order)\n",
    "        best = None\n",
    "        for li in line_infos:\n",
    "            if li[\"min_x0\"] is None or li[\"min_x0\"] > LEFT_X_MAX:\n",
    "                continue\n",
    "            if all(tok in li[\"txt\"] for tok in tokens):\n",
    "                # prefer the left-most, then highest on page\n",
    "                score = (li[\"min_x0\"], li[\"avg_y\"])\n",
    "                if best is None or score < best[0]:\n",
    "                    best = (score, li)\n",
    "        if best:\n",
    "            bands[label] = best[1][\"avg_y\"]\n",
    "\n",
    "    # --- Auto-legend fallback (no whitelist) ---\n",
    "    # If we found too few bands (e.g., new slide layouts), infer labels from left-side lines.\n",
    "    if len(bands) < 2:\n",
    "        BLOCK_TOKENS = {\"yoy\", \"(%)\", \"%)\", \"(s$\", \"$\", \"bn\", \"aum\", \"earning assets\"}\n",
    "        auto_candidates = []\n",
    "        for li in line_infos:\n",
    "            if li[\"min_x0\"] is None or li[\"min_x0\"] > LEFT_X_MAX:\n",
    "                continue\n",
    "            txt = li[\"txt\"]\n",
    "            letters = sum(ch.isalpha() for ch in txt)\n",
    "            digits  = sum(ch.isdigit() for ch in txt)\n",
    "            # accept lines that look like category phrases (more letters than digits, not unit lines)\n",
    "            if letters <= digits:\n",
    "                continue\n",
    "            if any(bt in txt for bt in BLOCK_TOKENS):\n",
    "                continue\n",
    "            if len(txt) < 5:   # too short\n",
    "                continue\n",
    "            # prefer multi-word phrases\n",
    "            word_count = len([t for t in txt.split() if t])\n",
    "            if word_count < 1:\n",
    "                continue\n",
    "            # keep as candidate\n",
    "            auto_candidates.append(li)\n",
    "\n",
    "        # Sort by being leftmost then by top position; take up to 6\n",
    "        auto_candidates.sort(key=lambda x: (x[\"min_x0\"], x[\"avg_y\"]))\n",
    "        for li in auto_candidates[:6]:\n",
    "            # Normalise label: title-case but keep slashes/hyphens as-is\n",
    "            label_txt = \" \".join(w.capitalize() if w.isalpha() else w for w in li[\"txt\"].split())\n",
    "            # Only add if not already present\n",
    "            if label_txt not in bands:\n",
    "                bands[label_txt] = li[\"avg_y\"]\n",
    "\n",
    "    return bands\n",
    "\n",
    "# --- Heuristic: derive slide title from word positions/font sizes ---\n",
    "def detect_metric_title_from_words(words, page_w, page_h):\n",
    "    \"\"\"\n",
    "    Heuristic: slide titles are large-font, top-centered lines spanning wide width.\n",
    "    - Group words into lines (by y bucket)\n",
    "    - Filter to top ~28% of the page, long-ish text, wide span, not left-legend\n",
    "    - Score by font size, span width, and proximity to the top\n",
    "    Returns the best-matching line text, or None.\n",
    "    \"\"\"\n",
    "    if not words:\n",
    "        return None\n",
    "\n",
    "    # Group words into 'lines' by quantized y (top)\n",
    "    lines = {}\n",
    "    for w in words:\n",
    "        t = (w.get(\"text\") or \"\").strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        top = w.get(\"top\"); bottom = w.get(\"bottom\")\n",
    "        if top is None or bottom is None:\n",
    "            continue\n",
    "        yb = round(top / 3.0)  # ~3pt bucket\n",
    "        lines.setdefault(yb, []).append(w)\n",
    "\n",
    "    candidates = []\n",
    "    for yb, ws in lines.items():\n",
    "        # Build text and features for this visual line\n",
    "        tokens = [(ww.get(\"text\") or \"\").strip() for ww in ws if (ww.get(\"text\") or \"\").strip()]\n",
    "        if not tokens:\n",
    "            continue\n",
    "        text_join = \" \".join(tokens)\n",
    "        low = text_join.lower()\n",
    "        avg_y = sum((ww.get(\"top\", 0.0) + ww.get(\"bottom\", 0.0)) / 2.0 for ww in ws) / len(ws)\n",
    "        avg_size = sum((ww.get(\"size\") or 0.0) for ww in ws) / len(ws)\n",
    "        x0s = [ww.get(\"x0\") for ww in ws if ww.get(\"x0\") is not None]\n",
    "        x1s = [ww.get(\"x1\") for ww in ws if ww.get(\"x1\") is not None]\n",
    "        if not x0s or not x1s:\n",
    "            continue\n",
    "        min_x0 = min(x0s); max_x1 = max(x1s)\n",
    "        span = max_x1 - min_x0\n",
    "\n",
    "        # Basic filters\n",
    "        if avg_y > page_h * 0.28:      # too low on the page to be the title\n",
    "            continue\n",
    "        if len(text_join) < 12:        # very short lines are unlikely to be the title\n",
    "            continue\n",
    "        if min_x0 < page_w * 0.12:     # exclude left legend/axis area\n",
    "            continue\n",
    "        if span < page_w * 0.45:       # title usually spans a good width\n",
    "            continue\n",
    "        # Avoid picking lines that are mostly numbers/units\n",
    "        digits = sum(ch.isdigit() for ch in text_join)\n",
    "        letters = sum(ch.isalpha() for ch in text_join)\n",
    "        if digits > letters:\n",
    "            continue\n",
    "\n",
    "        # Score: large font, wide span, close to the top\n",
    "        score = (avg_size * 2.0) + (span / page_w) + (1.0 - (avg_y / page_h))\n",
    "        candidates.append((score, text_join))\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "    candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "    return candidates[0][1]\n",
    "\n",
    "def detect_metric_title(page_text):\n",
    "    lines = [ln.strip() for ln in (page_text or \"\").splitlines() if ln.strip()]\n",
    "    if not lines:\n",
    "        return \"metric\"\n",
    "    # 1) Prioritize exact match anywhere\n",
    "    for ln in lines:\n",
    "        if \"net interest margin\" in ln.lower():\n",
    "            return ln\n",
    "    # 2) Early strong hints (top lines)\n",
    "    for ln in lines[:12]:\n",
    "        low = ln.lower()\n",
    "        if \"margin\" in low or \"%\" in low or \"net interest\" in low or \"allowances\" in low:\n",
    "            return ln\n",
    "    # 3) Fallback\n",
    "    return lines[0]\n",
    "\n",
    "def guess_legend_labels(plain_words):\n",
    "    text = \" \".join((w.get(\"text\") or \"\") for w in plain_words).lower()\n",
    "    labels=[]\n",
    "    if \"commercial book\" in text: labels.append(\"Commercial book\")\n",
    "    if \"group\" in text: labels.append(\"Group\")\n",
    "    return labels or [\"Series A\",\"Series B\"]\n",
    "\n",
    "def looks_like_nim_value(n):\n",
    "    \"\"\"\n",
    "    Heuristic filter for NIM (%): keep plausible percentage-like values only.\n",
    "    - numeric value between ~0.5 and 5.0\n",
    "    - and the source text had a decimal point or a percent sign\n",
    "    \"\"\"\n",
    "    txt = (n.get(\"text\") or \"\").strip()\n",
    "    v = n.get(\"_num\")\n",
    "    has_decimal = \".\" in txt\n",
    "    has_pct = \"%\" in txt\n",
    "    return (v is not None) and (0.5 <= v <= 5.0) and (has_decimal or has_pct)\n",
    "\n",
    "def kmeans_1d(vals, iters=10):\n",
    "    if not vals: return None, []\n",
    "    vals_sorted = sorted(vals)\n",
    "    # init using quartiles if possible\n",
    "    if len(vals_sorted) >= 4:\n",
    "        q1 = statistics.quantiles(vals_sorted, n=4)[0]\n",
    "        q3 = statistics.quantiles(vals_sorted, n=4)[-1]\n",
    "    else:\n",
    "        q1, q3 = min(vals_sorted), max(vals_sorted)\n",
    "    centers=[q1, q3]\n",
    "    for _ in range(iters):\n",
    "        A,B=[],[]\n",
    "        for v in vals_sorted:\n",
    "            (A if abs(v-centers[0])<=abs(v-centers[1]) else B).append(v)\n",
    "        if A: centers[0]=sum(A)/len(A)\n",
    "        if B: centers[1]=sum(B)/len(B)\n",
    "    assigns=[0 if abs(v-centers[0])<=abs(v-centers[1]) else 1 for v in vals_sorted]\n",
    "    # Map assignments back to original order\n",
    "    idx_map = {v_i:i for i,v_i in enumerate(vals_sorted)}\n",
    "    return centers, [assigns[idx_map[v]] for v in [w for w in vals]]\n",
    "\n",
    "def bind_line_like(quarters, numbers, page_h):\n",
    "    if not quarters or not numbers: return {}\n",
    "    quarters = sorted(quarters, key=lambda w: w[\"_cx\"])\n",
    "    # X window from quarter spacing\n",
    "    dxs=[quarters[i+1][\"_cx\"]-quarters[i][\"_cx\"] for i in range(len(quarters)-1)]\n",
    "    X_TOL = max(30.0, (statistics.median(dxs) if dxs else 80.0)*0.45)\n",
    "\n",
    "    tops=[n.get(\"top\") for n in numbers if n.get(\"top\") is not None]\n",
    "    centers, assigns = kmeans_1d(tops) if tops else (None, [])\n",
    "    if not centers:\n",
    "        mid = statistics.median(tops) if tops else page_h/2\n",
    "        centers=[mid-60, mid+60]\n",
    "        assigns=[0 if y<=mid else 1 for y in tops]\n",
    "\n",
    "    # decide which center is upper/lower\n",
    "    upper_idx, lower_idx = (0,1) if centers[0] <= centers[1] else (1,0)\n",
    "    band_upper=[]; band_lower=[]\n",
    "    # assign numbers to bands in original order of 'numbers'\n",
    "    j=0\n",
    "    for n in numbers:\n",
    "        if n.get(\"top\") is None: continue\n",
    "        idx = assigns[j]; j+=1\n",
    "        (band_upper if idx==upper_idx else band_lower).append(n)\n",
    "\n",
    "    global_min_top = min(tops) if tops else 0.0\n",
    "    q_top0 = quarters[0].get(\"top\", page_h)\n",
    "    global_max_above = max(220.0, (q_top0 - global_min_top)*1.15)\n",
    "    Y_MIN_GAP = 6.0\n",
    "\n",
    "    def pick_nearest_above(qw, pool):\n",
    "        qx=qw[\"_cx\"]; q_top=qw.get(\"top\", page_h)\n",
    "        cand=[]\n",
    "        for n in pool:\n",
    "            nx=word_cx(n); nbot=n.get(\"bottom\")\n",
    "            if nx is None or nbot is None: continue\n",
    "            if abs(nx-qx) <= X_TOL:\n",
    "                dy = q_top - nbot\n",
    "                if dy >= Y_MIN_GAP and dy <= global_max_above:\n",
    "                    cand.append((dy,n))\n",
    "        cand.sort(key=lambda x:x[0])\n",
    "        return cand[0][1] if cand else None\n",
    "\n",
    "    out={}\n",
    "    for qw in quarters:\n",
    "        up = pick_nearest_above(qw, band_upper)\n",
    "        lo = pick_nearest_above(qw, band_lower)\n",
    "        if up is None and band_upper: up=min(band_upper, key=lambda n: abs(word_cx(n)-qw[\"_cx\"]))\n",
    "        if lo is None and band_lower: lo=min(band_lower, key=lambda n: abs(word_cx(n)-qw[\"_cx\"]))\n",
    "        if up and lo:\n",
    "            out[qw.get(\"text\")] = {\"group_nim\": lo[\"_num\"], \"commercial_nim\": up[\"_num\"]}\n",
    "    return out\n",
    "\n",
    "\n",
    "def bind_bar_like(quarters, numbers, page_h):\n",
    "    if not quarters or not numbers: return {}\n",
    "    quarters = sorted(quarters, key=lambda w: w[\"_cx\"])\n",
    "    dxs=[quarters[i+1][\"_cx\"]-quarters[i][\"_cx\"] for i in range(len(quarters)-1)]\n",
    "    X_TOL = max(30.0, (statistics.median(dxs) if dxs else 80.0)*0.40)\n",
    "    Y_MIN_GAP = 4.0\n",
    "    global_max_above = page_h\n",
    "\n",
    "    def pick_nearest_above(qw, pool):\n",
    "        qx=qw[\"_cx\"]; q_top=qw.get(\"top\", page_h)\n",
    "        cand=[]\n",
    "        for n in pool:\n",
    "            nx=word_cx(n); nbot=n.get(\"bottom\")\n",
    "            if nx is None or nbot is None: continue\n",
    "            if abs(nx-qx) <= X_TOL:\n",
    "                dy = q_top - nbot\n",
    "                if dy >= Y_MIN_GAP and dy <= global_max_above:\n",
    "                    cand.append((dy,n))\n",
    "        cand.sort(key=lambda x:x[0])\n",
    "        return cand[0][1] if cand else None\n",
    "\n",
    "    out={}\n",
    "    for qw in quarters:\n",
    "        n = pick_nearest_above(qw, numbers)\n",
    "        if n:\n",
    "            out[qw.get(\"text\")] = n[\"_num\"]\n",
    "    return out\n",
    "\n",
    "# --- Stacked bar binder\n",
    "def bind_stacked_bar_like(quarters, numbers, words, page_h):\n",
    "    \"\"\"\n",
    "    Heuristic for stacked bar charts:\n",
    "    - Detect left-side category labels (CATEGORY_LABELS) to form horizontal bands (y positions).\n",
    "    - For each quarter (x), pick the nearest number within each category band (y proximity).\n",
    "    - Detect a 'Total' as the largest number either clearly ABOVE the bands or clearly BELOW them.\n",
    "    Output:\n",
    "        { \"2Q25\": {\"Investment banking\": 31, \"Wealth management\": 649, ... , \"Total\": 1395}, ... }\n",
    "    \"\"\"\n",
    "    if not quarters or not numbers:\n",
    "        return {}\n",
    "\n",
    "    cat_bands = find_category_bands(words)\n",
    "    if not cat_bands:\n",
    "        return {}\n",
    "\n",
    "    quarters = sorted(quarters, key=lambda w: w[\"_cx\"])\n",
    "    dxs = [quarters[i+1][\"_cx\"] - quarters[i][\"_cx\"] for i in range(len(quarters)-1)]\n",
    "    X_TOL = max(36.0, (statistics.median(dxs) if dxs else 80.0) * 0.45)\n",
    "\n",
    "    nums = [n for n in numbers if n.get(\"top\") is not None and n.get(\"bottom\") is not None]\n",
    "    if not nums:\n",
    "        return {}\n",
    "\n",
    "    # y centers for numbers\n",
    "    def ny(n): return (n.get(\"top\", 0.0) + n.get(\"bottom\", 0.0)) / 2.0\n",
    "\n",
    "    # Band Y tolerance for category assignment\n",
    "    BAND_Y_TOL = 26.0\n",
    "\n",
    "    # Band centers\n",
    "    band_y_values = list(cat_bands.values())\n",
    "    highest_band_center = min(band_y_values)   # smaller y = higher on page\n",
    "    lowest_band_center  = max(band_y_values)\n",
    "\n",
    "    # Define cutoffs for \"Total\" zones\n",
    "    total_above_cutoff = highest_band_center - 18.0   # numbers above all bands\n",
    "    total_below_cutoff = lowest_band_center + 48.0    # numbers below all bands\n",
    "\n",
    "    out = {}\n",
    "    for qw in quarters:\n",
    "        qx = qw[\"_cx\"]\n",
    "        quarter_key = qw.get(\"text\")\n",
    "        row = {}\n",
    "\n",
    "        # Per-category pick by vertical proximity to label band\n",
    "        for label, y_band in cat_bands.items():\n",
    "            best = None\n",
    "            best_score = 1e9\n",
    "            for n in nums:\n",
    "                nx = word_cx(n)\n",
    "                if nx is None or abs(nx - qx) > X_TOL:\n",
    "                    continue\n",
    "                dy = abs(ny(n) - y_band)\n",
    "                if dy <= BAND_Y_TOL:\n",
    "                    score = dy + 0.01 * abs(nx - qx)\n",
    "                    if score < best_score:\n",
    "                        best_score = score\n",
    "                        best = n\n",
    "            if best is not None:\n",
    "                row[label] = best.get(\"_num\")\n",
    "\n",
    "        # Detect Total above-or-below bands within the same X window\n",
    "        candidates = []\n",
    "        for n in nums:\n",
    "            nx = word_cx(n)\n",
    "            if nx is None or abs(nx - qx) > X_TOL:\n",
    "                continue\n",
    "            t = n.get(\"top\", page_h)\n",
    "            if t <= total_above_cutoff or t >= total_below_cutoff:\n",
    "                candidates.append(n)\n",
    "\n",
    "        if candidates:\n",
    "            total_val = max(candidates, key=lambda n: n.get(\"_num\", float(\"-inf\"))).get(\"_num\")\n",
    "            if total_val is not None:\n",
    "                row[\"Total\"] = total_val\n",
    "\n",
    "        if row:\n",
    "            out[quarter_key] = row\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def consolidate_metrics(scanned_doc):\n",
    "    all_out={\"source\": scanned_doc.get(\"source\"), \"pages\":[]}\n",
    "    for pg in scanned_doc.get(\"pages\", []):\n",
    "        page_no=pg.get(\"page_number\")\n",
    "        page_h = pg.get(\"height\", 540.0)\n",
    "        text   = pg.get(\"text\",\"\")\n",
    "        words  = pg.get(\"words\", [])\n",
    "        quarters, numbers, plain = split_words(words)\n",
    "\n",
    "        # Prefer a title inferred from word positions/font sizes; fall back to text-only\n",
    "        metric_from_words = detect_metric_title_from_words(words, pg.get(\"width\", 960.0), page_h)\n",
    "        metric_title = (metric_from_words or detect_metric_title(text)).strip()\n",
    "        mt_low = metric_title.lower()\n",
    "        is_percentage = (\"net interest margin\" in mt_low) or (\"margin\" in mt_low and \"%\" in mt_low)\n",
    "        looks_like_chart = bool(quarters) and bool(numbers)\n",
    "\n",
    "        result={}\n",
    "        chart_type=\"text-or-table\"\n",
    "        if looks_like_chart and is_percentage:\n",
    "            chart_type=\"line-like\"\n",
    "            numbers_for_line = [n for n in numbers if looks_like_nim_value(n)]\n",
    "            result = bind_line_like(quarters, numbers_for_line, page_h)\n",
    "        elif looks_like_chart:\n",
    "            # Try stacked-bar first if we can see any known category labels\n",
    "            cat_bands = find_category_bands(words)\n",
    "            if len(cat_bands) >= 1:\n",
    "                chart_type = \"stacked-bar\"\n",
    "                result = bind_stacked_bar_like(quarters, numbers, words, page_h)\n",
    "                # fall back to simple bar if nothing extracted\n",
    "                if not result:\n",
    "                    chart_type = \"bar-like\"\n",
    "                    result = bind_bar_like(quarters, numbers, page_h)\n",
    "            else:\n",
    "                chart_type = \"bar-like\"\n",
    "                result = bind_bar_like(quarters, numbers, page_h)\n",
    "\n",
    "        # Optional: rename keys if legend clearly detected\n",
    "        if chart_type == \"line-like\" and result:\n",
    "            legend = guess_legend_labels(plain)\n",
    "            if legend == [\"Commercial book\",\"Group\"]:\n",
    "                # already named in bind_line_like as group_nim/commercial_nim\n",
    "                pass\n",
    "\n",
    "        # --- Table fallback: if no chart extracted, try the largest detected table ---\n",
    "        if (not result) and (pg.get(\"tables\")):\n",
    "            tables = pg.get(\"tables\") or []\n",
    "            def table_size(t):\n",
    "                rows = t.get(\"rows\") or []\n",
    "                cols = len(t.get(\"headers\") or [])\n",
    "                return (len(rows) * max(cols, 1))\n",
    "            biggest = max(tables, key=table_size) if tables else None\n",
    "            if biggest and (biggest.get(\"rows\")):\n",
    "                chart_type = \"table\"\n",
    "                result = {\n",
    "                    \"headers\": biggest.get(\"headers\") or [],\n",
    "                    \"rows\": biggest.get(\"rows\") or []\n",
    "                }\n",
    "\n",
    "        all_out[\"pages\"].append({\n",
    "            \"page\": page_no,\n",
    "            \"metric\": metric_title,\n",
    "            \"chart_type\": chart_type,\n",
    "            \"extracted\": result\n",
    "        })\n",
    "    return all_out\n",
    "\n",
    "metrics = consolidate_metrics(doc)\n",
    "Path(OUT_METRICS_JSON).parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUT_METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"✅ Wrote metrics → {OUT_METRICS_JSON}\")\n",
    "\n",
    "# === Print a concise summary of detected metrics for ALL pages ===\n",
    "print(\"\\n=== Page metrics summary ===\")\n",
    "print(f\"Source: {metrics.get('source')}\")\n",
    "pages_list = metrics.get(\"pages\", [])\n",
    "print(f\"Total pages indexed: {len(pages_list)}\\n\")\n",
    "\n",
    "# === Detailed extracts (only pages with extracted data) ===\n",
    "print(\"\\n=== Detailed extracts (pages with extracted data) ===\")\n",
    "for p in pages_list:\n",
    "    extracted = p.get(\"extracted\")\n",
    "    if not extracted:\n",
    "        continue\n",
    "    page = p.get(\"page\")\n",
    "    metric = (p.get(\"metric\") or \"\").strip()\n",
    "    ctype = p.get(\"chart_type\")\n",
    "    print(f\"\\n[Page {page}] {metric}  ({ctype})\")\n",
    "    # pretty-print dicts or small tables\n",
    "    if isinstance(extracted, dict) and \"headers\" in extracted and \"rows\" in extracted:\n",
    "        headers = extracted.get(\"headers\") or []\n",
    "        rows = extracted.get(\"rows\") or []\n",
    "        preview = rows[:8]\n",
    "        print(\"headers:\", headers)\n",
    "        for r in preview:\n",
    "            print(r)\n",
    "        if len(rows) > len(preview):\n",
    "            print(f\"... (+{len(rows)-len(preview)} more rows)\")\n",
    "    else:\n",
    "        print(json.dumps(extracted, indent=2))\n",
    "\n",
    "# === Quick confirm for NIM pages (line-like only) ===\n",
    "for p in pages_list:\n",
    "    metric_text = (p.get(\"metric\") or \"\").lower()\n",
    "    if p.get(\"chart_type\") == \"line-like\" and \"net interest margin\" in metric_text:\n",
    "        print(f\"\\n[NIM] page {p.get('page')}\")\n",
    "        print(json.dumps(p.get(\"extracted\", {}), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
