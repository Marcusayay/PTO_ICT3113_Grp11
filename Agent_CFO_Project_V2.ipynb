{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb8e4733",
      "metadata": {
        "id": "bb8e4733"
      },
      "source": [
        "# Agent CFO — Performance Optimization & Design\n",
        "\n",
        "---\n",
        "This is the starter notebook for your project. Follow the required structure below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wkMIj4Ssetku",
      "metadata": {
        "id": "wkMIj4Ssetku"
      },
      "source": [
        "You will design and optimize an Agent CFO assistant for a listed company. The assistant should answer finance/operations questions using RAG (Retrieval-Augmented Generation) + agentic reasoning, with response time (latency) as the primary metric.\n",
        "\n",
        "Your system must:\n",
        "*   Ingest the company’s public filings.\n",
        "*   Retrieve relevant passages efficiently.\n",
        "*   Compute ratios/trends via tool calls (calculator, table parsing).\n",
        "*   Produce answers with valid citations to the correct page/table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a4c0e3b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyBKaJ1EXo5qvIcLVjbWaSQeT_pL5VA6XhU\"  # replace with your key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c138dd7",
      "metadata": {
        "id": "0c138dd7"
      },
      "source": [
        "## 1. Config & Secrets\n",
        "\n",
        "Fill in your API keys in secrets. **Do not hardcode keys** in cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8a6098a4",
      "metadata": {
        "id": "8a6098a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Example:\n",
        "# os.environ['GEMINI_API_KEY'] = 'your-key-here'\n",
        "# os.environ['OPENAI_API_KEY'] = 'your-key-here'\n",
        "\n",
        "COMPANY_NAME = \"DBS Bank\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7a81e9",
      "metadata": {
        "id": "8b7a81e9"
      },
      "source": [
        "## 2. Data Download (Dropbox)\n",
        "\n",
        "*   Annual Reports: last 3–5 years.\n",
        "*   Quarterly Results Packs & MD&A (Management Discussion & Analysis).\n",
        "*   Investor Presentations and Press Releases.\n",
        "*   These files must be submitted later as a deliverable in the Dropbox data pack.\n",
        "*   Upload them under `/content/data/`.\n",
        "\n",
        "Scope limit: each team will ingest minimally 15 PDF files total.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d4e754",
      "metadata": {
        "id": "b0d4e754"
      },
      "source": [
        "## 3. System Requirements\n",
        "\n",
        "**Retrieval & RAG**\n",
        "*   Use a vector index (e.g., FAISS, LlamaIndex) + a keyword filter (BM25/ElasticSearch).\n",
        "*   Citations must include: report name, year, page number, section/table.\n",
        "\n",
        "**Agentic Reasoning**\n",
        "*   Support at least 3 tool types: calculator, table extraction, multi-document compare.\n",
        "*   Reasoning must follow a plan-then-act pattern (not a single unstructured call).\n",
        "\n",
        "**Instrumentation**\n",
        "*   Log timings for: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total.\n",
        "*   Log: tokens used, cache hits, tools invoked.\n",
        "*   Record p50/p95 latencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6b53c3ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage1] Scanning folder: All → found 29 document(s)\n",
            "[Stage1] Processing: 1Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=1\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 1Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 1Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=1\n",
            "          → Pages detected: 17\n",
            "[Stage1] Done: 1Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 1Q24_trading_update.pdf\n",
            "          → Period (filename): year=2024, quarter=1\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 1Q24_trading_update.pdf\n",
            "[Stage1] Processing: 1Q25_CEO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=1\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 1Q25_CEO_presentation.pdf\n",
            "[Stage1] Processing: 1Q25_CFO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=1\n",
            "          → Pages detected: 18\n",
            "[Stage1] Done: 1Q25_CFO_presentation.pdf\n",
            "[Stage1] Processing: 1Q25_trading_update.pdf\n",
            "          → Period (filename): year=2025, quarter=1\n",
            "          → Pages detected: 7\n",
            "[Stage1] Done: 1Q25_trading_update.pdf\n",
            "[Stage1] Processing: 2Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 4\n",
            "[Stage1] Done: 2Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 2Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 30\n",
            "[Stage1] Done: 2Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 2Q24_performance_summary.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 34\n",
            "[Stage1] Done: 2Q24_performance_summary.pdf\n",
            "[Stage1] Processing: 2Q24_press_statement.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 2Q24_press_statement.pdf\n",
            "[Stage1] Processing: 2Q24_suppl.xls\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::Index: shape=(38, 11), non-empty cells=62\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::1.Highlights: shape=(69, 21), non-empty cells=668\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::2.PerShare: shape=(31, 14), non-empty cells=137\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::3.NetInterest: shape=(51, 12), non-empty cells=300\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::4.NonInterest: shape=(24, 12), non-empty cells=142\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::5.Expenses: shape=(19, 12), non-empty cells=99\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::6.Allowances: shape=(33, 12), non-empty cells=193\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::7.Loans: shape=(42, 8), non-empty cells=176\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::8.FVOCI & CFH: shape=(34, 8), non-empty cells=144\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::9.Deposits: shape=(38, 8), non-empty cells=196\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::10. Debts issued: shape=(19, 8), non-empty cells=73\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::11.NPL,Coverage ratios: shape=(22, 8), non-empty cells=72\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::12.NPA: shape=(69, 8), non-empty cells=279\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::13.CumulativeAllowances: shape=(40, 8), non-empty cells=168\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::14.Capital: shape=(15, 8), non-empty cells=50\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::15.Mix: shape=(45, 6), non-empty cells=128\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::16.Consumer: shape=(21, 8), non-empty cells=88\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::17.Institutional: shape=(22, 8), non-empty cells=90\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::18.Markets: shape=(22, 8), non-empty cells=90\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::19.Others: shape=(22, 8), non-empty cells=90\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::20.S'pore: shape=(23, 8), non-empty cells=96\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::21.HK: shape=(22, 8), non-empty cells=94\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::22.GreaterChina: shape=(23, 8), non-empty cells=96\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::23.SSEA: shape=(22, 8), non-empty cells=94\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::24.ROW: shape=(23, 8), non-empty cells=96\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::25.P&L and OCI: shape=(67, 7), non-empty cells=271\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::26.BalSheet: shape=(48, 10), non-empty cells=233\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::27.CashFlow: shape=(58, 4), non-empty cells=128\n",
            "[Stage1][tabular] Excel parsed 2Q24_suppl.xls::28.Legend: shape=(12, 1), non-empty cells=11\n",
            "          → Table blocks: 37\n",
            "[Stage1] Done: 2Q24_suppl.xls\n",
            "[Stage1] Processing: 2Q25_CEO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 5\n",
            "[Stage1] Done: 2Q25_CEO_presentation.pdf\n",
            "[Stage1] Processing: 2Q25_CFO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 29\n",
            "[Stage1] Done: 2Q25_CFO_presentation.pdf\n",
            "[Stage1] Processing: 2Q25_performance_summary.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 35\n",
            "[Stage1] Done: 2Q25_performance_summary.pdf\n",
            "[Stage1] Processing: 2Q25_press_statement.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 7\n",
            "[Stage1] Done: 2Q25_press_statement.pdf\n",
            "[Stage1] Processing: 2Q25_suppl.xls\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::Index: shape=(38, 11), non-empty cells=62\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::1.Highlights: shape=(65, 17), non-empty cells=614\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::2.PerShare: shape=(31, 14), non-empty cells=113\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::3.NetInterest: shape=(51, 8), non-empty cells=218\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::4.NonInterest: shape=(23, 8), non-empty cells=95\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::5.Expenses: shape=(19, 8), non-empty cells=68\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::6.Allowances: shape=(32, 8), non-empty cells=129\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::7.Loans: shape=(39, 8), non-empty cells=176\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::8.FVOCI & CFH: shape=(34, 8), non-empty cells=144\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::9.Deposits: shape=(43, 8), non-empty cells=225\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::10. Debts issued: shape=(19, 8), non-empty cells=73\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::11.NPL,Coverage ratios: shape=(21, 8), non-empty cells=72\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::12.NPA: shape=(66, 8), non-empty cells=270\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::13.CumulativeAllowances: shape=(39, 8), non-empty cells=166\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::14.Capital: shape=(22, 9), non-empty cells=70\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::15.Mix: shape=(45, 6), non-empty cells=118\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::16.Consumer: shape=(21, 8), non-empty cells=88\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::17.Institutional: shape=(22, 8), non-empty cells=90\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::18.Markets: shape=(22, 8), non-empty cells=90\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::19.Others: shape=(22, 8), non-empty cells=90\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::20.S'pore: shape=(23, 8), non-empty cells=96\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::21.HK: shape=(22, 8), non-empty cells=94\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::22.GreaterChina: shape=(22, 8), non-empty cells=94\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::23.SSEA: shape=(22, 8), non-empty cells=94\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::24.ROW: shape=(23, 8), non-empty cells=96\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::25.P&L and OCI: shape=(67, 7), non-empty cells=271\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::26.BalSheet: shape=(48, 10), non-empty cells=233\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::27.CashFlow: shape=(61, 4), non-empty cells=137\n",
            "[Stage1][tabular] Excel parsed 2Q25_suppl.xls::28.Legend: shape=(20, 1), non-empty cells=19\n",
            "          → Table blocks: 37\n",
            "[Stage1] Done: 2Q25_suppl.xls\n",
            "[Stage1] Processing: 3Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=3\n",
            "          → Pages detected: 4\n",
            "[Stage1] Done: 3Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 3Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=3\n",
            "          → Pages detected: 21\n",
            "[Stage1] Done: 3Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 3Q24_trading_update.pdf\n",
            "          → Period (filename): year=2024, quarter=3\n",
            "          → Pages detected: 7\n",
            "[Stage1] Done: 3Q24_trading_update.pdf\n",
            "[Stage1] Processing: 4Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 4Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 4Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 30\n",
            "[Stage1] Done: 4Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 4Q24_performance_summary.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 45\n",
            "[Stage1] Done: 4Q24_performance_summary.pdf\n",
            "[Stage1] Processing: 4Q24_press_statement.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 8\n",
            "[Stage1] Done: 4Q24_press_statement.pdf\n",
            "[Stage1] Processing: 4Q24_suppl.xls\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::Index: shape=(38, 11), non-empty cells=62\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::1.Highlights: shape=(68, 23), non-empty cells=811\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::2.PerShare: shape=(31, 12), non-empty cells=97\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::3.NetInterest: shape=(51, 12), non-empty cells=323\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::4.NonInterest: shape=(24, 12), non-empty cells=142\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::5.Expenses: shape=(19, 12), non-empty cells=98\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::6.Allowances: shape=(32, 12), non-empty cells=189\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::7.Loans: shape=(38, 8), non-empty cells=170\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::8.FVOCI & CFH: shape=(35, 11), non-empty cells=202\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::9.Deposits: shape=(34, 8), non-empty cells=193\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::10. Debts issued: shape=(19, 8), non-empty cells=73\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::11.NPL,Coverage ratios: shape=(21, 8), non-empty cells=72\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::12.NPA: shape=(67, 8), non-empty cells=274\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::13.CumulativeAllowances: shape=(39, 8), non-empty cells=166\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::14.Capital: shape=(23, 9), non-empty cells=74\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::15.Mix: shape=(48, 9), non-empty cells=186\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::16.Consumer: shape=(23, 12), non-empty cells=133\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::17.Institutional: shape=(24, 12), non-empty cells=135\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::18.Markets: shape=(24, 12), non-empty cells=135\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::19.Others: shape=(24, 12), non-empty cells=135\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::20.S'pore: shape=(23, 12), non-empty cells=141\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::21.HK: shape=(22, 12), non-empty cells=139\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::22.GreaterChina: shape=(23, 12), non-empty cells=141\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::23.SSEA: shape=(22, 12), non-empty cells=139\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::24.ROW: shape=(23, 12), non-empty cells=141\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::25.P&L and OCI: shape=(68, 10), non-empty cells=405\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::26.BalSheet: shape=(50, 10), non-empty cells=236\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::27.CashFlow: shape=(64, 4), non-empty cells=146\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::28.Legend: shape=(18, 1), non-empty cells=17\n",
            "[Stage1][tabular] Excel parsed 4Q24_suppl.xls::Quarterly Breakdown-YE only: shape=(46, 6), non-empty cells=87\n",
            "          → Table blocks: 38\n",
            "[Stage1] Done: 4Q24_suppl.xls\n",
            "[Stage1] Processing: dbs-annual-report-2020.pdf\n",
            "          → Period (filename): year=2020, quarter=NULL\n",
            "          → Pages detected: 196\n",
            "[Stage1] Done: dbs-annual-report-2020.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2021.pdf\n",
            "          → Period (filename): year=2021, quarter=NULL\n",
            "          → Pages detected: 115\n",
            "[Stage1] Done: dbs-annual-report-2021.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2022.pdf\n",
            "          → Period (filename): year=2022, quarter=NULL\n",
            "          → Pages detected: 115\n",
            "[Stage1] Done: dbs-annual-report-2022.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2023.pdf\n",
            "          → Period (filename): year=2023, quarter=NULL\n",
            "          → Pages detected: 115\n",
            "[Stage1] Done: dbs-annual-report-2023.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2024.pdf\n",
            "          → Period (filename): year=2024, quarter=NULL\n",
            "          → Pages detected: 111\n",
            "[Stage1] Done: dbs-annual-report-2024.pdf\n",
            "[Stage1] Total raw chunks prepared: 8125\n",
            "[Stage1] Metadata rows: 8125\n",
            "[Stage1] Embedding provider selected: st:sentence-transformers/all-MiniLM-L6-v2 (backend=st)\n",
            "[Stage1] Embedded 8125 chunks (dim=384)\n",
            "[Stage1] FAISS index size: 8125\n",
            "Saved KB rows: 8125 → data/kb_chunks.parquet\n",
            "Saved texts:    (8125,) → data/kb_texts.npy\n",
            "Saved index:    8125 vecs → data/kb_index.faiss\n",
            "Saved meta:     data/kb_meta.json\n",
            "[Stage1] Parquet sanity: 112 rows from tabular sources (.csv/.xls/.xlsx)\n",
            "[Stage1] Parquet by extension: {'.pdf': 8013, '.xls': 112}\n",
            "[Stage1] ↳ Excel rows indexed: 112\n",
            "[Stage1] Coverage → year filled: 100.0%, quarter filled: 30.2%\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Stage1.py — Ingestion Pipeline\n",
        "\n",
        "Builds a Knowledge Base (KB) + Vector Store with metadata.\n",
        "Outputs:\n",
        "  - data/kb_chunks.parquet      # canonical KB with metadata per chunk\n",
        "  - data/kb_texts.npy           # chunk texts (parallel array)\n",
        "  - data/kb_index.faiss         # FAISS index of embeddings\n",
        "  - data/kb_meta.json           # small meta: embedding dim, model, version\n",
        "\n",
        "Environment (optional):\n",
        "  OPENAI_API_KEY    — for text-embedding-3-large or 3-small\n",
        "  GEMINI_API_KEY    — for gemini-embedding text-002 (if you prefer)\n",
        "\n",
        "You can also use local SentenceTransformers if installed.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "import os, re, json, math, uuid, pathlib, warnings\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Dict, Any, Optional, Iterable, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- optional deps ---\n",
        "try:\n",
        "    import faiss  # type: ignore\n",
        "    _HAVE_FAISS = True\n",
        "except Exception:\n",
        "    _HAVE_FAISS = False\n",
        "\n",
        "try:\n",
        "    from rank_bm25 import BM25Okapi  # lightweight BM25 for hybrid\n",
        "    _HAVE_BM25 = True\n",
        "except Exception:\n",
        "    _HAVE_BM25 = False\n",
        "\n",
        "# PDF text extraction (pypdf) — optional\n",
        "try:\n",
        "    from pypdf import PdfReader  # minimal + reliable\n",
        "    _HAVE_PDF = True\n",
        "except Exception:\n",
        "    _HAVE_PDF = False\n",
        "\n",
        "# Embeddings backends (we'll load lazily in Provider)\n",
        "\n",
        "\n",
        "DATA_DIR = os.environ.get(\"AGENT_CFO_DATA_DIR\", \"All\")\n",
        "OUT_DIR = os.environ.get(\"AGENT_CFO_OUT_DIR\", \"data\")\n",
        "EMBED_BACKEND = os.environ.get(\"AGENT_CFO_EMBED_BACKEND\", \"st\")  # 'auto', 'openai', 'gemini', 'st'\n",
        "CHUNK_TOKENS = 450  # ~sentence-y chunks; we chunk by chars but aim for this size\n",
        "CHUNK_OVERLAP = 80\n",
        "\n",
        "pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "\n",
        "_YEAR_PAT = re.compile(r\"\\b(20\\d{2})\\b\")\n",
        "_Q_PAT = re.compile(r\"([1-4])Q(\\d{2})\", re.I)  # e.g., 3Q24 (relaxed, allows underscores etc.)\n",
        "_FY_PAT = re.compile(r\"\\bFY\\s?(20\\d{2})\\b\", re.I)\n",
        "\n",
        "# Additional period patterns found in page headers\n",
        "_QY_PAT_1 = re.compile(r\"\\b([1-4])\\s*Q\\s*(20\\d{2}|\\d{2})\\b\", re.I)   # e.g., 1 Q 2025, 2Q24\n",
        "_QY_PAT_2 = re.compile(r\"\\bQ\\s*([1-4])\\s*(20\\d{2}|\\d{2})\\b\", re.I)     # e.g., Q3 2024\n",
        "_QY_PAT_3 = re.compile(r\"\\b([1-4])Q\\s*(20\\d{2}|\\d{2})\\b\", re.I)        # e.g., 3Q 2024\n",
        "_FY_PAT_2 = re.compile(r\"\\bF[Yy]\\s*(20\\d{2})\\b\")\n",
        "\n",
        "\n",
        "def infer_period_from_text(text: str, filename_year: Optional[int] = None) -> Tuple[Optional[int], Optional[int]]:\n",
        "    \"\"\"Infer (year, quarter) from the *header-like* part of a PDF page.\n",
        "    Strategy:\n",
        "    1) Look only at the first ~8 non-empty lines (avoid table bodies).\n",
        "    2) Collect all Q/Y candidates across patterns.\n",
        "    3) Prefer matches with 4-digit year.\n",
        "    4) If filename_year is provided, prefer candidates whose year == filename_year.\n",
        "    5) Otherwise choose the candidate with the *max* year.\n",
        "    6) If no Q/Y, accept FY headers; never infer from lone years.\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return (None, None)\n",
        "    # Consider only the very top of the page (likely title/header)\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    head = \"\\n\".join(lines[:8])  # top ~8 lines\n",
        "\n",
        "    # Gather candidates (q,y)\n",
        "    candidates: list[tuple[int, int, bool]] = []  # (q, y, has_4digit)\n",
        "    for pat in (_QY_PAT_1, _QY_PAT_2, _QY_PAT_3):\n",
        "        for m in pat.finditer(head):\n",
        "            q = int(m.group(1))\n",
        "            yy = m.group(2)\n",
        "            y = int(yy)\n",
        "            if y < 100:\n",
        "                y = 2000 + y\n",
        "                has4 = False\n",
        "            else:\n",
        "                has4 = True\n",
        "            candidates.append((q, y, has4))\n",
        "\n",
        "    if candidates:\n",
        "        # Prefer 4-digit year matches\n",
        "        four_digit = [c for c in candidates if c[2]]\n",
        "        pool = four_digit if four_digit else candidates\n",
        "        # If filename_year given, prefer that\n",
        "        if filename_year is not None:\n",
        "            same_year = [c for c in pool if c[1] == filename_year]\n",
        "            if same_year:\n",
        "                q, y, _ = same_year[0]\n",
        "                return (y, q)\n",
        "        # Else choose the max year (most recent)\n",
        "        q, y, _ = max(pool, key=lambda t: t[1])\n",
        "        return (y, q)\n",
        "\n",
        "    # FY header (year only) — accept if present\n",
        "    m = _FY_PAT_2.search(head)\n",
        "    if m:\n",
        "        return (int(m.group(1)), None)\n",
        "\n",
        "    return (None, None)\n",
        "def _dbg(msg: str):\n",
        "    if os.environ.get(\"AGENT_CFO_VERBOSE\", \"1\") != \"0\":\n",
        "        print(msg)\n",
        "# -----------------------------\n",
        "# Lightweight table extractor (keywords windows)\n",
        "# -----------------------------\n",
        "\n",
        "_KEY_TABLE_SPECS = [\n",
        "    # Margins\n",
        "    (re.compile(r\"\\bnet\\s*interest\\s*margin\\b|\\bnim\\b\", re.I), \"NIM table\"),\n",
        "    # Income lines\n",
        "    (re.compile(r\"\\b(total|operating)\\s+income\\b\", re.I), \"Total/Operating income\"),\n",
        "    (re.compile(r\"\\bnet\\s+interest\\s+income\\b|\\bnii\\b\", re.I), \"Net interest income\"),\n",
        "    (re.compile(r\"\\b(non[- ]?interest|other)\\s+income\\b|\\bfee(?:\\s+and)?\\s+commission\\s+income\\b\", re.I), \"Non-interest/fee income\"),\n",
        "    # Expenses (Opex)\n",
        "    (re.compile(r\"\\boperating\\s+expenses\\b|\\bopex\\b|^expenses$|^total\\s+expenses\\b|staff\\s+costs|technology\\s+(?:and\\s+)?operations?|it\\s+spend|amortisation\\s+of\\s+intangible\", re.I), \"Opex table\"),\n",
        "    # Efficiency\n",
        "    (re.compile(r\"\\bcost\\s*[-/]\\s*income\\b|\\bcost\\s*to\\s*income\\b|\\bcti\\b|\\befficiency\\s+ratio\\b\", re.I), \"CTI table\"),\n",
        "    # Credit costs / allowances\n",
        "    (re.compile(r\"\\ballowances\\b|\\bprovisions?\\b|\\becl\\b|\\bcredit\\s+costs?\\b|\\bimpairment\\b\", re.I), \"Allowances\"),\n",
        "    # Profit lines\n",
        "    (re.compile(r\"\\bprofit\\s+before\\s+allowances\\b|\\boperating\\s+profit\\b\", re.I), \"Operating profit\"),\n",
        "    (re.compile(r\"\\bprofit\\s+before\\s+tax\\b|\\bpbt\\b|\\bpre[- ]tax\\s+profit\\b\", re.I), \"PBT\"),\n",
        "    (re.compile(r\"\\bnet\\s+profit\\b|\\bprofit\\s+after\\s+tax\\b|\\bpat\\b|\\battributable\\s+profit\\b\", re.I), \"Net profit\"),\n",
        "    # Balance sheet snapshot\n",
        "    (re.compile(r\"\\bcustomer\\s+loans\\b|\\bgross\\s+loans\\b|\\bloan\\s+book\\b\", re.I), \"Loans\"),\n",
        "    (re.compile(r\"\\bcustomer\\s+deposits\\b|\\bdeposits?\\b\", re.I), \"Deposits\"),\n",
        "    # Asset quality\n",
        "    (re.compile(r\"\\bnpl\\s+ratio\\b|\\bnon[- ]?performing\\b\", re.I), \"Asset quality (NPL)\"),\n",
        "    # Capital & returns\n",
        "    (re.compile(r\"\\bCET\\s*1\\b|\\bcommon\\s+equity\\s+tier\\s*1\\b|\\bcapital\\s+adequacy\\b\", re.I), \"Capital & CET1\"),\n",
        "    (re.compile(r\"\\breturn\\s+on\\s+equity\\b|\\broe\\b|\\breturn\\s+on\\s+assets\\b|\\broa\\b\", re.I), \"Returns (ROE/ROA)\"),\n",
        "]\n",
        "\n",
        "def extract_key_tables_from_page(text: str, window_lines: int = 24) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Find small windows around key table keywords and return blocks.\n",
        "    Returns list of (section_hint, block_text).\n",
        "    \"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    out: List[Tuple[str, str]] = []\n",
        "    for i, ln in enumerate(lines):\n",
        "        for pat, label in _KEY_TABLE_SPECS:\n",
        "            if pat.search(ln):\n",
        "                start = max(0, i - 2)\n",
        "                end = min(len(lines), i + window_lines)\n",
        "                block = \"\\n\".join(lines[start:end])\n",
        "                out.append((label, block))\n",
        "                break\n",
        "    return out\n",
        "\n",
        "SECTION_LABELS = {\n",
        "    r\"key ratios|highlights|summary\": \"highlights/summary\",\n",
        "    r\"net interest margin|nim\\b\": \"Net interest margin (NIM)\",\n",
        "    r\"cost[- ]?to[- ]?income|cti|efficiency ratio\": \"Cost-to-income (CTI)\",\n",
        "    r\"operating expenses|^expenses$|opex|staff costs|technology|it spend\": \"Operating expenses (Opex)\",\n",
        "    r\"income statement|statement of (comprehensive )?income|total income|operating income|non[- ]?interest income|fee and commission|net interest income|nii\": \"Income statement\",\n",
        "    r\"balance sheet|statement of financial position|customer loans|deposits\": \"Balance sheet\",\n",
        "    r\"allowances|provisions|credit costs|impairment|ecl\": \"Allowances / Credit costs\",\n",
        "    r\"profit before allowances|operating profit|profit before tax|pbt|net profit|pat\": \"Profit\",\n",
        "    r\"npl ratio|non[- ]?performing\": \"Asset quality\",\n",
        "    r\"cet ?1|common equity tier 1|capital adequacy\": \"Capital & CET1\",\n",
        "    r\"return on equity|roe|return on assets|roa\": \"Returns\",\n",
        "    r\"management discussion|md&amp;a|md&a\": \"MD&A\",\n",
        "}\n",
        "\n",
        "_TABULAR_EXTS = {'.csv', '.xls', '.xlsx'}\n",
        "\n",
        "def _is_pdf(path: str) -> bool:\n",
        "    return str(path).lower().endswith('.pdf')\n",
        "\n",
        "def _is_tabular(path: str) -> bool:\n",
        "    return any(str(path).lower().endswith(ext) for ext in _TABULAR_EXTS)\n",
        "\n",
        "\n",
        "def infer_period_from_filename(fname: str) -> Tuple[Optional[int], Optional[int]]:\n",
        "    \"\"\"Infer (year, quarter) from common file naming conventions.\n",
        "    Examples: DBS_3Q24_CFO_Presentation.pdf -> (2024, 3)\n",
        "              dbs-annual-report-2023.pdf    -> (2023, None)\n",
        "    \"\"\"\n",
        "    base = fname.upper()\n",
        "    m = _Q_PAT.search(base)\n",
        "    if m:\n",
        "        q = int(m.group(1))\n",
        "        yy = int(m.group(2))\n",
        "        year = 2000 + yy if yy < 100 else yy\n",
        "        return (year, q)\n",
        "    m = _YEAR_PAT.search(base)\n",
        "    if m:\n",
        "        return (int(m.group(1)), None)\n",
        "    m = _FY_PAT.search(base)\n",
        "    if m:\n",
        "        return (int(m.group(1)), None)\n",
        "    return (None, None)\n",
        "\n",
        "\n",
        "def clean_section_hint(text: str) -> Optional[str]:\n",
        "    # naive regex scan to tag common sections; optional\n",
        "    for pat, label in SECTION_LABELS.items():\n",
        "        if re.search(pat, text, flags=re.IGNORECASE):\n",
        "            return label\n",
        "    return None\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Chunking\n",
        "# -----------------------------\n",
        "\n",
        "def _split_text(text: str, chunk_size_chars: int = 1800, overlap_chars: int = 320) -> List[str]:\n",
        "    text = (text or \"\").strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    out = []\n",
        "    i = 0\n",
        "    n = len(text)\n",
        "    while i < n:\n",
        "        j = min(n, i + chunk_size_chars)\n",
        "        out.append(text[i:j])\n",
        "        if j == n:\n",
        "            break\n",
        "        i = max(i + chunk_size_chars - overlap_chars, j)  # ensure progress\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# PDF parsing\n",
        "# -----------------------------\n",
        "\n",
        "def extract_pdf_pages(pdf_path: str) -> List[Tuple[int, str]]:\n",
        "    \"\"\"Return list of (page_number_1based, text).\"\"\"\n",
        "    if not _HAVE_PDF:\n",
        "        raise RuntimeError(\"pypdf not installed. pip install pypdf\")\n",
        "    reader = PdfReader(pdf_path)\n",
        "    out = []\n",
        "    for i, page in enumerate(reader.pages, start=1):\n",
        "        try:\n",
        "            txt = page.extract_text() or \"\"\n",
        "        except Exception:\n",
        "            txt = \"\"\n",
        "        out.append((i, txt))\n",
        "    return out\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Tabular (CSV/Excel) parsing\n",
        "# -----------------------------\n",
        "\n",
        "def _df_to_blocks(df: pd.DataFrame, rows_per_block: int = 40) -> List[str]:\n",
        "    \"\"\"Split a DataFrame into row blocks and render each as a compact CSV string.\n",
        "    Keeps headers on each block for standalone readability.\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return []\n",
        "    # Drop all-empty columns\n",
        "    df = df.dropna(axis=1, how='all')\n",
        "    # Convert everything to string to prevent pyarrow dtype issues downstream\n",
        "    df = df.astype(str)\n",
        "    blocks = []\n",
        "    n = len(df)\n",
        "    for i in range(0, n, rows_per_block):\n",
        "        part = df.iloc[i:i+rows_per_block]\n",
        "        csv_str = part.to_csv(index=False)\n",
        "        blocks.append(csv_str)\n",
        "    return blocks\n",
        "\n",
        "\n",
        "def extract_tabular_chunks(path: str) -> List[Tuple[str, Optional[str]]]:\n",
        "    \"\"\"Return a list of (block_text, sheet_name) for CSV/Excel files with robust error logging.\n",
        "    For CSV → one pseudo-sheet named 'CSV'. For Excel → one per sheet.\n",
        "    The reader tries multiple strategies (header=0, header=None) to cope with\n",
        "    formatted investor-supplement sheets where the first rows are titles.\n",
        "    \"\"\"\n",
        "    out: List[Tuple[str, Optional[str]]] = []\n",
        "    lower = path.lower()\n",
        "    base = os.path.basename(path)\n",
        "\n",
        "    def _summarize_df(df: pd.DataFrame) -> str:\n",
        "        if df is None or df.empty:\n",
        "            return \"empty\"\n",
        "        ncells = int(df.notna().sum().sum())\n",
        "        return f\"shape={df.shape}, non-empty cells={ncells}\"\n",
        "\n",
        "    try:\n",
        "        if lower.endswith('.csv'):\n",
        "            try:\n",
        "                df = pd.read_csv(path, low_memory=False, dtype=object)\n",
        "                print(f\"[Stage1][tabular] CSV opened {base}: {_summarize_df(df)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[Stage1][tabular] CSV parse failed for {base}: {e}\")\n",
        "                return []\n",
        "            blocks = _df_to_blocks(df)\n",
        "            if not blocks:\n",
        "                print(f\"[Stage1][tabular] CSV has no non-empty blocks: {base}\")\n",
        "            for block in blocks:\n",
        "                out.append((block, 'CSV'))\n",
        "            return out\n",
        "\n",
        "        # Excel path\n",
        "        engine = None\n",
        "        if lower.endswith('.xlsx'):\n",
        "            engine = 'openpyxl'\n",
        "        elif lower.endswith('.xls'):\n",
        "            engine = 'xlrd'\n",
        "        try:\n",
        "            xl = pd.ExcelFile(path, engine=engine) if engine else pd.ExcelFile(path)\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage1][tabular] Excel open failed for {base}: {e} (install 'openpyxl' for .xlsx or 'xlrd' for .xls)\")\n",
        "            return []\n",
        "\n",
        "        for sheet in xl.sheet_names:\n",
        "            df = None\n",
        "            # Strategy A: header on first non-empty row\n",
        "            try:\n",
        "                df = xl.parse(sheet, dtype=object)  # default header=0\n",
        "                # Drop leading all-NaN rows (visual titles often occupy top few)\n",
        "                while not df.empty and df.iloc[0].isna().all():\n",
        "                    df = df.iloc[1:]\n",
        "            except Exception as e:\n",
        "                print(f\"[Stage1][tabular] Sheet parse failed {base}::{sheet} (header=0): {e}\")\n",
        "\n",
        "            # Strategy B: no header → promote first non-empty row afterwards\n",
        "            if df is None or df.empty or df.notna().sum().sum() < 5:\n",
        "                try:\n",
        "                    df_b = xl.parse(sheet, header=None, dtype=object)\n",
        "                    # Drop leading empty rows\n",
        "                    while not df_b.empty and df_b.iloc[0].isna().all():\n",
        "                        df_b = df_b.iloc[1:]\n",
        "                    # Forward-fill header row then set it as columns if sensible\n",
        "                    if not df_b.empty:\n",
        "                        header_row = df_b.iloc[0].astype(str).str.strip()\n",
        "                        if header_row.notna().sum() >= max(2, int(df_b.shape[1] * 0.2)):\n",
        "                            df_b.columns = header_row\n",
        "                            df_b = df_b.iloc[1:]\n",
        "                    df = df_b if (df is None or df.empty) else df\n",
        "                except Exception as e:\n",
        "                    print(f\"[Stage1][tabular] Sheet parse failed {base}::{sheet} (header=None): {e}\")\n",
        "\n",
        "            if df is None or df.empty:\n",
        "                print(f\"[Stage1][tabular] No data in {base}::{sheet}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"[Stage1][tabular] Excel parsed {base}::{sheet}: {_summarize_df(df)}\")\n",
        "            blocks = _df_to_blocks(df)\n",
        "            if not blocks:\n",
        "                print(f\"[Stage1][tabular] No non-empty blocks in {base}::{sheet}\")\n",
        "                continue\n",
        "            for block in blocks:\n",
        "                out.append((block, sheet))\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(f\"[Stage1][tabular] Unexpected error {base}: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Embedding providers\n",
        "# -----------------------------\n",
        "class EmbeddingProvider:\n",
        "    name: str = \"\"\n",
        "    dim: int = 0\n",
        "    def embed_batch(self, texts: List[str]) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class OpenAIProvider(EmbeddingProvider):\n",
        "    def __init__(self, model: str = \"text-embedding-3-small\"):\n",
        "        from openai import OpenAI  # requires OPENAI_API_KEY\n",
        "        self.client = OpenAI()\n",
        "        self.model = model\n",
        "        # dims: 3-small=1536, 3-large=3072\n",
        "        self.dim = 1536 if \"small\" in model else 3072\n",
        "        self.name = f\"openai:{model}\"\n",
        "    def embed_batch(self, texts: List[str]) -> np.ndarray:\n",
        "        if not texts:\n",
        "            return np.zeros((0, self.dim), dtype=np.float32)\n",
        "        resp = self.client.embeddings.create(model=self.model, input=texts)\n",
        "        vecs = [d.embedding for d in resp.data]\n",
        "        return np.asarray(vecs, dtype=np.float32)\n",
        "\n",
        "\n",
        "class STProvider(EmbeddingProvider):\n",
        "    def __init__(self, model: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "        from sentence_transformers import SentenceTransformer  # optional\n",
        "        self.model_name = model\n",
        "        self.model = SentenceTransformer(model)\n",
        "        self.dim = self.model.get_sentence_embedding_dimension()\n",
        "        self.name = f\"st:{model}\"\n",
        "    def embed_batch(self, texts: List[str]) -> np.ndarray:\n",
        "        if not texts:\n",
        "            return np.zeros((0, self.dim), dtype=np.float32)\n",
        "        vecs = self.model.encode(texts, batch_size=64, show_progress_bar=False, convert_to_numpy=True, normalize_embeddings=True)\n",
        "        return vecs.astype(np.float32)\n",
        "\n",
        "\n",
        "def pick_provider(backend: str = EMBED_BACKEND) -> EmbeddingProvider:\n",
        "    \"\"\"Pick embedding provider based on argument or environment variable.\n",
        "    backend can be 'auto', 'openai', 'gemini', or 'st'.\n",
        "    Auto-detect priority: OpenAI → Gemini → SentenceTransformers.\"\"\"\n",
        "    backend = (backend or 'auto').lower()\n",
        "\n",
        "    # --- Explicit backend ---\n",
        "    if backend == 'openai':\n",
        "        return OpenAIProvider('text-embedding-3-small')\n",
        "    elif backend == 'st' or backend == 'sentence-transformers':\n",
        "        return STProvider('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    elif backend == 'gemini':\n",
        "        try:\n",
        "            from google import generativeai as genai\n",
        "            key = os.environ.get('GEMINI_API_KEY')\n",
        "            if not key:\n",
        "                raise RuntimeError('GEMINI_API_KEY not set')\n",
        "            genai.configure(api_key=key)\n",
        "            class GeminiProvider(EmbeddingProvider):\n",
        "                def __init__(self):\n",
        "                    self.name = 'gemini:embedding-001'\n",
        "                    self.dim = 0  # default size unknown initially\n",
        "                def embed_batch(self, texts: List[str]) -> np.ndarray:\n",
        "                    vecs = []\n",
        "                    for t in texts:\n",
        "                        resp = genai.embed_content(model='models/embedding-001', content=t)\n",
        "                        emb = resp.get('embedding') if isinstance(resp, dict) else getattr(resp, 'embedding', None)\n",
        "                        if emb is None:\n",
        "                            raise RuntimeError('Gemini embed_content returned no embedding')\n",
        "                        vecs.append(emb)\n",
        "                    arr = np.asarray(vecs, dtype=np.float32)\n",
        "                    if self.dim == 0 and arr.size:\n",
        "                        self.dim = int(arr.shape[1])\n",
        "                    return arr\n",
        "            return GeminiProvider()\n",
        "        except Exception as e:\n",
        "            warnings.warn(f'Gemini provider init failed: {e}')\n",
        "\n",
        "    # --- Auto detection ---\n",
        "    if os.environ.get('OPENAI_API_KEY'):\n",
        "        try:\n",
        "            return OpenAIProvider('text-embedding-3-small')\n",
        "        except Exception as e:\n",
        "            warnings.warn(f'OpenAI provider init failed: {e}')\n",
        "    if os.environ.get('GEMINI_API_KEY'):\n",
        "        try:\n",
        "            from google import generativeai as genai\n",
        "            genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
        "            class GeminiProvider(EmbeddingProvider):\n",
        "                def __init__(self):\n",
        "                    self.name = 'gemini:embedding-001'\n",
        "                    self.dim = 0\n",
        "                def embed_batch(self, texts: List[str]) -> np.ndarray:\n",
        "                    vecs = []\n",
        "                    for t in texts:\n",
        "                        resp = genai.embed_content(model='models/embedding-001', content=t)\n",
        "                        emb = resp.get('embedding') if isinstance(resp, dict) else getattr(resp, 'embedding', None)\n",
        "                        if emb is None:\n",
        "                            raise RuntimeError('Gemini embed_content returned no embedding')\n",
        "                        vecs.append(emb)\n",
        "                    arr = np.asarray(vecs, dtype=np.float32)\n",
        "                    if self.dim == 0 and arr.size:\n",
        "                        self.dim = int(arr.shape[1])\n",
        "                    return arr\n",
        "            return GeminiProvider()\n",
        "        except Exception as e:\n",
        "            warnings.warn(f'Gemini provider init failed: {e}')\n",
        "    try:\n",
        "        return STProvider('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    except Exception as e:\n",
        "        raise SystemExit(f'No embedding backend available. Install sentence-transformers or set an API key. {e}')\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Safe Parquet save with dtype sanitization\n",
        "# -----------------------------\n",
        "\n",
        "def _sanitize_and_save_parquet(df: pd.DataFrame, path: str) -> None:\n",
        "    \"\"\"Sanitize dtypes and save to Parquet, with fallbacks.\n",
        "    - Forces primitive/nullable dtypes that are parquet-friendly\n",
        "    - Tries pyarrow → fastparquet → CSV fallback\n",
        "    \"\"\"\n",
        "    d = df.copy()\n",
        "    # Standardize dtypes\n",
        "    if 'doc_id' in d:\n",
        "        d['doc_id'] = d['doc_id'].astype('string')\n",
        "    if 'file' in d:\n",
        "        d['file'] = d['file'].astype('string')\n",
        "    if 'section_hint' in d:\n",
        "        d['section_hint'] = d['section_hint'].astype('string')\n",
        "    if 'page' in d:\n",
        "        d['page'] = pd.to_numeric(d['page'], errors='coerce').fillna(0).astype('int32')\n",
        "    if 'year' in d:\n",
        "        # nullable small int for compactness\n",
        "        d['year'] = pd.to_numeric(d['year'], errors='coerce').astype('Int16')\n",
        "    if 'quarter' in d:\n",
        "        d['quarter'] = pd.to_numeric(d['quarter'], errors='coerce').astype('Int8')\n",
        "\n",
        "    # Try engines in order\n",
        "    errors = []\n",
        "    for engine in ('pyarrow', 'fastparquet'):\n",
        "        try:\n",
        "            d.to_parquet(path, engine=engine, index=False)\n",
        "            return\n",
        "        except Exception as e:\n",
        "            errors.append(f\"{engine}: {e}\")\n",
        "    # Final CSV fallback\n",
        "    csv_path = os.path.splitext(path)[0] + '.csv'\n",
        "    d.to_csv(csv_path, index=False)\n",
        "    raise RuntimeError(\n",
        "        \"Failed to save Parquet with both pyarrow and fastparquet. \"\n",
        "        f\"Wrote CSV fallback at {csv_path}. Errors: {' | '.join(errors)}\"\n",
        "    )\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main ingest\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    doc_id: str\n",
        "    file: str\n",
        "    page: int\n",
        "    year: Optional[int]\n",
        "    quarter: Optional[int]\n",
        "    section_hint: Optional[str]\n",
        "    text: str\n",
        "\n",
        "\n",
        "def walk_pdfs(root: str) -> List[str]:\n",
        "    # Kept for backward compatibility (returns only PDFs)\n",
        "    files = []\n",
        "    for p in pathlib.Path(root).rglob(\"*.pdf\"):\n",
        "        files.append(str(p))\n",
        "    return sorted(files)\n",
        "\n",
        "\n",
        "def walk_all_docs(root: str) -> List[str]:\n",
        "    \"\"\"Return PDFs + CSV + Excel paths under root.\"\"\"\n",
        "    paths: List[str] = []\n",
        "    for p in pathlib.Path(root).rglob(\"*\"):\n",
        "        if not p.is_file():\n",
        "            continue\n",
        "        s = str(p)\n",
        "        if _is_pdf(s) or _is_tabular(s):\n",
        "            paths.append(s)\n",
        "    return sorted(paths)\n",
        "\n",
        "\n",
        "def build_kb() -> Dict[str, Any]:\n",
        "    docs = walk_all_docs(DATA_DIR)\n",
        "    print(f\"[Stage1] Scanning folder: {DATA_DIR} → found {len(docs)} document(s)\")\n",
        "    if not docs:\n",
        "        raise SystemExit(f\"No PDFs, CSVs or Excels found under {DATA_DIR}. Place files there.\")\n",
        "\n",
        "    rows: List[Dict[str, Any]] = []\n",
        "    texts: List[str] = []\n",
        "\n",
        "    for path in docs:\n",
        "        fname = os.path.basename(path)\n",
        "        print(f\"[Stage1] Processing: {fname}\")\n",
        "        # Infer (year, quarter) from filename first, then log\n",
        "        year, quarter = infer_period_from_filename(fname)\n",
        "        ylog = year if year is not None else \"NULL\"\n",
        "        qlog = quarter if quarter is not None else \"NULL\"\n",
        "        print(f\"          → Period (filename): year={ylog}, quarter={qlog}\")\n",
        "        if _is_pdf(path):\n",
        "            pages = extract_pdf_pages(path)\n",
        "            print(f\"          → Pages detected: {len(pages)}\")\n",
        "            for page_num, page_text in pages:\n",
        "                if not page_text.strip():\n",
        "                    continue\n",
        "                section_hint = clean_section_hint(page_text[:500])\n",
        "                for chunk_text in _split_text(page_text):\n",
        "                    doc_id = str(uuid.uuid4())\n",
        "                    rows.append({\n",
        "                        \"doc_id\": doc_id,\n",
        "                        \"file\": fname,\n",
        "                        \"page\": page_num,\n",
        "                        \"year\": year,\n",
        "                        \"quarter\": quarter,\n",
        "                        \"section_hint\": section_hint,\n",
        "                    })\n",
        "                    texts.append(chunk_text)\n",
        "            # Second pass: infer period from page header text if missing, and extract key tables\n",
        "            # Re-iterate pages to attach refined (year, quarter) per page and table windows\n",
        "            for page_num, page_text in pages:\n",
        "                if not page_text.strip():\n",
        "                    continue\n",
        "\n",
        "                # --- Smarter Logic Starts Here ---\n",
        "                # Start with the period from the filename as the default \"final\" period.\n",
        "                final_year, final_quarter = year, quarter\n",
        "\n",
        "                # Infer the period from the page's header text.\n",
        "                page_year, page_quarter = infer_period_from_text(page_text, filename_year=year)\n",
        "\n",
        "                # DECISION LOGIC:\n",
        "                # Only update the quarter if the filename DID NOT provide one, but the page DID.\n",
        "                # This enhances data from annual reports without corrupting quarterly reports.\n",
        "                if final_quarter is None and page_quarter is not None:\n",
        "                    # As a safety check, ensure the year from the page matches the filename's year if available.\n",
        "                    if page_year is not None and final_year is not None and page_year == final_year:\n",
        "                        final_quarter = page_quarter\n",
        "                    # If the filename had no year either, trust the page completely.\n",
        "                    elif final_year is None:\n",
        "                        final_year = page_year\n",
        "                        final_quarter = page_quarter\n",
        "                \n",
        "                # If the filename provided a quarter, we ALWAYS trust it. No 'else' is needed,\n",
        "                # as we simply don't change `final_quarter` in case of a conflict.\n",
        "\n",
        "                # Extract small windows for key tables (NIM/Opex/CTI) using the validated period.\n",
        "                for label, block in extract_key_tables_from_page(page_text):\n",
        "                    doc_id = str(uuid.uuid4())\n",
        "                    rows.append({\n",
        "                        \"doc_id\": doc_id,\n",
        "                        \"file\": fname,\n",
        "                        \"page\": page_num,\n",
        "                        \"year\": final_year,      # Use the validated year\n",
        "                        \"quarter\": final_quarter,  # Use the validated quarter\n",
        "                        \"section_hint\": label,\n",
        "                    })\n",
        "                    texts.append(block)\n",
        "                # --- Smarter Logic Ends Here ---\n",
        "        elif _is_tabular(path):\n",
        "            blocks = extract_tabular_chunks(path)\n",
        "            if blocks:\n",
        "                print(f\"          → Table blocks: {len(blocks)}\")\n",
        "            else:\n",
        "                print(f\"          → Table blocks: 0 (no parsable content)\")\n",
        "            for block_text, sheet in blocks:\n",
        "                # Prefer a readable section label like \"table:Highlights\"\n",
        "                sheet_label = sheet if sheet else (\"CSV\" if path.lower().endswith('.csv') else \"sheet\")\n",
        "                section_hint = f\"table:{sheet_label}\"\n",
        "                doc_id = str(uuid.uuid4())\n",
        "                rows.append({\n",
        "                    \"doc_id\": doc_id,\n",
        "                    \"file\": fname,\n",
        "                    \"page\": 1,\n",
        "                    \"year\": year,\n",
        "                    \"quarter\": quarter,\n",
        "                    \"section_hint\": section_hint,\n",
        "                })\n",
        "                texts.append(block_text)\n",
        "        else:\n",
        "            print(f\"          → Skipped (unsupported type)\")\n",
        "        print(f\"[Stage1] Done: {fname}\")\n",
        "\n",
        "    print(f\"[Stage1] Total raw chunks prepared: {len(texts)}\")\n",
        "\n",
        "    kb = pd.DataFrame(rows)\n",
        "    print(f\"[Stage1] Metadata rows: {len(kb)}\")\n",
        "\n",
        "    texts_np = np.array(texts, dtype=object)\n",
        "\n",
        "    # embed\n",
        "    provider = pick_provider(EMBED_BACKEND)\n",
        "    print(f\"[Stage1] Embedding provider selected: {getattr(provider, 'name', type(provider).__name__)} (backend={EMBED_BACKEND})\")\n",
        "    try:\n",
        "        vecs = provider.embed_batch(list(texts_np))\n",
        "    except Exception as e:\n",
        "        warn_msg = str(e)\n",
        "        print(f\"[Stage1] ⚠️ Provider failed: {getattr(provider, 'name', type(provider).__name__)} → {warn_msg}\")\n",
        "        print(\"[Stage1] → Falling back to SentenceTransformers (all-MiniLM-L6-v2)...\")\n",
        "        fallback = STProvider('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        provider = fallback\n",
        "        vecs = provider.embed_batch(list(texts_np))\n",
        "    print(f\"[Stage1] Embedded {vecs.shape[0]} chunks (dim={vecs.shape[1]})\")\n",
        "\n",
        "    if not _HAVE_FAISS:\n",
        "        raise SystemExit(\"faiss is not installed. pip install faiss-cpu\")\n",
        "\n",
        "    # build index (L2 on normalized vectors works as cosine)\n",
        "    index = faiss.IndexFlatIP(vecs.shape[1])\n",
        "    # ensure normalized\n",
        "    norms = np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-12\n",
        "    vecs_norm = (vecs / norms).astype(np.float32)\n",
        "    index.add(vecs_norm)\n",
        "    print(f\"[Stage1] FAISS index size: {index.ntotal}\")\n",
        "\n",
        "    # save artifacts\n",
        "    kb_path = os.path.join(OUT_DIR, \"kb_chunks.parquet\")\n",
        "    text_path = os.path.join(OUT_DIR, \"kb_texts.npy\")\n",
        "    index_path = os.path.join(OUT_DIR, \"kb_index.faiss\")\n",
        "    meta_path = os.path.join(OUT_DIR, \"kb_meta.json\")\n",
        "\n",
        "    # Save KB with robust parquet saver\n",
        "    _sanitize_and_save_parquet(kb, kb_path)\n",
        "    np.save(text_path, texts_np)\n",
        "    faiss.write_index(index, index_path)\n",
        "    with open(meta_path, \"w\") as f:\n",
        "        json.dump({\"embedding_provider\": provider.name, \"dim\": int(vecs.shape[1])}, f)\n",
        "\n",
        "    print(f\"Saved KB rows: {len(kb)} → {kb_path}\")\n",
        "    print(f\"Saved texts:    {texts_np.shape} → {text_path}\")\n",
        "    print(f\"Saved index:    {index.ntotal} vecs → {index_path}\")\n",
        "    print(f\"Saved meta:     {meta_path}\")\n",
        "\n",
        "    # Parquet sanity: ensure tabular sources were indexed\n",
        "    try:\n",
        "        kb_loaded = pd.read_parquet(kb_path)\n",
        "        tab_like = kb_loaded['file'].str.lower().str.endswith(('.csv','.xls','.xlsx'))\n",
        "        tab_count = int(tab_like.sum())\n",
        "        print(f\"[Stage1] Parquet sanity: {tab_count} rows from tabular sources (.csv/.xls/.xlsx)\")\n",
        "        try:\n",
        "            ext_counts = (\n",
        "                kb_loaded['file']\n",
        "                .str.lower()\n",
        "                .str.extract(r'(\\.[a-z0-9]+)$')[0]\n",
        "                .value_counts()\n",
        "                .to_dict()\n",
        "            )\n",
        "            print(f\"[Stage1] Parquet by extension: {ext_counts}\")\n",
        "            excel_rows = int(kb_loaded['file'].str.lower().str.endswith(('.xls','.xlsx')).sum())\n",
        "            print(f\"[Stage1] ↳ Excel rows indexed: {excel_rows}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage1] Extension breakdown failed: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Stage1] Parquet sanity check failed: {e}\")\n",
        "\n",
        "    # --- Post-build coverage report ---\n",
        "    try:\n",
        "        qm = (~kb['quarter'].isna()).mean()\n",
        "        ym = (~kb['year'].isna()).mean()\n",
        "        print(f\"[Stage1] Coverage → year filled: {ym:.1%}, quarter filled: {qm:.1%}\")\n",
        "        # spot-check mismatches between filename and stored metadata\n",
        "        import re\n",
        "        pat = re.compile(r\"([1-4])Q(\\d{2})\", re.I)\n",
        "        mismatches = 0\n",
        "        for i,r in kb.iterrows():\n",
        "            m = pat.search(str(r['file']))\n",
        "            if not m:\n",
        "                continue\n",
        "            qf = int(m.group(1)); yf = 2000 + int(m.group(2))\n",
        "            y_ok = (pd.isna(r['year'])) or (int(r['year']) == yf)\n",
        "            q_ok = (pd.isna(r['quarter'])) or (int(r['quarter']) == qf)\n",
        "            if not (y_ok and q_ok):\n",
        "                mismatches += 1\n",
        "                if mismatches <= 5:\n",
        "                    print(f\"  ↳ mismatch: {r['file']} p.{r['page']} stored=({r['year']},{r['quarter']}) expected=({yf},{qf})\")\n",
        "        if mismatches:\n",
        "            print(f\"[Stage1] Mismatch count (sampled): {mismatches}\")\n",
        "    except Exception as _:\n",
        "        pass\n",
        "\n",
        "    return {\"kb\": kb_path, \"texts\": text_path, \"index\": index_path, \"meta\": meta_path}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    build_kb()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f532a3fb",
      "metadata": {},
      "source": [
        " ### Gemini Version 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2698633f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage1] Scanning folder: All → found 29 document(s)\n",
            "[Stage1] Processing: 1Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=1\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 1Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 1Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=1\n",
            "          → Pages detected: 17\n",
            "[Stage1] Done: 1Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 1Q24_trading_update.pdf\n",
            "          → Period (filename): year=2024, quarter=1\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 1Q24_trading_update.pdf\n",
            "[Stage1] Processing: 1Q25_CEO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=1\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 1Q25_CEO_presentation.pdf\n",
            "[Stage1] Processing: 1Q25_CFO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=1\n",
            "          → Pages detected: 18\n",
            "[Stage1] Done: 1Q25_CFO_presentation.pdf\n",
            "[Stage1] Processing: 1Q25_trading_update.pdf\n",
            "          → Period (filename): year=2025, quarter=1\n",
            "          → Pages detected: 7\n",
            "[Stage1] Done: 1Q25_trading_update.pdf\n",
            "[Stage1] Processing: 2Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 4\n",
            "[Stage1] Done: 2Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 2Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 30\n",
            "[Stage1] Done: 2Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 2Q24_performance_summary.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 34\n",
            "[Stage1] Done: 2Q24_performance_summary.pdf\n",
            "[Stage1] Processing: 2Q24_press_statement.pdf\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 2Q24_press_statement.pdf\n",
            "[Stage1] Processing: 2Q24_suppl.xls\n",
            "          → Period (filename): year=2024, quarter=2\n",
            "          → Excel sheet parsed 'Index': shape=(38, 11)\n",
            "          → Excel sheet parsed '1.Highlights': shape=(69, 21)\n",
            "          → Excel sheet parsed '2.PerShare': shape=(31, 14)\n",
            "          → Excel sheet parsed '3.NetInterest': shape=(51, 12)\n",
            "          → Excel sheet parsed '4.NonInterest': shape=(24, 12)\n",
            "          → Excel sheet parsed '5.Expenses': shape=(19, 12)\n",
            "          → Excel sheet parsed '6.Allowances': shape=(33, 12)\n",
            "          → Excel sheet parsed '7.Loans': shape=(42, 8)\n",
            "          → Excel sheet parsed '8.FVOCI & CFH': shape=(34, 8)\n",
            "          → Excel sheet parsed '9.Deposits': shape=(38, 8)\n",
            "          → Excel sheet parsed '10. Debts issued': shape=(19, 8)\n",
            "          → Excel sheet parsed '11.NPL,Coverage ratios': shape=(22, 8)\n",
            "          → Excel sheet parsed '12.NPA': shape=(69, 8)\n",
            "          → Excel sheet parsed '13.CumulativeAllowances': shape=(40, 8)\n",
            "          → Excel sheet parsed '14.Capital': shape=(15, 8)\n",
            "          → Excel sheet parsed '15.Mix': shape=(45, 6)\n",
            "          → Excel sheet parsed '16.Consumer': shape=(21, 8)\n",
            "          → Excel sheet parsed '17.Institutional': shape=(22, 8)\n",
            "          → Excel sheet parsed '18.Markets': shape=(22, 8)\n",
            "          → Excel sheet parsed '19.Others': shape=(22, 8)\n",
            "          → Excel sheet parsed '20.S'pore': shape=(23, 8)\n",
            "          → Excel sheet parsed '21.HK': shape=(22, 8)\n",
            "          → Excel sheet parsed '22.GreaterChina': shape=(23, 8)\n",
            "          → Excel sheet parsed '23.SSEA': shape=(22, 8)\n",
            "          → Excel sheet parsed '24.ROW': shape=(23, 8)\n",
            "          → Excel sheet parsed '25.P&L and OCI': shape=(67, 7)\n",
            "          → Excel sheet parsed '26.BalSheet': shape=(48, 10)\n",
            "          → Excel sheet parsed '27.CashFlow': shape=(58, 4)\n",
            "          → Excel sheet parsed '28.Legend': shape=(12, 1)\n",
            "          → Table blocks: 37\n",
            "[Stage1] Done: 2Q24_suppl.xls\n",
            "[Stage1] Processing: 2Q25_CEO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 5\n",
            "[Stage1] Done: 2Q25_CEO_presentation.pdf\n",
            "[Stage1] Processing: 2Q25_CFO_presentation.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 29\n",
            "[Stage1] Done: 2Q25_CFO_presentation.pdf\n",
            "[Stage1] Processing: 2Q25_performance_summary.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 35\n",
            "[Stage1] Done: 2Q25_performance_summary.pdf\n",
            "[Stage1] Processing: 2Q25_press_statement.pdf\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Pages detected: 7\n",
            "[Stage1] Done: 2Q25_press_statement.pdf\n",
            "[Stage1] Processing: 2Q25_suppl.xls\n",
            "          → Period (filename): year=2025, quarter=2\n",
            "          → Excel sheet parsed 'Index': shape=(38, 11)\n",
            "          → Excel sheet parsed '1.Highlights': shape=(65, 17)\n",
            "          → Excel sheet parsed '2.PerShare': shape=(31, 14)\n",
            "          → Excel sheet parsed '3.NetInterest': shape=(51, 8)\n",
            "          → Excel sheet parsed '4.NonInterest': shape=(23, 8)\n",
            "          → Excel sheet parsed '5.Expenses': shape=(19, 8)\n",
            "          → Excel sheet parsed '6.Allowances': shape=(32, 8)\n",
            "          → Excel sheet parsed '7.Loans': shape=(39, 8)\n",
            "          → Excel sheet parsed '8.FVOCI & CFH': shape=(34, 8)\n",
            "          → Excel sheet parsed '9.Deposits': shape=(43, 8)\n",
            "          → Excel sheet parsed '10. Debts issued': shape=(19, 8)\n",
            "          → Excel sheet parsed '11.NPL,Coverage ratios': shape=(21, 8)\n",
            "          → Excel sheet parsed '12.NPA': shape=(66, 8)\n",
            "          → Excel sheet parsed '13.CumulativeAllowances': shape=(39, 8)\n",
            "          → Excel sheet parsed '14.Capital': shape=(22, 9)\n",
            "          → Excel sheet parsed '15.Mix': shape=(45, 6)\n",
            "          → Excel sheet parsed '16.Consumer': shape=(21, 8)\n",
            "          → Excel sheet parsed '17.Institutional': shape=(22, 8)\n",
            "          → Excel sheet parsed '18.Markets': shape=(22, 8)\n",
            "          → Excel sheet parsed '19.Others': shape=(22, 8)\n",
            "          → Excel sheet parsed '20.S'pore': shape=(23, 8)\n",
            "          → Excel sheet parsed '21.HK': shape=(22, 8)\n",
            "          → Excel sheet parsed '22.GreaterChina': shape=(22, 8)\n",
            "          → Excel sheet parsed '23.SSEA': shape=(22, 8)\n",
            "          → Excel sheet parsed '24.ROW': shape=(23, 8)\n",
            "          → Excel sheet parsed '25.P&L and OCI': shape=(67, 7)\n",
            "          → Excel sheet parsed '26.BalSheet': shape=(48, 10)\n",
            "          → Excel sheet parsed '27.CashFlow': shape=(61, 4)\n",
            "          → Excel sheet parsed '28.Legend': shape=(20, 1)\n",
            "          → Table blocks: 37\n",
            "[Stage1] Done: 2Q25_suppl.xls\n",
            "[Stage1] Processing: 3Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=3\n",
            "          → Pages detected: 4\n",
            "[Stage1] Done: 3Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 3Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=3\n",
            "          → Pages detected: 21\n",
            "[Stage1] Done: 3Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 3Q24_trading_update.pdf\n",
            "          → Period (filename): year=2024, quarter=3\n",
            "          → Pages detected: 7\n",
            "[Stage1] Done: 3Q24_trading_update.pdf\n",
            "[Stage1] Processing: 4Q24_CEO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 6\n",
            "[Stage1] Done: 4Q24_CEO_presentation.pdf\n",
            "[Stage1] Processing: 4Q24_CFO_presentation.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 30\n",
            "[Stage1] Done: 4Q24_CFO_presentation.pdf\n",
            "[Stage1] Processing: 4Q24_performance_summary.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 45\n",
            "[Stage1] Done: 4Q24_performance_summary.pdf\n",
            "[Stage1] Processing: 4Q24_press_statement.pdf\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Pages detected: 8\n",
            "[Stage1] Done: 4Q24_press_statement.pdf\n",
            "[Stage1] Processing: 4Q24_suppl.xls\n",
            "          → Period (filename): year=2024, quarter=4\n",
            "          → Excel sheet parsed 'Index': shape=(38, 11)\n",
            "          → Excel sheet parsed '1.Highlights': shape=(68, 23)\n",
            "          → Excel sheet parsed '2.PerShare': shape=(31, 12)\n",
            "          → Excel sheet parsed '3.NetInterest': shape=(51, 12)\n",
            "          → Excel sheet parsed '4.NonInterest': shape=(24, 12)\n",
            "          → Excel sheet parsed '5.Expenses': shape=(19, 12)\n",
            "          → Excel sheet parsed '6.Allowances': shape=(32, 12)\n",
            "          → Excel sheet parsed '7.Loans': shape=(38, 8)\n",
            "          → Excel sheet parsed '8.FVOCI & CFH': shape=(35, 11)\n",
            "          → Excel sheet parsed '9.Deposits': shape=(34, 8)\n",
            "          → Excel sheet parsed '10. Debts issued': shape=(19, 8)\n",
            "          → Excel sheet parsed '11.NPL,Coverage ratios': shape=(21, 8)\n",
            "          → Excel sheet parsed '12.NPA': shape=(67, 8)\n",
            "          → Excel sheet parsed '13.CumulativeAllowances': shape=(39, 8)\n",
            "          → Excel sheet parsed '14.Capital': shape=(23, 9)\n",
            "          → Excel sheet parsed '15.Mix': shape=(48, 9)\n",
            "          → Excel sheet parsed '16.Consumer': shape=(23, 12)\n",
            "          → Excel sheet parsed '17.Institutional': shape=(24, 12)\n",
            "          → Excel sheet parsed '18.Markets': shape=(24, 12)\n",
            "          → Excel sheet parsed '19.Others': shape=(24, 12)\n",
            "          → Excel sheet parsed '20.S'pore': shape=(23, 12)\n",
            "          → Excel sheet parsed '21.HK': shape=(22, 12)\n",
            "          → Excel sheet parsed '22.GreaterChina': shape=(23, 12)\n",
            "          → Excel sheet parsed '23.SSEA': shape=(22, 12)\n",
            "          → Excel sheet parsed '24.ROW': shape=(23, 12)\n",
            "          → Excel sheet parsed '25.P&L and OCI': shape=(68, 10)\n",
            "          → Excel sheet parsed '26.BalSheet': shape=(50, 10)\n",
            "          → Excel sheet parsed '27.CashFlow': shape=(64, 4)\n",
            "          → Excel sheet parsed '28.Legend': shape=(18, 1)\n",
            "          → Excel sheet parsed 'Quarterly Breakdown-YE only': shape=(47, 6)\n",
            "          → Table blocks: 38\n",
            "[Stage1] Done: 4Q24_suppl.xls\n",
            "[Stage1] Processing: dbs-annual-report-2020.pdf\n",
            "          → Period (filename): year=2020, quarter=NULL\n",
            "          → Pages detected: 196\n",
            "[Stage1] Done: dbs-annual-report-2020.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2021.pdf\n",
            "          → Period (filename): year=2021, quarter=NULL\n",
            "          → Pages detected: 115\n",
            "[Stage1] Done: dbs-annual-report-2021.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2022.pdf\n",
            "          → Period (filename): year=2022, quarter=NULL\n",
            "          → Pages detected: 115\n",
            "[Stage1] Done: dbs-annual-report-2022.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2023.pdf\n",
            "          → Period (filename): year=2023, quarter=NULL\n",
            "          → Pages detected: 115\n",
            "[Stage1] Done: dbs-annual-report-2023.pdf\n",
            "[Stage1] Processing: dbs-annual-report-2024.pdf\n",
            "          → Period (filename): year=2024, quarter=NULL\n",
            "          → Pages detected: 111\n",
            "[Stage1] Done: dbs-annual-report-2024.pdf\n",
            "[Stage1] Total raw chunks prepared: 3497\n",
            "\n",
            "--------------------------------------------------\n",
            "[Stage1] Final Ingestion Reconciliation Report\n",
            "--------------------------------------------------\n",
            "  - Documents Discovered: 29\n",
            "  - Documents Indexed:    29\n",
            "  - Unindexed / Empty:    0\n",
            "\n",
            "  ✅ All discovered documents were successfully indexed.\n",
            "--------------------------------------------------\n",
            "\n",
            "--------------------------------------------------\n",
            "[Stage1] Per-File Period Tagging Verification Report\n",
            "--------------------------------------------------\n",
            "📄 File: 1Q24_CEO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=1\n",
            "   - Stored:   Y=2024, Q=1\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 1Q24_CFO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=1\n",
            "   - Stored:   Y=2024, Q=1\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 1Q24_trading_update.pdf\n",
            "   - Expected: Y=2024, Q=1\n",
            "   - Stored:   Y=2024, Q=1\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 1Q25_CEO_presentation.pdf\n",
            "   - Expected: Y=2025, Q=1\n",
            "   - Stored:   Y=2025, Q=1\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 1Q25_CFO_presentation.pdf\n",
            "   - Expected: Y=2025, Q=1\n",
            "   - Stored:   Y=2025, Q=1\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 1Q25_trading_update.pdf\n",
            "   - Expected: Y=2025, Q=1\n",
            "   - Stored:   Y=2025, Q=1\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q24_CEO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=2\n",
            "   - Stored:   Y=2024, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q24_CFO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=2\n",
            "   - Stored:   Y=2024, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q24_performance_summary.pdf\n",
            "   - Expected: Y=2024, Q=2\n",
            "   - Stored:   Y=2024, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q24_press_statement.pdf\n",
            "   - Expected: Y=2024, Q=2\n",
            "   - Stored:   Y=2024, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q24_suppl.xls\n",
            "   - Expected: Y=2024, Q=2\n",
            "   - Stored:   Y=2024, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q25_CEO_presentation.pdf\n",
            "   - Expected: Y=2025, Q=2\n",
            "   - Stored:   Y=2025, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q25_CFO_presentation.pdf\n",
            "   - Expected: Y=2025, Q=2\n",
            "   - Stored:   Y=2025, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q25_performance_summary.pdf\n",
            "   - Expected: Y=2025, Q=2\n",
            "   - Stored:   Y=2025, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q25_press_statement.pdf\n",
            "   - Expected: Y=2025, Q=2\n",
            "   - Stored:   Y=2025, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 2Q25_suppl.xls\n",
            "   - Expected: Y=2025, Q=2\n",
            "   - Stored:   Y=2025, Q=2\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 3Q24_CEO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=3\n",
            "   - Stored:   Y=2024, Q=3\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 3Q24_CFO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=3\n",
            "   - Stored:   Y=2024, Q=3\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 3Q24_trading_update.pdf\n",
            "   - Expected: Y=2024, Q=3\n",
            "   - Stored:   Y=2024, Q=3\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 4Q24_CEO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=4\n",
            "   - Stored:   Y=2024, Q=4\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 4Q24_CFO_presentation.pdf\n",
            "   - Expected: Y=2024, Q=4\n",
            "   - Stored:   Y=2024, Q=4\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 4Q24_performance_summary.pdf\n",
            "   - Expected: Y=2024, Q=4\n",
            "   - Stored:   Y=2024, Q=4\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 4Q24_press_statement.pdf\n",
            "   - Expected: Y=2024, Q=4\n",
            "   - Stored:   Y=2024, Q=4\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: 4Q24_suppl.xls\n",
            "   - Expected: Y=2024, Q=4\n",
            "   - Stored:   Y=2024, Q=4\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: dbs-annual-report-2020.pdf\n",
            "   - Expected: Y=2020, Q=N/A\n",
            "   - Stored:   Y=2020, Q=N/A\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: dbs-annual-report-2021.pdf\n",
            "   - Expected: Y=2021, Q=N/A\n",
            "   - Stored:   Y=2021, Q=N/A\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: dbs-annual-report-2022.pdf\n",
            "   - Expected: Y=2022, Q=N/A\n",
            "   - Stored:   Y=2022, Q=N/A\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: dbs-annual-report-2023.pdf\n",
            "   - Expected: Y=2023, Q=N/A\n",
            "   - Stored:   Y=2023, Q=N/A\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "📄 File: dbs-annual-report-2024.pdf\n",
            "   - Expected: Y=2024, Q=N/A\n",
            "   - Stored:   Y=2024, Q=N/A\n",
            "   - Status:   ✅ OK\n",
            "-------------------------\n",
            "--------------------------------------------------\n",
            "\n",
            "[Stage1] Embedding with model: sentence-transformers/all-MiniLM-L12-v2\n",
            "[Stage1] Embedded 3497 chunks (dim=384)\n",
            "[Stage1] FAISS index size: 3497\n",
            "Saved KB: 3497 rows → data/kb_chunks.parquet\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "\"\"\"\n",
        "Stage1.py — Ingestion Pipeline\n",
        "\n",
        "Builds a Knowledge Base (KB) + Vector Store with metadata.\n",
        "\"\"\"\n",
        "import os, re, json, uuid, pathlib\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- optional deps ---\n",
        "try:\n",
        "    import faiss\n",
        "    _HAVE_FAISS = True\n",
        "except Exception:\n",
        "    _HAVE_FAISS = False\n",
        "\n",
        "try:\n",
        "    from pypdf import PdfReader\n",
        "    _HAVE_PDF = True\n",
        "except Exception:\n",
        "    _HAVE_PDF = False\n",
        "\n",
        "DATA_DIR = os.environ.get(\"AGENT_CFO_DATA_DIR\", \"All\")\n",
        "OUT_DIR = os.environ.get(\"AGENT_CFO_OUT_DIR\", \"data\")\n",
        "EMBED_BACKEND = os.environ.get(\"AGENT_CFO_EMBED_BACKEND\", \"st\")\n",
        "CHUNK_TOKENS = 450\n",
        "CHUNK_OVERLAP = 80\n",
        "\n",
        "pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Utilities & Constants ---\n",
        "_YEAR_PAT = re.compile(r\"\\b(20\\d{2})\\b\")\n",
        "_Q_PAT = re.compile(r\"([1-4])Q(\\d{2})\", re.I)\n",
        "_FY_PAT = re.compile(r\"\\bFY\\s?(20\\d{2})\\b\", re.I)\n",
        "_QY_PAT_1 = re.compile(r\"\\b([1-4])\\s*Q\\s*(20\\d{2}|\\d{2})\\b\", re.I)\n",
        "_QY_PAT_2 = re.compile(r\"\\bQ\\s*([1-4])\\s*(20\\d{2}|\\d{2})\\b\", re.I)\n",
        "_QY_PAT_3 = re.compile(r\"\\b([1-4])Q\\s*(20\\d{2}|\\d{2})\\b\", re.I)\n",
        "_FY_PAT_2 = re.compile(r\"\\bF[Yy]\\s*(20\\d{2})\\b\")\n",
        "\n",
        "MAX_TABLE_WINDOWS_PER_PAGE = 3\n",
        "DEFAULT_WINDOW_LINES = 18\n",
        "\n",
        "SHEET_SECTION_PATTERNS = [\n",
        "    (r\"^\\s*(?:1\\.)?\\s*highlights\\b|^highlights$\", \"highlights/summary\"),\n",
        "    (r\"expenses|opex\", \"Operating expenses (Opex)\"),\n",
        "    (r\"net\\s*interest\", \"Net interest income\"),\n",
        "    (r\"non[- ]?interest|fee|commission\", \"Non-interest/fee income\"),\n",
        "    (r\"cost\\s*[-/ ]?to\\s*[-/ ]?income|\\bcti\\b\", \"Cost-to-income (CTI)\"),\n",
        "    (r\"npl|coverage\\s+ratios\", \"Asset quality (NPL)\"),\n",
        "    (r\"loans\", \"Loans\"), (r\"deposits\", \"Deposits\"), (r\"capital|cet\\s*1\", \"Capital & CET1\"),\n",
        "    (r\"return\\s+on\\s+equity|\\broe\\b\", \"Returns (ROE/ROA)\"), (r\"profit|pbt|pat\", \"Profit\"),\n",
        "]\n",
        "\n",
        "def sheet_section_label(sheet_name: Optional[str]) -> Optional[str]:\n",
        "    s = (sheet_name or \"\").strip()\n",
        "    if not s: return None\n",
        "    for pat, label in SHEET_SECTION_PATTERNS:\n",
        "        if re.search(pat, s, flags=re.IGNORECASE): return label\n",
        "    return None\n",
        "\n",
        "def infer_period_from_text(text: str, filename_year: Optional[int] = None) -> Tuple[Optional[int], Optional[int]]:\n",
        "    if not text: return (None, None)\n",
        "    head = \"\\n\".join([ln.strip() for ln in text.splitlines() if ln.strip()][:8])\n",
        "    candidates: list[tuple[int, int]] = []\n",
        "    for pat in (_QY_PAT_1, _QY_PAT_2, _QY_PAT_3):\n",
        "        for m in pat.finditer(head):\n",
        "            q, yy_str = int(m.group(1)), m.group(2)\n",
        "            y = int(yy_str)\n",
        "            if y < 100: y = 2000 + y\n",
        "            candidates.append((q, y))\n",
        "    if candidates:\n",
        "        if filename_year is not None:\n",
        "            same_year = [c for c in candidates if c[1] == filename_year]\n",
        "            if same_year: return (filename_year, same_year[0][0])\n",
        "        q, y = max(candidates, key=lambda t: t[1])\n",
        "        return (y, q)\n",
        "    m = _FY_PAT_2.search(head)\n",
        "    if m: return (int(m.group(1)), None)\n",
        "    return (None, None)\n",
        "\n",
        "_KEY_TABLE_SPECS = [\n",
        "    (re.compile(r\"\\bnet\\s*interest\\s*margin\\b|\\bnim\\b\", re.I), \"NIM table\"),\n",
        "    (re.compile(r\"\\b(total|operating)\\s+income\\b\", re.I), \"Total/Operating income\"),\n",
        "    (re.compile(r\"\\b(operating|staff|other)?\\s*expenses\\b|\\bopex\\b|\\bcosts?\\b\", re.I), \"Opex table\"),\n",
        "    (re.compile(r\"cost\\s*[/\\-\\–_]?\\s*to?\\s*income(\\s*ratio)?|cost\\s*/\\s*income|\\bcti\\b\", re.I), \"CTI table\"),\n",
        "]\n",
        "\n",
        "def extract_key_tables_from_page(text: str) -> List[Tuple[str, str]]:\n",
        "    if not text: return []\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "    out: List[Tuple[str, str]] = []\n",
        "    for i, ln in enumerate(lines):\n",
        "        for pat, label in _KEY_TABLE_SPECS:\n",
        "            if pat.search(ln):\n",
        "                start, end = max(0, i - 2), min(len(lines), i + DEFAULT_WINDOW_LINES)\n",
        "                out.append((label, \"\\n\".join(lines[start:end]))); break\n",
        "    return out\n",
        "\n",
        "_TABULAR_EXTS = {'.csv', '.xls', '.xlsx'}\n",
        "def _is_pdf(path: str) -> bool: return str(path).lower().endswith('.pdf')\n",
        "def _is_tabular(path: str) -> bool: return any(str(path).lower().endswith(ext) for ext in _TABULAR_EXTS)\n",
        "\n",
        "def infer_period_from_filename(fname: str) -> Tuple[Optional[int], Optional[int]]:\n",
        "    base = fname.upper()\n",
        "    m = _Q_PAT.search(base)\n",
        "    if m:\n",
        "        q, yy = int(m.group(1)), int(m.group(2))\n",
        "        return (2000 + yy if yy < 100 else yy, q)\n",
        "    m = _YEAR_PAT.search(base)\n",
        "    if m: return (int(m.group(1)), None)\n",
        "    m = _FY_PAT.search(base)\n",
        "    if m: return (int(m.group(1)), None)\n",
        "    return (None, None)\n",
        "\n",
        "def _split_text(text: str) -> List[str]:\n",
        "    text = (text or \"\").strip()\n",
        "    if not text: return []\n",
        "    chunk_size, overlap = 1800, 320\n",
        "    out, i, n = [], 0, len(text)\n",
        "    while i < n:\n",
        "        j = min(n, i + chunk_size)\n",
        "        out.append(text[i:j])\n",
        "        if j == n: break\n",
        "        i = max(i + chunk_size - overlap, j)\n",
        "    return out\n",
        "\n",
        "def extract_pdf_pages(path: str) -> List[Tuple[int, str]]:\n",
        "    if not _HAVE_PDF: raise RuntimeError(\"pypdf not installed. pip install pypdf\")\n",
        "    reader = PdfReader(path)\n",
        "    return [(i, p.extract_text() or \"\") for i, p in enumerate(reader.pages, 1)]\n",
        "\n",
        "def _df_to_blocks(df: pd.DataFrame) -> List[str]:\n",
        "    if df is None or df.empty: return []\n",
        "    df = df.dropna(axis=1, how='all').astype(str)\n",
        "    return [df.iloc[i:i+40].to_csv(index=False) for i in range(0, len(df), 40)]\n",
        "\n",
        "def extract_tabular_chunks(path: str) -> List[Tuple[str, Optional[str]]]:\n",
        "    base = os.path.basename(path)\n",
        "    try:\n",
        "        lower = path.lower()\n",
        "        if lower.endswith('.csv'):\n",
        "            df = pd.read_csv(path, low_memory=False, dtype=object)\n",
        "            print(f\"          → CSV parsed: shape={df.shape}\")\n",
        "            return [(block, 'CSV') for block in _df_to_blocks(df)]\n",
        "        engine = 'openpyxl' if lower.endswith('.xlsx') else ('xlrd' if lower.endswith('.xls') else None)\n",
        "        xl = pd.ExcelFile(path, engine=engine)\n",
        "        out = []\n",
        "        for sheet in xl.sheet_names:\n",
        "            df = xl.parse(sheet, dtype=object)\n",
        "            print(f\"          → Excel sheet parsed '{sheet}': shape={df.shape}\")\n",
        "            for block in _df_to_blocks(df): out.append((block, sheet))\n",
        "        return out\n",
        "    except Exception as e:\n",
        "        print(f\"          → ⚠️ WARNING: Parse failed for {base}: {e}\")\n",
        "        return []\n",
        "\n",
        "def pick_provider() -> Tuple[Any, str]:  # Simplified EmbeddingProvider\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
        "    return SentenceTransformer(model_name), model_name\n",
        "\n",
        "def walk_all_docs(root: str) -> List[str]:\n",
        "    paths = []\n",
        "    for p in pathlib.Path(root).rglob(\"*\"):\n",
        "        if p.is_file() and (_is_pdf(str(p)) or _is_tabular(str(p))):\n",
        "            paths.append(str(p))\n",
        "    return sorted(paths)\n",
        "\n",
        "def build_kb() -> Dict[str, Any]:\n",
        "    docs = walk_all_docs(DATA_DIR)\n",
        "    print(f\"[Stage1] Scanning folder: {DATA_DIR} → found {len(docs)} document(s)\")\n",
        "    if not docs: raise SystemExit(f\"No documents found under {DATA_DIR}.\")\n",
        "\n",
        "    rows, texts = [], []\n",
        "    for path in docs:\n",
        "        fname = os.path.basename(path)\n",
        "        print(f\"[Stage1] Processing: {fname}\")\n",
        "        year, quarter = infer_period_from_filename(fname)\n",
        "        print(f\"          → Period (filename): year={year or 'NULL'}, quarter={quarter or 'NULL'}\")\n",
        "        \n",
        "        if _is_pdf(path):\n",
        "            pages = extract_pdf_pages(path)\n",
        "            print(f\"          → Pages detected: {len(pages)}\")\n",
        "            for page_num, page_text in pages:\n",
        "                if not page_text.strip(): continue\n",
        "                for chunk_text in _split_text(page_text):\n",
        "                    rows.append({\"doc_id\": str(uuid.uuid4()), \"file\": fname, \"page\": page_num, \"year\": year, \"quarter\": quarter, \"section_hint\": None})\n",
        "                    texts.append(chunk_text)\n",
        "            \n",
        "            for page_num, page_text in pages:\n",
        "                final_year, final_quarter = year, quarter\n",
        "                page_year, page_quarter = infer_period_from_text(page_text, filename_year=year)\n",
        "                if final_quarter is None and page_quarter is not None:\n",
        "                    if page_year == final_year: final_quarter = page_quarter\n",
        "                    elif final_year is None: final_year, final_quarter = page_year, page_quarter\n",
        "                \n",
        "                for label, block in extract_key_tables_from_page(page_text):\n",
        "                    rows.append({\"doc_id\": str(uuid.uuid4()), \"file\": fname, \"page\": page_num, \"year\": final_year, \"quarter\": final_quarter, \"section_hint\": label})\n",
        "                    texts.append(block)\n",
        "\n",
        "        elif _is_tabular(path):\n",
        "            blocks = extract_tabular_chunks(path)\n",
        "            if not blocks:\n",
        "                print(f\"          → WARNING: No content extracted from table: {fname}\")\n",
        "            else:\n",
        "                print(f\"          → Table blocks: {len(blocks)}\")\n",
        "            for block_text, sheet in blocks:\n",
        "                section_hint = sheet_section_label(sheet) or f\"table:{sheet}\"\n",
        "                rows.append({\"doc_id\": str(uuid.uuid4()), \"file\": fname, \"page\": 1, \"year\": year, \"quarter\": quarter, \"section_hint\": section_hint})\n",
        "                texts.append(block_text)\n",
        "        print(f\"[Stage1] Done: {fname}\")\n",
        "\n",
        "    print(f\"[Stage1] Total raw chunks prepared: {len(texts)}\")\n",
        "    kb = pd.DataFrame(rows)\n",
        "\n",
        "    # --- Ingestion Reconciliation Report ---\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"[Stage1] Final Ingestion Reconciliation Report\")\n",
        "    print(\"-\"*50)\n",
        "    discovered_files = {os.path.basename(p) for p in docs}\n",
        "    indexed_files = set(kb['file'].unique()) if not kb.empty else set()\n",
        "    missing_files = discovered_files - indexed_files\n",
        "    print(f\"  - Documents Discovered: {len(discovered_files)}\")\n",
        "    print(f\"  - Documents Indexed:    {len(indexed_files)}\")\n",
        "    print(f\"  - Unindexed / Empty:    {len(missing_files)}\")\n",
        "    if missing_files:\n",
        "        print(\"\\n  [ATTENTION] The following files were NOT indexed (likely empty or parse failure):\")\n",
        "        for fname in sorted(list(missing_files)): print(f\"    - {fname}\")\n",
        "    else:\n",
        "        print(\"\\n  ✅ All discovered documents were successfully indexed.\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    # --- Per-File Period Tagging Verification ---\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"[Stage1] Per-File Period Tagging Verification Report\")\n",
        "    print(\"-\"*50)\n",
        "    if not kb.empty:\n",
        "        for fname in sorted(list(indexed_files)):\n",
        "            year_fn, quarter_fn = infer_period_from_filename(fname)\n",
        "            expected_str = f\"Y={year_fn or 'N/A'}, Q={quarter_fn or 'N/A'}\"\n",
        "            file_df = kb[kb['file'] == fname]\n",
        "            stored_periods = {(int(y) if pd.notna(y) else None, int(q) if pd.notna(q) else None)\n",
        "                              for y, q in file_df[['year', 'quarter']].drop_duplicates().to_numpy()}\n",
        "            stored_str = \"; \".join([f\"Y={p[0] or 'N/A'}, Q={p[1] or 'N/A'}\" for p in stored_periods])\n",
        "            status = \"\"\n",
        "            if len(stored_periods) > 1:\n",
        "                status = \"⚠️ INCONSISTENT (Multiple periods tagged for one file)\"\n",
        "            elif len(stored_periods) == 1:\n",
        "                y_s, q_s = list(stored_periods)[0]\n",
        "                if y_s == year_fn and q_s == quarter_fn: status = \"✅ OK\"\n",
        "                elif y_s == year_fn and quarter_fn is None and q_s is not None: status = \"✅ OK (ENHANCED)\"\n",
        "                else: status = \"⚠️ MISMATCH (Stored period conflicts with filename)\"\n",
        "            print(f\"📄 File: {fname}\\n   - Expected: {expected_str}\\n   - Stored:   {stored_str}\\n   - Status:   {status}\\n\" + \"-\"*25)\n",
        "    print(\"-\"*50 + \"\\n\")\n",
        "    \n",
        "    if kb.empty: raise SystemExit(\"No data was indexed. Halting before embedding.\")\n",
        "\n",
        "    provider, provider_name = pick_provider()\n",
        "    # The provider is now the all-mpnet-base-v2 model\n",
        "    print(f\"[Stage1] Embedding with model: {provider_name}\")\n",
        "    vecs = provider.encode(texts, normalize_embeddings=True).astype(np.float32)\n",
        "    dim = provider.get_sentence_embedding_dimension()\n",
        "    print(f\"[Stage1] Embedded {vecs.shape[0]} chunks (dim={dim})\")\n",
        "\n",
        "    if not _HAVE_FAISS: raise SystemExit(\"faiss not installed. pip install faiss-cpu\")\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(vecs)\n",
        "    print(f\"[Stage1] FAISS index size: {index.ntotal}\")\n",
        "\n",
        "    kb_path, text_path, index_path, meta_path = [os.path.join(OUT_DIR, f) for f in [\"kb_chunks.parquet\", \"kb_texts.npy\", \"kb_index.faiss\", \"kb_meta.json\"]]\n",
        "    kb.to_parquet(kb_path, engine='pyarrow', index=False)\n",
        "    np.save(text_path, np.array(texts, dtype=object))\n",
        "    faiss.write_index(index, index_path)\n",
        "    # Also update the meta file to reflect the new model if necessary\n",
        "    with open(meta_path, \"w\") as f: json.dump({\"embedding_provider\": f\"st:{provider_name}\", \"dim\": dim}, f)\n",
        "\n",
        "    print(f\"Saved KB: {len(kb)} rows → {kb_path}\")\n",
        "    return {\"kb\": kb_path, \"texts\": text_path, \"index\": index_path, \"meta\": meta_path}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    build_kb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1280f3ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage2] Initialized successfully from 'data'.\n",
            "🔬 Checking for: 'Net Interest Margin of 2.13%'\n",
            "\n",
            "--- Top 5 Retrieved Chunks ---\n",
            "\n",
            "[1] Source: 2Q25_CFO_presentation.pdf, Page: 6, Year: 2025\n",
            "-------------------------\n",
            "\n",
            "[2] Source: 3Q24_CFO_presentation.pdf, Page: 8, Year: 2024\n",
            "-------------------------\n",
            "\n",
            "[3] Source: 4Q24_CFO_presentation.pdf, Page: 6, Year: 2024\n",
            "-------------------------\n",
            "\n",
            "[4] Source: 2Q24_CFO_presentation.pdf, Page: 6, Year: 2024\n",
            "-------------------------\n",
            "\n",
            "[5] Source: 1Q24_CFO_presentation.pdf, Page: 5, Year: 2024\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "# sanity_check_s1.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "\n",
        "# --- Assume g2.py is in the same folder ---\n",
        "from g2 import init_stage2, hybrid_search \n",
        "\n",
        "# 1. Initialize your Stage 2 components to load the KB\n",
        "init_stage2(out_dir=\"data\")\n",
        "\n",
        "# 2. Define your \"Golden Fact\" as a query\n",
        "#    Be as specific as possible!\n",
        "query = \"Net Interest Margin of 2.13%\"\n",
        "\n",
        "print(f\"🔬 Checking for: '{query}'\")\n",
        "\n",
        "# 3. Run ONLY the retrieval function\n",
        "retrieved_chunks = hybrid_search(query, top_k=5)\n",
        "\n",
        "# 4. Print the results to inspect them\n",
        "print(\"\\n--- Top 5 Retrieved Chunks ---\")\n",
        "for i, chunk in enumerate(retrieved_chunks):\n",
        "    print(f\"\\n[{i+1}] Source: {chunk['file']}, Page: {chunk['page']}, Year: {chunk['year']}\")\n",
        "    print(\"-\" * 25)\n",
        "    # You'll need to load the texts array to see the content\n",
        "    # This part can be added to your script\n",
        "    # text_content = texts[kb[kb.doc_id == chunk['doc_id']].index[0]]\n",
        "    # print(text_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "425c04d4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 3734\n",
            "Missing year %: 0.0\n",
            "Missing quarter %: 0.7490626673808248\n",
            "Sample mismatches (file, page, stored_year, stored_q, expected_year, expected_q):\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, re\n",
        "\n",
        "df = pd.read_parquet(\"data/kb_chunks.parquet\")\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Missing year %:\", df['year'].isna().mean())\n",
        "print(\"Missing quarter %:\", df['quarter'].isna().mean())\n",
        "\n",
        "# Compare filename-derived expectation vs stored metadata\n",
        "qpat = re.compile(r\"\\b([1-4])Q(\\d{2})\\b\", re.I)\n",
        "def yq_from_name(fn):\n",
        "    m = qpat.search(fn.upper())\n",
        "    if m:\n",
        "        q = int(m.group(1)); yy = int(m.group(2)); y = 2000 + yy\n",
        "        return y, q\n",
        "    return None, None\n",
        "\n",
        "mismatch = []\n",
        "for i, r in df.iterrows():\n",
        "    y2, q2 = yq_from_name(str(r.file))\n",
        "    if q2 is not None:   # only check quartered docs\n",
        "        y_ok = (pd.isna(r.year) and y2 is None) or (not pd.isna(r.year) and int(r.year)==y2)\n",
        "        q_ok = (pd.isna(r.quarter) and q2 is None) or (not pd.isna(r.quarter) and int(r.quarter)==q2)\n",
        "        if not (y_ok and q_ok):\n",
        "            mismatch.append((r.file, r.page, r.year, r.quarter, y2, q2))\n",
        "            if len(mismatch) > 20: break\n",
        "\n",
        "print(\"Sample mismatches (file, page, stored_year, stored_q, expected_year, expected_q):\")\n",
        "for x in mismatch[:20]:\n",
        "    print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42229982",
      "metadata": {},
      "source": [
        "### Check Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1724c115",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] KB embedder = st:sentence-transformers/all-MiniLM-L12-v2\n",
            "[INFO] KB size = 3497 rows\n",
            "\n",
            "--- 🔍 AUDIT: Chunk Inspector for: 1Q24_CFO_presentation.pdf ---\n",
            "Found 23 chunks. Showing first 3:\n",
            "\n",
            "--- Chunk #1 | file=1Q24_CFO_presentation.pdf | page=1 | year=2024 | q=1.0 | section=None ---\n",
            "Disclaimer: The information contained in this document is intended only for use during the presentation and should not be disseminated or distributed to parties outside the presentation. \n",
            "DBS Bank accepts no liability whatsoever with respect to the use of this document or its contents.  \n",
            "DBS Group Holdings \n",
            "1Q 2024 financial results\n",
            "May 2, 2024\n",
            "Record quarterly income and earnings\n",
            "--------------------------------------------------------------------------------\n",
            "--- Chunk #2 | file=1Q24_CFO_presentation.pdf | page=2 | year=2024 | q=1.0 | section=None ---\n",
            "Highlights\n",
            "2\n",
            "First-quarter net profit at $2.96 billion with ROE at 19.4%, both at new highs\n",
            " Commercial book total income up 14% to $5.31 billion\n",
            "o NIM expands 8bp to 2.77% from higher interest rates\n",
            "o Net fee income crosses $1 billion for the first time\n",
            "o Treasury customer sales reaches a new record\n",
            " Markets trading income declines 9% due to higher funding cost\n",
            " Cost-income ratio at 37%\n",
            "First-quarter net profit up 24% QoQ\n",
            " Commercial book total income rises 9% QoQ as fee income and treasury customer sales reach new highs\n",
            " Commercial book net interest margin rises 2bp\n",
            " Markets trading in\n",
            "--------------------------------------------------------------------------------\n",
            "--- Chunk #3 | file=1Q24_CFO_presentation.pdf | page=3 | year=2024 | q=1.0 | section=None ---\n",
            "33\n",
            "negative\n",
            "positiveImpact on earnings:\n",
            "2,571\n",
            "1Q23 net \n",
            "profit\n",
            "263\n",
            "Net \n",
            "interest \n",
            "income\n",
            "192\n",
            "Fee \n",
            "income\n",
            "189 23\n",
            "Markets \n",
            "trading\n",
            "income\n",
            "197\n",
            "Expenses\n",
            "77\n",
            "GP\n",
            "51\n",
            "SP\n",
            "65\n",
            "Tax and \n",
            "others\n",
            "2,951\n",
            "1Q24 net \n",
            "profit\n",
            "(S$m) 1Q24 YoY %\n",
            "Total income 5,557\n",
            "Commercial book\n",
            "Markets trading\n",
            "Expenses 2,079\n",
            "Profit before allowances 3,478\n",
            "Allowances 135 (16)\n",
            "Net profit 2,956\n",
            "5,311\n",
            "246\n",
            "+8% +23% -9%+44% +10%\n",
            "1Q net profit up 15% YoY to new quarterly high\n",
            "Reported net profit 2,951\n",
            "13\n",
            "14\n",
            "(9)\n",
            "10\n",
            "14\n",
            "15\n",
            "15\n",
            "Treasury \n",
            "customer \n",
            "sales & \n",
            "other income\n",
            "(5)\n",
            "2,956\n",
            "Commercial book\n",
            "record\n",
            "record\n",
            "record\n",
            " Commercial book total income\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "--- 🎯 AUDIT: Retrieval Relevance Test ---\n",
            "\n",
            "=== 'net interest margin' ===\n",
            "[1] score=0.6937 | file=3Q24_CFO_presentation.pdf | p.8 | Y=2024 Q=3.0 | section=NIM table\n",
            "     8 **NET INTEREST MARGIN** (%) 2.14 2.14 2.11 2.77 2.83 2.83 3,647 3,769 3,796 -142 1Q24 -175 2Q24 -199 3Q24 3,505 3,594 3,597Net interest income (S$m) Group Commercial book 3Q commercial book net interest income up 1% QoQ, NIM stable at 2.83% 10,649 11,212 -441 9M23 -516 9M24 10,208 10,696 2.16 2.13 2.7\n",
            "[2] score=0.6937 | file=3Q24_CFO_presentation.pdf | p.8 | Y=2024 Q=3.0 | section=None\n",
            "     8 **NET INTEREST MARGIN** (%) 2.14 2.14 2.11 2.77 2.83 2.83 3,647 3,769 3,796 -142 1Q24 -175 2Q24 -199 3Q24 3,505 3,594 3,597Net interest  income (S$m) Group  Commercial book 3Q commercial book net interest income up 1% QoQ, NIM  stable at 2.83% 10,649 11,212 -441 9M23 -516 9M24 10,208 10,696 2.16 2.13 \n",
            "[3] score=0.6642 | file=2Q25_CFO_presentation.pdf | p.6 | Y=2025 Q=2.0 | section=NIM table\n",
            "     6 **NET INTEREST MARGIN** (%) 2.14 2.11 2.15 2.12 2.05 2.83 2.83 2.77 2.68 2.55 3,769 3,796 3,831 3,719 3,625 -175 2Q24 -199 3Q24 -103 4Q24 -38 1Q25 23 2Q25 3,594 3,597 3,728 3,681 3,648 Net interest income (S$m) Group Commercial book 2Q group net interest income higher YoY and little changed QoQ, lower\n",
            "\n",
            "=== 'operating expenses' ===\n",
            "[1] score=0.5917 | file=2Q24_CFO_presentation.pdf | p.11 | Y=2024 Q=2.0 | section=Opex table\n",
            "     1H cost-income ratio at 39% 11 Cost / income (%) Other expenses Staff expenses (S$m) 716 777 860 746 777 1,215 1,261 1,345 1,333 1,395 2Q23 3Q23 4Q23 1Q24 2Q24 1,931 2,038 2,205 2,079 2,172 38 39 44 37 40 1,383 1,523 2,430 2,728 1H23 1H24 3,813 4,251 38 39\n",
            "[2] score=0.5917 | file=2Q24_CFO_presentation.pdf | p.11 | Y=2024 Q=2.0 | section=None\n",
            "     1H cost-income ratio at 39% 11 Cost / income  (%) Other  expenses  Staff  expenses (S$m)  716 777 860 746 777 1,215 1,261 1,345 1,333 1,395 2Q23 3Q23 4Q23 1Q24 2Q24 1,931 2,038 2,205 2,079 2,172 38 39 44 37 40 1,383 1,523 2,430 2,728 1H23 1H24 3,813 4,251 38 39\n",
            "[3] score=0.5905 | file=dbs-annual-report-2023.pdf | p.15 | Y=2023 Q=nan | section=None\n",
            "      assets was at 128% and at 226% after  considering collateral. (E) Expenses Expenses rose 14% to SGD 8.06 billion  led by a 15% increase in staff costs to  SGD 5.04 billion. Excluding Citi Consumer  Taiwan and non-recurring technology and  other costs, expenses rose 10% and the  underlying cost-inco\n",
            "\n",
            "=== 'cost to income ratio' ===\n",
            "[1] score=0.6841 | file=4Q24_CFO_presentation.pdf | p.11 | Y=2024 Q=4.0 | section=Opex table\n",
            "     FY cost-income ratio unchanged at 40% 11 Cost / income (%) 746 777 827 951 1,333 1,395 1,422 1,444 1Q24 2Q24 3Q24 4Q24 2,079 2,172 2,249 2,395 37 40 39 44 3,020 3,301 5,036 5,594 FY23 FY24 8,056 8,895 40 40 Other expenses Staff expenses (S$m)\n",
            "[2] score=0.6841 | file=4Q24_CFO_presentation.pdf | p.11 | Y=2024 Q=4.0 | section=None\n",
            "     FY cost-income ratio unchanged at 40% 11 Cost / income (%) 746 777 827 951 1,333 1,395 1,422 1,444 1Q24 2Q24 3Q24 4Q24 2,079 2,172 2,249 2,395 37 40 39 44 3,020 3,301 5,036 5,594 FY23 FY24 8,056 8,895 40 40 Other  expenses  Staff  expenses (S$m)\n",
            "[3] score=0.6740 | file=3Q24_CFO_presentation.pdf | p.14 | Y=2024 Q=3.0 | section=Opex table\n",
            "     3Q and 9M cost-income ratio stable at 39% 14 Cost / income (%) 777 777 827 1,261 1,395 1,422 3Q23 2Q24 3Q24 2,038 2,172 2,249 39 40 39 2,160 2,350 3,691 4,150 9M23 9M24 5,851 6,500 39 39 Other expenses Staff expenses (S$m)\n"
          ]
        }
      ],
      "source": [
        "import os, re, json, faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Config ---\n",
        "OUT_DIR = \"data\"\n",
        "FILE_TO_INSPECT = r\"1Q24_CFO_presentation.pdf\" \n",
        "TEST_QUERIES = [\"net interest margin\", \"operating expenses\", \"cost to income ratio\"]\n",
        "NUM_CHUNKS_TO_SHOW = 3\n",
        "TOP_K = 3\n",
        "\n",
        "# --- Load KB ---\n",
        "kb_path   = os.path.join(OUT_DIR, \"kb_chunks.parquet\")\n",
        "texts_path= os.path.join(OUT_DIR, \"kb_texts.npy\")\n",
        "index_path= os.path.join(OUT_DIR, \"kb_index.faiss\")\n",
        "meta_path = os.path.join(OUT_DIR, \"kb_meta.json\")\n",
        "\n",
        "kb    = pd.read_parquet(kb_path)\n",
        "texts = np.load(texts_path, allow_pickle=True)\n",
        "index = faiss.read_index(index_path)\n",
        "\n",
        "with open(meta_path) as f:\n",
        "    meta = json.load(f)\n",
        "provider_str = meta.get(\"embedding_provider\", \"\")\n",
        "model_name = re.match(r\"^st:(.+)$\", provider_str).group(1) if provider_str.startswith(\"st:\") else \"sentence-transformers/all-MiniLM-L12-v2\"\n",
        "st = SentenceTransformer(model_name)\n",
        "\n",
        "print(f\"[INFO] KB embedder = {provider_str}\")\n",
        "print(f\"[INFO] KB size = {len(kb)} rows\\n\")\n",
        "\n",
        "# --- File Audit ---\n",
        "if FILE_TO_INSPECT.endswith(\".pdf\"):\n",
        "    mask = kb[\"file\"] == FILE_TO_INSPECT\n",
        "else:\n",
        "    mask = kb[\"file\"].str.contains(FILE_TO_INSPECT, flags=re.I, regex=True, na=False)\n",
        "\n",
        "indices = kb.index[mask]\n",
        "print(f\"--- 🔍 AUDIT: Chunk Inspector for: {FILE_TO_INSPECT} ---\")\n",
        "if indices.empty:\n",
        "    print(f\"[ERROR] No chunks found. Examples:\\n\", kb[\"file\"].value_counts().head(10))\n",
        "else:\n",
        "    print(f\"Found {len(indices)} chunks. Showing first {NUM_CHUNKS_TO_SHOW}:\\n\")\n",
        "    for i, ridx in enumerate(indices[:NUM_CHUNKS_TO_SHOW], start=1):\n",
        "        meta_row = kb.loc[ridx]\n",
        "        print(f\"--- Chunk #{i} | file={meta_row['file']} | page={meta_row['page']} | year={meta_row['year']} | q={meta_row['quarter']} | section={meta_row['section_hint']} ---\")\n",
        "        print(texts[ridx][:600])\n",
        "        print(\"-\"*80)\n",
        "\n",
        "# --- Retrieval Relevance Audit (with optional extension filter/boost) ---\n",
        "\n",
        "EXT_FILTER = None          # options: None, \"excel\", \"pdf\"\n",
        "PREFER_EXCEL = True        # small boost for .xls/.xlsx rows\n",
        "CANDIDATE_MULT = 15        # search deeper, then filter/re-rank\n",
        "\n",
        "ext_map = kb[\"file\"].str.lower().str.extract(r\"(\\.[a-z0-9]+)$\")[0]\n",
        "\n",
        "def is_excel(idx): \n",
        "    e = ext_map.iloc[idx]\n",
        "    return e in (\".xls\", \".xlsx\")\n",
        "\n",
        "def is_pdf(idx):\n",
        "    return ext_map.iloc[idx] == \".pdf\"\n",
        "\n",
        "print(\"\\n--- 🎯 AUDIT: Retrieval Relevance Test ---\")\n",
        "for query in TEST_QUERIES:\n",
        "    qv = st.encode([query], normalize_embeddings=True).astype(np.float32)\n",
        "    # deep search then filter\n",
        "    D, I = index.search(qv, TOP_K * CANDIDATE_MULT)\n",
        "    cand = [(int(idx), float(score)) for idx, score in zip(I[0], D[0]) if idx >= 0]\n",
        "\n",
        "    # optional filtering by extension\n",
        "    if EXT_FILTER == \"excel\":\n",
        "        cand = [(i,s) for (i,s) in cand if is_excel(i)]\n",
        "    elif EXT_FILTER == \"pdf\":\n",
        "        cand = [(i,s) for (i,s) in cand if is_pdf(i)]\n",
        "\n",
        "    # gentle Excel preference for ratio/YoY-ish asks\n",
        "    if PREFER_EXCEL and re.search(r\"\\byoy\\b|year[-\\s]?on[-\\s]?year|ratio|%|cti\", query, re.I):\n",
        "        cand = [(i, s + (0.08 if is_excel(i) else 0.0)) for (i,s) in cand]\n",
        "\n",
        "    # take top-K after filtering/boosting\n",
        "    cand = sorted(cand, key=lambda t: t[1], reverse=True)[:TOP_K]\n",
        "\n",
        "    print(f\"\\n=== '{query}' ===\")\n",
        "    for rank, (idx, score) in enumerate(cand, start=1):\n",
        "        meta_row = kb.iloc[idx]\n",
        "        snippet  = texts[idx][:300].replace(\"\\n\", \" \")\n",
        "        pat = re.compile(re.escape(query), re.I)\n",
        "        snippet = pat.sub(lambda m: f\"**{m.group(0).upper()}**\", snippet)\n",
        "\n",
        "        print(f\"[{rank}] score={score:.4f} | file={meta_row['file']} | p.{meta_row['page']} \"\n",
        "              f\"| Y={meta_row.get('year')} Q={meta_row.get('quarter')} | section={meta_row.get('section_hint')}\")\n",
        "        print(f\"     {snippet}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffb05fc",
      "metadata": {
        "id": "6ffb05fc"
      },
      "source": [
        "## 4. Baseline Pipeline\n",
        "\n",
        "**Baseline (starting point)**\n",
        "*   Naive chunking.\n",
        "*   Single-pass vector search.\n",
        "*   One LLM call, no caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "44e191db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage2] init → OUT_DIR=data\n",
            "[Stage2] KB embedding provider=st:sentence-transformers/all-MiniLM-L6-v2 dim=384\n",
            "[Stage2] KB rows=8125, texts=8125\n",
            "[Stage2] FAISS loaded=True\n",
            "[Stage2] BM25 enabled=True\n",
            "[Stage2] Query embedder ready: lazy-init\n",
            "[Stage2] Ready. Use answer_with_llm(query) to generate.\n"
          ]
        }
      ],
      "source": [
        "_Q_PAT_FN = re.compile(r\"([1-4])Q(\\d{2})\", re.I)\n",
        "\n",
        "def _infer_yq_from_filename(fname: str) -> tuple[Optional[int], Optional[int]]:\n",
        "    if not fname:\n",
        "        return (None, None)\n",
        "    s = str(fname).upper()\n",
        "    m = _Q_PAT_FN.search(s)\n",
        "    if m:\n",
        "        q = int(m.group(1)); yy = int(m.group(2)); y = 2000 + yy\n",
        "        return (y, q)\n",
        "    m = re.search(r\"(20\\d{2})\", s)\n",
        "    if m:\n",
        "        return (int(m.group(1)), None)\n",
        "    return (None, None)\n",
        "\"\"\"\n",
        "Stage2.py — Baseline Retrieval + Generation (RAG)\n",
        "\n",
        "Consumes Stage1 artifacts:\n",
        "  data/kb_chunks.parquet\n",
        "  data/kb_texts.npy\n",
        "  data/kb_index.faiss\n",
        "\n",
        "Retrieval:\n",
        "  - Hybrid (Vector + BM25 if available)\n",
        "  - Period-aware filter for phrases like \"last N years/quarters\"\n",
        "Generation:\n",
        "  - One LLM call (Gemini/OpenAI placeholder); returns answer + citations\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "import os, re, json, math\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Timing / logging (simple)\n",
        "import time, contextlib\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def timeblock(row: dict, key: str):\n",
        "    t0 = time.perf_counter()\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        row[key] = round((time.perf_counter() - t0) * 1000.0, 2)\n",
        "\n",
        "class _Instr:\n",
        "    def __init__(self):\n",
        "        self.rows = []\n",
        "    def log(self, row):\n",
        "        self.rows.append(row)\n",
        "    def df(self):\n",
        "        cols = ['Query','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','Tools']\n",
        "        df = pd.DataFrame(self.rows)\n",
        "        for c in cols:\n",
        "            if c not in df:\n",
        "                df[c] = None\n",
        "        return df[cols]\n",
        "\n",
        "instr = _Instr()\n",
        "\n",
        "\n",
        "VERBOSE = bool(int(os.environ.get(\"AGENT_CFO_VERBOSE\", \"1\")))  # default ON; set 0 to silence\n",
        "\n",
        "# --- Hardcoded LLM selection (instead of environment variables) ---\n",
        "LLM_BACKEND = \"gemini\"  # choose from \"gemini\" or \"openai\"\n",
        "GEMINI_MODEL_NAME = \"models/gemini-2.5-flash\"\n",
        "OPENAI_MODEL_NAME = \"gpt-4o-mini\"\n",
        "\n",
        "# --- Query-aware preferences and numeric helpers ---\n",
        "# Query-aware preferences\n",
        "QUERY_HINTS = {\n",
        "    \"nim\": {\n",
        "        \"must_any\": [r\"\\bnim\\b\", r\"net\\s+interest\\s+margin\"],\n",
        "        \"prefer_sections\": [\"Net interest margin (NIM)\", \"NIM table\", \"highlights/summary\"],\n",
        "    },\n",
        "    \"opex\": {\n",
        "        \"must_any\": [r\"operating\\s+expenses\", r\"\\bopex\\b\"],\n",
        "        \"prefer_sections\": [\"Operating expenses (Opex)\", \"Income statement\", \"MD&A\"],\n",
        "    },\n",
        "    \"cti\": {\n",
        "        \"must_any\": [r\"cost[- ]?to[- ]?income\", r\"\\bcti\\b\", r\"efficiency\\s+ratio\"],\n",
        "        \"prefer_sections\": [\"Cost-to-income (CTI)\", \"Income statement\", \"highlights/summary\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "_HAS_NUMBER = re.compile(r\"\\d[\\d,\\.]*\")\n",
        "def _numeric_score(s: str) -> float:\n",
        "    # reward blocks with several numbers (likely tables)\n",
        "    if not s:\n",
        "        return 0.0\n",
        "    n = len(_HAS_NUMBER.findall(s))\n",
        "    return min(0.35, 0.05 * max(0, n-1))  # up to +0.35\n",
        "\n",
        "# --- Retrieval toggles ---\n",
        "USE_VECTOR = True   # set False to force BM25-only retrieval\n",
        "# --- Helper: classify query type for hints ---\n",
        "def _classify_query(q: str) -> Optional[str]:\n",
        "    ql = q.lower()\n",
        "    if \"nim\" in ql or \"net interest margin\" in ql:\n",
        "        return \"nim\"\n",
        "    if \"opex\" in ql or \"operating expense\" in ql:\n",
        "        return \"opex\"\n",
        "    if \"cti\" in ql or \"cost-to-income\" in ql or \"efficiency ratio\" in ql:\n",
        "        return \"cti\"\n",
        "    return None\n",
        "\n",
        "# --- Lazy, notebook-friendly globals (set by init_stage2) ---\n",
        "OUT_DIR = None\n",
        "KB_PARQUET = None\n",
        "KB_TEXTS = None\n",
        "KB_INDEX = None\n",
        "KB_META = None\n",
        "\n",
        "kb: Optional[pd.DataFrame] = None\n",
        "texts: Optional[np.ndarray] = None\n",
        "index = None\n",
        "bm25 = None\n",
        "_HAVE_FAISS = False\n",
        "_HAVE_BM25 = False\n",
        "_INITIALIZED = False\n",
        "\n",
        "class _EmbedLoader:\n",
        "    def __init__(self):\n",
        "        self.impl = None\n",
        "        self.dim = None\n",
        "        self.name = None\n",
        "        if KB_META and os.path.exists(KB_META):\n",
        "            with open(KB_META) as f:\n",
        "                meta = json.load(f)\n",
        "                self.name = meta.get(\"embedding_provider\")\n",
        "                self.dim = meta.get(\"dim\")\n",
        "    def embed(self, texts: List[str]) -> np.ndarray:\n",
        "        if self.impl is None:\n",
        "            preferred = (self.name or '').lower()\n",
        "            # 1) If KB was built with Sentence-Transformers\n",
        "            if 'sentence-transformers' in preferred or preferred.startswith('st'):\n",
        "                from sentence_transformers import SentenceTransformer\n",
        "                model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "                st = SentenceTransformer(model)\n",
        "                self.impl = (\"st\", model)\n",
        "                self.dim = st.get_sentence_embedding_dimension()\n",
        "                def _fn(batch):\n",
        "                    vecs = st.encode(batch, batch_size=64, show_progress_bar=False, convert_to_numpy=True, normalize_embeddings=True)\n",
        "                    return vecs.astype(np.float32)\n",
        "                self.fn = _fn\n",
        "            # 2) If KB was built with OpenAI\n",
        "            elif preferred.startswith('openai'):\n",
        "                from openai import OpenAI\n",
        "                if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "                    raise RuntimeError(\"KB was built with OpenAI embeddings but OPENAI_API_KEY is not set.\")\n",
        "                self.client = OpenAI()\n",
        "                model = \"text-embedding-3-small\"\n",
        "                self.impl = (\"openai\", model)\n",
        "                self.dim = 1536\n",
        "                def _fn(batch):\n",
        "                    resp = self.client.embeddings.create(model=model, input=batch)\n",
        "                    vecs = [d.embedding for d in resp.data]\n",
        "                    return np.asarray(vecs, dtype=np.float32)\n",
        "                self.fn = _fn\n",
        "            # 3) If KB was built with Gemini\n",
        "            elif preferred.startswith('gemini'):\n",
        "                try:\n",
        "                    from google import generativeai as genai\n",
        "                except Exception as e:\n",
        "                    raise RuntimeError(\"KB was built with Gemini embeddings but google-generativeai is not installed. `pip install google-generativeai`.\") from e\n",
        "                if not os.environ.get(\"GEMINI_API_KEY\"):\n",
        "                    raise RuntimeError(\"KB was built with Gemini embeddings but GEMINI_API_KEY is not set.\")\n",
        "                genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "                self.impl = (\"gemini\", \"models/embedding-001\")\n",
        "                self.dim = 768 if (self.dim is None) else self.dim\n",
        "                def _fn(batch):\n",
        "                    vecs = []\n",
        "                    for t in batch:\n",
        "                        resp = genai.embed_content(model='models/embedding-001', content=t)\n",
        "                        emb = resp.get('embedding') if isinstance(resp, dict) else getattr(resp, 'embedding', None)\n",
        "                        if emb is None:\n",
        "                            raise RuntimeError('Gemini embed_content returned no embedding')\n",
        "                        vecs.append(emb)\n",
        "                    return np.asarray(vecs, dtype=np.float32)\n",
        "                self.fn = _fn\n",
        "            # 4) Fallback auto-detect (prefer ST so it works offline)\n",
        "            else:\n",
        "                if os.environ.get(\"OPENAI_API_KEY\"):\n",
        "                    from openai import OpenAI\n",
        "                    self.client = OpenAI()\n",
        "                    model = \"text-embedding-3-small\"\n",
        "                    self.impl = (\"openai\", model)\n",
        "                    self.dim = 1536\n",
        "                    def _fn(batch):\n",
        "                        resp = self.client.embeddings.create(model=model, input=batch)\n",
        "                        vecs = [d.embedding for d in resp.data]\n",
        "                        return np.asarray(vecs, dtype=np.float32)\n",
        "                    self.fn = _fn\n",
        "                elif os.environ.get(\"GEMINI_API_KEY\"):\n",
        "                    from google import generativeai as genai\n",
        "                    genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "                    self.impl = (\"gemini\", \"models/embedding-001\")\n",
        "                    self.dim = 768 if (self.dim is None) else self.dim\n",
        "                    def _fn(batch):\n",
        "                        vecs = []\n",
        "                        for t in batch:\n",
        "                            resp = genai.embed_content(model='models/embedding-001', content=t)\n",
        "                            emb = resp.get('embedding') if isinstance(resp, dict) else getattr(resp, 'embedding', None)\n",
        "                            if emb is None:\n",
        "                                raise RuntimeError('Gemini embed_content returned no embedding')\n",
        "                            vecs.append(emb)\n",
        "                        return np.asarray(vecs, dtype=np.float32)\n",
        "                    self.fn = _fn\n",
        "                else:\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "                    st = SentenceTransformer(model)\n",
        "                    self.impl = (\"st\", model)\n",
        "                    self.dim = st.get_sentence_embedding_dimension()\n",
        "                    def _fn(batch):\n",
        "                        vecs = st.encode(batch, batch_size=64, show_progress_bar=False, convert_to_numpy=True, normalize_embeddings=True)\n",
        "                        return vecs.astype(np.float32)\n",
        "                    self.fn = _fn\n",
        "        return self.fn(texts)\n",
        "\n",
        "EMB = None  # will be initialized inside init_stage2() after KB_META is known\n",
        "\n",
        "def init_stage2(out_dir: str = \"data\") -> None:\n",
        "    \"\"\"Initialize Stage 2 in a Jupyter-friendly way.\n",
        "    Loads KB artifacts, FAISS, and BM25. Call this once per notebook kernel.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    global OUT_DIR, KB_PARQUET, KB_TEXTS, KB_INDEX, KB_META\n",
        "    global kb, texts, index, bm25, _HAVE_FAISS, _HAVE_BM25, _INITIALIZED\n",
        "\n",
        "    OUT_DIR = out_dir\n",
        "    KB_PARQUET = os.path.join(OUT_DIR, \"kb_chunks.parquet\")\n",
        "    KB_TEXTS   = os.path.join(OUT_DIR, \"kb_texts.npy\")\n",
        "    KB_INDEX   = os.path.join(OUT_DIR, \"kb_index.faiss\")\n",
        "    KB_META    = os.path.join(OUT_DIR, \"kb_meta.json\")\n",
        "\n",
        "    if VERBOSE:\n",
        "        print(f\"[Stage2] init → OUT_DIR={OUT_DIR}\")\n",
        "\n",
        "    if not (os.path.exists(KB_PARQUET) and os.path.exists(KB_TEXTS) and os.path.exists(KB_INDEX)):\n",
        "        raise RuntimeError(f\"KB artifacts not found under '{OUT_DIR}'. Run Stage1.build_kb() first.\")\n",
        "\n",
        "    # Load KB tables\n",
        "    kb = _load_kb_table(KB_PARQUET)\n",
        "    texts = np.load(KB_TEXTS, allow_pickle=True)\n",
        "\n",
        "    # (Optional but helpful) Print embedding provider from KB meta if available\n",
        "    if KB_META and os.path.exists(KB_META):\n",
        "        try:\n",
        "            meta = json.load(open(KB_META))\n",
        "            if VERBOSE:\n",
        "                print(f\"[Stage2] KB embedding provider={meta.get('embedding_provider')} dim={meta.get('dim')}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    if VERBOSE:\n",
        "        print(f\"[Stage2] KB rows={len(kb)}, texts={len(texts)}\")\n",
        "\n",
        "    # FAISS\n",
        "    try:\n",
        "        import faiss  # type: ignore\n",
        "        _HAVE_FAISS = True\n",
        "        idx = faiss.read_index(KB_INDEX)\n",
        "    except Exception as e:\n",
        "        _HAVE_FAISS = False\n",
        "        idx = None\n",
        "    globals()['index'] = idx\n",
        "\n",
        "    if VERBOSE:\n",
        "        print(f\"[Stage2] FAISS loaded={bool(idx)}\")\n",
        "\n",
        "    # BM25 (optional)\n",
        "    try:\n",
        "        from rank_bm25 import BM25Okapi\n",
        "        tokenized = [str(t).lower().split() for t in texts]\n",
        "        bm25 = BM25Okapi(tokenized)\n",
        "        _HAVE_BM25 = True\n",
        "    except Exception:\n",
        "        bm25 = None\n",
        "        _HAVE_BM25 = False\n",
        "    globals()['bm25'] = bm25\n",
        "\n",
        "    if VERBOSE:\n",
        "        print(f\"[Stage2] BM25 enabled={_HAVE_BM25}\")\n",
        "\n",
        "    # Initialize query embedder **after** KB_META is known so it matches the store\n",
        "    globals()['EMB'] = _EmbedLoader()\n",
        "    if VERBOSE:\n",
        "        try:\n",
        "            impl = getattr(EMB, 'impl', None)\n",
        "            print(f\"[Stage2] Query embedder ready: {impl if impl else 'lazy-init'}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Mark initialized\n",
        "    _INITIALIZED = True\n",
        "\n",
        "def _ensure_init():\n",
        "    if not globals().get('_INITIALIZED', False):\n",
        "        raise RuntimeError(\"Stage2 is not initialized. Call init_stage2(out_dir='data') first in your notebook.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Robust KB loader (parquet → fastparquet → csv)\n",
        "# -----------------------------\n",
        "\n",
        "def _load_kb_table(parquet_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load the KB table with fallbacks.\n",
        "    1) pandas.read_parquet (default engine)\n",
        "    2) pandas.read_parquet(engine='fastparquet')\n",
        "    3) CSV fallback at same basename (kb_chunks.csv)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return pd.read_parquet(parquet_path)\n",
        "    except Exception as e1:\n",
        "        try:\n",
        "            return pd.read_parquet(parquet_path, engine='fastparquet')\n",
        "        except Exception as e2:\n",
        "            csv_path = os.path.splitext(parquet_path)[0] + '.csv'\n",
        "            if os.path.exists(csv_path):\n",
        "                df = pd.read_csv(csv_path)\n",
        "                # Ensure required columns exist\n",
        "                for c in ['doc_id','file','page','year','quarter','section_hint']:\n",
        "                    if c not in df.columns:\n",
        "                        df[c] = np.nan\n",
        "                # Coerce numeric cols\n",
        "                if 'page' in df: df['page'] = pd.to_numeric(df['page'], errors='coerce').fillna(0).astype(int)\n",
        "                if 'year' in df: df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "                if 'quarter' in df: df['quarter'] = pd.to_numeric(df['quarter'], errors='coerce')\n",
        "                return df\n",
        "            raise RuntimeError(\n",
        "                \"Failed to read KB Parquet with both engines and no CSV fallback. \"\n",
        "                f\"Errors: pyarrow={e1} | fastparquet={e2}\"\n",
        "            )\n",
        "\n",
        "# -----------------------------\n",
        "# Helper: period filters\n",
        "# -----------------------------\n",
        "\n",
        "def _detect_last_n_years(q: str) -> Optional[int]:\n",
        "    ql = q.lower()\n",
        "    for pat in [\"last three years\", \"last 3 years\", \"past three years\", \"past 3 years\"]:\n",
        "        if pat in ql:\n",
        "            return 3\n",
        "    return None\n",
        "\n",
        "def _detect_last_n_quarters(q: str) -> Optional[int]:\n",
        "    ql = q.lower()\n",
        "    for pat in [\"last five quarters\", \"last 5 quarters\", \"past five quarters\", \"past 5 quarters\"]:\n",
        "        if pat in ql:\n",
        "            return 5\n",
        "    return None\n",
        "\n",
        "\n",
        "def _period_filter(hits: List[Dict[str, Any]], want_years: Optional[int], want_quarters: Optional[int]) -> List[Dict[str, Any]]:\n",
        "    if not hits:\n",
        "        return hits\n",
        "    df = pd.DataFrame(hits)\n",
        "    if want_quarters:\n",
        "        df = df.sort_values([\"year\", \"quarter\"], ascending=[False, False])\n",
        "        df = df[df[\"quarter\"].notna()]\n",
        "        seen = set(); keep_idx = []\n",
        "        for i, r in df.iterrows():\n",
        "            key = (int(r.year), int(r.quarter))\n",
        "            if key in seen: continue\n",
        "            keep_idx.append(i); seen.add(key)\n",
        "            if len(keep_idx) >= want_quarters: break\n",
        "        if VERBOSE:\n",
        "            print(f\"[Stage2] period filter (quarters) → kept={[(int(hits[i]['year']), int(hits[i]['quarter'])) for i in keep_idx]}\")\n",
        "        return [hits[i] for i in keep_idx] if keep_idx else hits\n",
        "    if want_years:\n",
        "        df = df.sort_values([\"year\"], ascending=[False])\n",
        "        df = df[df[\"year\"].notna()]\n",
        "        seen = set(); keep_idx = []\n",
        "        for i, r in df.iterrows():\n",
        "            y = int(r.year)\n",
        "            if y in seen: continue\n",
        "            keep_idx.append(i); seen.add(y)\n",
        "            if len(keep_idx) >= want_years: break\n",
        "        if VERBOSE:\n",
        "            print(f\"[Stage2] period filter (years) → kept={[(int(hits[i]['year'])) for i in keep_idx]}\")\n",
        "        return [hits[i] for i in keep_idx] if keep_idx else hits\n",
        "    return hits\n",
        "\n",
        "# -----------------------------\n",
        "# Hybrid retrieval\n",
        "# -----------------------------\n",
        "\n",
        "def hybrid_search(query: str, top_k=12, alpha=0.6) -> List[Dict[str, Any]]:\n",
        "    _ensure_init()\n",
        "    \"\"\"Return list of hit dicts with metadata.\n",
        "    alpha weights vector vs BM25: score = alpha*vec + (1-alpha)*bm25\n",
        "    \"\"\"\n",
        "    row = {\"Query\": query, \"Tools\": [\"retriever\"]}\n",
        "    with timeblock(row, \"T_total\"):\n",
        "        with timeblock(row, \"T_retrieve\"):\n",
        "            vec_scores = None\n",
        "            if USE_VECTOR and _HAVE_FAISS and index is not None and EMB is not None:\n",
        "                try:\n",
        "                    qv = EMB.embed([query])\n",
        "                    # Validate dimensionality against KB meta if available\n",
        "                    try:\n",
        "                        meta_dim = int(EMB.dim) if EMB.dim is not None else None\n",
        "                    except Exception:\n",
        "                        meta_dim = None\n",
        "                    if meta_dim is not None and qv.shape[1] != meta_dim:\n",
        "                        raise RuntimeError(f\"Embedding dimension mismatch: query={qv.shape[1]} vs KB={meta_dim}. Rebuild Stage1 with the same provider or align Stage2 to use the same embedding backend.\")\n",
        "                    qv = qv / (np.linalg.norm(qv, axis=1, keepdims=True) + 1e-12)\n",
        "                    sims, ids = index.search(qv.astype(np.float32), top_k)\n",
        "                    vec_scores = {int(ix): float(s) for ix, s in zip(ids[0], sims[0]) if ix != -1}\n",
        "                except Exception as e:\n",
        "                    if VERBOSE:\n",
        "                        print(f\"[Stage2] Vector search disabled for this query → {type(e).__name__}: {e}\")\n",
        "                    vec_scores = None  # continue with BM25-only\n",
        "            bm25_scores = None\n",
        "            if _HAVE_BM25 and bm25 is not None:\n",
        "                qtype = _classify_query(query)\n",
        "                q_terms = query.lower().split()\n",
        "                if qtype == \"opex\":\n",
        "                    q_terms += [\"operating\", \"expenses\", \"opex\", \"income\", \"statement\"]\n",
        "                elif qtype == \"cti\":\n",
        "                    q_terms += [\"cost\", \"income\", \"ratio\", \"efficiency\", \"cti\"]\n",
        "                elif qtype == \"nim\":\n",
        "                    q_terms += [\"nim\", \"net\", \"interest\", \"margin\"]\n",
        "                scores = bm25.get_scores(q_terms)\n",
        "                top_idx = np.argsort(scores)[-top_k:][::-1]\n",
        "                bm25_scores = {int(i): float(scores[i]) for i in top_idx}\n",
        "        with timeblock(row, \"T_rerank\"):\n",
        "            fused = {}\n",
        "            if vec_scores:\n",
        "                for i,s in vec_scores.items():\n",
        "                    fused[i] = fused.get(i, 0.0) + alpha*s\n",
        "            if bm25_scores:\n",
        "                m = max(bm25_scores.values()) or 1.0\n",
        "                for i,s in bm25_scores.items():\n",
        "                    fused[i] = fused.get(i, 0.0) + (1-alpha)*(s/m)\n",
        "            if not fused:\n",
        "                hits = []\n",
        "            else:\n",
        "                # preliminary top list\n",
        "                prelim = sorted(fused.items(), key=lambda x: x[1], reverse=True)[:top_k*2]\n",
        "                qtype = _classify_query(query)\n",
        "                hits = []\n",
        "\n",
        "             # --- NEW: Recency & Relevance Boosting Logic ---\n",
        "                # Check if the query is time-sensitive\n",
        "                want_years = _detect_last_n_years(query)\n",
        "                want_quarters = _detect_last_n_quarters(query)\n",
        "\n",
        "                # Determine the baseline year for recency calculation\n",
        "                latest_year = kb['year'].max()\n",
        "                if want_years:\n",
        "                    # For fiscal year queries, the most relevant documents are ANNUAL reports.\n",
        "                    # Set the baseline to the latest year for which an annual report exists.\n",
        "                    annual_reports = kb[kb['quarter'].isna()]\n",
        "                    if not annual_reports.empty:\n",
        "                        latest_year = annual_reports['year'].max()\n",
        "\n",
        "                for i, base in prelim:\n",
        "                    meta = kb.iloc[i]\n",
        "                    boost = 0.0\n",
        "                    \n",
        "                    # 1. Existing Section & Numeric Boosts\n",
        "                    if qtype and isinstance(meta.section_hint, str):\n",
        "                        prefs = QUERY_HINTS[qtype][\"prefer_sections\"]\n",
        "                        if meta.section_hint in prefs:\n",
        "                            boost += 0.25\n",
        "                    preview = str(texts[i])[:800]\n",
        "                    boost += _numeric_score(preview)\n",
        "\n",
        "                    # 2. NEW Recency Boost (for time-sensitive queries)\n",
        "                    if (want_years or want_quarters) and not pd.isna(meta.year):\n",
        "                        year_diff = latest_year - meta.year\n",
        "                        if year_diff == 0:\n",
        "                            boost += 0.8  # Strongest boost for the latest year\n",
        "                        elif year_diff <= 2:\n",
        "                            boost += 0.5  # Medium boost for the last 2-3 years\n",
        "                        elif year_diff <= 4:\n",
        "                            boost += 0.2  # Small boost for older but recent docs\n",
        "                    \n",
        "                    # 3. NEW Report Type Boost\n",
        "                    is_annual_report = pd.isna(meta.quarter)\n",
        "                    if want_years and is_annual_report:\n",
        "                        boost += 0.3 # Boost annual reports for yearly queries\n",
        "                    if want_quarters and not is_annual_report:\n",
        "                        boost += 0.3 # Boost quarterly reports for quarterly queries\n",
        "                        \n",
        "                    fused[i] = base + boost\n",
        "                \n",
        "                top = sorted(prelim, key=lambda x: fused[x[0]], reverse=True)[:top_k]\n",
        "                for i,score in top:\n",
        "                    meta = kb.iloc[i]\n",
        "                    y = int(meta.year) if not pd.isna(meta.year) else None\n",
        "                    q = int(meta.quarter) if not pd.isna(meta.quarter) else None\n",
        "                    if (y is None) or (q is None):\n",
        "                        y2, q2 = _infer_yq_from_filename(meta.file)\n",
        "                        if y is None:\n",
        "                            y = y2\n",
        "                        if q is None:\n",
        "                            q = q2\n",
        "                    hits.append({\n",
        "                        \"doc_id\": meta.doc_id,\n",
        "                        \"file\": meta.file,\n",
        "                        \"page\": int(meta.page),\n",
        "                        \"year\": y,\n",
        "                        \"quarter\": q,\n",
        "                        \"section_hint\": meta.section_hint if isinstance(meta.section_hint, str) else None,\n",
        "                        \"preview\": str(texts[i])[:800],\n",
        "                        \"score\": float(score),\n",
        "                    })\n",
        "    instr.log(row)\n",
        "    if VERBOSE:\n",
        "        kept = [(h.get('year'), h.get('quarter'), h.get('file')) for h in hits[:5]]\n",
        "        print(f\"[Stage2] retrieved top={len(hits)} sample={kept}\")\n",
        "    return hits\n",
        "\n",
        "\n",
        "def format_citation(hit: dict) -> str:\n",
        "    parts = [hit.get(\"file\",\"?\")]\n",
        "    if hit.get(\"year\"):\n",
        "        if hit.get(\"quarter\"):\n",
        "            parts.append(f\"{hit['quarter']}Q{str(hit['year'])[2:]}\")\n",
        "        else:\n",
        "            parts.append(str(hit[\"year\"]))\n",
        "    parts.append(f\"p.{hit.get('page','?')}\")\n",
        "    sec = hit.get(\"section_hint\")\n",
        "    if sec:\n",
        "        parts.append(sec)\n",
        "    return \" — \".join(parts)\n",
        "\n",
        "\n",
        "def _context_from_hits(hits: List[Dict[str,Any]], top_ctx=3, max_chars=1200) -> str:\n",
        "    _ensure_init()\n",
        "    blocks = []\n",
        "    for h in hits[:top_ctx]:\n",
        "        text = str(texts[kb.index[kb.doc_id == h[\"doc_id\"]][0]]) if (kb.doc_id == h[\"doc_id\"]).any() else h.get(\"preview\",\"\")\n",
        "        if len(text) > max_chars:\n",
        "            text = text[:max_chars] + \" ...\"\n",
        "        blocks.append(f\"[{format_citation(h)}]\\n{text}\")\n",
        "    return \"\\n\\n\".join(blocks)\n",
        "\n",
        "# -----------------------------\n",
        "# LLM call helper\n",
        "# -----------------------------\n",
        "\n",
        "def _call_llm(prompt: str) -> str:\n",
        "    backend = LLM_BACKEND.lower()\n",
        "    if backend == \"gemini\":\n",
        "        try:\n",
        "            from google import generativeai as genai\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\"Selected backend 'gemini' but google-generativeai is not installed. `pip install google-generativeai`.\") from e\n",
        "        api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "        if not api_key:\n",
        "            raise RuntimeError(\"Selected backend 'gemini' but GEMINI_API_KEY is not set.\")\n",
        "        model_name = GEMINI_MODEL_NAME\n",
        "        try:\n",
        "            genai.configure(api_key=api_key)\n",
        "            model = genai.GenerativeModel(model_name)\n",
        "            resp = model.generate_content(prompt)\n",
        "            text = getattr(resp, 'text', None) if resp is not None else None\n",
        "            if not text:\n",
        "                text = str(resp)\n",
        "            if VERBOSE:\n",
        "                print(f\"[Stage2] LLM=Gemini ({model_name})\")\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Gemini generation failed: {e}\") from e\n",
        "    elif backend == \"openai\":\n",
        "        try:\n",
        "            from openai import OpenAI\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\"Selected backend 'openai' but the OpenAI SDK is not installed. `pip install openai`.\") from e\n",
        "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "        if not api_key:\n",
        "            raise RuntimeError(\"Selected backend 'openai' but OPENAI_API_KEY is not set.\")\n",
        "        try:\n",
        "            client = OpenAI()\n",
        "            model = OPENAI_MODEL_NAME\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\":\"system\",\"content\":\"You are Agent CFO.\"},{\"role\":\"user\",\"content\": prompt}],\n",
        "                temperature=0.2,\n",
        "            )\n",
        "            text = resp.choices[0].message.content\n",
        "            if VERBOSE:\n",
        "                print(f\"[Stage2] LLM=OpenAI ({model})\")\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"OpenAI generation failed: {e}\") from e\n",
        "    else:\n",
        "        raise RuntimeError(\"Invalid LLM_BACKEND setting; choose 'gemini' or 'openai'.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Generation (one call)\n",
        "# -----------------------------\n",
        "\n",
        "def answer_with_llm(query: str, top_k_retrieval=12, top_ctx=3) -> Dict[str, Any]:\n",
        "    _ensure_init()\n",
        "    want_years = _detect_last_n_years(query)\n",
        "    want_quarters = _detect_last_n_quarters(query)\n",
        "\n",
        "    qtype = _classify_query(query)\n",
        "    if qtype in (\"opex\", \"cti\") and top_ctx < 5:\n",
        "        top_ctx = 5\n",
        "\n",
        "    hits = hybrid_search(query, top_k=top_k_retrieval, alpha=0.6)\n",
        "    hits = _period_filter(hits, want_years, want_quarters)\n",
        "\n",
        "    context = _context_from_hits(hits, top_ctx=top_ctx)\n",
        "\n",
        "    system_task = (\n",
        "        \"You are Agent CFO. Answer the user's finance/operations question using ONLY the provided context. \"\n",
        "        \"When you state any figures, also provide citations in the format: \"\n",
        "        \"[Report, Year/Quarter, p.X, Section/Table]. Keep the answer concise and factual.\"\n",
        "    )\n",
        "    user_prompt = (\n",
        "        f\"Question:\\n{query}\\n\\n\"\n",
        "        f\"Context passages (use for citations):\\n{context}\\n\\n\"\n",
        "        \"Instructions:\\n\"\n",
        "        \"1) If a value cannot be supported by the context, say so.\\n\"\n",
        "        \"2) Include citations inline like: (DBS 3Q24 CFO Presentation — p.14 — Cost/Income table).\\n\"\n",
        "        \"3) End with a short one-line takeaway.\"\n",
        "    )\n",
        "    prompt = f\"{system_task}\\n\\n{user_prompt}\"\n",
        "\n",
        "    row = {\"Query\": f\"[generate] {query}\", \"Tools\": [\"retriever\",\"generator\"], \"Tokens\": 0}\n",
        "\n",
        "    # Placeholder for your LLM call; swap in Gemini/OpenAI\n",
        "    with timeblock(row, \"T_total\"), timeblock(row, \"T_generate\"):\n",
        "        text = _call_llm(prompt)\n",
        "        row[\"Tokens\"] = int(len(prompt)//4)\n",
        "\n",
        "    instr.log(row)\n",
        "\n",
        "    explicit_citations = \"\\n\".join(f\"- {format_citation(h)}\" for h in hits[:top_ctx])\n",
        "    final_answer = text.strip() + \"\\n\\nCitations:\\n\" + explicit_citations\n",
        "\n",
        "    return {\"answer\": final_answer, \"hits\": hits[:top_ctx], \"raw_model_text\": text}\n",
        "\n",
        "def get_logs() -> pd.DataFrame:\n",
        "    \"\"\"Return the instrumentation DataFrame for display in notebooks.\"\"\"\n",
        "    return instr.df()\n",
        "\n",
        "def is_initialized() -> bool:\n",
        "    return bool(globals().get('_INITIALIZED', False))\n",
        "\n",
        "# Benchmark queries as required\n",
        "BENCHMARK_QUERIES = [\n",
        "    \"Report the Gross Margin (or Net Interest Margin, if a bank) over the last 5 quarters, with values.\",\n",
        "    \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
        "    \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\",\n",
        "]\n",
        "\n",
        "\n",
        "def run_benchmark(top_k_retrieval=12, top_ctx=3) -> List[Dict[str, Any]]:\n",
        "    out = []\n",
        "    for q in BENCHMARK_QUERIES:\n",
        "        out.append({\"query\": q, **answer_with_llm(q, top_k_retrieval=top_k_retrieval, top_ctx=top_ctx)})\n",
        "    return out\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    od = os.environ.get(\"AGENT_CFO_OUT_DIR\", \"data\")\n",
        "    init_stage2(od)\n",
        "    if VERBOSE:\n",
        "        print(\"[Stage2] Ready. Use answer_with_llm(query) to generate.\")\n",
        "    if os.environ.get(\"RUN_DEMO\", \"0\") == \"1\":\n",
        "        for r in run_benchmark():\n",
        "            print(\"\\nQ:\", r[\"query\"], \"\\n\")\n",
        "            print(r[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e8dff02",
      "metadata": {},
      "source": [
        "### Gemini Version 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b25c04ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage2] Initialized successfully from 'data'.\n",
            "[Stage2] Ready. Use answer_with_llm() or answer_with_agent().\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Stage2.py — Baseline Retrieval + Generation (RAG) & Agentic Reasoning\n",
        "\n",
        "Consumes Stage1 artifacts. Provides two main functions:\n",
        "1. answer_with_llm: A simple, single-call RAG pipeline.\n",
        "2. answer_with_agent: An advanced, multi-step agentic pipeline with tool use.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "import os, re, json, math, traceback\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Timing / logging (simple)\n",
        "import time, contextlib\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def timeblock(row: dict, key: str):\n",
        "    t0 = time.perf_counter()\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        row[key] = round((time.perf_counter() - t0) * 1000.0, 2)\n",
        "\n",
        "class _Instr:\n",
        "    def __init__(self):\n",
        "        self.rows = []\n",
        "    def log(self, row):\n",
        "        self.rows.append(row)\n",
        "    def df(self):\n",
        "        cols = ['Query','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','Tools']\n",
        "        df = pd.DataFrame(self.rows)\n",
        "        for c in cols:\n",
        "            if c not in df:\n",
        "                df[c] = None\n",
        "        return df[cols]\n",
        "\n",
        "instr = _Instr()\n",
        "\n",
        "\n",
        "VERBOSE = bool(int(os.environ.get(\"AGENT_CFO_VERBOSE\", \"1\")))\n",
        "\n",
        "# --- Hardcoded LLM selection (instead of environment variables) ---\n",
        "LLM_BACKEND = \"gemini\"\n",
        "GEMINI_MODEL_NAME = \"models/gemini-2.5-flash\"\n",
        "OPENAI_MODEL_NAME = \"gpt-4o-mini\"\n",
        "\n",
        "# --- Query-aware preferences and numeric helpers ---\n",
        "QUERY_HINTS = {\n",
        "    \"nim\": { \"prefer_sections\": [\"Net interest margin (NIM)\", \"NIM table\", \"highlights/summary\"]},\n",
        "    \"opex\": {\"prefer_sections\": [\"Operating expenses (Opex)\", \"Expenses\", \"Staff expenses\", \"Operating costs\", \"Income statement\", \"MD&A\", \"highlights/summary\"]},\n",
        "    \"cti\": {\"prefer_sections\": [\"Cost-to-income (CTI)\", \"Income statement\", \"highlights/summary\"]},\n",
        "    \"oer\": {\"prefer_sections\": [\"Operating expenses (Opex)\", \"Total/Operating income\", \"Income statement\", \"highlights/summary\"]},\n",
        "}\n",
        "\n",
        "def _numeric_score(s: str) -> float:\n",
        "    if not s: return 0.0\n",
        "    return min(0.35, 0.05 * max(0, len(re.findall(r\"\\d[\\d,\\.]*\", s))-1))\n",
        "\n",
        "# --- Retrieval toggles ---\n",
        "USE_VECTOR = True\n",
        "def _classify_query(q: str) -> Optional[str]:\n",
        "    ql = q.lower()\n",
        "    if \"nim\" in ql or \"net interest margin\" in ql: return \"nim\"\n",
        "    if \"opex\" in ql or \"operating expense\" in ql or re.search(r\"\\bexpenses\\b\", ql): return \"opex\"\n",
        "    if re.search(r\"\\bcti\\b|cost[\\s\\-_\\/]*to?\\s*[\\s\\-_\\/]*income|efficiency\\s*ratio\", ql): return \"cti\"\n",
        "    # Operating Efficiency Ratio (OER): explicit phrase, acronym, or division symbol context\n",
        "    if re.search(r\"\\boperating\\s+efficiency\\s+ratio\\b|\\boer\\b\", ql) or (\"÷\" in ql and \"operating\" in ql and \"income\" in ql):\n",
        "        return \"oer\"\n",
        "    return None\n",
        "\n",
        "# --- Lazy, notebook-friendly globals (set by init_stage2) ---\n",
        "kb: Optional[pd.DataFrame] = None\n",
        "texts: Optional[np.ndarray] = None\n",
        "index, bm25, EMB = None, None, None\n",
        "_HAVE_FAISS, _HAVE_BM25, _INITIALIZED = False, False, False\n",
        "\n",
        "class _EmbedLoader:\n",
        "    def __init__(self):\n",
        "        self.impl, self.dim, self.name, self.fn = None, None, None, None\n",
        "        meta_path = os.path.join(os.environ.get(\"AGENT_CFO_OUT_DIR\", \"data\"), \"kb_meta.json\")\n",
        "        if os.path.exists(meta_path):\n",
        "            with open(meta_path) as f:\n",
        "                self.name = json.load(f).get(\"embedding_provider\")\n",
        "    def embed(self, texts: List[str]) -> np.ndarray:\n",
        "        if self.impl is None:\n",
        "            try:\n",
        "                from sentence_transformers import SentenceTransformer\n",
        "                model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "                st = SentenceTransformer(model_name)\n",
        "                self.impl, self.dim = (\"st\", model_name), st.get_sentence_embedding_dimension()\n",
        "                self.fn = lambda b: st.encode(b, normalize_embeddings=True).astype(np.float32)\n",
        "            except ImportError:\n",
        "                raise RuntimeError(\"Default embedding provider not found. Please `pip install sentence-transformers`.\")\n",
        "        return self.fn(texts)\n",
        "\n",
        "def init_stage2(out_dir: str = \"data\") -> None:\n",
        "    global kb, texts, index, bm25, _HAVE_FAISS, _HAVE_BM25, _INITIALIZED, EMB\n",
        "    os.environ[\"AGENT_CFO_OUT_DIR\"] = out_dir\n",
        "    paths = [os.path.join(out_dir, f) for f in [\"kb_chunks.parquet\", \"kb_texts.npy\", \"kb_index.faiss\"]]\n",
        "    if not all(os.path.exists(p) for p in paths):\n",
        "        raise RuntimeError(f\"KB artifacts not found in '{out_dir}'. Run Stage1 first.\")\n",
        "    kb, texts = pd.read_parquet(paths[0]), np.load(paths[1], allow_pickle=True)\n",
        "    try:\n",
        "        import faiss\n",
        "        _HAVE_FAISS, index = True, faiss.read_index(paths[2])\n",
        "    except ImportError: _HAVE_FAISS, index = False, None\n",
        "    try:\n",
        "        from rank_bm25 import BM25Okapi\n",
        "        _HAVE_BM25, bm25 = True, BM25Okapi([str(t).lower().split() for t in texts])\n",
        "    except ImportError: _HAVE_BM25, bm25 = False, None\n",
        "    EMB = _EmbedLoader()\n",
        "    _INITIALIZED = True\n",
        "    if VERBOSE: print(f\"[Stage2] Initialized successfully from '{out_dir}'.\")\n",
        "\n",
        "def _ensure_init():\n",
        "    if not _INITIALIZED: raise RuntimeError(\"Stage2 not initialized. Call init_stage2() first.\")\n",
        "\n",
        "def _infer_yq_from_filename(fname: str) -> tuple[Optional[int], Optional[int]]:\n",
        "    if not fname: return (None, None)\n",
        "    s = str(fname).upper()\n",
        "    m = re.search(r\"([1-4])Q(\\d{2})\", s, re.I)\n",
        "    if m:\n",
        "        q, yy = int(m.group(1)), int(m.group(2))\n",
        "        return (2000 + yy if yy < 100 else yy, q)\n",
        "    m = re.search(r\"(20\\d{2})\", s)\n",
        "    if m: return (int(m.group(1)), None)\n",
        "    return (None, None)\n",
        "\n",
        "def _detect_last_n_years(q: str) -> Optional[int]:\n",
        "    ql = q.lower()\n",
        "    # explicit three/3 + optional 'fiscal'\n",
        "    if re.search(r\"last\\s+(three|3)\\s+(fiscal\\s+)?years?\", ql):\n",
        "        return 3\n",
        "    # generic integer before (fiscal) years\n",
        "    m = re.search(r\"last\\s+(\\d+)\\s+(fiscal\\s+)?years?\", ql)\n",
        "    if m:\n",
        "        try:\n",
        "            return int(m.group(1))\n",
        "        except Exception:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def _detect_last_n_quarters(q: str) -> Optional[int]:\n",
        "    if re.search(r\"last (five|5) quarters\", q, re.I): return 5\n",
        "    return None\n",
        "\n",
        "def _period_filter(hits: List[Dict[str, Any]], want_years: Optional[int], want_quarters: Optional[int]) -> List[Dict[str, Any]]:\n",
        "    if not hits or (want_years is None and want_quarters is None): return hits\n",
        "    df = pd.DataFrame(hits)\n",
        "    if want_quarters:\n",
        "        df = df.sort_values([\"year\", \"quarter\"], ascending=False).dropna(subset=[\"year\", \"quarter\"])\n",
        "        keep_idx = df.drop_duplicates(subset=[\"year\", \"quarter\"]).index[:want_quarters]\n",
        "        return [hits[i] for i in keep_idx]\n",
        "    if want_years:\n",
        "        df = df.sort_values(\"year\", ascending=False).dropna(subset=[\"year\"])\n",
        "        keep_idx = df.drop_duplicates(subset=[\"year\"]).index[:want_years]\n",
        "        return [hits[i] for i in keep_idx]\n",
        "    return hits\n",
        "\n",
        "def hybrid_search(query: str, top_k=12, alpha=0.6) -> List[Dict[str, Any]]:\n",
        "    _ensure_init()\n",
        "    vec_scores, bm25_scores = {}, {}\n",
        "    if USE_VECTOR and _HAVE_FAISS and index and EMB:\n",
        "        qv = EMB.embed([query])\n",
        "        qv /= np.linalg.norm(qv, axis=1, keepdims=True)\n",
        "        sims, ids = index.search(qv.astype(np.float32), top_k * 2)\n",
        "        vec_scores = {int(i): float(s) for i, s in zip(ids[0], sims[0]) if i != -1}\n",
        "    if _HAVE_BM25 and bm25:\n",
        "        scores = bm25.get_scores(query.lower().split())\n",
        "        top_idx = np.argsort(scores)[-top_k*2:]\n",
        "        bm25_scores = {int(i): float(scores[i]) for i in top_idx}\n",
        "    \n",
        "    fused = {k: (alpha * vec_scores.get(k, 0)) + ((1 - alpha) * (bm25_scores.get(k, 0) / (max(bm25_scores.values()) or 1.0))) for k in set(vec_scores) | set(bm25_scores)}\n",
        "    \n",
        "    qtype = _classify_query(query)\n",
        "    want_years, want_quarters = _detect_last_n_years(query), _detect_last_n_quarters(query)\n",
        "    latest_year = kb['year'].max()\n",
        "    if want_years and not kb[kb['quarter'].isna()].empty: latest_year = kb[kb['quarter'].isna()]['year'].max()\n",
        "\n",
        "    # NEW: favor explicit periods mentioned in the query (e.g., \"4Q24\", \"FY2024\")\n",
        "    desired_periods = _desired_periods_from_query(query)  # list of (year, quarter) where quarter=None means annual\n",
        "    desired_set = set(desired_periods) if desired_periods else set()\n",
        "\n",
        "    for i in fused:\n",
        "        meta = kb.iloc[i]\n",
        "        boost = _numeric_score(str(texts[i])[:800])\n",
        "        # Strongly boost exact period matches; de-boost non-matches when a period is explicitly requested\n",
        "        hit_y = int(meta.year) if pd.notna(meta.year) else None\n",
        "        hit_q = int(meta.quarter) if pd.notna(meta.quarter) else None\n",
        "        if desired_set:\n",
        "            if (hit_y, hit_q) in desired_set:\n",
        "                boost += 1.2\n",
        "            else:\n",
        "                boost -= 2.0 # MODIFIED: Increased penalty for period mismatch\n",
        "\n",
        "        # Additional anchor-aware boosts/penalties\n",
        "        sec_low = str(meta.section_hint or \"\").lower()\n",
        "        file_low = str(meta.file or \"\").lower()\n",
        "\n",
        "        # If querying CTI, strongly prefer CTI/highlights and penalize NIM pages\n",
        "        if qtype == \"cti\":\n",
        "            if (\"cti\" in sec_low) or (\"cost-to-income\" in sec_low) or re.search(r\"cost\\s*[/\\-\\–_]?\\s*to\\s*income\", sec_low):\n",
        "                boost += 0.6\n",
        "            if \"nim\" in sec_low:\n",
        "                boost -= 0.8\n",
        "            # Ask for Highlights or supplement explicitly → boost sheets\n",
        "            if (\"highlights\" in query.lower()) and ((\"highlights\" in sec_low) or (\"highlights\" in file_low)):\n",
        "                boost += 0.5\n",
        "            if (\"suppl\" in query.lower() or \"2q24_suppl\" in query.lower()) and (\"suppl\" in file_low):\n",
        "                boost += 0.4\n",
        "\n",
        "        # Mild preference to Excel/tabular supplements for ratio % that come from highlights tables\n",
        "        if qtype in (\"cti\", \"nim\", \"opex\") and file_low.endswith((\".xls\", \".xlsx\")):\n",
        "            boost += 0.15\n",
        "\n",
        "        if qtype and isinstance(meta.section_hint, str) and meta.section_hint in QUERY_HINTS[qtype][\"prefer_sections\"]: boost += 0.25\n",
        "        if (want_years or want_quarters) and pd.notna(meta.year):\n",
        "            year_diff = latest_year - meta.year\n",
        "            if year_diff == 0: boost += 1.0\n",
        "            elif year_diff <= 2: boost += 0.6\n",
        "            elif year_diff <= 4: boost += 0.25\n",
        "        is_annual = pd.isna(meta.quarter)\n",
        "        if want_years and is_annual: boost += 0.3\n",
        "        if want_quarters and not is_annual: boost += 0.3\n",
        "        # Prefer PDFs slightly for chart-derived % metrics; prefer tables slightly for sums.\n",
        "        ext = str(kb.iloc[i].file).lower().rsplit(\".\", 1)[-1]\n",
        "        # If the query mentions a particular file or the 'Highlights' tab, boost matching hits\n",
        "        qlow = query.lower()\n",
        "        hit_file = str(kb.iloc[i].file).lower()\n",
        "        hit_section = str(kb.iloc[i].section_hint or \"\").lower()\n",
        "        # Keep generic boosts (lower than the CTI-specific ones above)\n",
        "        if \"2q24_suppl\" in qlow and \"2q24_suppl\" in hit_file:\n",
        "            boost += 0.3\n",
        "        if \"highlights\" in qlow and (\"highlights\" in hit_section or \"highlights\" in hit_file):\n",
        "            boost += 0.25\n",
        "        if ext in (\"xls\", \"xlsx\"):\n",
        "            # Prefer sheets for YoY/aggregations\n",
        "            if re.search(r\"\\byoy\\b|year[- ]?on[- ]?year|total\\b|sum\\b|\\blast\\s+\\d+\\s+years\", query, re.I):\n",
        "                boost += 0.15\n",
        "            # For NIM specifically, sheets often have the % cleanly; small positive nudge\n",
        "            if re.search(r\"\\bnim\\b|net\\s*interest\\s*margin\", query, re.I):\n",
        "                boost += 0.10\n",
        "            # For generic %/ratio (CTI, other ratios) give sheets a mild *positive* nudge because Excel “Highlights” often holds clean decimals.\n",
        "            if re.search(r\"\\bcti\\b|cost\\s*/\\s*income|efficiency\\s*ratio|(?:^| )ratio\\b|%\", query, re.I):\n",
        "                boost += 0.05\n",
        "        else:\n",
        "            # small preference for PDFs when question is for reported % (NIM/CTI/ratio)\n",
        "            if re.search(r\"\\bnim\\b|net\\s*interest\\s*margin|cti|cost\\s*/\\s*income|ratio|%\", query, re.I):\n",
        "                boost += 0.1\n",
        "        fused[i] += boost\n",
        "        \n",
        "    hits = [{\"doc_id\": kb.iloc[i].doc_id, \"file\": kb.iloc[i].file, \"page\": int(kb.iloc[i].page), \"year\": int(kb.iloc[i].year) if pd.notna(kb.iloc[i].year) else None, \"quarter\": int(kb.iloc[i].quarter) if pd.notna(kb.iloc[i].quarter) else None, \"section_hint\": kb.iloc[i].section_hint, \"score\": float(score)} for i, score in sorted(fused.items(), key=lambda x: x[1], reverse=True)[:top_k]]\n",
        "    return hits\n",
        "\n",
        "def format_citation(hit: dict) -> str:\n",
        "    parts = [hit.get(\"file\", \"?\")]\n",
        "    y = hit.get(\"year\")\n",
        "    q = hit.get(\"quarter\")\n",
        "    if y is not None and q is not None:\n",
        "        parts.append(f\"{int(q)}Q{str(int(y))[-2:]}\")\n",
        "    elif y is not None:\n",
        "        parts.append(str(int(y)))\n",
        "    if hit.get(\"page\") is not None:\n",
        "        parts.append(f\"p.{int(hit['page'])}\")\n",
        "    if hit.get(\"section_hint\"):\n",
        "        parts.append(hit[\"section_hint\"])\n",
        "    return \", \".join(parts)\n",
        "\n",
        "def _context_from_hits(hits: List[Dict[str, Any]], top_ctx=3) -> str:\n",
        "    return \"\\n\\n\".join([f\"[{format_citation(h)}]\\n{texts[kb.index[kb.doc_id == h['doc_id']][0]][:1200]}\" for h in hits[:top_ctx]])\n",
        "\n",
        "def _call_llm(prompt: str, dry_run: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Calls the selected LLM API.\n",
        "    MODIFIED: Now accepts a 'dry_run' boolean toggle.\n",
        "    \"\"\"\n",
        "    if dry_run:\n",
        "        print(\"\\n\" + \"=\"*25 + \" DRY RUN: PROMPT PREVIEW \" + \"=\"*25)\n",
        "        print(prompt)\n",
        "        print(\"=\"*70)\n",
        "        if \"Return ONLY a valid JSON object\" in prompt:\n",
        "            return '{\"plan\": [{\"tool\": \"dry_run_tool\", \"parameters\": {\"status\": \"Dry run mode enabled\"}}]}'\n",
        "        else:\n",
        "            return \"This is a dry run. The API was not called.\"\n",
        "\n",
        "    backend = LLM_BACKEND.lower()\n",
        "    try:\n",
        "        if backend == \"gemini\":\n",
        "            from google import generativeai as genai\n",
        "            if not os.environ.get(\"GEMINI_API_KEY\"): raise ValueError(\"GEMINI_API_KEY not set.\")\n",
        "            genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "            model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
        "            return model.generate_content(prompt).text\n",
        "        elif backend == \"openai\":\n",
        "            from openai import OpenAI\n",
        "            if not os.environ.get(\"OPENAI_API_KEY\"): raise ValueError(\"OPENAI_API_KEY not set.\")\n",
        "            client = OpenAI()\n",
        "            resp = client.chat.completions.create(model=OPENAI_MODEL_NAME, messages=[{\"role\":\"user\",\"content\": prompt}], temperature=0.1)\n",
        "            return resp.choices[0].message.content\n",
        "        else: raise ValueError(f\"Invalid LLM_BACKEND: {backend}\")\n",
        "    except Exception as e:\n",
        "        return f\"LLM Generation Failed: {e}\"\n",
        "\n",
        "def answer_with_llm(query: str, top_k_retrieval=12, top_ctx=3, dry_run: bool = False) -> Dict[str, Any]:\n",
        "    _ensure_init()\n",
        "    want_years, want_quarters = _detect_last_n_years(query), _detect_last_n_quarters(query)\n",
        "    hits = hybrid_search(query, top_k=top_k_retrieval)\n",
        "    hits = _period_filter(hits, want_years, want_quarters)\n",
        "    context = _context_from_hits(hits, top_ctx=top_ctx)\n",
        "    prompt = f\"You are Agent CFO. Answer the question based ONLY on the provided context. Cite your sources inline. Question: {query}\\n\\nContext:\\n{context}\"\n",
        "    answer = _call_llm(prompt, dry_run=dry_run)\n",
        "    return {\"answer\": answer, \"hits\": hits[:top_ctx]}\n",
        "\n",
        "def tool_calculator(expression: str) -> str:\n",
        "    try:\n",
        "        import re\n",
        "        # Normalize: remove thousands separators, handle %, and simple units\n",
        "        s = str(expression)\n",
        "        # 1) remove thousands separators (1,234,567.89)\n",
        "        s = re.sub(r'(?<=\\d),(?=\\d{3}\\b)', '', s)\n",
        "        # 2) turn percentages like 37% into (37/100)\n",
        "        s = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*%', r'(\\1/100)', s)\n",
        "        # 3) currency symbols\n",
        "        s = re.sub(r'(?i)[s]?\\$\\s*', '', s)\n",
        "        # 4) units to scientific notation\n",
        "        s = re.sub(r'(?i)\\b(bn|billion|b)\\b', 'e9', s)\n",
        "        s = re.sub(r'(?i)\\b(mn|million|m)\\b', 'e6', s)\n",
        "        # 4.5) stray trailing commas or semicolons\n",
        "        s = re.sub(r'[,\\;]\\s*$', '', s)\n",
        "        # 5) allowlist filter\n",
        "        safe = re.sub(r'[^0-9eE\\+\\-*/(). ]', '', s)\n",
        "        # remove any remaining commas inside numbers\n",
        "        safe = re.sub(r'(?<=\\d),(?=\\d)', '', safe)\n",
        "        result = eval(safe)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "def _desired_periods_from_query(query: str) -> list[tuple[int|None, int|None]]:\n",
        "    \"\"\"\n",
        "    Parse explicit periods from query text, like '1Q25', '4Q24', or 'FY2024'.\n",
        "    Returns list of (year, quarter) where quarter=None denotes annual.\n",
        "    \"\"\"\n",
        "    out: list[tuple[int|None, int|None]] = []\n",
        "    for m in re.finditer(r\"\\b([1-4])Q(\\d{2})\\b\", query.upper()):\n",
        "        q, yy = int(m.group(1)), int(m.group(2))\n",
        "        out.append((2000 + yy, q))\n",
        "    for m in re.finditer(r\"\\bFY\\s?(20\\d{2})\\b\", query.upper()):\n",
        "        out.append((int(m.group(1)), None))\n",
        "    return out\n",
        "\n",
        "def tool_table_extraction(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Robust single-value extractor with anchor-aware windows and scoring.\n",
        "    Prefers:\n",
        "      - Percentages with decimals near 'NIM/Net interest margin' or 'Cost / income/CTI'\n",
        "      - Monetary amounts next to 'Operating expenses/Total income' with units (S$m, bn/mn)\n",
        "    Avoids:\n",
        "      - Isolated chart ticks (e.g., 1, 4, 6)\n",
        "      - Dashes ('-') or values without supporting context\n",
        "    Returns: \"Value: <clean>[%], Source: <citation>\"\n",
        "    \"\"\"\n",
        "    if VERBOSE: print(f\"  [Tool Call: table_extraction] with query: '{query}'\")\n",
        "    hits = hybrid_search(query, top_k=6)\n",
        "    if not hits:\n",
        "        return \"Error: No relevant data found.\"\n",
        "\n",
        "    qtype = _classify_query(query) or \"\"\n",
        "    desired_periods = _desired_periods_from_query(query)\n",
        "\n",
        "    ql = query.lower()\n",
        "    want_percent = bool(re.search(r\"\\b(cti|cost[\\s\\-_\\/]*to?\\s*income|margin|nim|ratio|%)\\b\", ql))\n",
        "    want_opex    = bool(re.search(r\"\\b(opex|operating\\s+expenses?)\\b\", ql))\n",
        "    want_income  = bool(re.search(r\"\\b(total\\s+(?:operating\\s+)?income|operating\\s+income|total\\s+income)\\b\", ql))\n",
        "\n",
        "    # Annual/quarter query detection\n",
        "    is_annual_query = bool(re.search(r\"\\bfy\\s?20\\d{2}\\b|last\\s+\\d+\\s+(?:fiscal\\s+)?years?\", query, re.I))\n",
        "\n",
        "    # Anchors\n",
        "    anchors = [\n",
        "        r\"net\\s*interest\\s*margin|nim\",\n",
        "        r\"cost\\s*[/\\-\\–_]?\\s*to?\\s*income|cti|efficiency\\s*ratio|operating\\s+efficiency\\s+ratio\",\n",
        "        r\"\\boperating\\s+expenses?\\b|\\bopex\\b|\\bstaff\\s+expenses?\\b|\\bother\\s+expenses?\\b|\\bcosts?\\b\",\n",
        "        r\"\\btotal\\s+operating\\s+income\\b|\\btotal\\s+income\\b|\\boperating\\s+income\\b\"\n",
        "    ]\n",
        "    anchor_pat = re.compile(\"|\".join(anchors), re.I)\n",
        "\n",
        "    # Numbers\n",
        "    # Percent-without-symbols are only accepted near anchors (see logic below)\n",
        "    pct_pat_strict = re.compile(r\"\\b(\\d{1,2}\\.\\d{1,2})\\s*%\")     # 2.68%\n",
        "    pct_pat_loose  = re.compile(r\"\\b(\\d{1,2}(?:\\.\\d{1,2})?)\\s*%\") # 2.7% / 40%\n",
        "    # NEW: percent-without-symbol candidates (used only near anchors)\n",
        "    nim_pct_nosym  = re.compile(r\"\\b(\\d\\.\\d{1,2})\\b\")             # 2.68\n",
        "    # allow CTI like 38 or 38.1 without a % symbol\n",
        "    cti_pct_nosym  = re.compile(r\"\\b([1-9]\\d(?:\\.\\d{1,2})?)\\b\")\n",
        "    money_pat = re.compile(r\"([-\\d]{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(S\\$\\s*)?(?:\\((?:S\\$\\s*)?m\\)|\\bmn\\b|\\bmillion\\b|\\bm\\b|\\((?:S\\$\\s*)?bn\\)|\\bbn\\b|\\bbillion\\b|\\bb\\b)?\", re.I)\n",
        "    unit_pat  = re.compile(r\"\\((?:S\\$\\s*)?m\\)|\\bmn\\b|\\bmillion\\b|\\bm\\b|\\((?:S\\$\\s*)?bn\\)|\\bbn\\b|\\bbillion\\b|\\bb\\b|\\(S\\$m\\)\", re.I)\n",
        "    sgdm_hint = re.compile(r\"\\(S\\$\\s*m\\)|S\\$m|S\\$\\s*m\", re.I)\n",
        "    yoy_guard = re.compile(r\"\\b(yoy|qoq|vs)\\b\", re.I)\n",
        "\n",
        "    def _section_score(hit: dict) -> float:\n",
        "        sec = (hit.get(\"section_hint\") or \"\").lower()\n",
        "        score = 0.0\n",
        "        if \"nim\" in sec: score += 1.0\n",
        "        if \"cti\" in sec or \"cost-to-income\" in sec: score += 1.0\n",
        "        if \"opex\" in sec or \"expenses\" in sec: score += 0.8\n",
        "        if \"income\" in sec: score += 0.5\n",
        "        return score\n",
        "\n",
        "    def clean_amount(num_str: str) -> str:\n",
        "        return (num_str or \"\").strip().replace(\",\", \"\")\n",
        "\n",
        "    def with_unit_to_scientific(window: str, raw: str, want_opex: bool, want_income: bool) -> str:\n",
        "        # Proximity-aware unit detection: only trust a unit if it appears near the number token\n",
        "        wlow = window.lower()\n",
        "        try:\n",
        "            pos = wlow.find(str(raw).lower())\n",
        "        except Exception:\n",
        "            pos = -1\n",
        "\n",
        "        def nearest_pos(tokens: list[str]) -> int:\n",
        "            best = 10**9\n",
        "            for t in tokens:\n",
        "                j = wlow.find(t)\n",
        "                if j != -1 and pos != -1:\n",
        "                    best = min(best, abs(j - pos))\n",
        "            return best\n",
        "\n",
        "        bn_tokens = [\"(s$bn)\", \" s$bn\", \" bn\", \"billion\", \" b)\"]  # simple set; spacing handles common OCR\n",
        "        m_tokens  = [\"(s$m)\", \" s$m\", \" mn\", \"million\", \" m)\"]\n",
        "\n",
        "        dist_bn = nearest_pos(bn_tokens)\n",
        "        dist_m  = nearest_pos(m_tokens)\n",
        "\n",
        "        # If both are present, prefer the closer one; if tie or neither close, prefer S$m for Opex/Income\n",
        "        near_thresh = 18  # characters\n",
        "        if dist_bn < dist_m and dist_bn <= near_thresh:\n",
        "            return f\"{raw}e9\"\n",
        "        if dist_m <= near_thresh or sgdm_hint.search(window):\n",
        "            return f\"{raw}e6\"\n",
        "\n",
        "        # If both tokens appear somewhere in the window but not near, prefer S$m (common slide header)\n",
        "        if re.search(r\"\\(s\\$\\s*bn\\)|\\bbn\\b|\\bbillion\\b\", wlow) and re.search(r\"\\(s\\$\\s*m\\)|\\bmn\\b|\\bmillion\\b|\\bm\\b\", wlow):\n",
        "            return f\"{raw}e6\"\n",
        "\n",
        "        # Default scaling: for Opex/Income queries, assume S$m\n",
        "        if want_opex or want_income:\n",
        "            return f\"{raw}e6\"\n",
        "\n",
        "        # Otherwise, leave as-is\n",
        "        return raw\n",
        "\n",
        "    candidates: list[tuple[float, str, str]] = []  # (score, value_repr, citation)\n",
        "\n",
        "    for hit in hits:\n",
        "        full_text = str(texts[kb.index[kb.doc_id == hit[\"doc_id\"]][0]])\n",
        "        flat = \" \".join(full_text.split())\n",
        "\n",
        "        # Widen scan: up to 6 anchors and a wider window—OCR often separates the number from the label\n",
        "        windows = []\n",
        "        for m in list(anchor_pat.finditer(flat))[-6:]:\n",
        "            start = max(0, m.start() - 500)\n",
        "            end   = min(len(flat), m.end() + 500)\n",
        "            windows.append(flat[start:end])\n",
        "        if not windows:\n",
        "            windows = [flat]\n",
        "\n",
        "        base = 0.4 + _section_score(hit)\n",
        "\n",
        "        # Add preference to annual docs for annual queries, quarterly for quarter queries\n",
        "        if is_annual_query and pd.isna(hit.get(\"quarter\")):\n",
        "            base += 0.5\n",
        "        if (not is_annual_query) and (hit.get(\"quarter\") is not None):\n",
        "            base += 0.2\n",
        "            \n",
        "        # If explicit periods were requested and this hit doesn't match, penalize\n",
        "        if desired_periods and (hit.get(\"year\"), hit.get(\"quarter\")) not in desired_periods:\n",
        "            base -= 0.4 # MODIFIED: Added penalty for period mismatch within the tool\n",
        "\n",
        "        for w in windows:\n",
        "            # Strip S$m and similar tokens before matching %\n",
        "            w = re.sub(r'\\(S\\$m\\)|S\\$m', '', w)\n",
        "            # Percent path\n",
        "            if want_percent:\n",
        "                def _pct_ok(v: float) -> bool:\n",
        "                    if qtype == \"nim\":\n",
        "                        return 0.5 <= v <= 5.0   # typical NIM range\n",
        "                    if qtype == \"cti\":\n",
        "                        return 15.0 <= v <= 80.0 # typical CTI range (broad)\n",
        "                    return 0.01 <= v <= 100.0\n",
        "\n",
        "                # MODIFIED: Stricter guards to prevent pulling CTI data for NIM queries and vice-versa\n",
        "                if qtype == \"cti\":\n",
        "                    if re.search(r\"(margin|nim)\", w, re.I) and not re.search(r\"(cost\\s*/\\s*income|cti|efficiency)\", w, re.I):\n",
        "                        continue\n",
        "                if qtype == \"nim\":\n",
        "                    if re.search(r\"(cost\\s*/\\s*income|cti|efficiency)\", w, re.I) and not re.search(r\"(margin|nim)\", w, re.I):\n",
        "                        continue\n",
        "\n",
        "                # strict decimals first (avoid chart tick integers)\n",
        "                for m in pct_pat_strict.finditer(w):\n",
        "                    val = float(m.group(1))\n",
        "                    if not _pct_ok(val):\n",
        "                        continue\n",
        "                    if qtype == \"cti\" and not re.search(r\"(cost\\s*/\\s*income|cti|efficiency)\", w, re.I):\n",
        "                        continue\n",
        "                    if qtype == \"nim\" and not re.search(r\"(margin|nim)\", w, re.I):\n",
        "                        continue\n",
        "                    s = base + 1.2\n",
        "                    if re.search(r\"margin|nim|cost\\s*/\\s*income|cti|efficiency\", w, re.I): s += 0.6\n",
        "                    candidates.append((s, f\"Value: {val}%, Source: {format_citation(hit)}\", format_citation(hit)))\n",
        "\n",
        "                # then loose (allow integers but heavily penalize)\n",
        "                for m in pct_pat_loose.finditer(w):\n",
        "                    val_str = m.group(1)\n",
        "                    if yoy_guard.search(w) and float(val_str) < 100:\n",
        "                        continue\n",
        "                    if re.search(rf\"Value:\\s*{re.escape(val_str)}%\", \" \".join(c[1] for c in candidates)):\n",
        "                        continue\n",
        "                    try: val = float(val_str)\n",
        "                    except: continue\n",
        "                    if not _pct_ok(val): continue\n",
        "                    if qtype == \"cti\" and not re.search(r\"(cost\\s*/\\s*income|cti|efficiency)\", w, re.I): continue\n",
        "                    if qtype == \"nim\" and not re.search(r\"(margin|nim)\", w, re.I): continue\n",
        "                    s = base + (0.05 if \".\" not in val_str else 0.6)\n",
        "                    if re.search(r\"margin|nim|cost\\s*/\\s*income|cti|efficiency\", w, re.I): s += 0.2\n",
        "                    candidates.append((s, f\"Value: {val}%, Source: {format_citation(hit)}\", format_citation(hit)))\n",
        "\n",
        "                # symbol-less % candidates near anchors\n",
        "                if re.search(r\"(margin|nim)\", w, re.I):\n",
        "                    for m in nim_pct_nosym.finditer(w):\n",
        "                        val = float(m.group(1))\n",
        "                        if 0.5 <= val <= 5.0 and not yoy_guard.search(w):\n",
        "                            s = base + 0.9\n",
        "                            candidates.append((s, f\"Value: {val}%, Source: {format_citation(hit)}\", format_citation(hit)))\n",
        "                if qtype == \"cti\" and re.search(r\"(cost\\s*/\\s*income|cti|efficiency)\", w, re.I):\n",
        "                    for m in cti_pct_nosym.finditer(w):\n",
        "                        val = float(m.group(1))\n",
        "                        if 15.0 <= val <= 80.0 and not yoy_guard.search(w):\n",
        "                            s = base + 0.9\n",
        "                            candidates.append((s, f\"Value: {val}%, Source: {format_citation(hit)}\", format_citation(hit)))\n",
        "\n",
        "            # Monetary path\n",
        "            if want_opex or want_income or not want_percent:\n",
        "                if want_opex and not re.search(r\"\\boperating\\s+expenses?\\b|\\bopex\\b|\\bstaff\\s+expenses?\\b|\\bother\\s+expenses?\\b|\\bcosts?\\b\", w, re.I): continue\n",
        "                if want_income and not re.search(r\"\\btotal\\s+operating\\s+income\\b|\\btotal\\s+income\\b|\\boperating\\s+income\\b\", w, re.I): continue\n",
        "                if (want_opex or want_income) and (str(hit.get(\"section_hint\") or \"\").lower().startswith(\"nim\")): continue\n",
        "                # MODIFIED: Stricter guard for CTI queries\n",
        "                if qtype == \"cti\" and re.search(r\"(margin|nim)\", w, re.I): continue\n",
        "                if want_income and re.search(r\"margin|nim\", w, re.I): continue\n",
        "\n",
        "                for m in money_pat.finditer(w):\n",
        "                    raw = clean_amount(m.group(1))\n",
        "                    if not raw or raw in (\"-\", \"–\"): continue\n",
        "                    tail = w[w.find(raw) + len(raw): w.find(raw) + len(raw) + 3]\n",
        "                    if \"%\" in tail: continue\n",
        "                    if \".\" not in raw and len(raw) <= 2 and not unit_pat.search(w): continue\n",
        "                    has_unit = bool(unit_pat.search(w) or sgdm_hint.search(w))\n",
        "                    if not has_unit and not (want_opex or want_income): continue\n",
        "                    \n",
        "                    num = with_unit_to_scientific(w, raw, want_opex, want_income)\n",
        "                    try: val = float(num.replace('e9','e9').replace('e6','e6'))\n",
        "                    except Exception: val = None\n",
        "                    \n",
        "                    # MODIFIED: Plausibility gates for monetary values\n",
        "                    too_huge_without_bn = (val is not None and val > 80e9 and not re.search(r\"\\b(s\\$\\s*bn|bn|billion)\\b\", w, re.I))\n",
        "                    if too_huge_without_bn: continue\n",
        "                    \n",
        "                    if yoy_guard.search(w):\n",
        "                        try:\n",
        "                            if val is not None and val < 100 and not unit_pat.search(w): continue\n",
        "                        except Exception: pass\n",
        "                        \n",
        "                    if is_annual_query:\n",
        "                        if want_income and (val is None or val < 1000e6): continue\n",
        "                        if want_opex and (val is None or val < 200e6): continue\n",
        "\n",
        "                    s = base + 0.9\n",
        "                    if re.search(r\"\\boperating\\s+expenses\\b|\\bopex\\b\", w, re.I): s += 0.6\n",
        "                    if re.search(r\"\\btotal\\s+operating\\s+income\\b|\\btotal\\s+income\\b|\\boperating\\s+income\\b\", w, re.I): s += 0.5\n",
        "                    candidates.append((s, f\"Value: {num}, Source: {format_citation(hit)}\", format_citation(hit)))\n",
        "\n",
        "    if not candidates:\n",
        "        return \"Error: No plausible value found in documents.\"\n",
        "\n",
        "    candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "    best_candidate = candidates[0][1] # Return the highest scored candidate\n",
        "    return best_candidate\n",
        "\n",
        "def tool_multi_document_compare(topic: str, files: list[str]) -> str:\n",
        "    if VERBOSE: print(f\"  [Tool Call: multi_document_compare] for topic '{topic}' in files: {files}\")\n",
        "    results = []\n",
        "    for file_name in files:\n",
        "        hits = hybrid_search(f\"In {file_name}, find info on: {topic}\", top_k=1)\n",
        "        if hits:\n",
        "            top_hit = hits[0]\n",
        "            full_text = texts[kb.index[kb.doc_id == top_hit[\"doc_id\"]][0]]\n",
        "            results.append(f\"From {file_name}:\\n{full_text}\\nSource: {format_citation(top_hit)}\")\n",
        "        else: results.append(f\"From {file_name}: No data found.\")\n",
        "    return \"\\n---\\n\".join(results)\n",
        "\n",
        "def _compile_or_repair_plan(query: str, plan: list[dict]) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Ensure every tool step has required parameters.\n",
        "    If the LLM omitted parameters, synthesize a deterministic plan based on the query.\n",
        "    Returns a fixed plan.\n",
        "    \"\"\"\n",
        "    def _has_params(step: dict) -> bool:\n",
        "        params = step.get(\"parameters\")\n",
        "        if not isinstance(params, dict): return False\n",
        "        return any(v not in (None, \"\", []) for v in params.values())\n",
        "\n",
        "    if plan and all(_has_params(s) for s in plan):\n",
        "        return plan\n",
        "\n",
        "    qtype = _classify_query(query) or \"\"\n",
        "    if not qtype and (\"÷\" in query and re.search(r\"operating\", query, re.I) and re.search(r\"income\", query, re.I)):\n",
        "        qtype = \"oer\"\n",
        "    want_years  = _detect_last_n_years(query)\n",
        "    want_quarts = _detect_last_n_quarters(query)\n",
        "\n",
        "    df = kb.copy()\n",
        "    df[\"y\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
        "    df[\"q\"] = pd.to_numeric(df[\"quarter\"], errors=\"coerce\")\n",
        "\n",
        "    steps: list[dict] = []\n",
        "\n",
        "    if qtype == \"nim\":\n",
        "        n = want_quarts or 5\n",
        "        qdf = df.dropna(subset=[\"y\",\"q\"]).sort_values([\"y\",\"q\"], ascending=[False, False])\n",
        "        periods = qdf[[\"y\",\"q\"]].drop_duplicates().head(n).to_records(index=False)\n",
        "        for y, q in periods:\n",
        "            y, q = int(y), int(q)\n",
        "            label = f\"{q}Q{str(y)[-2:]}\"\n",
        "            steps.append({ \"step\": f\"Extract NIM for {label}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Net interest margin (%) for {label}\"}, \"store_as\": f\"nim_{y}_{q}\"})\n",
        "        return steps\n",
        "\n",
        "    if qtype == \"opex\":\n",
        "        n = want_years or 3\n",
        "        ydf = df[df[\"q\"].isna()].dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
        "        if ydf.empty: ydf = df.dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
        "        years = [int(y) for y in ydf[\"y\"].drop_duplicates().head(n)]\n",
        "        for y in years:\n",
        "            steps.append({ \"step\": f\"Extract Operating expenses for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Operating expenses (total) for fiscal year {y}\"}, \"store_as\": f\"opex_fy{y}\"})\n",
        "        if len(years) >= 2:\n",
        "            y0, y1 = years[0], years[1]\n",
        "            steps.append({ \"step\": f\"Compute YoY % change in Opex FY{y0} vs FY{y1}\", \"tool\": \"calculator\", \"parameters\": {\"expression\": f\"(( ${{opex_fy{y0}}} - ${{opex_fy{y1}}} ) / ${{opex_fy{y1}}}) * 100\"}, \"store_as\": f\"opex_yoy_{y0}_{y1}\"})\n",
        "        if len(years) >= 3:\n",
        "            y1, y2 = years[1], years[2]\n",
        "            steps.append({ \"step\": f\"Compute YoY % change in Opex FY{y1} vs FY{y2}\", \"tool\": \"calculator\", \"parameters\": {\"expression\": f\"(( ${{opex_fy{y1}}} - ${{opex_fy{y2}}} ) / ${{opex_fy{y2}}}) * 100\"}, \"store_as\": f\"opex_yoy_{y1}_{y2}\"})\n",
        "        latest = years[0] if years else None\n",
        "        if latest:\n",
        "            steps.append({ \"step\": f\"Compare MD&A Opex drivers for FY{latest}\", \"tool\": \"multi_document_compare\", \"parameters\": {\"topic\": f\"Operating expense drivers FY{latest}\", \"files\": [\"dbs-annual-report-2024.pdf\", \"4Q24_CFO_presentation.pdf\", \"4Q24_performance_summary.pdf\"]}, \"store_as\": \"opex_drivers_fylatest\"})\n",
        "        return steps\n",
        "\n",
        "    # MODIFIED: Corrected the deterministic plan for Operating Efficiency Ratio\n",
        "    if qtype == \"oer\":\n",
        "        n = want_years or 3\n",
        "        ydf = df[df[\"q\"].isna()].dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
        "        if ydf.empty: ydf = df.dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
        "        years = [int(y) for y in ydf[\"y\"].drop_duplicates().head(n)]\n",
        "        for y in years:\n",
        "            steps.append({ \"step\": f\"Extract Opex for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Operating expenses (total) for fiscal year {y}\"}, \"store_as\": f\"opex_fy{y}\"})\n",
        "            steps.append({ \"step\": f\"Extract Operating income for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Operating income for fiscal year {y}\"}, \"store_as\": f\"opinc_fy{y}\"})\n",
        "            steps.append({ \"step\": f\"Compute Operating Efficiency Ratio (Opex / Operating Income) for FY{y}\", \"tool\": \"calculator\", \"parameters\": {\"expression\": f\"(${{opex_fy{y}}} / ${{opinc_fy{y}}}) * 100\"}, \"store_as\": f\"oer_fy{y}\"})\n",
        "        return steps\n",
        "\n",
        "    if qtype == \"cti\":\n",
        "        n = want_years or 3\n",
        "        ydf = df[df[\"q\"].isna()].dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
        "        if ydf.empty: ydf = df.dropna(subset=[\"y\"]).sort_values(\"y\", ascending=False)\n",
        "        years = [int(y) for y in ydf[\"y\"].drop_duplicates().head(n)]\n",
        "        for y in years:\n",
        "            steps.append({ \"step\": f\"Extract CTI (reported %) for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Cost / income (%) for fiscal year {y}\"}, \"store_as\": f\"cti_fy{y}\"})\n",
        "            steps.append({ \"step\": f\"Extract Opex for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Operating expenses (total) for fiscal year {y}\"}, \"store_as\": f\"opex_fy{y}\"})\n",
        "            steps.append({ \"step\": f\"Extract Total/Operating income for FY{y}\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": f\"Total income (or Operating income) for fiscal year {y}\"}, \"store_as\": f\"income_fy{y}\"})\n",
        "            steps.append({ \"step\": f\"Compute CTI for FY{y} if not reported\", \"tool\": \"calculator\", \"parameters\": {\"expression\": f\"${{opex_fy{y}}} / ${{income_fy{y}}}\"}, \"store_as\": f\"cti_calc_fy{y}\"})\n",
        "        return steps\n",
        "\n",
        "    steps.append({ \"step\": \"Extract a directly relevant figure\", \"tool\": \"table_extraction\", \"parameters\": {\"query\": query}, \"store_as\": \"value_1\"})\n",
        "    return steps\n",
        "\n",
        "def answer_with_agent(query: str, dry_run: bool = False) -> Dict[str, Any]:\n",
        "    _ensure_init()\n",
        "    row = {\"Query\": f\"[agent] {query}\"}\n",
        "    execution_log = []\n",
        "    \n",
        "    with timeblock(row, \"T_total\"), timeblock(row, \"T_reason\"):\n",
        "        # == STEP 1: PLANNING ==\n",
        "        planning_prompt = f\"\"\"You are a financial analyst agent. Create a JSON plan to answer the user's query.\n",
        "\n",
        "Tools Available:\n",
        "- `table_extraction(query: str)`: Finds a single reported data point (e.g., a percentage or a monetary value) from slides/annuals/supplements.\n",
        "- `calculator(expression: str)`: Calculates a math expression using numbers you already extracted.\n",
        "- `multi_document_compare(topic: str, files: list[str])`: Pulls comparable snippets from multiple files.\n",
        "\n",
        "Planning Rules:\n",
        "1) **Prefer reported metrics over recomputing from components.** For NIM and CTI, extract the **reported percentage** (e.g., \"Net interest margin (%)\" or \"Cost / income (%)\") from CFO deck, performance summary, or the Excel supplement. For **Operating Efficiency Ratio (Opex ÷ Operating Income)** there may not be a reported field; plan to compute it from Opex and Operating Income if needed.\n",
        "2) When the request is for the **last N quarters/years**, plan steps that **directly extract those N reported values** (e.g., 1Q25, 4Q24, 3Q24...) instead of deriving them.\n",
        "3) Use `calculator` only for simple arithmetic (e.g., YoY %, CTI if you have Opex and Total/Operating Income). Never pass text with units/commas/% into the calculator—use only clean numeric placeholders you previously extracted.\n",
        "4) Always include `\"store_as\"` for every extraction step. Use short keys like `nim_1q25`, `cti_fy2024`, `opex_fy2023`, `income_fy2023`, etc.\n",
        "5) If the query asks for drivers/MD&amp;A points, add one step to extract or quote the relevant lines (you may use `table_extraction` for MD&amp;A text).\n",
        "\n",
        "User Query: \"{query}\"\n",
        "Return ONLY a valid JSON object with a \"plan\" key.\"\"\"\n",
        "        if VERBOSE: print(\"[Agent] Step 1: Generating execution plan...\")\n",
        "        \n",
        "        plan_response = _call_llm(planning_prompt)\n",
        "        plan = None\n",
        "        try:\n",
        "            json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', plan_response, re.DOTALL)\n",
        "            plan_str = json_match.group(1) if json_match else plan_response\n",
        "            plan = json.loads(plan_str)[\"plan\"]\n",
        "            execution_log.append({\"step\": \"Planning\", \"plan\": plan})\n",
        "            if VERBOSE: print(\"[Agent] Plan generated successfully.\")\n",
        "        except (json.JSONDecodeError, KeyError) as e:\n",
        "            error_msg = f\"Failed to parse a valid plan from LLM response.\\nError: {e}\\nLLM Response:\\n---\\n{plan_response}\\n---\"\n",
        "            return {\"answer\": error_msg, \"hits\": [], \"execution_log\": execution_log}\n",
        "        \n",
        "        if dry_run:\n",
        "            answer = f\"DRY RUN MODE: The agent generated the following plan and stopped before execution.\\n\\n{json.dumps(plan, indent=2)}\"\n",
        "            return {\"answer\": answer, \"hits\": [], \"execution_log\": execution_log}\n",
        "\n",
        "        # == STEP 2: ACTING (Live Mode Only) ==\n",
        "        if VERBOSE: print(\"[Agent] Step 2: Executing plan...\")\n",
        "        tool_mapping = {\"calculator\": tool_calculator, \"table_extraction\": tool_table_extraction, \"multi_document_compare\": tool_multi_document_compare}\n",
        "        execution_state = {}\n",
        "\n",
        "        repaired_plan = _compile_or_repair_plan(query, plan)\n",
        "        if repaired_plan != plan:\n",
        "            execution_log.append({\"step\": \"PlanRepair\", \"note\": \"LLM plan lacked parameters; synthesized deterministic plan.\", \"repaired_plan\": repaired_plan})\n",
        "        plan = repaired_plan\n",
        "\n",
        "        for i, step in enumerate(plan):\n",
        "            tool, params, store_as = step.get(\"tool\"), step.get(\"parameters\", {}), step.get(\"store_as\")\n",
        "\n",
        "            if tool == \"table_extraction\" and not params.get(\"query\"): params[\"query\"] = query\n",
        "            if tool == \"calculator\" and not params.get(\"expression\"):\n",
        "                execution_log.append({\"step\": f\"Execution {i+1}\", \"tool_call\": f\"{tool}({params})\", \"error\": \"Missing 'expression' parameter\"})\n",
        "                continue\n",
        "\n",
        "            for p_name, p_value in params.items():\n",
        "                if isinstance(p_value, str):\n",
        "                    for var_name, var_value in execution_state.items():\n",
        "                        p_value = p_value.replace(f\"${{{var_name}}}\", str(var_value))\n",
        "                params[p_name] = p_value\n",
        "\n",
        "            if tool in tool_mapping:\n",
        "                try:\n",
        "                    result = tool_mapping[tool](**params)\n",
        "                    execution_log.append({\"step\": f\"Execution {i+1}\", \"tool_call\": f\"{tool}({params})\", \"result\": result})\n",
        "                    if store_as:\n",
        "                        cap = None\n",
        "                        m_val = re.search(r'Value:\\s*([-\\d.,]+)\\s*(%|e9|e6|bn|billion|b|mn|million|m)?', result, re.I)\n",
        "                        if m_val:\n",
        "                            raw = m_val.group(1).replace(',', '')\n",
        "                            unit = (m_val.group(2) or '').lower()\n",
        "                            if unit == '%': cap = f\"({raw}/100)\"\n",
        "                            elif unit in ('bn', 'billion', 'b', 'e9'): cap = f\"{raw}e9\"\n",
        "                            elif unit in ('mn', 'million', 'm', 'e6'): cap = f\"{raw}e6\"\n",
        "                            else: cap = raw\n",
        "                        else:\n",
        "                            m_any = re.search(r'([-\\d]+(?:\\.\\d+)?)', result)\n",
        "                            if m_any: cap = m_any.group(1)\n",
        "                        if store_as and cap is not None:\n",
        "                            execution_state[store_as] = cap\n",
        "                except Exception as e:\n",
        "                    execution_log.append({\"step\": f\"Execution {i+1}\", \"tool_call\": f\"{tool}({params})\", \"error\": str(e)})\n",
        "            else:\n",
        "                execution_log.append({\"step\": f\"Execution {i+1}\", \"error\": f\"Tool '{tool}' not found.\"})\n",
        "        if VERBOSE: print(\"[Agent] Plan execution complete.\")\n",
        "\n",
        "        # == STEP 3: SYNTHESIS (Live Mode Only) ==\n",
        "        if VERBOSE: print(\"[Agent] Step 3: Synthesizing final answer...\")\n",
        "        synthesis_prompt = f\"\"\"You are Agent CFO. Provide a final answer to the user's query based ONLY on the provided Tool Execution Log.\n",
        "User Query: \"{query}\"\n",
        "Tool Execution Log:\n",
        "{json.dumps(execution_log, indent=2)}\n",
        "Final Answer:\"\"\"\n",
        "        final_answer = _call_llm(synthesis_prompt)\n",
        "        \n",
        "    row[\"Tools\"] = json.dumps([step.get(\"tool_call\") for step in execution_log if \"Execution\" in step.get(\"step\", \"\")])\n",
        "    instr.log(row)\n",
        "    return {\"answer\": final_answer, \"hits\": [], \"execution_log\": execution_log}\n",
        "\n",
        "def get_logs() -> pd.DataFrame:\n",
        "    return instr.df()\n",
        "\n",
        "def is_initialized() -> bool:\n",
        "    return _INITIALIZED\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    init_stage2()\n",
        "    if VERBOSE: print(\"[Stage2] Ready. Use answer_with_llm() or answer_with_agent().\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96667aff",
      "metadata": {},
      "source": [
        "### Check Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d5055c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Tool Call: table_extraction] with query: 'Cost/income ratio for 1Q23 in 2Q24_suppl.xls Highlights'\n",
            "Cost/income ratio for 1Q23 in 2Q24_suppl.xls Highlights → Value: 2.83%, Source: 3Q24_CFO_presentation.pdf, 3Q24, p.2, NIM table\n",
            "  [Tool Call: table_extraction] with query: 'Cost/income ratio for 2Q23 in 2Q24_suppl.xls Highlights'\n",
            "Cost/income ratio for 2Q23 in 2Q24_suppl.xls Highlights → Value: 2.83%, Source: 3Q24_CFO_presentation.pdf, 3Q24, p.2, NIM table\n",
            "  [Tool Call: table_extraction] with query: 'Cost/income ratio for 3Q23 in 2Q24_suppl.xls Highlights'\n",
            "Cost/income ratio for 3Q23 in 2Q24_suppl.xls Highlights → Value: 2.83%, Source: 3Q24_CFO_presentation.pdf, 3Q24, p.2, NIM table\n",
            "  [Tool Call: table_extraction] with query: 'Cost/income ratio for 4Q23 in 2Q24_suppl.xls Highlights'\n",
            "Cost/income ratio for 4Q23 in 2Q24_suppl.xls Highlights → Value: 2.83%, Source: 3Q24_CFO_presentation.pdf, 3Q24, p.2, NIM table\n",
            "  [Tool Call: table_extraction] with query: 'Cost/income ratio for 1Q24 in 2Q24_suppl.xls Highlights'\n",
            "Cost/income ratio for 1Q24 in 2Q24_suppl.xls Highlights → Value: 2.83%, Source: 3Q24_CFO_presentation.pdf, 3Q24, p.2, NIM table\n",
            "  [Tool Call: table_extraction] with query: 'Cost/income ratio for 2Q24 in 2Q24_suppl.xls Highlights'\n",
            "Cost/income ratio for 2Q24 in 2Q24_suppl.xls Highlights → Value: 2.83%, Source: 3Q24_CFO_presentation.pdf, 3Q24, p.2, NIM table\n"
          ]
        }
      ],
      "source": [
        "queries = [\n",
        "    \"Cost/income ratio for 1Q23 in 2Q24_suppl.xls Highlights\",\n",
        "    \"Cost/income ratio for 2Q23 in 2Q24_suppl.xls Highlights\",\n",
        "    \"Cost/income ratio for 3Q23 in 2Q24_suppl.xls Highlights\",\n",
        "    \"Cost/income ratio for 4Q23 in 2Q24_suppl.xls Highlights\",\n",
        "    \"Cost/income ratio for 1Q24 in 2Q24_suppl.xls Highlights\",\n",
        "    \"Cost/income ratio for 2Q24 in 2Q24_suppl.xls Highlights\",\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(q, \"→\", tool_table_extraction(q))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21927938",
      "metadata": {},
      "source": [
        "### Code Audit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9952c7dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage2] Initialized successfully from 'data'.\n",
            "\n",
            "==========================================================================================\n",
            "DRY RUN → Report the Net Interest Margin (NIM) over the last 5 quarters, with values, and add 1–2 lines of explanation.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938397.736184 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "--- Answer ---\n",
            " DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Extract the reported Net Interest Margin (NIM) for the most recent quarter (Q1 2025).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Net interest margin (%) for Q1 2025\",\n",
            "    \"store_as\": \"nim_1q25\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract the reported Net Interest Margin (NIM) for the prior quarter (Q4 2024).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Net interest margin (%) for Q4 2024\",\n",
            "    \"store_as\": \"nim_4q24\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract the reported Net Interest Margin (NIM) for two quarters ago (Q3 2024).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Net interest margin (%) for Q3 2024\",\n",
            "    \"store_as\": \"nim_3q24\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract the reported Net Interest Margin (NIM) for three quarters ago (Q2 2024).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Net interest margin (%) for Q2 2024\",\n",
            "    \"store_as\": \"nim_2q24\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract the reported Net Interest Margin (NIM) for four quarters ago (Q1 2024).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Net interest margin (%) for Q1 2024\",\n",
            "    \"store_as\": \"nim_1q24\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract 1-2 lines of explanation or commentary regarding Net Interest Margin (NIM) from the financial documents (e.g., MD&A, CFO commentary).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"explanation or commentary on Net Interest Margin or NIM trends\",\n",
            "    \"store_as\": \"nim_explanation\"\n",
            "  }\n",
            "]\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 6\n",
            "\n",
            "==========================================================================================\n",
            "DRY RUN → Show Operating Expenses (Opex) for the last 3 fiscal years, year-on-year comparison, and summarize the top 3 Opex drivers from the MD&A.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938405.545836 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "--- Answer ---\n",
            " DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for the most recent fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses (Opex) for FY2024\",\n",
            "    \"store_as\": \"opex_fy2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for the second most recent fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses (Opex) for FY2023\",\n",
            "    \"store_as\": \"opex_fy2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for the third most recent fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses (Opex) for FY2022\",\n",
            "    \"store_as\": \"opex_fy2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the year-on-year comparison for Operating Expenses between FY2024 and FY2023.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"expression\": \"((opex_fy2024 - opex_fy2023) / opex_fy2023) * 100\",\n",
            "    \"store_as\": \"opex_yoy_fy2024_vs_fy2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the year-on-year comparison for Operating Expenses between FY2023 and FY2022.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"expression\": \"((opex_fy2023 - opex_fy2022) / opex_fy2022) * 100\",\n",
            "    \"store_as\": \"opex_yoy_fy2023_vs_fy2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract a summary of the top 3 Operating Expenses drivers from the Management Discussion and Analysis (MD&A) section.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses drivers from MD&A\",\n",
            "    \"store_as\": \"opex_drivers_mdna\"\n",
            "  }\n",
            "]\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 6\n",
            "\n",
            "==========================================================================================\n",
            "DRY RUN → Calculate the Cost-to-Income Ratio (CTI) for the last 3 fiscal years; show your working and give 1–2 lines of implications.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938417.331158 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "--- Answer ---\n",
            " DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Extract the reported Cost-to-Income Ratio (CTI) for fiscal year 2024.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Cost-to-income ratio (%) for FY2024\",\n",
            "    \"store_as\": \"cti_fy2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract the reported Cost-to-Income Ratio (CTI) for fiscal year 2023.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Cost-to-income ratio (%) for FY2023\",\n",
            "    \"store_as\": \"cti_fy2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract the reported Cost-to-Income Ratio (CTI) for fiscal year 2022.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Cost-to-income ratio (%) for FY2022\",\n",
            "    \"store_as\": \"cti_fy2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract 1-2 lines of Management Discussion & Analysis (MD&A) commentary related to the Cost-to-Income Ratio or operating efficiency from the latest fiscal year's report to provide implications.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"MD&A commentary on cost-to-income ratio or operating efficiency for FY2024\",\n",
            "    \"store_as\": \"cti_implications\"\n",
            "  }\n",
            "]\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 4\n",
            "\n",
            "==========================================================================================\n",
            "DRY RUN → Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938426.883230 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "--- Answer ---\n",
            " DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for the latest fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses for FY2024\",\n",
            "    \"store_as\": \"opex_fy2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for the second latest fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses for FY2023\",\n",
            "    \"store_as\": \"opex_fy2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for the third latest fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses for FY2022\",\n",
            "    \"store_as\": \"opex_fy2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the year-on-year change in Operating Expenses from FY2023 to FY2024.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"expression\": \"((opex_fy2024 - opex_fy2023) / opex_fy2023) * 100\",\n",
            "    \"store_as\": \"opex_yoy_fy2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the year-on-year change in Operating Expenses from FY2022 to FY2023.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"expression\": \"((opex_fy2023 - opex_fy2022) / opex_fy2022) * 100\",\n",
            "    \"store_as\": \"opex_yoy_fy2023\"\n",
            "  }\n",
            "]\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 5\n",
            "\n",
            "==========================================================================================\n",
            "DRY RUN → Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938433.373847 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "--- Answer ---\n",
            " DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for fiscal year 2024.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses (Opex) for FY2024\",\n",
            "    \"store_as\": \"opex_fy2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Income for fiscal year 2024.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Income for FY2024\",\n",
            "    \"store_as\": \"operating_income_fy2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the Operating Efficiency Ratio for fiscal year 2024.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"expression\": \"opex_fy2024 / operating_income_fy2024\",\n",
            "    \"store_as\": \"oer_fy2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for fiscal year 2023.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses (Opex) for FY2023\",\n",
            "    \"store_as\": \"opex_fy2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Income for fiscal year 2023.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Income for FY2023\",\n",
            "    \"store_as\": \"operating_income_fy2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the Operating Efficiency Ratio for fiscal year 2023.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"expression\": \"opex_fy2023 / operating_income_fy2023\",\n",
            "    \"store_as\": \"oer_fy2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Expenses for fiscal year 2022.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Expenses (Opex) for FY2022\",\n",
            "    \"store_as\": \"opex_fy2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Extract Operating Income for fiscal year 2022.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"query\": \"Operating Income for FY2022\",\n",
            "    \"store_as\": \"operating_income_fy2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the Operating Efficiency Ratio for fiscal year 2022.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"expression\": \"opex_fy2022 / operating_income_fy2022\",\n",
            "    \"store_as\": \"oer_fy2022\"\n",
            "  }\n",
            "]\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 9\n",
            "\n",
            "==========================================================================================\n",
            "LIVE → Report the Net Interest Margin (NIM) over the last 5 quarters, with values, and add 1–2 lines of explanation.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938440.268685 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'Net interest margin (%) for 2Q25'\n",
            "  [Tool Call: table_extraction] with query: 'Net interest margin (%) for 1Q25'\n",
            "  [Tool Call: table_extraction] with query: 'Net interest margin (%) for 4Q24'\n",
            "  [Tool Call: table_extraction] with query: 'Net interest margin (%) for 3Q24'\n",
            "  [Tool Call: table_extraction] with query: 'Net interest margin (%) for 2Q24'\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938451.531751 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Answer ---\n",
            " Based on the provided Tool Execution Log:\n",
            "\n",
            "Net Interest Margin (NIM) for the available quarters:\n",
            "*   2Q25: 2.61%\n",
            "*   3Q24: 2.83%\n",
            "*   2Q24: 2.83%\n",
            "\n",
            "Data for 1Q25 and 4Q24 could not be retrieved. Additionally, no explanation regarding Net Interest Margin was found in the tool execution.\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 6\n",
            "• PlanRepair → (no result)\n",
            "• table_extraction({'query': 'Net interest margin (%) for 2Q25'}) → Value: 2.61%, Source: 2Q25_performance_summary.pdf, 2Q25, p.10, NIM table\n",
            "• table_extraction({'query': 'Net interest margin (%) for 1Q25'}) → Error: No plausible value found in documents.\n",
            "• table_extraction({'query': 'Net interest margin (%) for 4Q24'}) → Error: No plausible value found in documents.\n",
            "• table_extraction({'query': 'Net interest margin (%) for 3Q24'}) → Value: 2.83%, Source: 3Q24_CFO_presentation.pdf, 3Q24, p.8, NIM table\n",
            "• table_extraction({'query': 'Net interest margin (%) for 2Q24'}) → Value: 2.83%, Source: 2Q24_CFO_presentation.pdf, 2Q24, p.6, NIM table\n",
            "\n",
            "==========================================================================================\n",
            "LIVE → Show Operating Expenses (Opex) for the last 3 fiscal years, year-on-year comparison, and summarize the top 3 Opex drivers from the MD&A.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938458.283176 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2024'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2023'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2022'\n",
            "  [Tool Call: multi_document_compare] for topic 'Operating expense drivers FY2024' in files: ['dbs-annual-report-2024.pdf', '4Q24_CFO_presentation.pdf', '4Q24_performance_summary.pdf']\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938469.661796 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Answer ---\n",
            " Here's a summary of the Operating Expenses (Opex) and year-on-year comparison for the last three fiscal years, based on the provided data:\n",
            "\n",
            "**Operating Expenses (Opex):**\n",
            "*   **FY2024:** $283 million\n",
            "*   **FY2023:** $283 million\n",
            "*   **FY2022:** $202 million\n",
            "\n",
            "**Year-on-Year Comparison:**\n",
            "*   **FY2024 vs FY2023:** 0.0% change\n",
            "*   **FY2023 vs FY2022:** 40.10% increase\n",
            "\n",
            "**Top 3 Opex Drivers from MD&A:**\n",
            "The provided tool execution log did not return specific drivers for Operating Expenses from the Management's Discussion & Analysis (MD&A). The result from the document comparison tool pertained to the Expected Credit Loss (ECL) framework and related audit assessments, rather than general operating expense drivers.\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 6\n",
            "• PlanRepair → (no result)\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2024'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2023'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2022'}) → Value: 202e6, Source: dbs-annual-report-2022.pdf, 2022, p.64\n",
            "• calculator({'expression': '(( 283e6 - 283e6 ) / 283e6) * 100'}) → Result: 0.0\n",
            "• calculator({'expression': '(( 283e6 - 202e6 ) / 202e6) * 100'}) → Result: 40.099009900990104\n",
            "• multi_document_compare({'topic': 'Operating expense drivers FY2024', 'files': ['dbs-annual-report-2024.pdf', '4Q24_CFO_presentation.pdf', '4Q24_performance_summary.pdf']}) → [multi-doc compare output]\n",
            "\n",
            "==========================================================================================\n",
            "LIVE → Calculate the Cost-to-Income Ratio (CTI) for the last 3 fiscal years; show your working and give 1–2 lines of implications.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938483.182765 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'Cost / income (%) for fiscal year 2024'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2024'\n",
            "  [Tool Call: table_extraction] with query: 'Total income (or Operating income) for fiscal year 2024'\n",
            "  [Tool Call: table_extraction] with query: 'Cost / income (%) for fiscal year 2023'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2023'\n",
            "  [Tool Call: table_extraction] with query: 'Total income (or Operating income) for fiscal year 2023'\n",
            "  [Tool Call: table_extraction] with query: 'Cost / income (%) for fiscal year 2022'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2022'\n",
            "  [Tool Call: table_extraction] with query: 'Total income (or Operating income) for fiscal year 2022'\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938491.603795 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Answer ---\n",
            " Based on the provided Tool Execution Log:\n",
            "\n",
            "**Cost-to-Income Ratio (CTI) Calculation:**\n",
            "\n",
            "*   **Fiscal Year 2024:**\n",
            "    *   Reported CTI: Not found.\n",
            "    *   Operating Expenses: 283e6\n",
            "    *   Total/Operating Income: Not found.\n",
            "    *   **Working:** CTI could not be calculated for FY2024 as Total/Operating Income data was not available.\n",
            "*   **Fiscal Year 2023:**\n",
            "    *   Reported CTI: Not found.\n",
            "    *   Operating Expenses: 283e6\n",
            "    *   Total/Operating Income: Not found.\n",
            "    *   **Working:** CTI could not be calculated for FY2023 as Total/Operating Income data was not available.\n",
            "*   **Fiscal Year 2022:**\n",
            "    *   Reported CTI: 8.06e9 (Source: dbs-annual-report-2023.pdf, 2023, p.15)\n",
            "    *   Operating Expenses: 202e6\n",
            "    *   Total/Operating Income: Not found.\n",
            "    *   **Working:** Although a reported CTI value was found, the corresponding Total/Operating Income data was not available, preventing independent calculation of the ratio using Operating Expenses. The reported value (8.06e9) is notably high.\n",
            "\n",
            "**Implications:**\n",
            "Due to the absence of CTI values for FY2024 and FY2023, and the highly unusual magnitude of the reported CTI for FY2022, it is not possible to provide meaningful implications regarding Cost-to-Income trends or operating efficiency based solely on the data extracted.\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 4\n",
            "• PlanRepair → (no result)\n",
            "• table_extraction({'query': 'Cost / income (%) for fiscal year 2024'}) → Error: No plausible value found in documents.\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2024'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Total income (or Operating income) for fiscal year 2024'}) → Error: No plausible value found in documents.\n",
            "• calculator({'expression': '283e6 / ${income_fy2024}'}) → Error: name 'e2024' is not defined\n",
            "• table_extraction({'query': 'Cost / income (%) for fiscal year 2023'}) → Error: No plausible value found in documents.\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2023'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Total income (or Operating income) for fiscal year 2023'}) → Error: No plausible value found in documents.\n",
            "• calculator({'expression': '283e6 / ${income_fy2023}'}) → Error: name 'e2023' is not defined\n",
            "• table_extraction({'query': 'Cost / income (%) for fiscal year 2022'}) → Value: 8.06e9, Source: dbs-annual-report-2023.pdf, 2023, p.15\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2022'}) → Value: 202e6, Source: dbs-annual-report-2022.pdf, 2022, p.64\n",
            "• table_extraction({'query': 'Total income (or Operating income) for fiscal year 2022'}) → Error: No plausible value found in documents.\n",
            "• calculator({'expression': '202e6 / ${income_fy2022}'}) → Error: name 'e2022' is not defined\n",
            "\n",
            "==========================================================================================\n",
            "LIVE → Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938510.298915 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2024'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2023'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2022'\n",
            "  [Tool Call: multi_document_compare] for topic 'Operating expense drivers FY2024' in files: ['dbs-annual-report-2024.pdf', '4Q24_CFO_presentation.pdf', '4Q24_performance_summary.pdf']\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938522.298562 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Answer ---\n",
            " Here are the Operating Expenses for the last 3 fiscal years and their year-on-year comparison:\n",
            "\n",
            "*   **Operating Expenses FY2024:** 283,000,000\n",
            "    *   Year-on-year change (FY2024 vs FY2023): 0.0%\n",
            "*   **Operating Expenses FY2023:** 283,000,000\n",
            "    *   Year-on-year change (FY2023 vs FY2022): 40.10%\n",
            "*   **Operating Expenses FY2022:** 202,000,000\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 5\n",
            "• PlanRepair → (no result)\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2024'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2023'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2022'}) → Value: 202e6, Source: dbs-annual-report-2022.pdf, 2022, p.64\n",
            "• calculator({'expression': '(( 283e6 - 283e6 ) / 283e6) * 100'}) → Result: 0.0\n",
            "• calculator({'expression': '(( 283e6 - 202e6 ) / 202e6) * 100'}) → Result: 40.099009900990104\n",
            "• multi_document_compare({'topic': 'Operating expense drivers FY2024', 'files': ['dbs-annual-report-2024.pdf', '4Q24_CFO_presentation.pdf', '4Q24_performance_summary.pdf']}) → [multi-doc compare output]\n",
            "\n",
            "==========================================================================================\n",
            "LIVE → Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938530.924727 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2024'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2023'\n",
            "  [Tool Call: table_extraction] with query: 'Operating expenses (total) for fiscal year 2022'\n",
            "  [Tool Call: multi_document_compare] for topic 'Operating expense drivers FY2024' in files: ['dbs-annual-report-2024.pdf', '4Q24_CFO_presentation.pdf', '4Q24_performance_summary.pdf']\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759938539.783901 38355000 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Answer ---\n",
            " I am sorry, but I cannot fulfill your request to calculate the Operating Efficiency Ratio for the last 3 fiscal years.\n",
            "\n",
            "The provided Tool Execution Log indicates that while Operating Expenses were extracted for FY2024, FY2023, and FY2022, the necessary 'Operating Income' figures for these years were not extracted, and therefore the Operating Efficiency Ratio was not calculated. The executed steps focused on extracting Operating Expenses and calculating their year-over-year percentage change, as well as comparing MD&A Opex drivers.\n",
            "\n",
            "--- Tool Execution Log (truncated) ---\n",
            "• Plan steps: 9\n",
            "• PlanRepair → (no result)\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2024'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2023'}) → Value: 283e6, Source: 4Q24_performance_summary.pdf, 4Q24, p.13, Opex table\n",
            "• table_extraction({'query': 'Operating expenses (total) for fiscal year 2022'}) → Value: 202e6, Source: dbs-annual-report-2022.pdf, 2022, p.64\n",
            "• calculator({'expression': '(( 283e6 - 283e6 ) / 283e6) * 100'}) → Result: 0.0\n",
            "• calculator({'expression': '(( 283e6 - 202e6 ) / 202e6) * 100'}) → Result: 40.099009900990104\n",
            "• multi_document_compare({'topic': 'Operating expense drivers FY2024', 'files': ['dbs-annual-report-2024.pdf', '4Q24_CFO_presentation.pdf', '4Q24_performance_summary.pdf']}) → [multi-doc compare output]\n",
            "\n",
            "==========================================================================================\n",
            "EXTRACTED NUMERIC PREVIEW\n",
            "\n",
            "Q1: Report the Net Interest Margin (NIM) over the last 5 quarter…\n",
            "{'values': ['2.61%,', '2.83%,', '2.83%,']}\n",
            "\n",
            "Q2: Show Operating Expenses (Opex) for the last 3 fiscal years, …\n",
            "{'values': ['283e6,', '283e6,', '202e6,']}\n",
            "\n",
            "Q3: Calculate the Cost-to-Income Ratio (CTI) for the last 3 fisc…\n",
            "{'values': ['283e6,', '283e6,', '8.06e9,', '202e6,']}\n",
            "\n",
            "Q4: Show Operating Expenses for the last 3 fiscal years, year-on…\n",
            "{'values': ['283e6,', '283e6,', '202e6,']}\n",
            "\n",
            "Q5: Calculate the Operating Efficiency Ratio (Opex ÷ Operating I…\n",
            "{'values': ['283e6,', '283e6,', '202e6,']}\n"
          ]
        }
      ],
      "source": [
        "# --- Smoke test for Agent CFO (Stage 2 already imported as g2) ---\n",
        "# Consolidated & de-duplicated query set (original + standardized)\n",
        "\n",
        "import os, json, pprint\n",
        "\n",
        "# 0) Init Stage 2 from your built artifacts\n",
        "import g2\n",
        "g2.init_stage2(out_dir=\"data\")\n",
        "\n",
        "# 1) Define focused queries (consolidated)\n",
        "QUERIES = [\n",
        "    # Keep NIM phrasing (triggers Stage2 'nim' logic)\n",
        "    \"Report the Net Interest Margin (NIM) over the last 5 quarters, with values, and add 1–2 lines of explanation.\",\n",
        "\n",
        "    # Opex YoY w/ MD&A (original, richer)\n",
        "    \"Show Operating Expenses (Opex) for the last 3 fiscal years, year-on-year comparison, and summarize the top 3 Opex drivers from the MD&A.\",\n",
        "\n",
        "    # CTI (original)\n",
        "    \"Calculate the Cost-to-Income Ratio (CTI) for the last 3 fiscal years; show your working and give 1–2 lines of implications.\",\n",
        "\n",
        "    # Opex YoY table-only (standardized)\n",
        "    \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
        "\n",
        "    # Operating Efficiency Ratio (new standardized)\n",
        "    \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\",\n",
        "]\n",
        "\n",
        "def _s(x, maxlen=240):\n",
        "    \"\"\"Safe short-string: handles None and trims long outputs.\"\"\"\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    try:\n",
        "        s = str(x)\n",
        "    except Exception:\n",
        "        s = repr(x)\n",
        "    s = s.replace(\"\\n\", \" \")\n",
        "    return s[:maxlen]\n",
        "\n",
        "def run_once(query: str, dry_run: bool):\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print((\"DRY RUN\" if dry_run else \"LIVE\"), \"→\", query)\n",
        "    out = g2.answer_with_agent(query, dry_run=dry_run)\n",
        "\n",
        "    ans = out.get(\"answer\", \"\")\n",
        "    print(\"\\n--- Answer ---\\n\", (ans or \"\").strip())\n",
        "\n",
        "    exec_log = out.get(\"execution_log\") or []\n",
        "    if exec_log:\n",
        "        print(\"\\n--- Tool Execution Log (truncated) ---\")\n",
        "        for step in exec_log:\n",
        "            step_name = step.get(\"step\", \"\")\n",
        "            tool_call = _s(step.get(\"tool_call\"))\n",
        "            result    = _s(step.get(\"result\"))\n",
        "            error     = _s(step.get(\"error\"))\n",
        "\n",
        "            if \"Planning\" in step_name:\n",
        "                plan = step.get(\"plan\") or []\n",
        "                print(\"• Plan steps:\", len(plan))\n",
        "            elif tool_call.startswith(\"calculator(\"):\n",
        "                print(\"•\", tool_call, \"→\", result or error or \"(no output)\")\n",
        "            elif tool_call.startswith(\"table_extraction(\"):\n",
        "                print(\"•\", tool_call, \"→\", result or \"(no result)\")\n",
        "            elif tool_call.startswith(\"multi_document_compare(\"):\n",
        "                print(\"•\", tool_call, \"→ [multi-doc compare output]\")\n",
        "            elif error:\n",
        "                print(\"•\", tool_call or step_name or \"(unknown step)\", \"ERROR:\", error)\n",
        "            else:\n",
        "                # Fallback for any step without a recognized shape\n",
        "                if step_name or tool_call or result:\n",
        "                    print(\"•\", step_name or tool_call or \"(step)\", \"→\", result or \"(no result)\")\n",
        "\n",
        "    return out\n",
        "\n",
        "# 2) DRY RUN (plans only)\n",
        "for q in QUERIES:\n",
        "    run_once(q, dry_run=True)\n",
        "\n",
        "# 3) LIVE RUNS (execute tools)\n",
        "live_results = []\n",
        "for q in QUERIES:\n",
        "    live_results.append(run_once(q, dry_run=False))\n",
        "\n",
        "# 4) Optional: Pull out the numeric values the agent stashed for calculators\n",
        "#    (Helpful to verify that %, commas, bn/mn were sanitized correctly.)\n",
        "def extract_state_vars(execution_log):\n",
        "    vars_seen = {}\n",
        "    for step in (execution_log or []):\n",
        "        res = step.get(\"result\")\n",
        "        if not res:\n",
        "            continue\n",
        "        res_s = str(res)\n",
        "        if \"Value:\" in res_s and \"Source:\" in res_s:\n",
        "            # e.g., \"Value: 37%, Source: ...\"\n",
        "            v = res_s.split(\"Value:\", 1)[1].split(\"Source:\", 1)[0].strip()\n",
        "            vars_seen.setdefault(\"values\", []).append(v)\n",
        "    return vars_seen\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"EXTRACTED NUMERIC PREVIEW\")\n",
        "for i, r in enumerate(live_results, 1):\n",
        "    vars_preview = extract_state_vars(r.get(\"execution_log\"))\n",
        "    print(f\"\\nQ{i}: {QUERIES[i-1][:60]}…\")\n",
        "    pprint.pp(vars_preview)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "620a9094",
      "metadata": {},
      "source": [
        "### Just to check available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "32c5af19",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available Models:\n",
            "\n",
            "- models/gemini-2.5-pro-preview-03-25\n",
            "- models/gemini-2.5-flash-preview-05-20\n",
            "- models/gemini-2.5-flash\n",
            "- models/gemini-2.5-flash-lite-preview-06-17\n",
            "- models/gemini-2.5-pro-preview-05-06\n",
            "- models/gemini-2.5-pro-preview-06-05\n",
            "- models/gemini-2.5-pro\n",
            "- models/gemini-2.0-flash-exp\n",
            "- models/gemini-2.0-flash\n",
            "- models/gemini-2.0-flash-001\n",
            "- models/gemini-2.0-flash-exp-image-generation\n",
            "- models/gemini-2.0-flash-lite-001\n",
            "- models/gemini-2.0-flash-lite\n",
            "- models/gemini-2.0-flash-preview-image-generation\n",
            "- models/gemini-2.0-flash-lite-preview-02-05\n",
            "- models/gemini-2.0-flash-lite-preview\n",
            "- models/gemini-2.0-pro-exp\n",
            "- models/gemini-2.0-pro-exp-02-05\n",
            "- models/gemini-exp-1206\n",
            "- models/gemini-2.0-flash-thinking-exp-01-21\n",
            "- models/gemini-2.0-flash-thinking-exp\n",
            "- models/gemini-2.0-flash-thinking-exp-1219\n",
            "- models/gemini-2.5-flash-preview-tts\n",
            "- models/gemini-2.5-pro-preview-tts\n",
            "- models/learnlm-2.0-flash-experimental\n",
            "- models/gemma-3-1b-it\n",
            "- models/gemma-3-4b-it\n",
            "- models/gemma-3-12b-it\n",
            "- models/gemma-3-27b-it\n",
            "- models/gemma-3n-e4b-it\n",
            "- models/gemma-3n-e2b-it\n",
            "- models/gemini-flash-latest\n",
            "- models/gemini-flash-lite-latest\n",
            "- models/gemini-pro-latest\n",
            "- models/gemini-2.5-flash-lite\n",
            "- models/gemini-2.5-flash-image-preview\n",
            "- models/gemini-2.5-flash-image\n",
            "- models/gemini-2.5-flash-preview-09-2025\n",
            "- models/gemini-2.5-flash-lite-preview-09-2025\n",
            "- models/gemini-robotics-er-1.5-preview\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759844543.896133 36142634 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# Best practice: store your key as an environment variable\n",
        "# Or replace \"YOUR_API_KEY\" with your actual key string for a quick test\n",
        "genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\", \"YOUR_API_KEY\"))\n",
        "\n",
        "print(\"Available Models:\\n\")\n",
        "\n",
        "# List all models and check which ones support the 'generateContent' method\n",
        "for model in genai.list_models():\n",
        "  if 'generateContent' in model.supported_generation_methods:\n",
        "    print(f\"- {model.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e9e3ea",
      "metadata": {
        "id": "01e9e3ea"
      },
      "source": [
        "## 5. Benchmark Runner\n",
        "\n",
        "Run these 3 standardized queries. Produce JSON then prose answers with citations. These are the standardized queries.\n",
        "\n",
        "*   Net Interest Margin (NIM) trend over last 5 quarters, values and 1–2 lines of explanation.\n",
        "    *   Expected: quarterly financial highlights.\n",
        "*   Operating Expenses (Opex) YoY for last 3 years; top 3 drivers from MD&A.\n",
        "    *   Expected: Opex table + MD&A commentary.\n",
        "*   Cost-to-Income Ratio (CTI) for last 3 years; show working + implications.\n",
        "    *   Expected: Operating Income & Opex lines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bddc40",
      "metadata": {
        "id": "e7bddc40"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Stage3.py — Benchmark Runner (Stage 3)\n",
        "\n",
        "Runs the 3 standardized queries, times them, saves JSON, and prints prose answers with citations.\n",
        "\n",
        "Artifacts written to OUT_DIR (default: data/):\n",
        "  - bench_results.json      # structured results\n",
        "  - bench_report.md         # human-readable answers with citations\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "import os, json, time\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Import Stage 2 API\n",
        "from Stage2 import init_stage2, answer_with_llm\n",
        "\n",
        "OUT_DIR = os.environ.get(\"AGENT_CFO_OUT_DIR\", \"data\")\n",
        "\n",
        "# --- Standardized queries (exact spec) ---\n",
        "QUERIES: List[str] = [\n",
        "    # 1) NIM trend over last 5 quarters\n",
        "    \"Report the Net Interest Margin (NIM) over the last 5 quarters, with values, and add 1–2 lines of explanation.\",\n",
        "    # 2) Opex YoY with top 3 drivers\n",
        "    \"Show Operating Expenses (Opex) for the last 3 fiscal years, year-on-year comparison, and summarize the top 3 Opex drivers from the MD&A.\",\n",
        "    # 3) CTI ratio for last 3 years with working & implications\n",
        "    \"Calculate the Cost-to-Income Ratio (CTI) for the last 3 fiscal years; show your working and give 1–2 lines of implications.\",\n",
        "]\n",
        "\n",
        "\n",
        "def _format_hits(hits: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    out = []\n",
        "    for h in hits:\n",
        "        out.append({\n",
        "            \"file\": h.get(\"file\"),\n",
        "            \"year\": h.get(\"year\"),\n",
        "            \"quarter\": h.get(\"quarter\"),\n",
        "            \"page\": h.get(\"page\"),\n",
        "            \"section_hint\": h.get(\"section_hint\"),\n",
        "        })\n",
        "    return out\n",
        "\n",
        "\n",
        "def run_benchmark(top_k_retrieval: int = 12, top_ctx: int = 3, out_dir: str = OUT_DIR, print_prose: bool = False) -> Dict[str, Any]:\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    init_stage2(out_dir)\n",
        "\n",
        "    rows = []\n",
        "    results: List[Dict[str, Any]] = []\n",
        "\n",
        "    for q in QUERIES:\n",
        "        t0 = time.perf_counter()\n",
        "        out = answer_with_llm(q, top_k_retrieval=top_k_retrieval, top_ctx=top_ctx)\n",
        "        lat_ms = round((time.perf_counter() - t0) * 1000.0, 2)\n",
        "\n",
        "        if print_prose:\n",
        "            print(f\"\\n=== Question ===\\n{q}\")\n",
        "            print(\"\\n--- Answer ---\\n\")\n",
        "            print(out[\"answer\"].strip())\n",
        "            if out.get(\"hits\"):\n",
        "                print(\"\\n--- Citations (top ctx) ---\")\n",
        "                for h in _format_hits(out.get(\"hits\", [])):\n",
        "                    y = f\" {h['year']}\" if h.get('year') is not None else \"\"\n",
        "                    qtr = f\" {h['quarter']}Q{str(h['year'])[2:]}\" if h.get('quarter') else \"\"\n",
        "                    sec = f\" — {h['section_hint']}\" if h.get('section_hint') else \"\"\n",
        "                    print(f\"- {h['file']}{y}{qtr} — p.{h['page']}{sec}\")\n",
        "            print(f\"\\n(latency: {lat_ms} ms)\")\n",
        "\n",
        "        results.append({\n",
        "            \"query\": q,\n",
        "            \"answer\": out[\"answer\"],\n",
        "            \"hits\": _format_hits(out.get(\"hits\", [])),\n",
        "            \"latency_ms\": lat_ms,\n",
        "        })\n",
        "        rows.append({\"Query\": q, \"Latency_ms\": lat_ms})\n",
        "\n",
        "    # Save JSON\n",
        "    json_path = os.path.join(out_dir, \"bench_results.json\")\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump({\"results\": results}, f, indent=2)\n",
        "\n",
        "    # Save simple markdown report\n",
        "    md_lines = [\"# Agent CFO — Benchmark Report\\n\"]\n",
        "    for i, r in enumerate(results, start=1):\n",
        "        md_lines.append(f\"\\n## Q{i}. {r['query']}\")\n",
        "        md_lines.append(\"\\n**Answer**\\n\\n\" + r[\"answer\"].strip())\n",
        "        if r.get(\"hits\"):\n",
        "            md_lines.append(\"\\n**Citations (top ctx)**\")\n",
        "            for h in r[\"hits\"]:\n",
        "                y = f\" {h['year']}\" if h.get('year') is not None else \"\"\n",
        "                qtr = f\" {h['quarter']}Q{str(h['year'])[2:]}\" if h.get('quarter') else \"\"\n",
        "                sec = f\" — {h['section_hint']}\" if h.get('section_hint') else \"\"\n",
        "                md_lines.append(f\"- {h['file']}{y}{qtr} — p.{h['page']}{sec}\")\n",
        "    md_path = os.path.join(out_dir, \"bench_report.md\")\n",
        "    with open(md_path, \"w\") as f:\n",
        "        f.write(\"\\n\".join(md_lines) + \"\\n\")\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    if print_prose and not df.empty:\n",
        "        p50 = float(df['Latency_ms'].quantile(0.5))\n",
        "        p95 = float(df['Latency_ms'].quantile(0.95))\n",
        "        print(f\"\\n=== Benchmark Summary ===\\nSaved JSON: {json_path}\\nSaved report: {md_path}\\nLatency p50: {p50:.1f} ms, p95: {p95:.1f} ms\")\n",
        "\n",
        "    # Return a compact summary (and a DataFrame for notebook display if desired)\n",
        "    return {\"json_path\": json_path, \"md_path\": md_path, \"summary\": df}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_benchmark(print_prose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d12439",
      "metadata": {},
      "source": [
        "### Gemini Version 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e435346",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Stage3] This runner expects Stage 2 to be imported by the caller (e.g., in a notebook).\n",
            "[Stage2] Initialized successfully from 'data'.\n",
            "[Stage3] init_stage2() called successfully.\n",
            "--- 🔬 RUNNING AGENT IN DRY RUN MODE ---\n",
            "\n",
            "========================= RUNNING AGENT BENCHMARK =========================\n",
            "--- 🔬 DRY RUN MODE IS ON ---\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1759904426.517095 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "=== Question ===\n",
            "Report the Net Interest Margin (NIM) over the last 5 quarters, with values, and add 1–2 lines of explanation.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Retrieve the Net Interest Margin (NIM) for Q1 2024.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Net Interest Margin for Q1 2024\"\n",
            "    },\n",
            "    \"store_as\": \"nim_q1_2024\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve the Net Interest Margin (NIM) for Q4 2023.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Net Interest Margin for Q4 2023\"\n",
            "    },\n",
            "    \"store_as\": \"nim_q4_2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve the Net Interest Margin (NIM) for Q3 2023.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Net Interest Margin for Q3 2023\"\n",
            "    },\n",
            "    \"store_as\": \"nim_q3_2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve the Net Interest Margin (NIM) for Q2 2023.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Net Interest Margin for Q2 2023\"\n",
            "    },\n",
            "    \"store_as\": \"nim_q2_2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve the Net Interest Margin (NIM) for Q1 2023.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Net Interest Margin for Q1 2023\"\n",
            "    },\n",
            "    \"store_as\": \"nim_q1_2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Compile the Net Interest Margin values and provide a brief explanation.\",\n",
            "    \"answer\": \"Net Interest Margin (NIM) over the last 5 quarters:\\nQ1 2024: ${nim_q1_2024}\\nQ4 2023: ${nim_q4_2023}\\nQ3 2023: ${nim_q3_2023}\\nQ2 2023: ${nim_q2_2023}\\nQ1 2023: ${nim_q1_2023}\\n\\nExplanation: Net Interest Margin (NIM) is a key profitability metric for financial institutions, representing the difference between interest income generated and interest paid, relative to the average earning assets. A higher NIM generally indicates a more profitable core lending business.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "(latency: 8173.25 ms)\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904434.672801 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "=== Question ===\n",
            "Show Operating Expenses (Opex) for the last 3 fiscal years, year-on-year comparison, and summarize the top 3 Opex drivers from the MD&A.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Retrieve Operating Expenses for the most recent fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Operating Expenses for the most recent fiscal year\"\n",
            "    },\n",
            "    \"store_as\": \"opex_fy1\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve Operating Expenses for the second most recent fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Operating Expenses for the second most recent fiscal year\"\n",
            "    },\n",
            "    \"store_as\": \"opex_fy2\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve Operating Expenses for the third most recent fiscal year.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Operating Expenses for the third most recent fiscal year\"\n",
            "    },\n",
            "    \"store_as\": \"opex_fy3\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the year-on-year comparison for Opex between the most recent and second most recent fiscal years.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"parameters\": {\n",
            "      \"expression\": \"(( ${opex_fy1} - ${opex_fy2} ) / ${opex_fy2}) * 100\"\n",
            "    },\n",
            "    \"store_as\": \"yoy_opex_fy1_fy2\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the year-on-year comparison for Opex between the second most recent and third most recent fiscal years.\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"parameters\": {\n",
            "      \"expression\": \"(( ${opex_fy2} - ${opex_fy3} ) / ${opex_fy3}) * 100\"\n",
            "    },\n",
            "    \"store_as\": \"yoy_opex_fy2_fy3\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Summarize the top 3 Operating Expense drivers from the Management Discussion & Analysis (MD&A) section.\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"top 3 Operating Expense drivers from the MD&A\"\n",
            "    },\n",
            "    \"store_as\": \"opex_drivers_summary\"\n",
            "  }\n",
            "]\n",
            "\n",
            "(latency: 5043.5 ms)\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904439.716300 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "\n",
            "=== Question ===\n",
            "Calculate the Cost-to-Income Ratio (CTI) for the last 3 fiscal years; show your working and give 1–2 lines of implications.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "DRY RUN MODE: The agent generated the following plan and stopped before execution.\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"step\": \"Retrieve Operating Expenses for the most recent fiscal year (e.g., FY2023).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Operating Expenses for fiscal year 2023\"\n",
            "    },\n",
            "    \"store_as\": \"opex_2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve Total Operating Income for the most recent fiscal year (e.g., FY2023).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Total Operating Income for fiscal year 2023\"\n",
            "    },\n",
            "    \"store_as\": \"income_2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the Cost-to-Income Ratio (CTI) for the most recent fiscal year (FY2023).\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"parameters\": {\n",
            "      \"expression\": \"${opex_2023} / ${income_2023}\"\n",
            "    },\n",
            "    \"store_as\": \"cti_2023\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve Operating Expenses for the second most recent fiscal year (e.g., FY2022).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Operating Expenses for fiscal year 2022\"\n",
            "    },\n",
            "    \"store_as\": \"opex_2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve Total Operating Income for the second most recent fiscal year (e.g., FY2022).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Total Operating Income for fiscal year 2022\"\n",
            "    },\n",
            "    \"store_as\": \"income_2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the Cost-to-Income Ratio (CTI) for the second most recent fiscal year (FY2022).\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"parameters\": {\n",
            "      \"expression\": \"${opex_2022} / ${income_2022}\"\n",
            "    },\n",
            "    \"store_as\": \"cti_2022\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve Operating Expenses for the third most recent fiscal year (e.g., FY2021).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Operating Expenses for fiscal year 2021\"\n",
            "    },\n",
            "    \"store_as\": \"opex_2021\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Retrieve Total Operating Income for the third most recent fiscal year (e.g., FY2021).\",\n",
            "    \"tool\": \"table_extraction\",\n",
            "    \"parameters\": {\n",
            "      \"query\": \"Total Operating Income for fiscal year 2021\"\n",
            "    },\n",
            "    \"store_as\": \"income_2021\"\n",
            "  },\n",
            "  {\n",
            "    \"step\": \"Calculate the Cost-to-Income Ratio (CTI) for the third most recent fiscal year (FY2021).\",\n",
            "    \"tool\": \"calculator\",\n",
            "    \"parameters\": {\n",
            "      \"expression\": \"${opex_2021} / ${income_2021}\"\n",
            "    },\n",
            "    \"store_as\": \"cti_2021\"\n",
            "  }\n",
            "]\n",
            "\n",
            "(latency: 14548.12 ms)\n",
            "\n",
            "=== AGENT Benchmark Summary ===\n",
            "Saved JSON: data/bench_results_agent.json\n",
            "Saved report: data/bench_report_agent.md\n",
            "Latency p50: 8173.2 ms, p95: 13910.6 ms\n",
            "\n",
            "--- 🚀 RUNNING AGENT IN LIVE API MODE ---\n",
            "\n",
            "========================= RUNNING AGENT BENCHMARK =========================\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904454.274018 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'interest income for the most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest expense for the most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'average earning assets for the most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest income for the second most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest expense for the second most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'average earning assets for the second most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest income for the third most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest expense for the third most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'average earning assets for the third most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest income for the fourth most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest expense for the fourth most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'average earning assets for the fourth most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest income for the fifth most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'interest expense for the fifth most recent quarter'\n",
            "  [Tool Call: table_extraction] with query: 'average earning assets for the fifth most recent quarter'\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904484.827914 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Question ===\n",
            "Report the Net Interest Margin (NIM) over the last 5 quarters, with values, and add 1–2 lines of explanation.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "I am sorry, but I cannot fulfill this request. The tool execution log indicates that there were errors when attempting to calculate the Net Interest Margin (NIM) for the last five quarters, specifically \"Error: Invalid characters.\" This suggests that the necessary financial data could not be processed, and therefore, I cannot report the NIM values or provide an explanation.\n",
            "\n",
            "(latency: 33053.33 ms)\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904487.328093 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'Operating Expenses for the latest fiscal year'\n",
            "  [Tool Call: table_extraction] with query: 'Operating Expenses for the fiscal year prior to the latest'\n",
            "  [Tool Call: table_extraction] with query: 'Operating Expenses for the fiscal year two years prior to the latest'\n",
            "  [Tool Call: table_extraction] with query: 'Top 3 Operating Expense drivers from the MD&A section of the latest annual report'\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904497.389478 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Question ===\n",
            "Show Operating Expenses (Opex) for the last 3 fiscal years, year-on-year comparison, and summarize the top 3 Opex drivers from the MD&A.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "I am sorry, but I cannot fulfill your request with the provided information.\n",
            "\n",
            "Here's why:\n",
            "*   **Operating Expenses for the last 3 fiscal years:** The `table_extraction` tool calls for the latest fiscal year, the prior fiscal year, and two years prior did not return numerical operating expense data. Instead, they returned unrelated text about share purchase mandates and employee share plans.\n",
            "*   **Year-on-year comparison:** Due to the failure in extracting the numerical operating expense data, the `calculator` tool returned \"Error: Invalid characters\" for both year-on-year calculations.\n",
            "*   **Top 3 Opex drivers from the MD&A:** The `table_extraction` tool call for this query returned a table of contents from a 2020 annual report, not the top 3 operating expense drivers from the MD&A section.\n",
            "\n",
            "(latency: 16755.81 ms)\n",
            "[Agent] Step 1: Generating execution plan...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904504.084553 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Agent] Plan generated successfully.\n",
            "[Agent] Step 2: Executing plan...\n",
            "  [Tool Call: table_extraction] with query: 'Operating Expenses for the most recent fiscal year'\n",
            "  [Tool Call: table_extraction] with query: 'Total Income for the most recent fiscal year'\n",
            "  [Tool Call: table_extraction] with query: 'Operating Expenses for the second most recent fiscal year'\n",
            "  [Tool Call: table_extraction] with query: 'Total Income for the second most recent fiscal year'\n",
            "  [Tool Call: table_extraction] with query: 'Operating Expenses for the third most recent fiscal year'\n",
            "  [Tool Call: table_extraction] with query: 'Total Income for the third most recent fiscal year'\n",
            "[Agent] Plan execution complete.\n",
            "[Agent] Step 3: Synthesizing final answer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "E0000 00:00:1759904516.903018 37453816 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Question ===\n",
            "Calculate the Cost-to-Income Ratio (CTI) for the last 3 fiscal years; show your working and give 1–2 lines of implications.\n",
            "\n",
            "--- Answer ---\n",
            "\n",
            "I am unable to calculate the Cost-to-Income Ratio (CTI) for the last three fiscal years or provide implications. The tool execution log indicates that the necessary financial data (Operating Expenses and Total Income) could not be extracted or processed, leading to \"Error: Invalid characters\" during calculation attempts for all fiscal years. Additionally, the final step to present the results and implications failed because the 'tool_code' was not found.\n",
            "\n",
            "(latency: 18087.46 ms)\n",
            "\n",
            "=== AGENT Benchmark Summary ===\n",
            "Saved JSON: data/bench_results_agent.json\n",
            "Saved report: data/bench_report_agent.md\n",
            "Latency p50: 18087.5 ms, p95: 31556.7 ms\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "\"\"\"\n",
        "Stage3.py — Benchmark Runner (Stage 3)\n",
        "\n",
        "Runs the 3 standardized queries for both the baseline and agentic pipelines,\n",
        "times them, saves JSON/Markdown reports, and prints prose answers with citations.\n",
        "\n",
        "Artifacts written to OUT_DIR (default: data/):\n",
        "  - bench_results_baseline.json / bench_results_agent.json\n",
        "  - bench_report_baseline.md / bench_report_agent.md\n",
        "\"\"\"\n",
        "import os, json, time\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "OUT_DIR = os.environ.get(\"AGENT_CFO_OUT_DIR\", \"data\")\n",
        "\n",
        "# --- Standardized queries (exact spec) ---\n",
        "QUERIES: List[str] = [\n",
        "    # 1) NIM trend over last 5 quarters\n",
        "    \"Report the Net Interest Margin (NIM) over the last 5 quarters, with values, and add 1–2 lines of explanation.\",\n",
        "    # 2) Opex YoY with top 3 drivers\n",
        "    \"Show Operating Expenses (Opex) for the last 3 fiscal years, year-on-year comparison, and summarize the top 3 Opex drivers from the MD&A.\",\n",
        "    # 3) CTI ratio for last 3 years with working & implications\n",
        "    \"Calculate the Cost-to-Income Ratio (CTI) for the last 3 fiscal years; show your working and give 1–2 lines of implications.\",\n",
        "    # 4) Opex YoY table only (absolute & % change)\n",
        "    \"Show Operating Expenses for the last 3 fiscal years, year-on-year comparison.\",\n",
        "    # 5) Operating Efficiency Ratio (Opex ÷ Operating Income) with working\n",
        "    \"Calculate the Operating Efficiency Ratio (Opex ÷ Operating Income) for the last 3 fiscal years, showing the working.\"\n",
        "]\n",
        "\n",
        "\n",
        "def _format_hits(hits: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Helper to format citation hits for JSON output.\"\"\"\n",
        "    out = []\n",
        "    if not hits: return out\n",
        "    for h in hits:\n",
        "        out.append({\n",
        "            \"file\": h.get(\"file\"),\n",
        "            \"year\": h.get(\"year\"),\n",
        "            \"quarter\": h.get(\"quarter\"),\n",
        "            \"page\": h.get(\"page\"),\n",
        "            \"section_hint\": h.get(\"section_hint\"),\n",
        "        })\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def run_benchmark(\n",
        "    print_prose: bool = True,\n",
        "    use_agent: bool = False,\n",
        "    out_dir: str = OUT_DIR,\n",
        "    dry_run: bool = False  # <-- NEW TOGGLE\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Runs the benchmark for either the baseline RAG or the agentic pipeline.\n",
        "    \n",
        "    Args:\n",
        "        print_prose: Whether to print results to the console.\n",
        "        use_agent: If True, uses answer_with_agent. If False, uses answer_with_llm.\n",
        "        out_dir: The directory to save report files.\n",
        "        dry_run: If True, prints prompts instead of calling the LLM API.\n",
        "    \"\"\"\n",
        "    # Guard: this module is intentionally NOT importing Stage 2.\n",
        "    # The caller/notebook must `import g2` first so that the following names\n",
        "    # are available in the global namespace.\n",
        "    if use_agent and 'answer_with_agent' not in globals():\n",
        "        raise RuntimeError(\"answer_with_agent is not defined. Import Stage 2 (g2) in the caller before running Stage 3.\")\n",
        "    if not use_agent and 'answer_with_llm' not in globals():\n",
        "        raise RuntimeError(\"answer_with_llm is not defined. Import Stage 2 (g2) in the caller before running Stage 3.\")\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    \n",
        "    if use_agent:\n",
        "        mode_name = \"agent\"\n",
        "        answer_func = answer_with_agent\n",
        "        print(\"\\n\" + \"=\"*25 + f\" RUNNING AGENT BENCHMARK \" + \"=\"*25)\n",
        "    else:\n",
        "        mode_name = \"baseline\"\n",
        "        answer_func = answer_with_llm\n",
        "        print(\"\\n\" + \"=\"*24 + f\" RUNNING BASELINE BENCHMARK \" + \"=\"*24)\n",
        "    \n",
        "    if dry_run:\n",
        "        print(\"--- 🔬 DRY RUN MODE IS ON ---\")\n",
        "\n",
        "    json_path = os.path.join(out_dir, f\"bench_results_{mode_name}.json\")\n",
        "    md_path = os.path.join(out_dir, f\"bench_report_{mode_name}.md\")\n",
        "\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    latency_rows = []\n",
        "\n",
        "    for q in QUERIES:\n",
        "        t0 = time.perf_counter()\n",
        "        # Pass the dry_run toggle to the answer function\n",
        "        out = answer_func(q, dry_run=dry_run)\n",
        "        lat_ms = round((time.perf_counter() - t0) * 1000.0, 2)\n",
        "\n",
        "        if print_prose:\n",
        "            print(f\"\\n=== Question ===\\n{q}\")\n",
        "            print(\"\\n--- Answer ---\\n\")\n",
        "            print(out[\"answer\"].strip())\n",
        "            if out.get(\"hits\"):\n",
        "                print(\"\\n--- Citations (top ctx) ---\")\n",
        "                for h in _format_hits(out.get(\"hits\", [])):\n",
        "                    y = f\" {int(h['year'])}\" if h.get('year') is not None else \"\"\n",
        "                    qtr_val = h.get('quarter')\n",
        "                    qtr = f\" {int(qtr_val)}Q{str(y).strip()[2:]}\" if qtr_val else \"\"\n",
        "                    sec = f\" — {h['section_hint']}\" if h.get('section_hint') else \"\"\n",
        "                    print(f\"- {h['file']}{y}{qtr} — p.{h['page']}{sec}\")\n",
        "            print(f\"\\n(latency: {lat_ms} ms)\")\n",
        "\n",
        "        results.append({ \"query\": q, \"answer\": out[\"answer\"], \"hits\": _format_hits(out.get(\"hits\", [])), \"execution_log\": out.get(\"execution_log\"), \"latency_ms\": lat_ms,})\n",
        "        latency_rows.append({\"Query\": q, \"Latency_ms\": lat_ms})\n",
        "\n",
        "    # Saving logic remains the same...\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump({\"results\": results}, f, indent=2)\n",
        "\n",
        "    md_lines = [f\"# Agent CFO — {mode_name.title()} Benchmark Report\\n\"]\n",
        "    for i, r in enumerate(results, start=1):\n",
        "        md_lines.append(f\"\\n---\\n\\n## Q{i}. {r['query']}\")\n",
        "        md_lines.append(\"\\n**Answer**\\n\\n\" + r[\"answer\"].strip())\n",
        "        if r.get(\"hits\"):\n",
        "            md_lines.append(\"\\n**Citations (top ctx)**\")\n",
        "            for h in r[\"hits\"]:\n",
        "                y = f\" {int(h['year'])}\" if h.get('year') is not None else \"\"\n",
        "                qtr_val = h.get('quarter')\n",
        "                qtr = f\" {int(qtr_val)}Q{str(y).strip()[2:]}\" if qtr_val else \"\"\n",
        "                sec = f\" — {h['section_hint']}\" if h.get('section_hint') else \"\"\n",
        "                md_lines.append(f\"- {h['file']}{y}{qtr} — p.{h['page']}{sec}\")\n",
        "        if r.get(\"execution_log\"):\n",
        "            md_lines.append(\"\\n**Execution Log**\\n\")\n",
        "            md_lines.append(\"```json\")\n",
        "            md_lines.append(json.dumps(r[\"execution_log\"], indent=2))\n",
        "            md_lines.append(\"```\")\n",
        "\n",
        "    with open(md_path, \"w\") as f:\n",
        "        f.write(\"\\n\".join(md_lines) + \"\\n\")\n",
        "\n",
        "    df = pd.DataFrame(latency_rows)\n",
        "    if print_prose and not df.empty:\n",
        "        p50 = float(df['Latency_ms'].quantile(0.5))\n",
        "        p95 = float(df['Latency_ms'].quantile(0.95))\n",
        "        print(f\"\\n=== {mode_name.upper()} Benchmark Summary ===\")\n",
        "        print(f\"Saved JSON: {json_path}\")\n",
        "        print(f\"Saved report: {md_path}\")\n",
        "        print(f\"Latency p50: {p50:.1f} ms, p95: {p95:.1f} ms\")\n",
        "\n",
        "    return {\"json_path\": json_path, \"md_path\": md_path, \"summary\": df}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # This script is intentionally *not* importing Stage 2.\n",
        "    # If someone runs it directly, we warn and exit gracefully.\n",
        "    print(\"[Stage3] This runner expects Stage 2 to be imported by the caller (e.g., in a notebook).\")\n",
        "    if 'init_stage2' in globals():\n",
        "        try:\n",
        "            init_stage2(out_dir=OUT_DIR)\n",
        "            print(\"[Stage3] init_stage2() called successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage3] init_stage2() failed: {e}\")\n",
        "    else:\n",
        "        print(\"[Stage3] Skipping init_stage2 — not present in globals().\")\n",
        "\n",
        "    # Try an agent dry run only if agent entrypoint is present.\n",
        "    if 'answer_with_agent' in globals():\n",
        "        print(\"--- 🔬 RUNNING AGENT IN DRY RUN MODE ---\")\n",
        "        try:\n",
        "            run_benchmark(use_agent=True, dry_run=True)\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage3] Agent dry run failed: {e}\")\n",
        "\n",
        "        print(\"\\n--- 🚀 RUNNING AGENT IN LIVE API MODE ---\")\n",
        "        try:\n",
        "            run_benchmark(use_agent=True, dry_run=False)\n",
        "        except Exception as e:\n",
        "            print(f\"[Stage3] Agent live run failed: {e}\")\n",
        "    else:\n",
        "        print(\"[Stage3] Agent functions not found in globals(); nothing to run.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683ebeda",
      "metadata": {
        "id": "683ebeda"
      },
      "source": [
        "## 6. Instrumentation\n",
        "\n",
        "Log timings: T_ingest, T_retrieve, T_rerank, T_reason, T_generate, T_total. Log tokens, cache hits, tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5425de5",
      "metadata": {
        "id": "d5425de5"
      },
      "outputs": [],
      "source": [
        "# Example instrumentation schema\n",
        "import pandas as pd\n",
        "logs = pd.DataFrame(columns=['Query','T_ingest','T_retrieve','T_rerank','T_reason','T_generate','T_total','Tokens','CacheHits','Tools'])\n",
        "logs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c01bf4",
      "metadata": {
        "id": "e8c01bf4"
      },
      "source": [
        "## 7. Optimizations\n",
        "\n",
        "**Required Optimizations**\n",
        "\n",
        "Each team must implement at least:\n",
        "*   2 retrieval optimizations (e.g., hybrid BM25+vector, smaller embeddings, dynamic k).\n",
        "*   1 caching optimization (query cache or ratio cache).\n",
        "*   1 agentic optimization (plan pruning, parallel sub-queries).\n",
        "*   1 system optimization (async I/O, batch embedding, memory-mapped vectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783f0e2e",
      "metadata": {
        "id": "783f0e2e"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement optimizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91ce833",
      "metadata": {
        "id": "a91ce833"
      },
      "source": [
        "## 8. Results & Plots\n",
        "\n",
        "Show baseline vs optimized. Include latency plots (p50/p95) and accuracy tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96550f3",
      "metadata": {
        "id": "d96550f3"
      },
      "outputs": [],
      "source": [
        "# TODO: Generate plots with matplotlib\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
